<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computation on Boettiger Group</title>
    <link>/categories/computation/</link>
    <description>Recent content in Computation on Boettiger Group</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Apr 2012 15:48:44 +0000</lastBuildDate>
    
	<atom:link href="/categories/computation/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Jordan&#39;s bigdata talk in Math/Stats series</title>
      <link>/2012/04/05/jordans-bigdata-talk-in-mathstats-series/</link>
      <pubDate>Thu, 05 Apr 2012 15:48:44 +0000</pubDate>
      
      <guid>/2012/04/05/jordans-bigdata-talk-in-mathstats-series/</guid>
      <description>Really excellent talk by Professor Michael Jordan from the Berkeley Statistics department visiting us at Davis yesterday. Haven&amp;rsquo;t seen a talk cover technical content with remarkable clarity for the algorithms and insights involved, while also covering such a breadth of material. My notes didn&amp;rsquo;t really keep up, but transcribing some of my scribbling into electronic form will have to wait until I have more time. (Their pubs are probably a better reference anyway.</description>
    </item>
    
    <item>
      <title>Relevant initiatives from today&#39;s Big Data press release</title>
      <link>/2012/03/29/relevant-initiatives-from-todays-big-data-press-release/</link>
      <pubDate>Thu, 29 Mar 2012 22:01:54 +0000</pubDate>
      
      <guid>/2012/03/29/relevant-initiatives-from-todays-big-data-press-release/</guid>
      <description>An exciting day for Big Data (particularly if your Berkeley).
NSF  Encouraging research universities to develop interdisciplinary graduate programs to prepare the next generation of data scientists and engineers; Funding a $10 million Expeditions in Computing project based at the University of California, Berkeley, that will integrate three powerful approaches for turning data into information - machine learning, cloud computing, and crowd sourcing; Providing the first round of grants to support “EarthCube” - a system that will allow geoscientists to access, analyze and share information about our planet; Convening researchers across disciplines to determine how Big Data can transform teaching and learning.</description>
    </item>
    
    <item>
      <title>Tuesday: pandoc citations notes, various</title>
      <link>/2012/03/27/tuesday-pandoc-citations-notes-various/</link>
      <pubDate>Tue, 27 Mar 2012 22:22:14 +0000</pubDate>
      
      <guid>/2012/03/27/tuesday-pandoc-citations-notes-various/</guid>
      <description>Markdown over latex? knitr may have solved the fundamental challenge of all Sweave/latex users with Markdown. Too many of us must be able to work with collaborators who don&amp;rsquo;t know LaTeX and journals that won&amp;rsquo;t accept LaTeX. It&amp;rsquo;s a sad state of the affairs, and has improved slowly for journals (at least many will take pdfs for initial submissions) if not for collaborators. Consequently getting away from LaTeX would be nice, but Word or Google docs just won&amp;rsquo;t cut it.</description>
    </item>
    
    <item>
      <title>Citations in markdown using knitr</title>
      <link>/2012/03/24/citations-in-markdown-using-knitr/</link>
      <pubDate>Sat, 24 Mar 2012 21:33:27 +0000</pubDate>
      
      <guid>/2012/03/24/citations-in-markdown-using-knitr/</guid>
      <description>I am finding myself more and more drawn to markdown rather then tex/Rnw as my standard format (not least of which is the ease of displaying the files on github, particularly now that we have automatic image uploading). One thing I miss from latex is the citation commands. (I understand these can be provided to markdown via Pandoc, but I&amp;rsquo;d like to simply have to knit the document, and not then run it through pandoc, latex, or another interpreter).</description>
    </item>
    
    <item>
      <title>Friday: some random notes</title>
      <link>/2012/03/20/friday-some-random-notes/</link>
      <pubDate>Tue, 20 Mar 2012 16:53:08 +0000</pubDate>
      
      <guid>/2012/03/20/friday-some-random-notes/</guid>
      <description>Computational tricks  tables in github markdown via knitr. clever Getting custom C/C++ CUDA working in R  Data management and sharing solutions for large files  NERSC uses globus online for interface for transferring terabytes/hr, pretty clever. NERSC also enables web hosting to share data.
 Software-Carpentry style Data management a nice start. An open solution could stick the data on figshare (or elsewhere), write the readmes in markdown and keep them on github with links to the data.</description>
    </item>
    
    <item>
      <title>Elegant &amp; fast data manipulation with data.table</title>
      <link>/2012/02/12/elegant-fast-data-manipulation-with-data-table/</link>
      <pubDate>Sun, 12 Feb 2012 13:39:03 +0000</pubDate>
      
      <guid>/2012/02/12/elegant-fast-data-manipulation-with-data-table/</guid>
      <description>Just learned about the R data.table package (ht @recology_) makes R data frames into ultra-fast, SQL-like objects.
One thing we get is some very nice and powerful syntax. Consider some simple data of replicate time series:
time &amp;lt;- rep(1:10, 10) replicate &amp;lt;- sort(time) value &amp;lt;- rnorm(100) df &amp;lt;- data.frame(replicate, time, value)  To apply a function to each set of replicates, instead of
sapply(1:max(df$replicate), function(i) mean( df[df$replicate == i,]$value) )  We can use</description>
    </item>
    
    <item>
      <title>Monday - Sweave workflow</title>
      <link>/2012/01/09/monday-13/</link>
      <pubDate>Mon, 09 Jan 2012 22:09:03 +0000</pubDate>
      
      <guid>/2012/01/09/monday-13/</guid>
      <description>Bibtex, Mendeley &amp;amp; Sweave Mendeley&amp;rsquo;s repeated entries in the bibfile is particularly annoying with my sweave workflow, as it throws an error from bibtex command that Make doesn&amp;rsquo;t want to ignore.
Also, in writing the documentation I&amp;rsquo;d like to point the .Rnw file to my global library&amp;rsquo;s bibtex document, but then this means having the .Rnw/tex file generated to by the package pointing to a file that&amp;rsquo;s outside the package.</description>
    </item>
    
    <item>
      <title>Better dynamic documents (Sweave) with syntax highlighting, caching, etc</title>
      <link>/2011/12/12/better-sweave-dynamic-documents-with-syntax-highlighting-easier-tools/</link>
      <pubDate>Mon, 12 Dec 2011 17:26:47 +0000</pubDate>
      
      <guid>/2011/12/12/better-sweave-dynamic-documents-with-syntax-highlighting-easier-tools/</guid>
      <description>The highlight package is a simple solution for very nice syntax highlighted code boxes in latex documents. Requires switching the driver, which is best done from within R and requires creating a makefile though. Needs the &amp;ldquo;highlight&amp;rdquo; package installed. Here&amp;rsquo;s a simple makefile.
A wealth/mess of Sweave related packages on the CRAN taskview for Reproducible Research (now what other software platform has a the equivalent of a Reproducible Research task view?</description>
    </item>
    
    <item>
      <title>Friday: wrightscape, ggplot, wp memory</title>
      <link>/2011/11/25/friday-wrightscape-ggplot-wp-memory/</link>
      <pubDate>Fri, 25 Nov 2011 20:32:59 +0000</pubDate>
      
      <guid>/2011/11/25/friday-wrightscape-ggplot-wp-memory/</guid>
      <description>more sub-model comparisons wrightscape sub-models:
 a1 independent alphas, global theta, sigmas
 bm &amp;ldquo;brownie&amp;rdquo; (alpha = 0, indep sigmas)
 a2 independent alpha, theta, global sigma
 s1 indep sigma, global alpha, theta
 s2 indep sigma, theta, global alpha
  Basic Nelder Mead Simulated annealing associated parameter estimates
This approach is really not finding a very robust solution.
Plotting with stats_summary() Using stats_summary instead of melt and cast computations and line and ribbon geometries for adding statistical layers to plots.</description>
    </item>
    
    <item>
      <title>some configuration notes: RStudio setup, syntax highlighting in sweave</title>
      <link>/2011/11/22/some-configuration-notes-rstudio-setup-syntax-highlighting-in-sweave/</link>
      <pubDate>Tue, 22 Nov 2011 18:51:19 +0000</pubDate>
      
      <guid>/2011/11/22/some-configuration-notes-rstudio-setup-syntax-highlighting-in-sweave/</guid>
      <description>Installing R-Studio on my dreamhost VPS server. Dreamhost runs debian lenny, which is a bit dated, making it necessary to install from source. (Would be easy on a modern ubuntu server). Here we go.
First, we probably want to install R from source to begin with (Lenny comes with cutting-edge R 2.7.1&amp;hellip;). This needs to be done with shared libs enabled. Also I needed to run it without recommended-packages to get the initial install working</description>
    </item>
    
    <item>
      <title>Parallel hpc on clusters in R, MPI</title>
      <link>/2011/11/10/parallel-hpc-on-clusters-in-r-mpi/</link>
      <pubDate>Thu, 10 Nov 2011 16:49:17 +0000</pubDate>
      
      <guid>/2011/11/10/parallel-hpc-on-clusters-in-r-mpi/</guid>
      <description>Some notes for reference on parallel computing strategies on R with dedicated high performance clusters.
parallelization in R For cluster computing in R, I&amp;rsquo;ve found the &amp;ldquo;snow&amp;rdquo; package with MPI to be the most flexible and robust solution. snowfall is a useful package to use multiple cores on a single processor, but requesting all 16 threads on a node is a much more difficult demand for the queue to fill than 16 threads on all nodes.</description>
    </item>
    
    <item>
      <title>Sunday</title>
      <link>/2011/11/06/sunday-5/</link>
      <pubDate>Sun, 06 Nov 2011 14:38:18 +0000</pubDate>
      
      <guid>/2011/11/06/sunday-5/</guid>
      <description>Computing notes A few configuration related things from migrating to the new laptop.
Clipboard and Vim vim clipboard - install vim-gnome &amp;ldquo;+y and &amp;ldquo;+p interact between vim and global clipboard, and y, shift+insert work within terminal.
make a repository bare so it can be pushed to (as opposed to moving to it&amp;rsquo;s working directory and running a pull). From stackoverflow:
mv repo/.git repo.git; rm -rf repo cd repo.git git config --bool core.</description>
    </item>
    
    <item>
      <title>Sparkleshare configuration</title>
      <link>/2011/11/04/sparkleshare-configuration/</link>
      <pubDate>Fri, 04 Nov 2011 22:35:11 +0000</pubDate>
      
      <guid>/2011/11/04/sparkleshare-configuration/</guid>
      <description>Configured sparkleshare across my linux server &amp;amp; laptops, and android phone. Provides a dropbox-style syncing and version history for all files using git. I can sync as much space as I have hardisk capacity, with as many users and machines as I like, at no cost. Wonderful.
Basic setup Get sparkleshare working on a server is dead simple, Can also use a github server, gitorious server, etc. Setup is clearly documented, which is really just doing a bunch of standard stuff if you have a server or github already set up.</description>
    </item>
    
    <item>
      <title>server file management from bowser: ajaxplorer, mollify</title>
      <link>/2011/11/01/server-file-management-from-bowser-ajaxplorer-mollify/</link>
      <pubDate>Tue, 01 Nov 2011 20:18:38 +0000</pubDate>
      
      <guid>/2011/11/01/server-file-management-from-bowser-ajaxplorer-mollify/</guid>
      <description>A few notes on trying out some server-based file sharing solutions.
ajaXplorer Kind of amazingly good and easy to install, with configuration-free functionality like previews of images and playing mp3s. More secure file sharing (at least, public link not generated until asked for, can have password assigned to it). Sharing is the only step not activated by default. Create a folder called &amp;ldquo;public&amp;rdquo; in the ajaxplorer directory, and this feature will appear.</description>
    </item>
    
    <item>
      <title>Optimal Control Exploration</title>
      <link>/2011/10/19/optimal-control-exploration/</link>
      <pubDate>Wed, 19 Oct 2011 23:01:10 +0000</pubDate>
      
      <guid>/2011/10/19/optimal-control-exploration/</guid>
      <description>Translating Jim&amp;rsquo;s Matlab code.
Adapted for Octave.
R version.
Document review:
 Chapter 04_Sanchirico_Final.pdf
 SanchiricoOptimalSpace_JEEM.pdf (Sanchirico &amp;amp; Wilen, 2005)
 Optimal_Rebuilding_AJAE2010.pdf, Optimal_Rebuilding_Supp_Material.pdf (Sanchirico et. al. 2010)
 Sanchirico_editsembedded.pdf: Book Chapter 1: Economically Optimal Management of a Metapopulation
  Reviewing Bett&amp;rsquo;s Practical Methods for Optimal Control using Nonlinear Programming. (( Practical Methods for Optimal Control and Estimation Using Nonlinear Programming, Second Edition (Advances in Design and Control) John T.</description>
    </item>
    
    <item>
      <title>Algorithms Group: Literate programming</title>
      <link>/2011/10/17/algorithms-group-literate-programming/</link>
      <pubDate>Mon, 17 Oct 2011 18:41:42 +0000</pubDate>
      
      <guid>/2011/10/17/algorithms-group-literate-programming/</guid>
      <description>Algorithms group today took a brake from discussing algorithms for an aside on coding practices. Today we focused primarily on literate programming tools for making better documented, more readable code. We covered:
 Sweave
 Google style guide, also see R core-team developer Hadley Wickam&amp;rsquo;sstyle guide (modified from Google)
 R coding practices grab-bag: using functionalized code, {&amp;hellip;}, S3 vs S4 classes.
 roxygen, roxygen2
  Next time: Github, then we&amp;rsquo;ll spend 30 minutes collaboratively adding roxygen documentation to our existing codes and committing changes over git.</description>
    </item>
    
    <item>
      <title>rfishbase Tutorial - updated &amp; extended</title>
      <link>/2011/10/12/rfishbase-tutorial-updated-extended/</link>
      <pubDate>Wed, 12 Oct 2011 11:59:49 +0000</pubDate>
      
      <guid>/2011/10/12/rfishbase-tutorial-updated-extended/</guid>
      <description>Updated rfishbase package. Include querying for a list of scientific names and the addition of more quantitative traits, though the selection is still somewhat limited. Demo includes how to grab some data to match a phylogenetic tree, and some regular expression (grep) searches for feeding behavior.
Source code
Windows binary also available.
# demo.R rm(list=ls()) require(rfishbase) ###### Grabbing, Loading &amp;amp; Caching Fishbase Data ###### ## Download and parse data for first 40 ids (36 fish) #fish.</description>
    </item>
    
    <item>
      <title>Algorithms Group, HMM meets EM</title>
      <link>/2011/10/10/algorithms-group-hmm-meets-em/</link>
      <pubDate>Mon, 10 Oct 2011 18:42:03 +0000</pubDate>
      
      <guid>/2011/10/10/algorithms-group-hmm-meets-em/</guid>
      <description>Alisa reviews HMM, EM, and shows us how to combine them.
The EM version treats the transition probabilities (exchanging coins) and emission probabilities (chance of heads/tails under each coin) as unknowns. Make a guess, calculate the blue line from before. This can be used to calculate a new guess that will hill climb to the locally optimum solution (EM).
New guess for the transition probability is:
$$ A_{lk} = \frac{f_i bi a{lk} ek(x{i+1}) }{P(x)} $$</description>
    </item>
    
    <item>
      <title>Friday, wordpress backups, pmc edits</title>
      <link>/2011/09/30/friday-wordpress-backups-pmc-edits/</link>
      <pubDate>Fri, 30 Sep 2011 17:51:31 +0000</pubDate>
      
      <guid>/2011/09/30/friday-wordpress-backups-pmc-edits/</guid>
      <description>Wordpress local copy  configured mysqldump backup, following dreamhost wiki (added cron job manually instead of in panel).  edit local wp-config.php to use localhost. Get the database name, user name and password from the lines above it, which are used later.
define(&#39;DB_HOST&#39;, &#39;localhost&#39;); // ...and the server MySQL is running on  create user: log in as root
mysql -u root -p  and create user
mysql&amp;gt; create database database_name mysql&amp;gt; create user &#39;username&#39;@&#39;localhost&#39; identified by &#39;password&#39;; mysql&amp;gt; create database database_name mysql&amp;gt; grant usage on *.</description>
    </item>
    
    <item>
      <title>memory management, cron</title>
      <link>/2011/09/07/memory-management-cron/</link>
      <pubDate>Wed, 07 Sep 2011 21:28:03 +0000</pubDate>
      
      <guid>/2011/09/07/memory-management-cron/</guid>
      <description>Create the memcheck.sh script that will write a mem.log file with the data, and agnuplot script that will plot it.
[gist id=1201994]
Then set up a cron job. First, set the editor to something functional:
export EDITOR=vi  then, crontab -e to edit the cron table. Add this line to run the command every 2 minutes (see wikipedia entry for quick intro), and plot it every 15 minutes:
*/2 * * * * /home/cboettig/.</description>
    </item>
    
    <item>
      <title>Algorithms group: Hidden Markov Models</title>
      <link>/2011/08/29/algorithms-group-hidden-markov-models/</link>
      <pubDate>Mon, 29 Aug 2011 21:43:42 +0000</pubDate>
      
      <guid>/2011/08/29/algorithms-group-hidden-markov-models/</guid>
      <description>Great group discussion on Hidden Markov Models tag-teamed by Yaniv and Alisa. Walked through the coin flip example, creating the forward algorithm, and the posterior decoding. In this case it is assumed model and parameters are known: two coins, known ratios, known rate of swapping; goal is to guess which coin is being used in a given interval. Algorithm does quite well, as shown in Yaniv&amp;rsquo;s awesome graph.
As usual in the notebook, click on the graph to get link-through to the code.</description>
    </item>
    
    <item>
      <title>Monday: scaling wrightscape examples</title>
      <link>/2011/08/29/monday-scaling-wrightscape-examples/</link>
      <pubDate>Mon, 29 Aug 2011 18:27:20 +0000</pubDate>
      
      <guid>/2011/08/29/monday-scaling-wrightscape-examples/</guid>
      <description>syntaxHighligher isn&amp;rsquo;t working. no idea why, posted to forums.
 Still no luck compiling gsl on carver. Can&amp;rsquo;t install gsl R package or compile wrightscape C code. posted C issue to NERSC, R issue to statscicomp.
   Commits to taxize pushed to Scott.
wrightscape parrotfish example Convergence test: with simple (common) initial values (alpha=.1, sigma=1), the different methods behave mostly appropriately: outer nested models out-perform inner ones, and likelihoods roughly agree between ouch package methods and wrightscape equivalents:</description>
    </item>
    
    <item>
      <title>Sunday: scaling, runs</title>
      <link>/2011/08/28/sunday-scaling-runs/</link>
      <pubDate>Sun, 28 Aug 2011 22:33:59 +0000</pubDate>
      
      <guid>/2011/08/28/sunday-scaling-runs/</guid>
      <description>laptop: ubuntu upgrades: 10.04 LTS -&amp;gt; 10.10 -&amp;gt; 11.04, geesh.
Set up for running primates.R in likelihood mode with abstracted parallelization:
Carver trouble getting wrightscape installed: even after module load gsl, cannot find gsl library. Testing on zero in mpi mode, 16. Testing on farm, mpi mode with snow, 16 cores.
hmm, high (9%) memory usage on primates.R on zero&amp;hellip; monitoring situation closely&amp;hellip; Only .3% on farm so far, which has 24G instead of zero&amp;rsquo;s 32Gig RAM.</description>
    </item>
    
    <item>
      <title>Saturday: working on computational scaling, ion, etc</title>
      <link>/2011/08/27/saturday-working-on-computational-scaling-ion-etc/</link>
      <pubDate>Sat, 27 Aug 2011 23:44:09 +0000</pubDate>
      
      <guid>/2011/08/27/saturday-working-on-computational-scaling-ion-etc/</guid>
      <description>Can I get a generic montecarlotest function working for both warningsignals and pmc?
Needs to be able to handle S4 classes as well as S3 classes, or need to define the methods update, simulate, loglik and getParameters for any object that would use the method. i.e. these need to be defined in warningsignals for its functions and in wrightscape/pmc for its creatures. then the generic can be used. Implementing now&amp;hellip; Completed.</description>
    </item>
    
    <item>
      <title>rropensci and some taxonomy in R with taxize</title>
      <link>/2011/08/26/rropensci-and-some-taxonomy-in-r-with-taxize/</link>
      <pubDate>Fri, 26 Aug 2011 23:16:22 +0000</pubDate>
      
      <guid>/2011/08/26/rropensci-and-some-taxonomy-in-r-with-taxize/</guid>
      <description>rfishbase Went through demo of rfishbase with Tomomi. Improved error handling, added a few data types and a few use cases.
I always forget that I have to drop nulls by indexing, not my return values of sapply.
x[!sapply(x, is.null)]  Very annoyed with fishbase id numbers (being discontinuous listings and unable to query xml by anything more intelligent). Querying all fishbase ids 1:30000, I get only 999 fish. hmm.</description>
    </item>
    
    <item>
      <title>FishBASE from R: some XML parsing</title>
      <link>/2011/08/26/ropensci-from-r-some-xml-parsing/</link>
      <pubDate>Fri, 26 Aug 2011 10:51:29 +0000</pubDate>
      
      <guid>/2011/08/26/ropensci-from-r-some-xml-parsing/</guid>
      <description>cross-posted from Wainwright Lab blog, archiving in the notebook here. This early tutorial includes some background on XML parsing from R using XPath. See the later rfishbase tutorial for more functionality.
In lab known for its quality data collection, high-speed video style, writing the weekly blog post can be a bit of a challenge for the local code monkey. That&amp;rsquo;s right, no videos today. But lucky for me, even this group can still make good use of publicly available data.</description>
    </item>
    
    <item>
      <title>Tuesday: rropensci, Rmpi, manuscripts, ...</title>
      <link>/2011/08/23/tuesday-rropensci-rmpi-manuscripts/</link>
      <pubDate>Tue, 23 Aug 2011 15:10:24 +0000</pubDate>
      
      <guid>/2011/08/23/tuesday-rropensci-rmpi-manuscripts/</guid>
      <description>rfishbase In answer to Tomomi&amp;rsquo;s question from last week, have basic functionality as an R package on github, rfishbase. Learned some slightly richer XML parsing in the process.
XML Notes Had to identify blocks by a child node that specifies the identity, and then find the sibling node that contains the content I needed. Goes something like this:
&amp;lt;dataObject&amp;gt; &amp;lt;dc:identifier&amp;gt;FB-Size-2&amp;lt;/dc:identifier&amp;gt; &amp;lt;dc:description&amp;gt; Text I need &amp;lt;/dc:description&amp;gt; &amp;lt;/dataObject&amp;gt;  Which I parsed in R as:</description>
    </item>
    
    <item>
      <title>Wednesday: migrating codes into MPI</title>
      <link>/2011/08/17/wednesday-migrating-codes-into-mpi/</link>
      <pubDate>Wed, 17 Aug 2011 22:53:33 +0000</pubDate>
      
      <guid>/2011/08/17/wednesday-migrating-codes-into-mpi/</guid>
      <description>Parellelization/Scaling of code MPI on farm cluster
Got my MPI codes running.
Much better way to get jobs into the queue, asking for 16 threads that don&amp;rsquo;t have to be on the same node is much faster. Can also ask for 161 threads, but will wait longer in the queue.
The trick to getting this to run was mostly getting the library set correctly. Setting the library path at the top of the script did the trick:</description>
    </item>
    
    <item>
      <title>Monday: Algorithms Discussion Group, EM finished</title>
      <link>/2011/07/25/monday-algorithms-discussion-group-em-finished/</link>
      <pubDate>Mon, 25 Jul 2011 17:58:55 +0000</pubDate>
      
      <guid>/2011/07/25/monday-algorithms-discussion-group-em-finished/</guid>
      <description>Finished up the EM algorithm today. Key was getting the right function to maximize. Turns out wikipedia has a very nice write up of this very example, but in our notation:
$$ E_p \log(p f_1) + (1-E_p) \log( (1-p) f_2 )$$
Where $E_p$ comes from the expectation step.
Jamie has joined us and has set up a github repository for the discussion group. Find the successful abstract algorithm there.</description>
    </item>
    
    <item>
      <title>CSGF Conference Notes</title>
      <link>/2011/07/24/csgf-conference-notes/</link>
      <pubDate>Sun, 24 Jul 2011 14:30:43 +0000</pubDate>
      
      <guid>/2011/07/24/csgf-conference-notes/</guid>
      <description>Just returned from 5 days in Washington, DC for the annual computational science graduate fellowship conference. No live notes/tweets, so just attempting to synthesize some of the major ideas before I get back to paper writing. Most of the conference material, including workshop slides, are archived online.
The high performance computing workshop made two things clear to me &amp;ndash; a lot of parallel computing can be done without lots of communication between nodes (i.</description>
    </item>
    
    <item>
      <title>CSGF 2010 Computing Practices Survey Summary</title>
      <link>/2011/07/24/csgf-2010-hpc-practices-survey-summary/</link>
      <pubDate>Sun, 24 Jul 2011 14:11:07 +0000</pubDate>
      
      <guid>/2011/07/24/csgf-2010-hpc-practices-survey-summary/</guid>
      <description>Thanks to everyone who participated in the CSGF 2010 Survey.With too many things going on this year, I didn&amp;rsquo;t conduct a survey at the 2011 Conference. But as people were asking about the survey, I thought I could at least make last year&amp;rsquo;s summary a bit more accessible. The following comes from the pdf report I submitted to Krell and a few example figures from data.This year&amp;rsquo;s survey was longer and broader, recieving over 90 responses from fellows and alumni.</description>
    </item>
    
    <item>
      <title>Segue: Easy cloud hpc in R, now with custom packages</title>
      <link>/2011/07/07/segue-easy-cloud-hpc-in-r-now-with-custom-packages/</link>
      <pubDate>Thu, 07 Jul 2011 16:45:05 +0000</pubDate>
      
      <guid>/2011/07/07/segue-easy-cloud-hpc-in-r-now-with-custom-packages/</guid>
      <description>After a few helpful emails from package creator JD Long, I have the segue package running with custom R packages. The package is available on Google code. With two lines of code I can start submitting jobs to very large clusters of computers on the Amazon cloud. For a basic introduction to the package see Jeff Breen&amp;rsquo;s post.
Quick notes on updating using mercurial: Since I&amp;rsquo;ve already pulled the code using</description>
    </item>
    
    <item>
      <title>EM Algorithm</title>
      <link>/2011/06/13/em-algorithm-2/</link>
      <pubDate>Mon, 13 Jun 2011 22:39:32 +0000</pubDate>
      
      <guid>/2011/06/13/em-algorithm-2/</guid>
      <description>Yaniv ran us through our second session on EM algorithms. We implemented a simple case described in this tutorial.
[gist id=1028113]
Code doesn&amp;rsquo;t reflect the abstraction of the algorithm into a proper Expectation step and Maximization step. We attempted this generalization:
[gist id=1028122]
Missed something in framing this correctly, since the maximization step includes a function that doesn&amp;rsquo;t depend on s[1]. Any ideas?</description>
    </item>
    
    <item>
      <title>Thursday Meetings: Duncan; Alan</title>
      <link>/2011/05/26/thursday-6/</link>
      <pubDate>Thu, 26 May 2011 23:53:05 +0000</pubDate>
      
      <guid>/2011/05/26/thursday-6/</guid>
      <description>Duncan Meeting  ROAuth/RCurl question. Mendeley is OAuth 1, github is OAuth 2 (simpler). Both are implemented in pure R in another package, may be good. OAuth 1 constructs complicated http urls with secret, and token, and random key, need to escape chars, etc. OAuth 2 is https, just uses token. Authentication options: Jeff&amp;rsquo;s ROAuth/Duncan&amp;rsquo;s mod, other OAuth package. RMendeley&amp;ndash; windows binary, competition? socialR &amp;ndash; discussed strategy to get a figure with matching code and data.</description>
    </item>
    
    <item>
      <title>Monday: some code-tricks, Algorithms group planning</title>
      <link>/2011/05/23/monday-5/</link>
      <pubDate>Mon, 23 May 2011 23:00:18 +0000</pubDate>
      
      <guid>/2011/05/23/monday-5/</guid>
      <description>Teary Some discussion on combining Greek letters with variables in R. Previously have solved this with substitute() command,
x = 4.5 plot(1:10, main = substitute(paste(&amp;quot;Kendall &amp;quot;, tau == val), list(val = x[1])))  but Peter has a more elegant solution that can be vectorized:
sapply(interaction(&amp;quot;sigma&amp;quot;,1:5, sep=&amp;quot; == &amp;quot;),function(x)parse(text=x)) #for instance plot(0) legend(&amp;quot;topright&amp;quot;,legend=sapply(interaction(&amp;quot;sigma&amp;quot;,1:5, sep=&amp;quot; == &amp;quot;),function(x)parse(text=x)),lty=2)  Better yet, bquote has a mechanism to evaluate an argument vs express the argument as a symbol, see gist id=1108159.</description>
    </item>
    
    <item>
      <title>Algorithms Discussion Group: MCMC</title>
      <link>/2011/05/04/algorithms-discussion-group-mcmc/</link>
      <pubDate>Wed, 04 May 2011 17:32:42 +0000</pubDate>
      
      <guid>/2011/05/04/algorithms-discussion-group-mcmc/</guid>
      <description>Implemented a basic MCMC routine in our little algorithms discussion group today, works quite nicely once you remember to use differences of log probabilities instead of ratios. Code and results below.
[gist id=956311]</description>
    </item>
    
    <item>
      <title>wrightscape profiling</title>
      <link>/2011/04/24/wrightscape-profiling/</link>
      <pubDate>Sun, 24 Apr 2011 18:50:11 +0000</pubDate>
      
      <guid>/2011/04/24/wrightscape-profiling/</guid>
      <description>Optimization at the R level is substantially slower than at the C level:
system.time(wright_test = wright(data,tree,regimes, alpha=ou2@sqrt.alpha^2, sigma=ou2@sigma)) user system elapsed 82.157 0.068 82.346 system.time(ws2 = wrightscape(trait, labrid$tree, regime=labrid$regimes, (ou2@sqrt.alpha)^2, ou2@sigma, theta=ou2@theta[[1]])) iter: 229, llik = 34.750, size = 0.000, par values = 0.000069 2.456353 0.000026 0.225234 0.973002 0.488713 user system elapsed 4.964 0.000 4.971  This is possibly due to repeating the lca matrix calculation. As it&amp;rsquo;s not done in a separate R function yet, the profiler cannot tell us this.</description>
    </item>
    
    <item>
      <title>Algorithms Discussion Group: algorithms Continued</title>
      <link>/2011/04/18/algorithms-discussion-group-abc-continued/</link>
      <pubDate>Mon, 18 Apr 2011 14:11:24 +0000</pubDate>
      
      <guid>/2011/04/18/algorithms-discussion-group-abc-continued/</guid>
      <description>Our little informal ABC group met again today to continue our discussion of ABC methods from last week. The updated code is included in the gist below. ((Nick asked about gists &amp;ndash; they are code boxes provided by Github that are easy to embed into blogs, etc. They provide automatic syntax highlighting and version management. For instance, I just opened last week&amp;rsquo;s gist and started editing during today&amp;rsquo;s session &amp;ndash; when I save it I get a new version ID, so last week&amp;rsquo;s post still points to last week&amp;rsquo;s code, but it doesn&amp;rsquo;t create a second copy, so you can tell if you have the right version.</description>
    </item>
    
    <item>
      <title>Monday: algorithms Meeting</title>
      <link>/2011/04/11/monday-abc-meeting-2/</link>
      <pubDate>Mon, 11 Apr 2011 16:21:09 +0000</pubDate>
      
      <guid>/2011/04/11/monday-abc-meeting-2/</guid>
      <description>Yaniv has started an algorithms discussion group. We just met with a few students to discuss implementing Approximate Bayesian Computing methods from scratch. Most of us had read (Beaumont, 2010) and (Csilléry et. al. 2010) but also followed [cite source=&amp;ldquo;pubmed&amp;rdquo;]12524368[/cite] most helpful during the session.
[gist id=914487]
This gets us as far as the regression step, Figure 1 of (Csilléry et. al. 2010). This in part distinguishes the approach from simple rejection sampling.</description>
    </item>
    
    <item>
      <title></title>
      <link>/1/01/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/</guid>
      <description>Tweaking Dockerfile for labnotebook to be simpler and more portable.</description>
    </item>
    
  </channel>
</rss>