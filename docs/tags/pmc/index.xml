<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pmc on Boettiger Group</title>
    <link>/tags/pmc/</link>
    <description>Recent content in Pmc on Boettiger Group</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="/tags/pmc/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>/1/01/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/</guid>
      <description>Research  Wrote summary function using bootstrap confidence intervals for the bootstraps of the likelihoods directly. On interpreting the bootstraps of likelihoods directly:   The extent to which the distributions themselves are distinct provides an indication of the ability to distinguish between models on the given phylogenetic tree and the actual data. For instance, if the tree was a star tree and the data produced by either BM or OU1, then all distributions would fall on top of one another.</description>
    </item>
    
    <item>
      <title>Bootstrapping Likelihood ratios</title>
      <link>/1/01/01/bootstrapping-likelihood-ratios/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/bootstrapping-likelihood-ratios/</guid>
      <description>Bootstraps of the likelihood ratio, holding the parameters fixed, finally completed.  Anoles: Summary Anoles table:
&amp;gt; summary(anoles_boots) [,1] [,2] [,3] [,4] [,5] [1,] 0.500000000 0.981399498 0.26514573 0.06668672 0.018154938 [2,] 0.009580545 0.500000000 0.15610274 0.04819938 0.011616566 [3,] 0.039233893 0.075349644 0.50000000 0.05699877 0.005443493 [4,] 0.004211230 0.004592917 0.01389950 0.50000000 0.006648916 [5,] 0.173457542 0.198303402 0.38893099 0.33891430 0.500000000 &amp;gt;  Labrids: &amp;gt; summary(labrid_boots) [,1] [,2] [,3] [,4] [1,] 0.5000000 6.036842e-05 0.0000000 0.0 [2,] 0.5424613 5.</description>
    </item>
    
    <item>
      <title>Exploring Difficulties with Existing Methods</title>
      <link>/1/01/01/exploring-difficulties-with-existing-methods/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/exploring-difficulties-with-existing-methods/</guid>
      <description>Model choice plays an increasingly dominant role in comparative phylogenetics. The software OUCH of Butler and King (2004) is built around the model comparison framework and returns a variety of information criteria for choosing between different models fitted to the tree.
 I&amp;rsquo;ve written a short R script to explore how robust these inferences are, and the results are rather surprising. None of the inferences holds up to the classical P value standard of 95% probability of being right, and the inference can be wrong more often than it is right &amp;ndash; a coin flip out-performs the model choice method based on these information criteria in certain cases.</description>
    </item>
    
    <item>
      <title>Follow-up on Parametric Bootstrapping</title>
      <link>/1/01/01/follow-up-on-parametric-bootstrapping/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/follow-up-on-parametric-bootstrapping/</guid>
      <description>Continuing on yesterday&amp;rsquo;s discussion of parametric boostrapping implementation. Peter sent some very helpful comments and agreed to having them here for reference; I&amp;rsquo;ve added some links.  &amp;ldquo;I&amp;rsquo;ve read up a bit on the bootstrap just now. First off, although parametric and nonparametric bootstrapping has always seemed very different to me, they fit in the same natural framework. The general idea is that in reality, there&amp;rsquo;s some real parameters x and some probability distribution P that&amp;rsquo;s given us some data.</description>
    </item>
    
    <item>
      <title>Implementing an example of low and high power trees</title>
      <link>/1/01/01/implementing-an-example-of-low-and-high-power-trees/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/implementing-an-example-of-low-and-high-power-trees/</guid>
      <description>Code implementation in felsenstein_tree.R
 I consider a star tree and a Felsenstein tree each of N nodes; M = (N+1)/2 tips. I consider an uncorrelated data set of M normal random variables, such as would be generated by either BM or OU models on the star tree. I produce a correlated data set such as would be generated by Brownian motion on the felsenstein tree. I generate 8 model fits &amp;ndash; fitting BM and OU to each tree under each data set.</description>
    </item>
    
    <item>
      <title>Likelihood Ratio Paper</title>
      <link>/1/01/01/likelihood-ratio-paper/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/likelihood-ratio-paper/</guid>
      <description>Higher resolution power plot for Anoles tree Figure (below right) shows power for increasing alpha in the Anoles tree. The vertical line shows the estimated value of alpha for the body-size data &amp;ndash; unlikely that a tree of this size can detect selection that is this weak even if it were present. Consequently, this fit should not be taken as evidence that BM is a better fit than the OU, but rather that the data is insufficient to inform this analysis.</description>
    </item>
    
    <item>
      <title>Likelihood Ratio Paper- Power in Trees</title>
      <link>/1/01/01/likelihood-ratio-paper--power-in-trees/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/likelihood-ratio-paper--power-in-trees/</guid>
      <description>Power in Trees tests (Results from single OU simulation per alpha, run yesterday) 2000 replicates gives a cleaner picture of the critical alpha, though with low alpha values the estimates of p are quite variable. Also more variable on the smaller trees. Even arbitrarily large alpha aren&amp;rsquo;t significant on the 5-taxa primate tree. On the small geospiza tree (13 taxa) from the geiger package we find:
0.5735 0.29 0.</description>
    </item>
    
    <item>
      <title>Meeting with Graham and Peter</title>
      <link>/1/01/01/meeting-with-graham-and-peter/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/meeting-with-graham-and-peter/</guid>
      <description>Discussion of Model Comparisons Primary focus of today&amp;rsquo;s discussion was rooted in Sunday&amp;rsquo;s entry
 On plotting quirks, haven&amp;rsquo;t figured out lattice but here&amp;rsquo;s yet another newer plotting engine for R I need to revisit how OUCH computes likelihood ratios and P values. Since some parameters are bounded to the positive real line (and may be small) the standard chi square isn&amp;rsquo;t correct. I should repeat the AIC-style analysis for likelihood ratios, though this is just a shift of where I put the zero line.</description>
    </item>
    
    <item>
      <title>Parallel R</title>
      <link>/1/01/01/parallel-r/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/parallel-r/</guid>
      <description>Parallelized LR_bootstrap_all() and model_bootstrap_all() bootstrapping functions. Lets the bootstrapping of different models (or LRs between models) to be performed on different machines. Using the snowfall package in R for easy parallel computing. The parallel loop is done through the sfLapply() function. Had to get libraries and functions exported to all loops using sfLibrary() and sfExportAll(). R-sig-hpc mailing list was very helpful at getting this up and running at 4am.</description>
    </item>
    
    <item>
      <title>Parametric bootstrapping</title>
      <link>/1/01/01/parametric-bootstrapping/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/parametric-bootstrapping/</guid>
      <description>There are several ways we can frame the bootstrapping question. What is the probability that we see a given likelihood ratio statistic (that the log likelihoods differ by a certain spread) just by chance? We have two versions of chance &amp;ndash; the chance we see this ratio when model a is correct and the chance we see this ratio when model b is correct. We simulate 2000 data sets under each model, generating a distribution of likelihood ratio scores for each data set.</description>
    </item>
    
    <item>
      <title>Power in trees</title>
      <link>/1/01/01/power-in-trees/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/power-in-trees/</guid>
      <description>Back to Phylogenetics after a week with only population dynamics.  Exploration  data created by brown simulation on the star tree in ouch matches the expected variance, Ïƒ^2^t. This variance is slightly reduced when simulated on the Felsenstein tree, as might be intuitively expected due to the increased correlations. The degree of decrease should be analytically attainable, but isn&amp;rsquo;t obvious to me at the moment. Example using functions in felsenstein_tree.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/1/01/01/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/research/</guid>
      <description>Maximum likelihood assignment based on arbitrary number of partitions now completed. Working on stochastic assignment. Now have functions for:   partitioning data into k groups, inferring an ancestral state painting based on this partition inferring a continuous model with k OU regimes based on this painting   need to add my function for the proper model-comparison bootstrap of likelihood ratio values rather than the likelihoods themselves. See my original entry on this approach.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/1/01/01/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/research/</guid>
      <description>A some point I&amp;rsquo;ll want to think more seriously about incorporating geographic information into comparative analyses. At some level this data is more available than appropriate continuous traits, as illustrated in the example phylogenetics wiki from Prof. Roderic Page that I just came across.  Today&amp;rsquo;s Goals  Repeating last night&amp;rsquo;s bootstraps on the likelihood ratio. Need to clean up and incorporate my bootstrap codes first. Should also explore the bootstrapping of the partitioning functions from yesterday.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/1/01/01/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/research/</guid>
      <description>Bootstrapped against 2000 replicate simulations overnight on both the Anoles dataset and the Labrids dataset. Distributions that overlap zero represent replicates that choose the wrong model. The Anoles data below; the first column corresponds to the likelihood ratios shown in Butler &amp;amp; King (2004), comparing each model against BM.   The Labrid dataset:   Find matching figures for the case of parameters held fixed on more recent entry</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/1/01/01/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/research/</guid>
      <description>Bootstrap the fitted models (rather than allow the parameters to be refit, simply evaluate the likelihood of the model under each simulated dataset) Directly evaluate Neyman-Pearson lemma for each pairwise model comparison. Also analyze the bootstrapped likelihoods directly (and without refitting) for each model.  To Do  Add a summary function for the likelihood_ratio_bootstrap.R library final wrapper function for infer_niches.R partitioning library More error handling and documentation Example of partitioning Anoles then bootstrapping Bootstrapping likelihoods directly  References on thinking about bootstrapping model comparisons  The original Neyman-Pearson paper Testing Statistical Hypotheses Text by Lehmann &amp;amp; Romano Permutation, Parametric and Bootstrap Tests of Hypotheses by Good Thanks to Peter on these; Bibsonomy collection  ouch2ape.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/1/01/01/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/research/</guid>
      <description>New Simulations  Now have code to run partitioned models on the Anoles dataset, compare partitioned models to the paintings chosen by Butler and King. Preliminary figures below. Models with _s are partitioned by my algorithm, others are the the original ones from earlier.   Also have examples with simulated data with a known number of partitions, to check the method. Tested with data produced at two peaks on the Labrid tree, the pattern seems similar to that of the Labrids &amp;ndash; comparisons involving any model with more than 2 peaks produce LR ratios that become very unlikely in either pairwise comparison.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/1/01/01/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/research/</guid>
      <description>Current Situation &amp;amp; Challenges 2000 bootstraps of models fitted to simulated ou2 data
 A single data set is produced by simulation under a specified ou2 model on the Labrid tree (actually one that was fitted to the original Labrid data). Each model (Brownian motion and 1 to 5 separate OU peaks (assigned by my partition function) is fitted to this dataset. Each fitted model is used to generate 2000 replicate datasets For each replicate dataset, the model used to generate it is compared to each other model in likelihood ratio test 2(log(L~1~) âˆ’ log(L~2~)), where L~1~ is the likelihood of the model that generated the data.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/1/01/01/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/research/</guid>
      <description>Graham &amp;amp; Peter Meeting Fig 1
Fig 2
 Decided that bootstrapping against fixed model parameters would be more difficult to interpret, Fig 1. Simulated data results with refitting seem strange (Fig. 2), perhaps related to fitting of the tree. Observed LR for data should at least remain symmetric, so something has gone wrong. Expected pattern should be deducible simply by upper left triangle of graphs, should accept the first model where the data becomes typical.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/1/01/01/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/research/</guid>
      <description>Bootstrapping procedures should have the option to refit the painting. Currently use the fixed painting but refit parameters. wrote the function peaks_update() which update the painting as well as the OU peak parameters.  20 replicates, bootstraps the painting step as well
Computing / Package  LR_bootstrap and model_bootstrap should be the same function call with an optional second model for the LR bootstrapping. Similarly the LR_bootstrap_all and model_bootstrap_all() should be the same function call.</description>
    </item>
    
    <item>
      <title>Solution to the strange behavior in ouch</title>
      <link>/1/01/01/solution-to-the-strange-behavior-in-ouch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/solution-to-the-strange-behavior-in-ouch/</guid>
      <description>Looks like my troubles actually stem from a bug in the code. I summarize the problem here, just as I posted in my query to R sig phylo. Essentially the program erroneously squares alpha at the moment, explaining the pattern I found yesterday. Giving it root alpha preemptively should be a good work around.

data(bimac) tree &amp;lt;- with(bimac,ouchtree(node,ancestor,time/max(time),species)) print(h2 &amp;lt;- hansen(log(bimac[&#39;size&#39;]),tree,bimac[&#39;OU.1&#39;],alpha=1,sigma=1))  The print command says alpha = 0.</description>
    </item>
    
    <item>
      <title>Still puzzling on LR</title>
      <link>/1/01/01/still-puzzling-on-lr/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/still-puzzling-on-lr/</guid>
      <description> The likelihood ratios when parameters are not held fixed, using data originally generated from a two peak model. Has 1000 bootstrap replicates per plot.   The likelihood ratios when parameters are held fixed, after being generated from a two-peak model. (2000 replicates each)   parameters held fixed, three peak model (200 replicates each)  </description>
    </item>
    
    <item>
      <title>Updating manuscript</title>
      <link>/1/01/01/updating-manuscript/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/updating-manuscript/</guid>
      <description>The progress of the past few days has lead to substantial revision proposals in my manuscript draft. Rewriting for discussion with Brian tomorrow. Currently revised outline:
 Intro
 Biological Motivation Comparative Methods and Comparing Models Model choice paradigm: the right direction, but incomplete  Simple Example
 The Star Tree Two hypotheses: stabilizing vs disruptive selection Information Criteria approach is insufficient Likelihood surfaces Likelihood ratio distribution  Anoles Example</description>
    </item>
    
    <item>
      <title>Wainwright Meeting</title>
      <link>/1/01/01/wainwright-meeting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/wainwright-meeting/</guid>
      <description>Discussed goals and appropriate approach. Settled on linear order rather than trying to directly implement the full MCMC over paintings solution directly. Breaks into four steps/manuscripts:
 Phylogenetic signal and model choice in Comparative Methods: Likelihood ratio approach Detecting changing constraints in evolution: varying alpha and sigma across the tree Bayesian approach for all existing continuous trait comparative methods MCMC over possible histories to infer number of niches</description>
    </item>
    
  </channel>
</rss>