<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lab-notebooks on Boettiger Group</title>
    <link>/lab-notebook/</link>
    <description>Recent content in Lab-notebooks on Boettiger Group</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Dec 2014 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/lab-notebook/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>/2014/12/30/notebook-maintenance-and-scaling/</link>
      <pubDate>Tue, 30 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/12/30/notebook-maintenance-and-scaling/</guid>
      <description>Repo files are 21Mb (zipped). Most of this is in assets/files (31 MB, mostly large pdfs including pubs), though _posts is 14 Mb. .git, by comparison, is 237 Mb.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/12/29/steps-to-a-more-portable-workflow/</link>
      <pubDate>Mon, 29 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/12/29/steps-to-a-more-portable-workflow/</guid>
      <description>Tweaking Dockerfile for labnotebook to be simpler and more portable.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/12/11/recomputation-org/</link>
      <pubDate>Thu, 11 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/12/11/recomputation-org/</guid>
      <description>Dear Ian, Lars,
I am a post-doctoral researcher in ecology with a strong interest in reproducible computation. I have just finished reading your paper, &amp;ldquo;Recomputation.org: Experiences of the first year and lessons learned.&amp;rdquo; Despite working in a very different field of research, both the approaches and experience you describe greatly resonate with my own experience.
In particular, you highlight the need to make computation reproducible with minimal overhead for the researcher: that is, taking these steps only after the project is done, with minimal effort, even if the work is &amp;ldquo;kludgy&amp;rdquo; and &amp;ldquo;held together with string.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/12/11/rrhack-notes/</link>
      <pubDate>Thu, 11 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/12/11/rrhack-notes/</guid>
      <description>Misc notes from #rrhack. Much more detail under our Github organization, including the issues tracker &amp;amp; wiki for the meeting and the start of the repositories for the various teaching modules.
Also see rrhack slack forum and twitter hashtag.
Key questions  Audience and motivation. Reproducibility isn&amp;rsquo;t a goal, it&amp;rsquo;s a means to an ends. Accelerating science is the goal. Motivation should be to accelerate &amp;amp; scale your own science.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/12/07/self-destroy-droplet-on-completion/</link>
      <pubDate>Sun, 07 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/12/07/self-destroy-droplet-on-completion/</guid>
      <description>Scott&amp;rsquo;s analogsea package provides a great way to script commands for cloud instances on the digitalocean platform. for instance, we can use analogsea to automatically start an instance of the desired size, submit a computationally intensive task, and then terminate the instance when the task completes successfully. This last step is particularly convenient since it makes it easier to use a very powerful (and thus expensive) instance for a short time, knowing it will terminate and avoid extra charges while idle.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/12/07/workflow/</link>
      <pubDate>Sun, 07 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/12/07/workflow/</guid>
      <description>My workflow has continued to evolve a bit since I last described it in this notebook. As these posts seem particularly popular, I have attempted to update the description to something a bit more current.
Lab Notebook When I began keeping a lab notebook (on OpenWetWare) I didn&amp;rsquo;t have Github or knitr, and though I would link to scripts on google-code, much of my day-to-day notes ended up directly in the notebook.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/12/04/lsn-nimble/</link>
      <pubDate>Thu, 04 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/12/04/lsn-nimble/</guid>
      <description>some sample data
library(sde) ## Loading required package: MASS ## Loading required package: stats4 ## Loading required package: fda ## Loading required package: splines ## Loading required package: Matrix ## ## Attaching package: &amp;#39;fda&amp;#39; ## The following object is masked from &amp;#39;package:graphics&amp;#39;: ## ## matplot ## Loading required package: zoo ## ## Attaching package: &amp;#39;zoo&amp;#39; ## The following objects are masked from &amp;#39;package:base&amp;#39;: ## ## as.Date, as.Date.numeric ## sde 2.0.15 ## Companion package to the book ## &amp;#39;Simulation and Inference for Stochastic Differential Equations With R Examples&amp;#39; ## Iacus, Springer NY, (2008) ## To check the errata corrige of the book, type vignette(&amp;quot;sde.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/12/04/lsn-nimble/</link>
      <pubDate>Thu, 04 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/12/04/lsn-nimble/</guid>
      <description>some sample data
library(sde) library(nimble) set.seed(123) d &amp;lt;- expression(0.5 * (10-x)) s &amp;lt;- expression(1) data &amp;lt;- as.data.frame(sde.sim(X0=6,drift=d, sigma=s, T=20, N=100))  sigma.x not provided, attempting symbolic derivation.  plot(data)  LSN version Test case: Set prior for m $\approx 0$:
lsn &amp;lt;- modelCode({ theta ~ dunif(1e-10, 100.0) sigma_x ~ dunif(1e-10, 100.0) sigma_y ~ dunif(1e-10, 100.0) m ~ dunif(-1e2, 1e2) x[1] ~ dunif(0, 100) y[1] ~ dunif(0, 100) for(i in 1:(N-1)){ mu_x[i] &amp;lt;- x[i] + y[i] * (theta - x[i]) x[i+1] ~ dnorm(mu_x[i], sd = sigma_x) mu_y[i] &amp;lt;- y[i] + m * t[i] y[i+1] ~ dnorm(mu_y[i], sd = sigma_y) } })  Constants in the model definition are the length of the dataset, $N$ and the time points of the sample.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/12/03/nimble-explore/</link>
      <pubDate>Wed, 03 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/12/03/nimble-explore/</guid>
      <description>Working through quick-start example in nimble manual
library(methods) library(knitr) # set dev to png for graphs with &amp;gt; 1e3 points ## caching nimble can create trouble! The manual gives essentially no introduction to what appears to be a classic BUGS example model for stochastically failing pumps.
library(nimble) ## ## Attaching package: &amp;#39;nimble&amp;#39; ## The following object is masked from &amp;#39;package:stats&amp;#39;: ## ## simulate pumpCode &amp;lt;- nimbleCode({ for (i in 1:N){ theta[i] ~ dgamma(alpha,beta) lambda[i] &amp;lt;- theta[i]*t[i] x[i] ~ dpois(lambda[i]) } alpha ~ dexp(1.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/12/03/nimble-explore/</link>
      <pubDate>Wed, 03 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/12/03/nimble-explore/</guid>
      <description>Working through quick-start example in nimble manual
The manual gives essentially no introduction to what appears to be a classic BUGS example model for stochastically failing pumps.
library(nimble) pumpCode &amp;lt;- modelCode({ for (i in 1:N){ theta[i] ~ dgamma(alpha,beta) lambda[i] &amp;lt;- theta[i]*t[i] x[i] ~ dpois(lambda[i]) } alpha ~ dexp(1.0) beta ~ dgamma(0.1,1.0) })  pumpConsts &amp;lt;- list(N = 10, t = c(94.3, 15.7, 62.9, 126, 5.24, 31.4, 1.05, 1.05, 2.1, 10.5)) pumpData &amp;lt;- list(x = c(5, 1, 5, 14, 3, 19, 1, 1, 4, 22))  pumpInits &amp;lt;- list(alpha = 1, beta = 1, theta = rep(0.</description>
    </item>
    
    <item>
      <title>OU model in Nimble</title>
      <link>/2014/12/03/ou-model-in-nimble/</link>
      <pubDate>Wed, 03 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/12/03/ou-model-in-nimble/</guid>
      <description>Sanity test with a simple model, Start with some sample data from an OU process:
library(&amp;quot;sde&amp;quot;) ## Loading required package: MASS ## Loading required package: stats4 ## Loading required package: fda ## Loading required package: splines ## Loading required package: Matrix ## ## Attaching package: &amp;#39;fda&amp;#39; ## The following object is masked from &amp;#39;package:graphics&amp;#39;: ## ## matplot ## Loading required package: zoo ## ## Attaching package: &amp;#39;zoo&amp;#39; ## The following objects are masked from &amp;#39;package:base&amp;#39;: ## ## as.</description>
    </item>
    
    <item>
      <title>OU model in Nimble</title>
      <link>/2014/12/03/ou-model-in-nimble/</link>
      <pubDate>Wed, 03 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/12/03/ou-model-in-nimble/</guid>
      <description>Sanity test with a simple model, Start with some sample data from an OU process:
library(&amp;quot;sde&amp;quot;) library(&amp;quot;nimble&amp;quot;) set.seed(123) d &amp;lt;- expression(0.5 * (10-x)) s &amp;lt;- expression(1) data &amp;lt;- as.data.frame(sde.sim(X0=6,drift=d, sigma=s, T=20, N=100))  sigma.x not provided, attempting symbolic derivation.  plot(data)  Specify this model in Nimble BUGS code
ou &amp;lt;- modelCode({ theta ~ dunif(1e-10, 100.0) r ~ dunif(1e-10, 20.0) sigma ~ dunif(1e-10, 100) x[1] ~ dunif(0, 100) for(t in 1:(N-1)){ mu[t] &amp;lt;- x[t] + r * (theta - x[t]) x[t+1] ~ dnorm(mu[t], sd = sigma) } })  nimble parameters</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/12/01/drone-vs-travis/</link>
      <pubDate>Mon, 01 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/12/01/drone-vs-travis/</guid>
      <description>A good question from Hilmar on why we&amp;rsquo;re using Drone CI in RNeXML development.
Short answer: Easy to use custom docker images for Drone. Note how much shorter our .drone.yml is. We actually still use Travis to test the package, while Drone CI is just testing the manuscript/supplement builds
Longer answer:
I think it&amp;rsquo;s a standing irony of the reproducible research toolkit we have in place here that the required software environment for the knitr/pandoc/latex pipeline is substantially more intensive than what is required merely to run the code examples.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/11/26/coreos-cluster-gotchas/</link>
      <pubDate>Wed, 26 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/11/26/coreos-cluster-gotchas/</guid>
      <description>Overall impression is that CoreOS is a promising way to easily set up a highly available cluster (e.g. when most important thing is that a service stays up when a node goes down) since it can migrate a containerized app to a new machine rather than having to already have the same app running on all machines. Either way a load-balancer needs to handle the addressing, which is do-able but somewhat tricky.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/11/24/coreos-docker-registries-etc/</link>
      <pubDate>Mon, 24 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/11/24/coreos-docker-registries-etc/</guid>
      <description>A secure docker registry Running one&amp;rsquo;s own docker registry is far more elegant than moving tarballs between machines (e.g. when migrating between servers, particularly for images that may contain sensitive data such as security credentials). While it&amp;rsquo;s super convenient to have a containerized version of the Docker registry ready for action, it doesn&amp;rsquo;t do much good without putting it behind an HTTPS server (otherwise we have to restart our entire docker service with the insecure flag to permit communication with an unauthenticated registry &amp;ndash; doesn&amp;rsquo;t sound like a good idea).</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/11/19/coreos-and-other-infrastructure-notes/</link>
      <pubDate>Wed, 19 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/11/19/coreos-and-other-infrastructure-notes/</guid>
      <description>CoreOS? Security model looks excellent. Some things not so clear:
 In a single node setup, what happens with updates? Would containers being run directly come down and not go back up automatically? In general, how effective or troublesome is it to run a single, low-demand app on a single node CoreOS rather than, say, an ubuntu image (e.g. just to benefit from the security updates model)? For instance, would an update cause a running app to exit in this scenario?</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/11/17/wssspe-feedback/</link>
      <pubDate>Mon, 17 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/11/17/wssspe-feedback/</guid>
      <description>WSSSPE working groups: Reproducibility, Reuse, and Sharing (Neil Che Hong) Our group focused on journal policies regarding software papers. Our objectives were:
 A Survey of journals that publish software papers. The Software Sustainability Institute already maintains a list
 A summary of policies each of these journals has in place regarding software papers. (e.g. licensing requirements, repository requirements, required sections in the manuscripts regarding installation or tests, etc).</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/11/14/nimble-explore/</link>
      <pubDate>Fri, 14 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/11/14/nimble-explore/</guid>
      <description>A quick first exploration of NIMBLE and some questions.
library(&amp;quot;nimble&amp;quot;) ## ## Attaching package: &amp;#39;nimble&amp;#39; ## The following object is masked from &amp;#39;package:stats&amp;#39;: ## ## simulate library(&amp;quot;sde&amp;quot;) ## Loading required package: MASS ## Loading required package: stats4 ## Loading required package: fda ## Loading required package: splines ## Loading required package: Matrix ## ## Attaching package: &amp;#39;fda&amp;#39; ## The following object is masked from &amp;#39;package:nimble&amp;#39;: ## ## inprod ## The following object is masked from &amp;#39;package:graphics&amp;#39;: ## ## matplot ## Loading required package: zoo ## ## Attaching package: &amp;#39;zoo&amp;#39; ## The following objects are masked from &amp;#39;package:base&amp;#39;: ## ## as.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/11/14/nimble-explore/</link>
      <pubDate>Fri, 14 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/11/14/nimble-explore/</guid>
      <description>A quick first exploration of NIMBLE and some questions.
library(&amp;quot;nimble&amp;quot;) library(&amp;quot;sde&amp;quot;)  Let&amp;rsquo;s simulate from a simple OU process: $dX = \alpha (\theta - X) dt + \sigma dB_t$
set.seed(123) d &amp;lt;- expression(0.5 * (10-x)) s &amp;lt;- expression(1) data &amp;lt;- as.data.frame(sde.sim(X0=6,drift=d, sigma=s, T=100, N=400))  ## sigma.x not provided, attempting symbolic derivation.  i.e. $\alpha = 0.5$, $\theta = 10$, $\sigma=1$, starting at $X_0 = 6$ and running for 100 time units with a dense sampling of 400 points.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/11/13/discrete-grid-notes/</link>
      <pubDate>Thu, 13 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/11/13/discrete-grid-notes/</guid>
      <description>Smoothing post-policy calc?
fig3 &amp;lt;- ggplot(policies, aes(stock, stock - value, color=method)) + stat_smooth(lwd=1.2, method=&amp;quot;loess&amp;quot;, degree=1, span=0.2, level=0, n=50) + facet_wrap(~method) + xlab(&amp;quot;stock size, x(t)&amp;quot;) + ylab(&amp;quot;escapement, S(t)&amp;quot;) + scale_colour_manual(values=colorkey, guide=FALSE) fig3 library(&amp;quot;dplyr&amp;quot;) s_policies &amp;lt;- select_(ggplot_build(fig3)$data[[1]], &amp;quot;x&amp;quot;, &amp;quot;PANEL&amp;quot;, &amp;quot;y&amp;quot;) s_policies$PANEL &amp;lt;- mapvalues(s_policies$PANEL, from = 1:6, to = levels(policies$method)) names(s_policies) &amp;lt;- names(policies) library(&amp;quot;tidyr&amp;quot;) opt_policy &amp;lt;- s_policies %&amp;gt;% mutate(harvest = stock - value) %&amp;gt;% select(stock, method, value = harvest) %&amp;gt;% spread(method, value) %&amp;gt;% select(-stock) OPT &amp;lt;- as.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/11/13/draft-wssspe-thoughts/</link>
      <pubDate>Thu, 13 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/11/13/draft-wssspe-thoughts/</guid>
      <description>Scratching out notes for lightning talk at WSSSPE&amp;hellip;
(CB from ropensci, Karthik too. )
 Responses to the challenges of academic software can be divided into roughly two categories. Give them better tools! Give them better training!
We do software: over 50 packages for accessing data repositories, integrating and manipulating, annotating and publishing data. We do training: workshops, online tutorials, developing course materials. But most importantly, we aim to build community.</description>
    </item>
    
    <item>
      <title>Dear DockerHub users: please configure your repository links</title>
      <link>/2014/11/07/dear-docker-hub-users/</link>
      <pubDate>Fri, 07 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/11/07/dear-docker-hub-users/</guid>
      <description>The DockerHub is a great resource for discovering and distributing Dockerfiles. Many users sharing public images take advantage of the Docker Hub&amp;rsquo;s Automated Build configuration, which is excellent as this automatically allows the Hub to display the Dockerfile and provides some medium of security above simply downloading and running some untrusted binary black box.
Unfortunately, far fewer users configure Repository Links to trigger builds to update even when the resulting Dockerfile is unchanged.</description>
    </item>
    
    <item>
      <title>linking binaries from other containers</title>
      <link>/2014/11/05/notes/</link>
      <pubDate>Wed, 05 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/11/05/notes/</guid>
      <description>Been thinking about this for a while, but @benmarwick &amp;rsquo;s examples with --volumes-from convinced me to give this a try.
While there&amp;rsquo;s an obvious level of convenience in having something like LaTeX bundled into the hadleyverse container so that users can build nice pdfs, if often feels not very docker-esque to me to just throw the kitchen sink into a container. At the risk of some added complexity, we can provide LaTeX from a dedicated TeX container to a container that doesn&amp;rsquo;t have it built in, like rocker/rstudio.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/11/03/three-interfaces-for-docker/</link>
      <pubDate>Mon, 03 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/11/03/three-interfaces-for-docker/</guid>
      <description>Here I outline three broad, different strategies for incorporating Docker into a user&amp;rsquo;s workflow, particularly from the perspective of an instructor getting a group of students up and running in a containerized environment, but also in the context of more generic collaborations. The options require progressively more setup and result in a progressively more &amp;lsquo;native&amp;rsquo; feel to running Docker. My emphasis is on running Dockerized R applications and RStudio, though much the same thing can be accomplished with iPython notebooks and many other web apps.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/10/29/the-viability-of-dockerized-research/</link>
      <pubDate>Wed, 29 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/10/29/the-viability-of-dockerized-research/</guid>
      <description>In the spirit of Greg&amp;rsquo;s post &amp;amp; the discussion here, I&amp;rsquo;d be interested in hearing more on people&amp;rsquo;s thoughts about the viability of Dockerized software both in the teaching classroom and beyond, as students continue in their research.
To start off, I thought I&amp;rsquo;d share a few of my own impressions, largely to give a target for anyone to push back against. In doing so I will also try to outline what I see as the features and potential workflow would look like, in hopes that it does not require any actual experience with docker to have an opinion on whether or not a particular strategy makes sense pedagogically.</description>
    </item>
    
    <item>
      <title>Goodbye Jekyll?</title>
      <link>/2014/10/28/jekyll-free/</link>
      <pubDate>Tue, 28 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/10/28/jekyll-free/</guid>
      <description>The great strength of Jekyll is in providing a really convenient HTML templating system through the _layouts and _includes directories and Liquid variables (including the auto-populated ones like page.previous.url).
For quickly deploying simple sites though, this is often unnecessary: one or two layout files will suffice, and an _includes directory is not so useful with only a single layout. The ease of maintenance by having a template divided into modular chunks is somewhat trumped by the greater simplicity of copying a single template or set of templates over into a new directory.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/10/21/docker-and-user-permissions-crazyness/</link>
      <pubDate>Tue, 21 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/10/21/docker-and-user-permissions-crazyness/</guid>
      <description>Lots of crazyness getting to the bottom of permissions changes, as discussed in:
 rocker issues tracker Stackoverflow question Docker mailing list  Long story short: docker cares only about UIDs, so we have to explicitly make sure these match. Some very good answers including from Docker core-team members on the discussion list. Overall approach outlined at the end of the rocker issues tracker.
Here&amp;rsquo;s the SO version of the question, for my reference:</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/10/20/notes/</link>
      <pubDate>Mon, 20 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/10/20/notes/</guid>
      <description>Keep thinking about this quote from Jeroen Oom&amp;rsquo;s recent piece on the arxiv:
 The role and shape of data is the main characteristic that distinguishes scientific computing. In most general purpose programming languages, data structures are instances of classes with well-defined fields and methods. [&amp;hellip;] Strictly defined structures make it possible to write code implementing all required operations in advance without knowing the actual content of the data. It also creates a clear separation between developers and users [emphasis added].</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/10/16/gitlab-and-other-configuration-notes/</link>
      <pubDate>Thu, 16 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/10/16/gitlab-and-other-configuration-notes/</guid>
      <description>Updating gitlab setup:
docker pull sameersbn/redis:latest docker pull sameersbn/gitlab:7.3.2-1 docker pull sameersbn/postgresql:latest mkdir -p /opt/gitlab/data mkdir -p /opt/postgresql/data docker run --name=postgresql -d \ -e &#39;DB_NAME=gitlabhq_production&#39; -e &#39;DB_USER=gitlab&#39; -e &#39;DB_PASS=password&#39; \ -v /opt/postgresql/data:/var/lib/postgresql \ sameersbn/postgresql:latest docker run --name=redis -d sameersbn/redis:latest docker run --name=gitlab -d \ --link postgresql:postgresql \ --link redis:redisio \ -p 10080:80 -p 10022:22 \ -v /opt/gitlab/data:/home/git/data \ sameersbn/gitlab:7.3.2-1  More consisely, do this with fig
gitlab: image: sameersbn/gitlab:7.3.2-1 links: - postgres - redis:redisio ports: - &amp;quot;10080:80&amp;quot; - &amp;quot;10022:22&amp;quot; volumes: - /opt/gitlab/data:/home/git/data environment: - SMTP_USER=USER@gmail.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/10/14/rocker-versioning/</link>
      <pubDate>Tue, 14 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/10/14/rocker-versioning/</guid>
      <description>Been looking into building versioned images for previous R releases using Docker, based on somewhat common requests to our recently begun rocker project. Versioning is under early development and the best way to go about this is not yet clear. Getting the correct version of R installed is not always trivial but is relatively straight forward, and I outline two approaches below.
Getting the correct version of packages (or even merely any compatible version of the package) to install is a considerably more difficult problem, which I&amp;rsquo;ll discuss later.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/10/09/lessons-learned-in-writing-dockerfiles/</link>
      <pubDate>Thu, 09 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/10/09/lessons-learned-in-writing-dockerfiles/</guid>
      <description>Writing dockerfiles is pretty straight forward. Nevertheless, a little extra care goes a long way. Docker&amp;rsquo;s own Best Practices are a great starting point, covering everything from formatting to use of certain commands. In Rocker, We&amp;rsquo;ve tried to follow all of these suggestions and have found them very helpful. In particular:
 Minimize the number of layers, but use \ to break commands across multiple lines,
 Always run apt-get update &amp;amp;&amp;amp; apt-get install -y .</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/10/08/response-to-software-discovery-index-report/</link>
      <pubDate>Wed, 08 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/10/08/response-to-software-discovery-index-report/</guid>
      <description>The NIH has recently announced the report of a landmark meeting which presents a vision for a Software Discovery Index (SDI). The report is both timely and focused on the key issues of locating, citing, reusing software:
 Software developers face challenges disseminating their software and measuring its adoption. Software users have difficulty identifying the most appropriate software for their work. Journal publishers lack a consistent way to handle software citations or to ensure reproducibility of published findings.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/10/07/notes/</link>
      <pubDate>Tue, 07 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/10/07/notes/</guid>
      <description>Misc Docker Notes  funny business with Locales, see #19  Misc notes on littler  INSTALL page is outdated. Instead, do:  apt-get update \ &amp;amp;&amp;amp; apt-get build-dep -y littler \ &amp;amp;&amp;amp; apt-get install autoconf git \ &amp;amp;&amp;amp; git clone https://github.com/eddelbuettel/littler.git \ &amp;amp;&amp;amp; /littler/./bootstrap  May want to symlink too:
ln -s /littler/examples/install.r /usr/local/bin/install.r \ &amp;amp;&amp;amp; ln -s /littler/examples/install2.r /usr/local/bin/install2.r \ &amp;amp;&amp;amp; ln -s /littler/examples/installGithub.r /usr/local/bin/installGithub.r \ &amp;amp;&amp;amp; ln -s /littler/examples/testInstalled.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/10/02/notes/</link>
      <pubDate>Thu, 02 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/10/02/notes/</guid>
      <description>docker 2014-09-29:
 Discussion with Dirk on repositories, library paths, versions. library paths: apt-get users the usr/lib path, while user-run install commands (e.g. install.packages) uses usr/local/lib/, path. Dirk recommends that /usr/local/lib/R/site-library is configured to be user-writable for package installation, rather than installing into home. building directly from CRAN building dependencies: apt-get build-dep, needs the corresponding deb-src lines. issues and tweaks to littler see PR #2  2014-10-01:
 Discussion on minimal images Discussion on analogsea + docker Blog coverage of Dirk&amp;rsquo;s talk on our Docker work.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/09/24/notes/</link>
      <pubDate>Wed, 24 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/09/24/notes/</guid>
      <description>rocker / docker  Talking over strategy with Dirk, see summary in #1 and follow-up issues, #3, #4, #5.  rdataone &amp;amp; EML Trying to fix travis issues. Much craziness.
travis.sh doesn&amp;rsquo;t provide notes on setup for repos where the R package is in a subdirectory. Looks like cd commands are persistent though throughout a travis file. okay.
 dataone is imported by EML but suggested by dataone. Since install_github likes to install the suggests list, this creates problems:</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/09/22/containerizing-my-development-environment/</link>
      <pubDate>Mon, 22 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/09/22/containerizing-my-development-environment/</guid>
      <description>A key challenge for reproducible research is developing solutions that integrate easily into a researcher&amp;rsquo;s existing workflow. Having to move all of one&amp;rsquo;s development onto remote machines, into a particular piece of workflow software or IDE, or even just constrained to a window running a local virtual machine in an unfamiliar or primitive environment isn&amp;rsquo;t particularly appealing. In my experience this doesn&amp;rsquo;t reflect the workflow of even those folks already concerned about reproducibility, and is, I suspect, a major barrier in adoption of such tools.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/09/09/server-backups/</link>
      <pubDate>Tue, 09 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/09/09/server-backups/</guid>
      <description>Digital Ocean Snapshots At $0.02 per gig per month, this looks like this is the cheapest way to make complete backups.
The process is rather manual: we have to sudo poweroff the droplet and then trigger the snapshot (the container will come back online after that, though we have to restart the services / active docker containers). We also have to delete old snapshots manually. Some of this can be automated from the API.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/09/08/server-security-basics/</link>
      <pubDate>Mon, 08 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/09/08/server-security-basics/</guid>
      <description>Security configuration We set up SSH key-only login on non-standard port, with root login forbidden. We then set up ufw firewall, fail2ban, and tripwire.
 Configure an SSH key login. Next, Create a user, add to sudoers, and then disable root login.. Edits /etc/ssh/sshd_config:
 Disabling root logins. (We&amp;rsquo;ll need to add ourselves to sudo first: (adduser, edit /etc/sudoers) Change ssh port from default to something else. Whitelist user login ids   Additionally, let&amp;rsquo;s be sure to disable password authentication: Add PasswordAuthentication no to /etc/ssh/sshd_config.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/09/05/drone-ci-and-docker/</link>
      <pubDate>Fri, 05 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/09/05/drone-ci-and-docker/</guid>
      <description>Drone CI: Continous integration in custom docker environments Having gotten accustomed to Docker, configuring the appropriate build environment for a Continuous Integration system like Travis CI or Shippable CI starts to feel incredibly tedious and archaic (particularly if you work primarily in a language like R or haskell that usually isn&amp;rsquo;t supported out of the box).
 We do not have to hack together a custom image environment We can build and test our environment locally instead of having to rely on trial-and-error pushes to the CI server We do not have to download, compile and install the development environment each time, (which frequently takes longer than the CI checks themselves and can break)  (Shippable provides a persistent environment too, by preserving the state of your &amp;lsquo;minion&amp;rsquo;.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/09/05/thoughts-on-harte-interview/</link>
      <pubDate>Fri, 05 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/09/05/thoughts-on-harte-interview/</guid>
      <description>Read this delightful John Harte Interview (ht @DynamicEcology) which resonates rather well with me (no surprise given our common background). Nevertheless, I would have to push back on a few pieces.
 From general laws flow absolutely bullet-proof insights and this is what we most need
 I must disagree. Bullet-proof insights are mathematical theorems. Their generality is an empirical question about their assumptions (not their predictions). (And lastly, I&amp;rsquo;m pretty much in support of the &amp;ldquo;what we most need&amp;rdquo; part, but it deserves to be substantiated.</description>
    </item>
    
    <item>
      <title>Docker tricks of the trade and best practices thoughts</title>
      <link>/2014/08/29/docker-notes/</link>
      <pubDate>Fri, 29 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/08/29/docker-notes/</guid>
      <description>Best practices questions Here are some tricks that may or may not be in keeping with best practices, input would be appreciated.
 Keep images small: use the --no-install-recommends option for apt-get, install true dependencies rather than big metapackages (like texlive-full). Avoid creating additional AUFS layers by combining RUN commands, etc? (limit was once 42, but is now at least 127). Can use RUN git clone ... to add data to a container in place of ADD, which invalidates caching.</description>
    </item>
    
    <item>
      <title>Reproducible research environments with Docker</title>
      <link>/2014/08/25/reproducible-research-environments-with-docker/</link>
      <pubDate>Mon, 25 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/08/25/reproducible-research-environments-with-docker/</guid>
      <description>Academic research takes place in computational environments of continually increasing complexity. This creates ever-higher barriers not only to reproducing or extending the results of other researchers, but also barriers to collaboration and training of new researchers.
Wouldn&amp;rsquo;t it be nice if we could all work in equivalent computing environments, such that whatever worked for me on my computer would work for you on yours? Wouldn&amp;rsquo;t it be nice if we could just clone and copy our entire software environment when we needed to move our computations over to a more powerful cloud or cluster computer?</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/08/14/docker-notes/</link>
      <pubDate>Thu, 14 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/08/14/docker-notes/</guid>
      <description>Ticking through a few more of the challenges I raised in my first post on docker; here I explore some of the issues about facilitating interaction with a docker container so that a user&amp;rsquo;s experience is more similar to working in their own environment and less like working on a remote terminal over ssh. While technically minor, these issues are probably the first stumbling blocks in making this a valid platform for new users.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/08/14/pdg-controlfest-notes/</link>
      <pubDate>Thu, 14 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/08/14/pdg-controlfest-notes/</guid>
      <description>Just wanted to give a quick update on stuff relevant to our adjustment costs paper in events of this week.
I think the talk on Tuesday went all right, (though thanks to a technology snafu going from reveal.js to pdf my most useful figure actually showing the bluefin tuna didn&amp;rsquo;t display &amp;ndash; I tried not to let on). I tried to keep the focus pretty big-picture throughout (we ignore these costs when we model, they matter) and avoid being too bold / prescriptive (e.</description>
    </item>
    
    <item>
      <title>An appropriate amount of fun with docker?</title>
      <link>/2014/08/08/an-appropriate-amount-of-fun-with-docker/</link>
      <pubDate>Fri, 08 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/08/08/an-appropriate-amount-of-fun-with-docker/</guid>
      <description>An update on my exploration with Docker. Title courtesy of Ted, with my hopes that this really does move us in a direction where we can spend less time thinking about the tools and computational environments. Not there yet though
I&amp;rsquo;ve gotten RStudio Server working in the ropensci-docker image (Issues/pull requests welcome!).
docker run -d -p 8787:8787 cboettig/ropensci-docker  will make an RStudio server instance available to you in your browser at localhost:8787.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/08/07/too-much-fun-with-docker/</link>
      <pubDate>Thu, 07 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/08/07/too-much-fun-with-docker/</guid>
      <description>NOTE: This post was originally drafted as a set of questions to the revived ropensci-discuss list, hopefully readers might join the discussion from there.
Been thinking about Docker and the discussion about reproducible research in the comments of Rich et al&amp;rsquo;s recent post on the rOpenSci blog where quite a few of people mentioned the potential for Docker as a way to facilitate this.
I&amp;rsquo;ve only just started playing around with Docker, and though I&amp;rsquo;m quite impressed, I&amp;rsquo;m still rather skeptical that non-crazies would ever use it productively.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/08/06/notes/</link>
      <pubDate>Wed, 06 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/08/06/notes/</guid>
      <description>Writing  Working on / finishing up slides for ESA talk and slides for hastingsfest  Exploring  Poking around a bit more in Docker yesterday, built some basic R containers for testing ropensci packages. https://github.com/ropensci/docker-ubuntu-r/tree/master/add-r-ropensci . Somewhat skeptical but still curious about the potential (or the need) to publish a docker image as a reproducible research object.
 Attempted to add Travis builds to the Docker repo (just for fun, eh?</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/07/31/notes/</link>
      <pubDate>Thu, 31 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/07/31/notes/</guid>
      <description>Berkeley Collaborative Environment Trying out the Berkeley image (Essentially ubuntu 14.04 XFCE with ipython and RStudio installed, but finely tuned to improve user experience; e.g. solid colors for faster remote window connections.)
Highly recommend their paper for the first explanation I&amp;rsquo;ve actually been able to follow that provides a definition of &amp;ldquo;DevOpts&amp;rdquo; (essentially, using scripts rather than documentation to manage consistent cross-platform installation) and explains the differences and similarities between the various programs operating in this sphere, sometimes as alternatives and simultaneously.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/07/21/notes/</link>
      <pubDate>Mon, 21 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/07/21/notes/</guid>
      <description>Reading Looking for this in my notes and couldn&amp;rsquo;t find it: An excellent paper from the Software Sustainability Institute and friends outlining the need and possible structure for sustaining career paths for software developers. &amp;ldquo;The research software engineer&amp;rdquo;, Dirk Gorissen. Provides a good response to the software issues highlighted by climategate, etc.
Remote conferencing (Based on earlier unposted notes). With so much going on, it&amp;rsquo;s nice to be able to follow highlights from some conferences remotely</description>
    </item>
    
    <item>
      <title>UPS and data vs optimal control</title>
      <link>/2014/07/21/ups-and-data-vs-optimal-control/</link>
      <pubDate>Mon, 21 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/07/21/ups-and-data-vs-optimal-control/</guid>
      <description>Random idea for possible further exploration:
The use of &amp;lsquo;big data&amp;rsquo; by UPS to perform lots of small efficiency gains seems to be everybody&amp;rsquo;s favorite example (NPR, The Economist). During a typical applications of optimal control for ecological conservation talk yesterday I couldn&amp;rsquo;t help thinking back to that story. The paradigm shift is not so much the kind or amount of the data being used as it is the control levers themselves.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/07/18/notes/</link>
      <pubDate>Fri, 18 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/07/18/notes/</guid>
      <description>CRAN trivia When should you bump version for a (rejected) resubmission?  Once accepted, any change other than to the metadata (essentially the DESCRIPTION file) needs an increased version. For submissions, we prefer (but do not insist on) a new number of each attempt.
 &amp;ndash;Prof Brian Ripley
Using non-CRAN repositories in SUGGESTS or ENAHANCES More dubious tricks, from Yihui:
 FYI, here is how R core checks dependencies: https://github.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/07/10/notes-on-tricks-in-manuscript-submission-and-collaboration/</link>
      <pubDate>Thu, 10 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/07/10/notes-on-tricks-in-manuscript-submission-and-collaboration/</guid>
      <description>Some thoughts on collaborating with markdown / dynamic document workflow Collaborating on manuscripts with other researchers when not writing in MS Word has been a perpetual nuisance for those of us not using Word (no doubt the others might say the same). When I first began writing papers I worked in LaTeX, and at that time I collaborated largely with others who already knew TeX (e.g. my mentors), so this wasn&amp;rsquo;t much of a problem.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/06/12/knitcitations-updates/</link>
      <pubDate>Thu, 12 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/06/12/knitcitations-updates/</guid>
      <description>Used some down-time while traveling to hammer out a long overdue update to my knitcitations package.
My first task inovled a backwards-compatible update fixing a few minor issues (see NEWS) and providing pandoc style inline citations v0.6-2, on CRAN.
I followed this with a ground-up rewrite, as I summarize in NEWS:
v1.0-1 This version is a ground-up rewrite of knitcitations, providing a more powerful interface while also streamlining the back end, mostly by relying more on external libraries for knitty gritty.</description>
    </item>
    
    <item>
      <title>Is statistical software harmful?</title>
      <link>/2014/06/04/is-statistical-software-harmful/</link>
      <pubDate>Wed, 04 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/06/04/is-statistical-software-harmful/</guid>
      <description>Ben Bolker has an excellent post on this complex issue over at Dynamic Ecology, which got me thinking about writing my own thoughts on the topic in reply.
Google recently announced that it will be making it&amp;rsquo;s own self-driving cars, rather than modifying those of others. Cars that won&amp;rsquo;t have steering wheels and pedals. Just a button that says &amp;ldquo;stop.&amp;rdquo; What does this tell us about the future of user-friendly complex statistical software?</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/05/30/plos-data-sharing-policy-reflections/</link>
      <pubDate>Fri, 30 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/05/30/plos-data-sharing-policy-reflections/</guid>
      <description>PLOS has posted an excellent update reflecting on their experiences a few months in to their new data sharing policy, which requires authors to include a statement of where the data can be obtained rather than providing it upon request. They do a rather excellent job of highlighting common concerns and offering well justified and explained replies where appropriate.
At the end of the piece they pose several excellent questions, which I reflect on here (mostly as a way of figuring out my own thoughts on these issues).</description>
    </item>
    
    <item>
      <title>packrat and rmarkdown</title>
      <link>/2014/05/28/notes/</link>
      <pubDate>Wed, 28 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/05/28/notes/</guid>
      <description>I&amp;rsquo;m pretty happy with the way rmarkdown looks like it can pretty much replace my [Makefile approach]() with a simple R command to rmarkdown::render(). Notably, a lot of the pandoc configuration can already go into the document&amp;rsquo;s yaml header (bibliography, csl, template, documentclass, etc), avoiding any messing around with the Makefile, etc.
Even more exciting is the pending RStudio integration with pandoc. This exposes the features of the rmarkdown package to the RStudio IDE buttons, but more importantly, seems like it will simplify the pandoc/latex dependency issues cross-platform.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/05/27/notes/</link>
      <pubDate>Tue, 27 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/05/27/notes/</guid>
      <description>nonparametric-bayes  nonparametric-bayes sensitivity-trends runs. nonparametric-bayes sensitivity.R runs: explore facets to see what setting causes the below-perfect performance cluster.  knitcitations  updates to knitcitations (paste fron NEWS) Looking at adapting CSL for inline text formatting csl/issues/33 Implemented pandoc rendering  ropensci  Use of .Renviron vs .Rprofile for API keys  Seems the difference between .Rprofile and .Renviron is that (a) the latter is just a named character vector, and (b) the latter is accessed by Sys.</description>
    </item>
    
    <item>
      <title>DIMACS Workshop on Global Change</title>
      <link>/2014/05/21/notes/</link>
      <pubDate>Wed, 21 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/05/21/notes/</guid>
      <description>Program Website My slides   Venue: 2063 Valley Life Science Building. 8:00 - 8:30 Registration and Breakfast 8:30 - 9:00 Welcome and Background 9:00 - 9:40 Revolutionizing Science &amp; Mathematics Education: the global change challenge Mark McCaffrey, National Center of Science Education 9:40 - 10:20 Mathematics and Climate: A New Partnership Hans Kaper, Georgetown University 10:20 - 10:50 Break 10:50 - 11:30 The Application of Information Theory to Ecology John Harte, University of California - Berkeley 11:30 - 12:10 A GIS Global Change Case Study Kevin Koy, University of California - Berkeley 12:10 - 1:30 Lunch 1:30 - 3:00 Panel 1: Communicating Global Change: Minda Berbeco, National Center of Science Education, Barbara Cozzens, Holly Gaff, Old Dominion University 3:00 - 3:30 Break 3:30 - 5:30 Contributed Talks: Sea-ice Albedo Feedback and the Tipping Points in Algae Dynamics Ivan Sudakov, University of Utah Predicting Future Extinction Debt from Present-Day Community Patterns Justin Kitzes, University of California-Berkeley Optimal Control of Restoration - the Role of Economic Threshold Adam Lampert, University of California-Davis Both Climate Change and Land Use Change Influenceinvasive Species&#39; Future Ranges Jennifer Weaver, University of California-Berkeley Towards a National Early Warning System for Human West Nile Virus Incidence Carrie Manore, Tulane University Wastes to Fuel - Waste a Valuable Resource Viral Sagar, Rutgers University 6:00 - 9:00 Banquet Dinner and Talk Finding the Sweet Spot Richard Salter, Oberlin College Location: The Faculty Club Howard Room University of California, Berkeley Tuesday, May 20, 2014 8:00 - 8:30 Breakfast 8:30 - 9:10 Massive Data Set Management and Analysis in the Context of Global Change Carl Boettiger, University of California - Santa Cruz 9:10 - 9:50 Understanding Socio-Ecosystems as Complex Networks in Changing Environments Neo Martinez, University of Arizona 9:50 - 10:30 Applications of GIS in Emerging Zoonotic Processes Jason Blackburn, University of Florida 10:30 - 11:00 Break 11:00 - 12:20 Panel 2: Data Deluge or Drought (Quality and Quantity): David Ackerly, University of California - Berkeley, Fred Roberts, Rutgers University, Philip Stark, University of California - Berkeley 12:20 - 1:30 Lunch 1:30 - 3:00 Workshops 1 and 2 (in parallel) 1: Student driven: Using Mathematics to Interface Global and Ecosystem Processes 2: Student driven: Using Mathematics to Link Individual and Population Level Processes 3:00 - 3:30 Break 3:30 - 4:30 Workshops 1 and 2 (continue) 1: Student driven: Using Mathematics to Interface Global and Ecosystem Processes 2: Student driven: Using Mathematics to Link Individual and Population Level Processes 4:30 - 5:00 Workshop report back Wednesday, May 21, 2014 8:00 - 8:30 Breakfast 8:30 - 9:10 When All Models are Wrong Andrea Saltelli, European Commission JRC 9:10 - 10:30 Panel 3: Are Our Models Adequate for Policy Formation: Solomon Hsiang, University of California - Berkeley, Donald Lucas, Lawrence Livermore National Laboratories, A.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/05/07/integrating-github-project-repos-into-the-notebook/</link>
      <pubDate>Wed, 07 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/05/07/integrating-github-project-repos-into-the-notebook/</guid>
      <description>For a while now most of my active research is developed through .Rmd scripts connected to a particular project repository (something I discuss at length in deep challenges with knitr workflows). In the previous post I discuss creating a template package with a more transparent organization of files, such as moving manuscripts from inst/doc/ to simply manuscripts/. This left these exploratory analysis scripts in inst/examples in a similarly unintuitive place.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/05/06/steps-to-a-more-portable-workflow/</link>
      <pubDate>Tue, 06 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/05/06/steps-to-a-more-portable-workflow/</guid>
      <description>While I have made my workflow for most of my ongoing projects available on Github for some time, this does not mean that it has been particularly easy to follow. Further, as I move from project to project I have slowly improved how I handle projects. For instance, I have since added unit tests (with testthat) and continuous integration (with travis-ci) to my repositories, and my handling of manuscripts has gotten more automated, with richer latex templates, yaml metadata, and simpler and more powerful makefiles.</description>
    </item>
    
    <item>
      <title>Deep challenges to dynamic documentation in daily workflows</title>
      <link>/2014/05/05/knitr-workflow-challenges/</link>
      <pubDate>Mon, 05 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/05/05/knitr-workflow-challenges/</guid>
      <description>We often discuss dynamic documents such as Sweave and knitr in reference to final products such as publications or software package vignettes. In this case, all the elements involved are already fixed: external functions, code, text, and so forth. The dynamic documentation engine is really just a tool to combine them (knit them together). Using dynamic documentation on a day-to-day basis on ongoing research presents a compelling opportunity but a rather more complex challenge as well.</description>
    </item>
    
    <item>
      <title>why I sign my reviews</title>
      <link>/2014/05/04/why-i-sign-my-reviews/</link>
      <pubDate>Sun, 04 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/05/04/why-i-sign-my-reviews/</guid>
      <description>For the past four years I have made an effort to sign all my reviews (which I try to keep to about one a month). It isn&amp;rsquo;t because I believe in radical openness or something crazy like that. Its really just my self interest involved &amp;ndash; at least mostly. Writing a review is an incredibly time consuming, and largely thankless task. Supposedly anonymous peer review is supposed to protect the reviewer, particularly the scenario of the less established scientist critiquing the work of the more established.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/05/02/multiple-uncertainty-notes/</link>
      <pubDate>Fri, 02 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/05/02/multiple-uncertainty-notes/</guid>
      <description>Logistic recruitment, uniform noise (Sethi Fig 3 configuration)
Logistic recruitment, lognormal noise Beverton-Holt recruitement, uniform noise Beverton-Holt recruitement, lognormal noise Logistic recruitment, uniform noise, small r Logistic recruitment, lognormal noise, small r Metadata From scenarios_meta.txt
Columns: y_grid: The observed stock size escapement: The optimal escapement policy. (y_grid value minus the escapement is the quota). sigma_g: The growth noise scaling factor sigma_m: The measurement error scaling factor (between observed stock x and measured stock y) sigma_i: The implementation noise scaling factor (between quota q set and harvest h realized).</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/05/02/scientific-computing-notes/</link>
      <pubDate>Fri, 02 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/05/02/scientific-computing-notes/</guid>
      <description>In my experience EC2 is good for some things but not for others. Consequently having some funding allocated for it would be great, but it would still be necessary to have other resources as well. I&amp;rsquo;ve found EC2 very good for running some reasonably portable analysis where you temporarily want some extra processors or memory. On the other hand, I&amp;rsquo;ve had some frustrations with it as well. You don&amp;rsquo;t have a persistent development environment unless you explicitly make and maintain a machine image, which means installing any software dependencies from scratch; sometimes a particular nuisance when you aren&amp;rsquo;t familiar with the architecture.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/04/29/notes/</link>
      <pubDate>Tue, 29 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/04/29/notes/</guid>
      <description>Labnotebook  Configure Github CDN Hmm, jekyll-assets. Not sure that this is preferable from just using the makefile to compile and minify assets seperately as needed. Move www.carlboettiger.info to host from gh-pages branch of labnotebook. This self-contained system is more standard, and it is strange for other gh-pages hosting to be using the same domain/subdomain to reference content that is actually on a gh-pages branch of some totally different repository.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/04/24/notebook-design-notes/</link>
      <pubDate>Thu, 24 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/04/24/notebook-design-notes/</guid>
      <description>Reading a little about Flat UI design (1, 2). Basic concept is that users now realize they can click on things without them looking like actual three-dimensional buttons. (Along with links, checkboxes, and forms). Frequently seems to use many different colors on a single page to bring some life back, though this might just make the design look like Windows 8 instead. I&amp;rsquo;ve started noticing this everwhere now that I know what it is.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/04/23/multiple-uncertainty-notes/</link>
      <pubDate>Wed, 23 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/04/23/multiple-uncertainty-notes/</guid>
      <description>Multiple uncertainty Handling variation in different grids. Cleaned up a bunch of transpose expressions in the code and make sure that dimensions are always properly aligned. Now problem can be solved on arbitrarily different grid discritizations for stock $x$, observed stock $y$, harvest $h$ and quota $q$. See multiple_uncertainty.m and example calls in testing.m
Taking a look a how we handle normalization when some of the probability density falls outside the discritized space.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/04/18/notes/</link>
      <pubDate>Fri, 18 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/04/18/notes/</guid>
      <description>EML I&amp;rsquo;ve added a interface for custom units. You don&amp;rsquo;t have to mess around with additionalMetadata as it should be handled automatically. Just define the unit itself, like this 1:
create_custom_unit(id = &amp;quot;metersSquaredPerHectare&amp;quot;, parentSI = &amp;quot;dimensionless&amp;quot;, unitType = &amp;quot;dimensionless&amp;quot;, multiplierToSI = &amp;quot;0.0001&amp;quot;, description = &amp;quot;Square meters per hectare&amp;quot;)  and then use the id you give as the unit type in your unit.defs. create_custom_unit updates a custom_units list in the EMLConfig environment, which the eml or write_eml functions detect and use to write in the additional metadata.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/04/17/notes/</link>
      <pubDate>Thu, 17 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/04/17/notes/</guid>
      <description>Units in EML Overview of how units are determined in the EML package:
library(EML) dat &amp;lt;- data.set(river = factor(c(&amp;quot;SAC&amp;quot;, &amp;quot;SAC&amp;quot;, &amp;quot;AM&amp;quot;)), spp = c(&amp;quot;Oncorhynchus tshawytscha&amp;quot;, &amp;quot;Oncorhynchus tshawytscha&amp;quot;, &amp;quot;Oncorhynchus kisutch&amp;quot;), stg = ordered(c(&amp;quot;smolt&amp;quot;, &amp;quot;parr&amp;quot;, &amp;quot;smolt&amp;quot;), levels=c(&amp;quot;parr&amp;quot;, &amp;quot;smolt&amp;quot;)), # levels indicates increasing level, eg. parr &amp;lt; smolt ct = c(293L, 410L, 210L), day = as.Date(c(&amp;quot;2013-09-01&amp;quot;, &amp;quot;2013-09-1&amp;quot;, &amp;quot;2013-09-02&amp;quot;)), stringsAsFactors = FALSE, col.defs = c(&amp;quot;River site used for collection&amp;quot;, &amp;quot;Species scientific name&amp;quot;, &amp;quot;Life Stage&amp;quot;, &amp;quot;count of live fish in traps&amp;quot;, &amp;quot;day traps were sampled (usually in morning thereof)&amp;quot;), unit.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/04/11/notes/</link>
      <pubDate>Fri, 11 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/04/11/notes/</guid>
      <description>labnotebook Updates to configuration to be more portable and lightweight:
 Drop APIs for Mendeley and Github in favor of just pulling from atom/rss feeds. Doesn&amp;rsquo;t require a platform-specific API or authentication, and has proven more robust, if sometimes less flexible and fancy. Drop git-modified and sha timestamps. It&amp;rsquo;s nice having these on the pages and included in the rdfa, but the information is accessible from the git repository and from Github.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/04/10/multiple-uncertainty-notes/</link>
      <pubDate>Thu, 10 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/04/10/multiple-uncertainty-notes/</guid>
      <description>multiple uncertainty  Set up Paul Fackler&amp;rsquo;s MDPSOLVE and run Paul&amp;rsquo;s code. Installing user-contributed extensions in matlab seems mostly a matter adding the unzipped source directories to the path, e.g. as so:
  currentdir = cd cd /home/cboettig/.matlab/MDPSOLVE addpath(genpath(cd)) cd /home/cboettig/.matlab/plot2svg addpath(genpath(cd)) cd(currentdir)  (I still find matlab/octave&amp;rsquo;s syntax of not distinguishing character strings from variable names from function names kind of terrifying, but I guess that&amp;rsquo;s the price of working with economists.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/04/09/multiple-uncertainty-notes/</link>
      <pubDate>Wed, 09 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/04/09/multiple-uncertainty-notes/</guid>
      <description>Attempt to replicate Figure 3, but with one noise at a time  Code: one_noise_at_a_time.m Uniform Noise Large noise means devation of 0.5, as in Sethi Other noise terms are 0 instead of 0.1  Figure 3  Code: carl_fig3.m Uniform Noise Large noise means devation of 0.5, as in Sethi Small noise means 0.1, as in Sethi  Now fixed. See:
 Updated code version of carl_fig3.m  One noise at a time, lognormal noise, sigma = 0.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/04/08/multiple-uncertainty-notes/</link>
      <pubDate>Tue, 08 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/04/08/multiple-uncertainty-notes/</guid>
      <description>Growth Noise Only Run:
matlab -nodesktop &amp;lt; testing.m &amp;gt; testing.log  Results from running testing.m:
 log normal noise sigma_g = 0.2 Other noise set to zero.
 Coarse grid 0:5:150 (See linked code all parameters)  measurement Noise only  Code: measurement_uncertainty.m sigma_m = 0.5 Other noise set to zero.
 Fine grid 0:1:150 (See linked code all parameters)  Implementation Noise only  Code: implementation_uncertainty.m sigma_i = 0.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/04/07/notes/</link>
      <pubDate>Mon, 07 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/04/07/notes/</guid>
      <description>ropensci Working on proposal. Discussion of section 2: other players in the domain (or rather, the many community interfaces with rOpenSci).
other  Discussion with Hadley re: API testing and test_if functionality, see testthat/141.
 Related with Hadley discussion on handling tests and keys for API packages, httr/93
 Software Carpentry developing R lessons
  rfishbase Add FAO areas (from 04/05), see rfishbase/20
EML  Discussion of unit handling, feedback from Karen.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/04/03/wisconsin-visit/</link>
      <pubDate>Thu, 03 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/04/03/wisconsin-visit/</guid>
      <description>Carl Boettiger Schedule 3-4 April
Thursday
   Person/activity Time Location     Arrive 3:00 Dane County Airport   Tony 4:00 pickup at hotel   Jesse Miller 4:30 Birge 448   Kyle Webert 5:00 Birge 457   Cristina Herren 5:30 Birge 456   Dinner with Tony, Karen Strier 6:00 leave from Birge Hall    Friday
   Person/activity Time Location     Breakfast, Meghan Fitzgerald and Fan Huan 7:30 pickup at hotel   Cecile Ane, Lam Si Tung Ho 9:00 Birge 341   Steve Carpenter and CFL folk 10:45 CFL 226A   Jeremy Ash 2:00 Birge 338   Break, walk over with Jacob 2:30 Birge 460   prep for seminar 3:00 Nolan Hall   seminar 3:30 Nolan Hall   reception 6:00 Tony&amp;rsquo;s house    Misc notes:</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/03/31/ropenhack-notes/</link>
      <pubDate>Mon, 31 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/03/31/ropenhack-notes/</guid>
      <description>Breakfast  discussion of what makes an API good or a total pain discussion of extending data.set class with metadata  Morning Session Chatting with Hadley:
Best practices for R client packages to REST APIs  (When) Do we return response call metadata? Very modular function construction Error handling, assertthat checks Explicit parsing, as seperate function. e.g. Better alternatives in place of require when loading SUGGESTS lists, which still pollutes the namespace; see examples in httr.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/03/24/review-of-progress-on-packages/</link>
      <pubDate>Mon, 24 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/03/24/review-of-progress-on-packages/</guid>
      <description>A lot of the past week has been focused on some catching up and tidying up in my active projects in metadata manipulation and publishing tools, EML, RNeXML, and rfigshare. The full story of the week and half unfolds on github, but summarizing progress here.
rfigshare Changes to httr interface orginally broke rfigshare, though working with @hadley the original mechanism was restored through sign_oauth1.0(). The changes provided a much nicer mechanism for handling oauth authentication without having to specify tokens directly, and resulted in a relatively straightforward overhaul of the authentication mechanism in the package, while still preserving the package API.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/03/20/software-sustainability-issues-in-r/</link>
      <pubDate>Thu, 20 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/03/20/software-sustainability-issues-in-r/</guid>
      <description>Editorial note: The following is slightly edited text from my post to R-devel discussing this issue, which I first drafted here.
 There seems to be some question of how frequently changes to software packages result in irreproducible results. I am sure that research using functions like glm and other functions that are shipped with base R are quite reliable; and after all they already benefit from being versioned with R releases (as Jeroen has argued).</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/03/18/notes/</link>
      <pubDate>Tue, 18 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/03/18/notes/</guid>
      <description>ropensci  Ensuring interoperability in R / ropensci projects. See pre-hackathon discussion: ropensci/hackathon/issues/#20 rfigshare to use new oauth interface of httr, see rfigshare/#72 Ugh. More fun with travis integration on RNeXML RNeXML/#61  pdg-control / policycosts  Started tidying up this repo&amp;rsquo;s manuscript folder a bit.
 Merge Paul&amp;rsquo;s various changes on tex and Word documents into Rmd  Misc  Whoops. Couldn&amp;rsquo;r resist a wee rant on G+, 2014-03-02 on this #PLOSfail discussion.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/03/11/notes/</link>
      <pubDate>Tue, 11 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/03/11/notes/</guid>
      <description>Reading  NAP report on &amp;ldquo;Abrupt impacts of climate change: anticipating suprises.&amp;rdquo;
 Nice overview of major climate tipping points. Interesting that the 2011 IPCC report put to rest concerns about a sudden transition of the thermohaline circulation within this century, despite good evidence that it is a bistable dynamic. Likewise appears to dismiss concerns of a tipping point related to the release of permafrost methane, thus putting aside the two most well-known and well-studied examples.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/03/10/notes/</link>
      <pubDate>Mon, 10 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/03/10/notes/</guid>
      <description>RNeXML merge travis integration with support for rrdf. See pull #57 Reply to Perry re nonparametric approaches 10am Andrew Skype meeting re: his manuscript rOpenSci discussion re: other services, formats. Reading Caldwell et al, Geophysical Letters. Good example of naiive data mining leading to spurious correlations from non-independent models. (/ht @FreshwaterEcology Looking over NSF&amp;rsquo;s Data Infrastructure Building Blocks, DIBB call and previously funded work.
 Remote control for Ubuntu via android?</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/03/07/notes/</link>
      <pubDate>Fri, 07 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/03/07/notes/</guid>
      <description>Thursday  Reading through Andrew&amp;rsquo;s manuscript Working on RNeXML checks / travis continuous integration. Completing documentation, updating unit tests to reflect recent API changes.
 Difficulty getting taxize dependency to pass travis check. Needed these lines in travis:  - sudo apt-get install gdal-bin libgdal1 libgdal1-dev netcdf-bin libproj-dev - ./travis-tool.sh install_aptget gdal-bin   Interview with Nature Careers journalist Amanda, discussing open notebook and open science developments  Friday  Finish up RNeXML checks / travis integration.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/02/19/cran-and-package-dependencies/</link>
      <pubDate>Wed, 19 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/02/19/cran-and-package-dependencies/</guid>
      <description>2014-02-19 R allows you to specify &amp;gt;= in a package dependency, not ==. The Comprehensive R Archive Network, CRAN, makes no requirement that package authors do not break their previous function API. For instance, if version 0.1 of the package had a function
foo &amp;lt;- function(x, y = 5){ ... }  then one could add new functionality in say, version 0.2 without breaking the existing API with a definition that looked like:</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/02/18/real-world-challenges-in-reproducible-research-code/</link>
      <pubDate>Tue, 18 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/02/18/real-world-challenges-in-reproducible-research-code/</guid>
      <description>Editorial Note: Scratchpad in replying to issues raised by the NESCent reproducibility exercise that included my prosecutor&amp;rsquo;s fallacy paper. See more developed version of this disucssion in the package issues log:
  #1 #2 #3  @hlapp Thanks for the bug reports; I think there are quite a few good illustrations of the challenges in sharing code here go beyond [&amp;ldquo;Publish your code, it&amp;rsquo;s good enough&amp;rdquo;](), despite the importance of that message.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/02/14/notes/</link>
      <pubDate>Fri, 14 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/02/14/notes/</guid>
      <description>pomdp Write Iadine, send example code (Reed example in multiple_uncertainty)
multiple-uncertainty Check in with Jim on how results compare to Sethi. See commit log for multiple_uncertainty
open-science  #PublishPerish14 continues Comments on software publishing https://github.com/mozillascience/code-research-object/issues/2#issuecomment-35109160  Reading:  Drake, J. M. 2014 Tail probabilities of extinction time in a large number of experimental populations. Ecology , 140206083444001. (doi:10.1890&amp;frasl;13-1107.1)  Neat result. thinking how this relates to predictions of Mangel and Tier 1993; probably still a significant deviation?</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/02/10/scratch-notes-while-outlining-talk/</link>
      <pubDate>Mon, 10 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/02/10/scratch-notes-while-outlining-talk/</guid>
      <description>Scratch notes for my seminar
Part I: Tipping Points: Early Warning signals and decision theory Global change threats. So what do we do? This is a pendulum. easy to predict. Not a pendulum. Oscillations not easy to predict. Crashes Tipping points No equation for $f_i(s,h)$ Everything matters. Data is good, getting better. Crushing our data under parameters. Stop throwing out the data. Early Warning signals Optimal Control problem -- Model the descision process!</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/02/07/nceas-workflows-day3/</link>
      <pubDate>Fri, 07 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/02/07/nceas-workflows-day3/</guid>
      <description>(Day 2 work) Hack-a-thon; no notebook entry but all progress appears in group Github repo: github.com/NCEAS/commdyn/. 78 Commits in 2 days, nice work team.
Discussion of challenges and opportunities in open data and ecological workflows
Synthesis and Reporting back
Group 1.5 Plan Product 1: Paper: Visualizing global change in long term community ecology studies: the strawmen?
 Lead: Sydney Jones  Long-term ecological research (LTER) sites have been collecting and publishing raw community ecology data for over 30 years from across the US and across a wide array of taxa.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/02/05/workflows-working-group-day-1/</link>
      <pubDate>Wed, 05 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/02/05/workflows-working-group-day-1/</guid>
      <description>Goals  Develop ideas for larger synthesis across systems Introduce scientists to the concept of workflow systems Introduce scientists to open data and methods sharing Gather requirements for collaboration tools that would allow scientists to use them and share data and workflows.  Participants  Ilkay Altintas, UC San Diego, Carl Boettiger, UC Davis, Erica Christensen, Utah State, Elsa Cleland, UCSD, Scott Collins, U New Mexico, Sam Fey, Dartmouth, Corinna Gries, U Wisconsin, Lauren Hallett, Berkeley, Stan Harpole, Iowa State, Dave Harris, UC Davis, Matt Jones, UC Santa Barbara, Sydney Jones, U New Mexico, Julie Ripplinger, Arizona State University, Andrew Rypel, WDNR, David Seekell, UVa, Elizabeth Siddon, U.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/01/31/notes/</link>
      <pubDate>Fri, 31 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/01/31/notes/</guid>
      <description>Scratch notes on uncertainty.
Function definition: multiple_uncertainty.m
Settings:
f=@(x, h) max( (x-h) * (1 - (x-h) ./ 100) + (x-h), 0); x_grid = [0:5:100]; h_grid = x_grid; % Must be same dimensions as x_grid, or L91 errors... Tmax = 5; sigma_g = 0.1; sigma_m = 0.; sigma_i = 0.0; delta = 0.05; pdf = @(p,mu,s) lognpdf(p ./ mu, 0, s); %pdf = @(p,mu,s) unifpdf(p, mu .* (1 - s), mu .</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/01/31/weekly-review/</link>
      <pubDate>Fri, 31 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/01/31/weekly-review/</guid>
      <description>EML  bug fixes and replies to various input from community on EML package
 Thoughts on understanding and using EML in research, including Dryad. See https://github.com/ropensci/EML/issues/82#issuecomment-33558301
  multiple-uncertainty Jim and Mike meeting  Why the steps in the optimal solution of the deterministic case? Irregularities in value function in first iteration: sometimes not exact ties; actually preferring to fish at almost 0 rather than 0.
 address range constraints on h and x.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/01/23/startup-culture-and-platforms-for-the-academy/</link>
      <pubDate>Thu, 23 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/01/23/startup-culture-and-platforms-for-the-academy/</guid>
      <description>Scientific Research: Moving beyond bubbles to platforms. The Economist contrasts the current start-up culture to that of the dotcom bubble. Their special report argues that while the dotcom bubble was characterized by heavy investment in a single idea with a &amp;ldquo;Build it and they will come&amp;rdquo; attitude, the current generation of startups is characterized by tinkering and rapid experimentation. They argue that this is possible thanks to the cheaply available &amp;ldquo;platforms&amp;rdquo; of open source software, cloud computing, APIs, and social media dissemination.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/01/15/asn-conference/</link>
      <pubDate>Wed, 15 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/01/15/asn-conference/</guid>
      <description>Note: posting this considerably after the fact as I did not have a chance to make a proper entry during the conference.
 Full program, abstracts, etc.
 President&amp;rsquo;s debate: are ecological communities saturated in species diversity? Watch the whole debate on youtube tweet log, maybe?. Or from the editor&amp;rsquo;s desk  Some highlights (such as on the top of my head 2 months later anyway, certainly others I&amp;rsquo;ve forgotten to mention.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/01/09/notes/</link>
      <pubDate>Thu, 09 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/01/09/notes/</guid>
      <description>fishbase API discussions continue some discussion / work on rfigshare continues (As Karthik writes comprehensive test suite, yay).
 Possible ontological term for simulated data? modeling and simulation operation looking for example using this term now&amp;hellip;
 Request for term on OBI
 Moore DDD investigators, full call
  .@NOAA gives a glimpse of what the future of scipub could be w/ web native format for this peer-reviewed report: http://t.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/01/07/notes/</link>
      <pubDate>Tue, 07 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/01/07/notes/</guid>
      <description>Coding  fishbase API discussions rfishbase updates pushed to CRAN Merges and minor bug fixes for rfigshare
 RNeXML: After some cooperative sleuth-work, we successfully resolved issue #23, uncovering a bug (missing feature really) in xmllint.
  as usual, detailed activity on github.
Reading  The sudden collapse of pollinator communities - Jelle Lever - 2014 - Ecology Letters - Wiley Online Library http://goo.gl/ZKuKsj Github has traffic stats again.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/01/06/notes/</link>
      <pubDate>Mon, 06 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/01/06/notes/</guid>
      <description>fishbase API discussions knitcitations (push previous updates to CRAN) data extraction from sardine collapse story (see EML in data/), news article My thoughts on SWC teaching web-native publication workflow reading, ToCs speaker invitation replies review request replies  Reading  &amp;ldquo;Are rapid transitions btwn invasive and native species caused by alt stable states, and does it matter?&amp;rdquo; http://feedly.com/k/1gbEIWT
 &amp;ldquo;Phylogenetic trait-based analyses of ecological networks.&amp;rdquo; http://feedly.com/k/1gbEvD6
 Nice editorial on &amp;ldquo;core elements of a TPB paper.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2014/01/02/open-science-literature-highlights/</link>
      <pubDate>Thu, 02 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/01/02/open-science-literature-highlights/</guid>
      <description>A student recently asked me for some recommendations for an article on an open science topic for a journal club. Since I haven&amp;rsquo;t jotted these down in one place before, though I might copy my reply here for my future reference, or in case anyone else is interested in my list.
There&amp;rsquo;s a variety of sub-topics one might focus on; though in my opinion there&amp;rsquo;s no good, consise overview of all of the topics in one place.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/12/10/notes/</link>
      <pubDate>Tue, 10 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/12/10/notes/</guid>
      <description>Consider the model
$$d X_t = \alpha \left(\theta - X_t\right)dt + \sigma dB_t $$
By Ito Isometry, we have:
$$\langle X \rangle_t = E_t(X) = \theta \left(1 - e^{-\alpha t} \right) + X_0 e^{-\alpha t}$$
and
$$\langle X^2 \rangle_t - \langle X \rangle_t^2 = V_t(X) = \frac{\sigma^2}{2 \alpha }\left(1 - e^{-2 \alpha t} \right)$$
If we assume discrete, uniform sampling of spacing $\tau$, then we have,
$$P(\theta | X; \alpha, \sigma) = \sqrt{\frac{1}{2\pi V_{\tau} }}^{T-1} \exp\left(-\frac{\sumt^{T-1} \left(X{t+1} - E\right)^2 }{2V}\right) $$</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/11/26/notes/</link>
      <pubDate>Tue, 26 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/11/26/notes/</guid>
      <description>RNeXML Character metadata EML provides a nice illustration of the kind of metadata we would want to typically accompany character trait data; at minimum, at the attribute level.
Some of this is already there &amp;ndash; we know if states are continuous or discrete, what possible states they can take on, and can add labels to state nodes to define what the symbols mean (however, perhaps an additional meta annotation node would be preferred).</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/11/19/notes/</link>
      <pubDate>Tue, 19 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/11/19/notes/</guid>
      <description>RNeXML  Feedback from Rutger, need to add about attributes so that RDFa abstraction references the right level of the DOM (issue #35).
 Looking for strategy for distilling RDF from RDFa in R, see my question on SO. Hopefully don&amp;rsquo;t have to wrap some C library myself&amp;hellip;  nonparametric-bayes Writing writing.
 Update pandoc templates to use yaml metadata for author, affiliation, abstract, etc. Avoids having to manually edit the elsarticle.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/11/17/rnexml-metadata-queries/</link>
      <pubDate>Sun, 17 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/11/17/rnexml-metadata-queries/</guid>
      <description>(From issue #20)
Basic metadata queries a question of how the user queries that metadata. Currently we have a metadata function that simply extracts all the metadata at the specified level (nexml, otus, trees, tree, etc) and returns a named character string in which the name corresponds to the rel or property and the value corresponds to the content or href, e.g.:
birds &amp;lt;- read.nexml(&amp;quot;birdOrders.xml&amp;quot;) meta &amp;lt;- get_metadata(birds)  prints the named string with the top-level (default-level) metadata elements as so:</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/11/14/notes/</link>
      <pubDate>Thu, 14 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/11/14/notes/</guid>
      <description>ropensci  ropensci stategic planning: wrote personal vision statement  RNeXML  Comments on issues #12 and #15, thinking about character matrices comments on #20, thinking about metadata parsing. (If only everyone knew xpath&amp;hellip;)  Commit details on Github</description>
    </item>
    
    <item>
      <title>So, you&#39;re active on Research Gate?</title>
      <link>/2013/11/14/research-gate/</link>
      <pubDate>Thu, 14 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/11/14/research-gate/</guid>
      <description>I have occassionally been getting this question:
 So, you&amp;rsquo;re active on ResearchGate?
 Sounds like being accused of some scandal, doesn&amp;rsquo;t it?
I&amp;rsquo;m not generally active on it - my impression is that the open science community is mostly skeptical about ResearchGate and any other &amp;ldquo;Social Network&amp;rdquo; for scientists, largely on the grounds that &amp;ldquo;we already use the same social networks everyone else uses.&amp;rdquo; Some object on more philosophical grounds (profit, Mendeley, etc), but heck I publish in Elsevier/Springer/Wiley so I won&amp;rsquo;t preach.</description>
    </item>
    
    <item>
      <title>Do we need a culture of Data Science in Academia?</title>
      <link>/2013/11/13/data-science-center/</link>
      <pubDate>Wed, 13 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/11/13/data-science-center/</guid>
      <description>Just my draft copy of a Guest blog post I wrote for Dynamic Ecology.
On Tuesday the Whitehouse Office of Science and Technology Policy announced the creation of a $37.8 million dollar initiative to promote a &amp;ldquo;Data Science Culture&amp;rdquo; in academic institutions, funded by the Gordon and Betty Moore Foundation, Alfred P. Sloan Foundation, and hosted in centers at the universities UC Berkeley, University of Washington, and New York University.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/11/08/mbi-day-five-notes/</link>
      <pubDate>Fri, 08 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/11/08/mbi-day-five-notes/</guid>
      <description>Panel discussion
 Hugh&amp;rsquo;s question on the usefulness of dynamic vs static models: do we have dynamical systems envy? Chris: are temporal dynamics historical artefact, and space the new frontier? Hugh: though decision theory is fundamentally temporal. really question of sequential decision vs single decision Hugh, on what would be his priority if he had time for new question: Solve the 2 player, 2 step SDP competition closed form.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/11/07/mbi-day-four-notes/</link>
      <pubDate>Thu, 07 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/11/07/mbi-day-four-notes/</guid>
      <description>Morning session Iadine Chades  Chadès, I., Carwardine, J., Martin, T.G., Nicol, S., Sabbadin, R. &amp;amp; Buffet, O. (2012) MOMDPs: a solution for modelling adaptive management problems. The Twenty-Sixth AAAI Conference on Artificial Intelligence (AAAI-12), pp. 267-273. Toronto, Canada.
 10.1098/rspb.2013.0325 Migratory connectivity magnifies the consequences of habitat loss from sea-level rise for shorebird populations
  Jake LaRiviera presents the challenges of the uncertainty table. Additional challenges in making an apples-to-apples comparison of the benefit of decreasing noise of different systems (e.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/11/06/mbi-day-three/</link>
      <pubDate>Wed, 06 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/11/06/mbi-day-three/</guid>
      <description>MBI Workshop Becky Epanchin-Niell  Motivating example of Rabies spatial control in Switzerland
 2012 Eco Let: should New Zealand survey for bark beetle? Cost of survellience, control, and damage. Epanchin-Niell et al. (2012)
 2012 JEEM spatial spread of star thistle: control spread and eradication as an integer programming problem in deterministic context. (with Wilen) Epanchin-Niell &amp;amp; Wilen (2012)
 Breaking landscape into individual landowners makes it less valuable to control early.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/11/05/mbi-day-two/</link>
      <pubDate>Tue, 05 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/11/05/mbi-day-two/</guid>
      <description>MBI Workshop Paul Armsworth Very nice example of control in creating a market for ecosystem services for landowners. Key feature is that multiple land-owners respond by adjusting their prices, and so payments can be divided into fraction going into subsidy and fraction going into conservation. When one land-owner controls land that is particularly good cost per conservation accomplished, they also stand to gain largest value.
Also looked at auction mechanism and impact of cooperation among landowners to create hold outs.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/11/04/mbi-notes/</link>
      <pubDate>Mon, 04 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/11/04/mbi-notes/</guid>
      <description>SUSTAINABLE MANAGEMENT OF LIVING NATURAL RESOURCES  Description Full Schedule Participants  Introductions Hastings Lou Gross  Big picture: big data, computational challenges.
 NEON, DataONE, ADW, iDigBio &amp;ldquo;Convergence&amp;rdquo; as the new interdisciplinary (National Academies) Rise of synthesis centers &amp;ldquo;Enabling architecture for next gen life science research&amp;rdquo; &amp;ndash; National Academies report Lou Gross (2013) Comp Science for Natural Resource Management &amp;ndash; Fuller, Wang, Gross (2007)
 language barriers: What&amp;rsquo;s a model?</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/10/17/rnexml-semantic-considerations/</link>
      <pubDate>Thu, 17 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/10/17/rnexml-semantic-considerations/</guid>
      <description>Some very good feedback from Hilmar as I tackle some of the semantic capabilities of NeXML in RNeXML. As the complete discussion is already archived in the Github issues tracking, (see in particular #26 and #24) I only paraphrase here.
One of the central advantages we can offer in programmatic generation of NeXML in the R environment is the ability to validate names and enhance the metadata included in the resulting nexml file using programmatic queries to taxonomic name resolution services such as ITIS, EOL, NCBI, as provided in the taxize package.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/10/16/notes/</link>
      <pubDate>Wed, 16 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/10/16/notes/</guid>
      <description>RNeXML  Example methods for metadata: https://github.com/ropensci/RNeXML/issues/20#issuecomment-26457772 Closes #19 https://github.com/ropensci/RNeXML/issues/19#issuecomment-26459110 Discussion of best identifiers for OTUs #24. Now waiting on Scott for choice of implementation  Misc R puzzle In R&amp;rsquo;s S4 methods, I can define methods with different signatures, i.e. different object classes for the same function call. But can I alter the names and number of arguments for a method?
As usual, see Github for details on commits and issues.</description>
    </item>
    
    <item>
      <title>Is it time to retire Pagel&#39;s lambda?</title>
      <link>/2013/10/11/is-it-time-to-retire-pagels-lambda/</link>
      <pubDate>Fri, 11 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/10/11/is-it-time-to-retire-pagels-lambda/</guid>
      <description>Pagel&amp;rsquo;s $\lambda$ (lambda), introduced in Pagel 1999 as a potential measure of &amp;ldquo;phylogenetic signal,&amp;rdquo; the extent to which correlations in traits reflect their shared evolutionary history (as approximated by Brownian motion).
Numerous critiques and ready alternatives have not appeared to decrease it&amp;rsquo;s popularity. There are many issues with the statistic, some of which I attempt to summarise below.
The $\lambda$ statistic is defined by the Brownian motion model together with a transformation of the branch lengths: multiply all internal branches by $\lambda$.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/10/10/notes/</link>
      <pubDate>Thu, 10 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/10/10/notes/</guid>
      <description>Authenticating via DataOne API Matt Jones provides a nice dataone package to handle accessing and posting data to DataOne nodes such as the KNB from R. Uploading files through the API requires authentication, which in turn requires a certificate from CILogin. As this process proved a bit tricky to me, I add some documentation here. I am using a Ubuntu (13.04) system, so the procedure might differ slightly for other systems.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/10/09/notes/</link>
      <pubDate>Wed, 09 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/10/09/notes/</guid>
      <description>ugh, most journals don&amp;rsquo;t seem to hold to their own data publication policies.
PNAS theoretically endorses UPSIDE, r citet(&amp;quot;10.1073/pnas.0400437101&amp;quot;) principles from the National Academy of Science:
 Principle 1. Authors should include in their publications the data, algorithms, or other information that is central or integral to the publication—that is, whatever is necessary to support the major claims of the paper and would enable one skilled in the art to verify or replicate the claims.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/10/08/notes/</link>
      <pubDate>Tue, 08 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/10/08/notes/</guid>
      <description>Fisheries data from Glaser et al. (2013) available at IchthyoDB Larvae and egg counts. About 4 GB, initialized in calcofi repo (local only).
Reading early warning with &amp;ldquo;Quickest Detection&amp;rdquo; algorithm described in Carpenter et al. (2013) and used by Batt et al. (2013), which includes a rather friendly explanation in the appendix (SI).
Uses a likelihood based method along with rather simple models of the probability of being in each state, and interestingly relies on the presence of a control system that has already experienced the transition.</description>
    </item>
    
    <item>
      <title>Extending ape::phylo class to NeXML:</title>
      <link>/2013/10/07/nexml-phylo-class-extension/</link>
      <pubDate>Mon, 07 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/10/07/nexml-phylo-class-extension/</guid>
      <description>While working on the RNeXML package, I have recently I have been puzzling over extending S3 objects to share some of the nice properties of S4 objects and methods while continuing to function with the potentially huge library of functions written to work with them. SO:
To illustrate this issue, consider the S3 class phylo provided by the ape package and used by most of the 30+ packages that reverse depend or reverse import ape.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/09/30/regime-vs-state/</link>
      <pubDate>Mon, 30 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/09/30/regime-vs-state/</guid>
      <description>Scratching out some thoughts here to address an issue that continues to bug me with the way the literature discusses these two very different issues.
The ecological literature on early warning signals and related subjects continually seems to confuse the concept of state and regime.
Let&amp;rsquo;s get this straight.
Regime $=$ Attractor
 State $\neq$ Attractor
 Nonlinear state change $\neq$ Regime shift 
Evidence that a regime shift occurred, and when the shift occurred (e.</description>
    </item>
    
    <item>
      <title>Reflections on the Mozilla Science Code Review Pilot</title>
      <link>/2013/09/25/mozilla-software-review/</link>
      <pubDate>Wed, 25 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/09/25/mozilla-software-review/</guid>
      <description>I was recently interviewed a Nature senior reporter Erika Check Hayden on the subject of the scientific code review project being conducted by Mozilla Science Lab. The piece appears in this week&amp;rsquo;s issue, Hayden 2013. My blog post sharing my own approach to code review is mentioned at the beginning of the article, though it is rather Roger Peng&amp;rsquo;s comments at the end that have stirred some interesting discussion.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/09/23/notes/</link>
      <pubDate>Mon, 23 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/09/23/notes/</guid>
      <description>nonparametric bayes Reading  Arnqvist, G. 2013 Editorial rejects? Novelty, schnovelty! Trends in ecology &amp;amp; evolution 28, 448-9. (doi:10.1016/j.tree.2013.05.007) Accounting for Complementarity to Maximize Monitoring Power for Species Management. 27, 988-999. (doi:10.1111/cobi.12092) Nes, E. H. Van, Hirota, M., Holmgren, M. &amp;amp; Scheffer, M. 2013 Tipping points in tropical tree cover: linking theory to data. (doi:10.1111/gcb.12398) Millar, R. B. 2002 Reference priors for Bayesian fisheries models. , 1492-1502. (doi:10.1139/F02-108) Mcallister, M.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/09/19/notes/</link>
      <pubDate>Thu, 19 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/09/19/notes/</guid>
      <description>writing manuscript slides data request to Glaser.
  gpdd  Global Popluation Dynamics Database initiated package rgpdd data extraction &amp;ndash; No API, but does provide direct dump in the form of a Microsoft Access mdb database. For the moment I&amp;rsquo;m using mdbtools: mdb-tables and mdb-extract to convert to CSV and then reading those into R. RODBC package installs but cannot read the database directly for me. Since data will fit into working memory no real reason to support database calls from R?</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/09/18/notes/</link>
      <pubDate>Wed, 18 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/09/18/notes/</guid>
      <description>nonparametric-bayes writing writing. see commits. Started slides for Mangel group retreat. (in progress). Working on requested review&amp;hellip; background reading too. reml read methods for data.set class, extending attributeList metadata tools.
  Scribble notes for interivew  we are where math was 400 years ago - present theorem without proof.
 code plays an ever-increasing role in our research, and hence in describing what we have done potentially the most precise and consise way to describe a method.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/09/16/notes/</link>
      <pubDate>Mon, 16 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/09/16/notes/</guid>
      <description>class=&#34;task-list&#34; finish up and push backlog of notebook updates knitcitations slidify (issue 46) recently resolved several further issues/requests with rfishbase  ropensci Have implemented a solution to extending data.frame with metadata that I was tackling the other day. This raises several open questions on how we do the implementation, including whether we restrict this extension to providing the attributeList-level metadata (or a subset thereof), or if we allow higher level nodes of eml to act as extensions of data.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/09/11/isees-workforce-development-day-2/</link>
      <pubDate>Wed, 11 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/09/11/isees-workforce-development-day-2/</guid>
      <description>Near the end of another excellent day of discussions we were asked to put pen to paper to outline our own views in writing. My own contribution was the following notebook scribble.
My own vision of what ISEES should be doing for workforce development:
ISEES would employ a multi-scale approach to improve basic computational expertise across the entire workforce necessary to fully participate in the modern software-immersed world of research through the development of training standards, while using a working-group model focused on emerging researcher-developer communities which would simultaneously improve the quality and synthesis of existing software tools while also delivering essential skills to the most transformative members of the research software communities.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/09/11/extending-data-frame-class/</link>
      <pubDate>Wed, 11 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/09/11/extending-data-frame-class/</guid>
      <description>I&amp;rsquo;d like to define a class that acts just like a data.frame, just like the data.table class does, but contains some additional metadata (e.g. the units associated with the columns) and has some additional methods associated with it (e.g. that might do something with those units) while also working with any function that simply knows how to handle data.frame objects.
How might this be done?
I&amp;rsquo;m not really sure where to start on this, so below is a summary of my attempt so far and some further puzzles I have stumbled across (e.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/09/10/isees-training-workshop-day-1/</link>
      <pubDate>Tue, 10 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/09/10/isees-training-workshop-day-1/</guid>
      <description>Education / Workforce Development Group Cannot do grand synthesis opaquely and be science. must be able to scale and evolve.
How did data succeed? What features really made the difference and what were just sideshows?
 Sticks (Funder and journal mandates?) Working groups (NCEAS) Training external forces: there is more data.
  Why one center? Why not 15 centers? Divided by discipline rather than region&amp;hellip;. synthesize the synthesis centers</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/09/09/lost-branches/</link>
      <pubDate>Mon, 09 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/09/09/lost-branches/</guid>
      <description>Just read Lost Branches on the Tree of Life in PLoS Biology and couldn&amp;rsquo;t agree more! I too am frequently frustrated by the lack of deposition or replies to email requests for data. The 16% reply rate seems consistent with other such studies. I agree with the general message that what is most needed is a cultural shift towards these expectations. I loved this paper overall but nonetheless cannot resist a few nitpicks.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/09/08/some-rfishbase-updates/</link>
      <pubDate>Sun, 08 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/09/08/some-rfishbase-updates/</guid>
      <description>Ever since writing the rfishbase package I&amp;rsquo;ve been frustrated by the lack of a proper API from Fishbase.org that would allow access to that wealth of information that is not exposed in the &amp;ldquo;Summary XML&amp;rdquo; files from which rfishbase extracts its content. Since writing the paper in Journal of Fish Biology, I continue to receive user requests asking if or how such-and-such a data element might be extracted. Usually this involves a disappointing boiler-plate reply about how the package is limited to the &amp;ldquo;Summary XML&amp;rdquo; data and that improved query potential must wait for a proper API from Fishbase.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/09/07/rnexml-milestone/</link>
      <pubDate>Sat, 07 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/09/07/rnexml-milestone/</guid>
      <description>We have also recently reached the first milestone in RNeXML. We can now read NeXML files into R and convert to the popular phylo format from the ape package, as well as writing the ape::phylo trees out into valid NeXML. We can also add basic metadata such as author, license, title and description to the file.
Development notes At the heart of this package is an internal S4 representation of the schema.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/09/06/nsf-math-bio-postdoc/</link>
      <pubDate>Fri, 06 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/09/06/nsf-math-bio-postdoc/</guid>
      <description>Guess it&amp;rsquo;s that time of year again. Just saw the reminder for this year&amp;rsquo;s RFP for NSF Biology Post-docs. As I was fortunate enough to receive one of these for the &amp;ldquo;Mathematical Biology&amp;rdquo; track through last year&amp;rsquo;s call, I have received a few requests for materials and advice. I&amp;rsquo;m not sure if I have any more insight for having received this funding, but as I appreciated the advice of others this time last year I&amp;rsquo;ll give it a shot.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/09/05/whitehouse-open-data-memorandum/</link>
      <pubDate>Thu, 05 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/09/05/whitehouse-open-data-memorandum/</guid>
      <description>Open Data Policy-Managing Information as an Asset
Far from implemented, though the tools and resources at the newly created Project Open Data (hosted on Github!) look very promising. Some choice quotations below:
Pursuant to Executive Order of May 9, 2013, &amp;ldquo;Making Open and Machine Readable the New Default for Government Information&amp;rdquo;
Any datasets in the agency&amp;rsquo;s enterprise data inventory that can be made publicly available must be listed at www.&amp;lt;agency&amp;gt;.gov/data in a human- and machine-readable format that enables automatic aggregation by Data.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/09/02/reml-milestone/</link>
      <pubDate>Mon, 02 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/09/02/reml-milestone/</guid>
      <description>Reached a milestone in reml development today with basic implementation of reading, writing, and publishing valid EML files and a working test suite.
An S4-based structure This involved a complete re-write of the pre-ESA code and is now completely S4-class based, allowing a more flexible structure that is easier and faster to extend. For instance, rather than having to explicitly think about the commands to parse and serialize a new metadata element that needs to be added from the schema, we just define the class for the object.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/08/29/notes/</link>
      <pubDate>Thu, 29 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/08/29/notes/</guid>
      <description>Digging through some old stuff in the course of correspondance on related issues, I came across a few outstanding puzzles I&amp;rsquo;ve been meaning to wrap up one day:
 Drift effecs &amp;ndash; some difficulties Waiting Time  and some actual results that could deserve some renewed attention too.
 Phase 1 Routes to branching  Also raises an interesting new question that could be addressed in this context: can we formulate a similar approach to the stochastic escape from an adaptive peak?</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/08/28/rnexml-coding/</link>
      <pubDate>Wed, 28 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/08/28/rnexml-coding/</guid>
      <description>test_ape.R unit tests now passing. Should still revise the coercion methods in nexml_write.R to something more clever. We aren&amp;rsquo;t coercing a tree to a nexml, we are building a nexml from a tree. Likewise handling the otu assignments of species names should be done directly 11:20 am 2013/08/28 start cleaning up old read/write methods obsoleted by toNeXML/fromNeXML methods 10:59 am 2013/08/28 inherited classes now replace all the original classes 10:54 am 2013/08/28 All inheritance-based classes appearing in inst/examples/trees.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/08/26/notes/</link>
      <pubDate>Mon, 26 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/08/26/notes/</guid>
      <description>misc tricks Always forget how to see the function definition of an S4 method:
showMethods(&amp;quot;xmlToS4&amp;quot;, includeDefs=TRUE)  ropensci  Closed rfigshare issue #50 Still retooling reml to S4 and ReXML to inheritance-based S4 classes building classes on the schema&amp;rsquo;s inheritance model 10:49 am 2013/08/26  In behavioral ecology we usually equate optimality with expected behavior arising from natural selection &amp;ndash; i.e. the extent to which the observed behavior deviates from the optimal behavior is assumed to be due to modeling inaccuracies (optimizing the wrong thing).</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/08/23/notes/</link>
      <pubDate>Fri, 23 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/08/23/notes/</guid>
      <description>Work Work  Finished review for R Journal (Wednesday) Finished review for TE. Began review for NSF updated service list (vita) Handling reimbursement of expenses  Misc  Whoa, we can/should now use http://doi.org instead of http://dx.doi.org  Software Sustainability materials Seems like a popular new item, listing a couple recent articles in one place here:
 Perspective in Science Magazine; also a critique and author&amp;rsquo;s rebuttal in a later edition.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/08/14/isees-day-2/</link>
      <pubDate>Wed, 14 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/08/14/isees-day-2/</guid>
      <description>Other services: Tangible infrastructure support services  Discovery registration system. Includes:  Software review and certification Use and quality metrics Ticket tracking Seed funding to join the ecosystem   Community Building  user defined registry  // Hackathon?
Consulting services  Support software lifecycle
 Function: Assist in full lifecycle software development: e.g. (and order notwithstanding) initiation, licensing, maintenance, hardening, extensible, release, decommissioning
 Mechanisms:
 Call for Proposals - to solicit consulting help (or to nominate a project to receive help) (e.</description>
    </item>
    
    <item>
      <title>ISEES software lifecycle and components workshop, Day 1</title>
      <link>/2013/08/13/isees-day-1/</link>
      <pubDate>Tue, 13 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/08/13/isees-day-1/</guid>
      <description>Range of large project to the long tail.
 statistical analyses One-off models community model Services (Blast)  Science Challenges Outcomes of previous community workshops
18 Grand Challenge areas. Highlights: Supermodels. human/biophysical systems shape and be shaped by water availability. (A vision similar to Microsoft&amp;rsquo;s &amp;ldquo;Model all Earth&amp;rdquo; Purves et al)
Functions and services areas: (priority ordering)
 Computational training (early career - all career) Assimilation and QA/QC tools Collaborative environment decisions and workflows software discovery consultants / collaborator community hub to converge on standards merging disparate tools user-friendly interfaces multiscale coupled modeling framework Software vetting (how about paper vetting?</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/08/08/esa-2013-notes-for-week/</link>
      <pubDate>Thu, 08 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/08/08/esa-2013-notes-for-week/</guid>
      <description>Sun Co-Leading the Workshop on R, DataONE and open science.
All material on github
Mon  Ives Plenary  Talking to Dave, Vasilis, Tye,
 Lunch Vasilis, Ryan Batt
 2:30 Chesson L100H / Ryan Batt L100J
 3:20 O&amp;rsquo;Regan L100H
 3:40 Adler L100H
 4 Yaekel M100HC
 ropensci meetup, funded by Github. Great turnout, great success. (And rare shot of dev team together in person).
 Theoretical ecology mixer</description>
    </item>
    
    <item>
      <title>F1000-Research publishing for ecologists</title>
      <link>/2013/08/07/f1000-research/</link>
      <pubDate>Wed, 07 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/08/07/f1000-research/</guid>
      <description>F1000-Research is waving article processing charges (APCs) for ecologists looking for an open access, open peer review platform to publish original research, null results, software papers, data papers, and an intriguing new category called &amp;ldquo;Observations&amp;rdquo;,
 to report serendipitous observations that they have not been able to study systematically, but that offer a starting point for further exploration. This is especially relevant for ecologists, as it provides a platform to report unexpected observations from the field, unrelated to the main goal of the field work.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/08/06/summarizing-earlier-warning-signal-under-control-notes/</link>
      <pubDate>Tue, 06 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/08/06/summarizing-earlier-warning-signal-under-control-notes/</guid>
      <description>NSF goals:  combine control methods and warning signals do non-parametric or machine learning increase or decrease chance of transition learning  Further areas (from comment piece) baselines (statistical; emperical) context-specific (additional data sources, reflecting context in model)  Warning signals in managed systems Management decreases the signal: compare likelihood statistic in unmanaged_warning managed_warning:
Estimating Stability in managed systems Recovery rate in optimally fished vs unfished system (based on the OU model): stability.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/08/01/notes/</link>
      <pubDate>Thu, 01 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/08/01/notes/</guid>
      <description>Registered for AmNat 2014 conference in Asilomar.
 Nice collection Data Visualization pieces from Nature Methods. vim clipboard: put older items from clipboard history using: &amp;quot;0p, &amp;quot;1p, &amp;quot;2p. See list in :reg. (from here) #ESA2013 Lotka-Volterra Talks Review methods to write S4 back to XML  from earlier:
misc reading  Duncan Hull&amp;rsquo;s Seven deadly sins of bioinformatics Carole&amp;rsquo;s Goble&amp;rsquo;s talk at ismb, as summarized in graphical form Interesting: researchobject.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/07/28/nonparametric-bayes-wrapping-up-sensitivity/</link>
      <pubDate>Sun, 28 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/07/28/nonparametric-bayes-wrapping-up-sensitivity/</guid>
      <description>Remote RStudio configuration (keep forgetting options and ports).
ssh -o &amp;quot;ExitOnForwardFailure yes&amp;quot; -f -N -L 1234:localhost:8787 one  Initialize runs for sensitivity, looping over parameters and data. See:
 sensitivity.md (Myers) sensitivity-allen.md  Overall:
ggplot(yields_dat) + geom_density(aes(value))  Compare over 12 simulation configurations with different parameters and different training data, the GP does consistently well. Only one case has relatively poor outcomes.
ggplot(yields_dat) + geom_density(aes(value, color=as.factor(simulation), fill=as.factor(simulation)), alpha=.5)   Run data backup to local disk NSF expense accounting calendar updates software paper policies email Luke Arbor reply looking at quick way to check out solutions to sums of Fisher wave equation over different diffusion coefficients (heterogenous dispersal rates), e.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/07/25/formal-semantics-with-reml/</link>
      <pubDate>Thu, 25 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/07/25/formal-semantics-with-reml/</guid>
      <description>A lot has been happening in the reml development over on our package Github page, particularly through discussion on the issues tracker we have been working through several of the major conceptual challenges in designing the package.
Semantics Writing Semantics. Lots of elements of the EML schema have semantic meaning, but we can&amp;rsquo;t start leveraging ontological tools while these terms are defined only as part of the Schema vocabulary. In their current state, they are just &amp;ldquo;meaningless bits of syntax&amp;rdquo;, e.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/07/22/xml-parsing-strategies/</link>
      <pubDate>Mon, 22 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/07/22/xml-parsing-strategies/</guid>
      <description>Writing out some advice for our GSOC student on XML parsing. (Now filed as RNeXML/#11
Here is some quick background on different ways we might go about extracting NeXML into an R object we want to work with. We can use S4 classes, R&amp;rsquo;s native data.frame and list types, or extract specific terms of interest with xpath. I illustrate each of these below using the example &amp;ldquo;trees.xml&amp;rdquo; in your repository.</description>
    </item>
    
    <item>
      <title>Notes from chat with Duncan</title>
      <link>/2013/07/19/notes/</link>
      <pubDate>Fri, 19 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/07/19/notes/</guid>
      <description>Keep metadata as part of the object Recursion problem coming up.
  Validating:  https://github.com/ropensci/reml/issues/7 Duncan has code using Matt&amp;rsquo;s java API If the EML isn&amp;rsquo;t valid, so what? Important for developers, users don&amp;rsquo;t care.
  API design  what&amp;rsquo;s with the do.call? This forces evaluation, can mess up lazyLoading, making for inefficient function handling.
 Schema to create S4 objects Create R objects first, and then toXML</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/07/17/updates-on-managing-references/</link>
      <pubDate>Wed, 17 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/07/17/updates-on-managing-references/</guid>
      <description>Mendeley API for Jekyll Finally finished off my Mendeley API for Jekyll (The top uses the Ruby API implementation from Michael Bus, copied here since it is not yet provided as a gem. scroll to the bottom for my plugin code). The Mendeley API implementation is remarkably clumsy. For instance, rather than allowing queries to the API that specify a user&amp;rsquo;s folder and a sort-by field, we are forced to first query the folder for a list of IDs and then query document details on every document in the folder, after which we can sort locally.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/07/11/visit-to-whoi/</link>
      <pubDate>Thu, 11 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/07/11/visit-to-whoi/</guid>
      <description>Presented my work from the nonparametric-bayes project, Avoiding tipping points in the management of ecological systems: a non-parametric Bayesian approach at the Woods Hole Oceangraphic Institution as part of their weekly Biology Department Seminar Series.
 9 - 9:30 Julie Kellner 9:30-10:15 Ben Jones, (Kellner group) 10:15 - 11:00 Math ecology group 11:00 - 11:30 Ian Carroll 11:30-12 Seminar prep 12-1 my seminar 1-2 Lunch with the Marine Policy Center (Mike Fogarty, Hauke Kite-Powell, Di Jin), Julie Kellner  Enjoyable visit, with some particularly great questions after talk: including challenges/opportunities in multi-dimensional examples, concerns about temporal heterogeneity, partially observed systems / working with catch data in place of stock assessment data.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/07/10/forking-the-r-journal/</link>
      <pubDate>Wed, 10 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/07/10/forking-the-r-journal/</guid>
      <description>All I really wanted to do is cite a paper in the R Journal, which is peer-reviewed, open access (CC-BY), LaTeX based and without author charges. Sure, I could do that already, but I like being able to programmatically generate citation metadata from a URL &amp;ndash; we do have this thing called the internet now, and citations are just links, right? Unfortunately, nice as it is, the R journal doesn&amp;rsquo;t have HTML landing pages for articles that embed the metadata.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/07/10/notes/</link>
      <pubDate>Wed, 10 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/07/10/notes/</guid>
      <description>PRSB paper is out.  TODO: Post to arxiv now that Drake&amp;rsquo;s side is out. Update vita. Reply to Drake. Clean up prosectors-fallacy repository. Post on paper(?)
 Note: github record of earlier version of paper turns out handy in reply, (showed earlier wording about not necessary).
 Also, some quick significance testing of distributional differences associated with the patterns we show in Figure 1, for what it&amp;rsquo;s worth (in reply to query - yay for clean workflow making this easy).</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/07/09/reviewing-software-revisited/</link>
      <pubDate>Tue, 09 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/07/09/reviewing-software-revisited/</guid>
      <description>Several weeks ago I wrote a post describing issues I commonly raise when reviewing software papers. This provoked a lively discussion among authors, editors, and other reviewers of software papers (most of us having been on at least both reviewing and authoring end), with quite varied perspectives as to whether such criteria were appropriate in this context. As I describe there, I view the concept of dedicated software papers as a somewhat necessary &amp;ldquo;hack&amp;rdquo; of the publishing system, and hope a more mature system will eventually come into place, as is now happening for data through efforts such as Dryad and associated journal archiving requirements.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/07/08/reml-update/</link>
      <pubDate>Mon, 08 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/07/08/reml-update/</guid>
      <description>Made substanial progress on the reml project. We have reached our first milestone, being able to:
 Successfully validate the EML generated (#28) Start a unit test suite write eml unit tests (#14) Extract appropriate R objects from EML dataTable read eml (#6) Add function to publish EML data through figshare publish eml (#3) Generate an EML file given a data.frame and appropriate metadata write eml (#2)  As illustrated by the example shown in the Readme:</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/06/26/starting-an-eml-package-for-r/</link>
      <pubDate>Wed, 26 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/06/26/starting-an-eml-package-for-r/</guid>
      <description>Started reml, and R package for reading, writing, manipulating and publishing EML files. More details and progress so far on the Github page; in particular flushing out design goals in the issues tracker.
Initial goals To start, I am aiming for a proof of principle case in which we can write an R data.frame into EML (issue #2), publish to a remote repository such as figshare (issue #3), and then read the data back in as the original R object types from the EML (issue #6).</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/06/24/notes/</link>
      <pubDate>Mon, 24 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/06/24/notes/</guid>
      <description>Exploring XML Schema in R I danced around the room after reading these lines in the excellent XML and Web Technologies for Data Sciences with R book:
 We can generate S4 class definitions corresponding to the data structures that are represented in the XML document. We can programmatically generate R code that will map an XML document adhering to this schema to corresponding R data structures. Similarly, we can automate the creation of code to serialize, or write, an R object of a particular type to a suitable XML format corresponding to the schema</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/06/23/notes-on-leveraging-the-ecological-markup-language/</link>
      <pubDate>Sun, 23 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/06/23/notes-on-leveraging-the-ecological-markup-language/</guid>
      <description>This post creates new tag eml for posts discussing the Ecological Markup Langauge or the implementation of an R parser thereof (reml).
Why EML? Jones et al.(2005) give an excellent explanation describing the relative advantage of the descriptive metadata approach over vertically integrated repositories (such as Genbank, TreeBase, or many other repostories that have been the focus of rOpenSci development to date).
In short, the EML approach allows archiving of very heterogeneous data without having to standardize everything into a narrow and pre-defined syntax.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/06/20/nonparametric-bayes-summary-ideas/</link>
      <pubDate>Thu, 20 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/06/20/nonparametric-bayes-summary-ideas/</guid>
      <description>If you do know the model and are simply uncertain about the parameters, you can often do all right (e.g. better than maximum likelihood approach) by doing the SDP over the Bayesian posterior distribution of the estimated model. Not surprisingly, if you don&amp;rsquo;t have the correct model, this can fail pretty dramatically (in particular in very nonlinear models, e.g. tipping point models I have been looking at). Model choice and model averaging approaches aren&amp;rsquo;t much help here, because often the structurally correct model doesn&amp;rsquo;t fit the observed data any better &amp;ndash; since the problems occur due to model inaccuracies where we don&amp;rsquo;t have data; e.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/06/18/figure-for-summarizing-simulations/</link>
      <pubDate>Tue, 18 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/06/18/figure-for-summarizing-simulations/</guid>
      <description>Trying to find a better way to summarize outputs of simulations,
Heavy over-plotting makes the simulation trajectories themselves hard to read, even with transparent curves. Instead, we can plot the cumulative profit (technically should be discounted first):
We can normalize these profits as a fraction of the theoretical optimum (true), providing a comparison that is less dependent on model parameters.
We can then attempt to plot these on a single plot, either as stacked histograms:</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/06/17/notes-for-van-noorden-chat/</link>
      <pubDate>Mon, 17 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/06/17/notes-for-van-noorden-chat/</guid>
      <description>Below are my scribble notes in prep for an interview with Richard, a writier for Nature.
 Advice for early-career scientists on how to think about organizing and publishing research data online.
Things like - why do it,
 Good for science (idealist), good for reputation (careerist), etc, but most importantly: helps you do your research.
I had the pleasure of meeting with then Secretary of Energy Stephen Chu last summer at a small Department of Energy computational science conference.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/06/13/notes/</link>
      <pubDate>Thu, 13 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/06/13/notes/</guid>
      <description>Assembling various loose ends and some ropensci work.
Misc things to work out and write at some date  Catch up on literature reading (unsorted list in Mendeley). Get entries into notebook.
 Write thoughts on selecting links anchor text in the notebook knitr script workflow: externalizing chunks, cache and figure prefixes.
 branching projects and unique repositories source code for all manuscripts into repositories clean up directories. in particular, establish separate prosecutors-fallacy repository Comments on workflow: Date-oriented (notebook) vs File-oriented (Github) explanation.</description>
    </item>
    
    <item>
      <title>What I look for in &#39;Software Papers&#39;</title>
      <link>/2013/06/13/what-i-look-for-in-software-papers/</link>
      <pubDate>Thu, 13 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/06/13/what-i-look-for-in-software-papers/</guid>
      <description>Update Thanks to the rich discussion in the comments and beyond, I&amp;rsquo;ve revised my thoughts on this somewhat, as I discuss in this more recent post.
I am more and more frequently reviewing &amp;lsquo;software papers:&amp;rsquo; which I define as publications whose primary purpose is to publicize a piece of scientific software and provide a traditional research product with hopes that it will receive citations and recognition from other researchers in grant and job reviews.</description>
    </item>
    
    <item>
      <title>manuscript reviews on github?</title>
      <link>/2013/06/10/mansucript-reviews-on-github/</link>
      <pubDate>Mon, 10 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/06/10/mansucript-reviews-on-github/</guid>
      <description>I was recently impressed to learn of Trevor Bedford&amp;rsquo;s strategy of seeking pre-approval for posting his reviewer&amp;rsquo;s comments as Github issues. Beyond providing links to the data and source-code, I generally don&amp;rsquo;t advertise the open science nature of papers I submit &amp;ndash; I guess I assume that if the reader or reviewers care, it should be easy enough for them to discover it. Consequently I am usually immediately frustrated to realize that upon receiving my reviews I have to create a second, private repository for the review material, our replies to reviewers, etc.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/06/05/semi-analytic-posteriors/</link>
      <pubDate>Wed, 05 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/06/05/semi-analytic-posteriors/</guid>
      <description>The difficulty in comparing the nonparametric Bayesian inference against parametric Bayesian inference is ensuring that the poorer performance of the latter is not do to numerical limitations of the MCMC (no one is quite so worried about the cases where the mcmc solution appears to work well&amp;hellip;) Convergence is almost impossible to truly establish, and lots of pathologies (correlations between variables, particularly without simulataneous updating) can frustrate it considerably. While multiple chains and long run times are the reasonable default, for simple enough models we can take a more direct approach.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/06/04/analytic-marginalizing-for-posteriors/</link>
      <pubDate>Tue, 04 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/06/04/analytic-marginalizing-for-posteriors/</guid>
      <description>Consider the model
$$ X_{t+1} = X_t r e^{-\beta X_t + \sigma Z_t } $$
with $Z_t$ a unit normal random variable. The likelihood of the sequence of $T$ observations of $X$ under this model is thus
$$P(X | r, \beta, \sigma) = \frac{1}{\sqrt{2 \pi \sigma^2}^{T-1}} \exp\left(\frac{\sumt^{T-1} \left(\log X{t+1} - \log X_t - \log r + \beta X_t\right)^2 }{2 \sigma^2}\right) $$
To integrate out $r$, $P(X | \beta, \sigma) = \int P(X | r, \beta, \sigma ) P&amp;reg; dr$, we&amp;rsquo;ll make this look like a Gaussian in $\log r$ by completing the square; getting the square on the outside of the sum.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/06/04/sensitivity-of-gp-comparisons-in-further-examples/</link>
      <pubDate>Tue, 04 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/06/04/sensitivity-of-gp-comparisons-in-further-examples/</guid>
      <description>Comparison of Nonparametric Bayesian Gaussian Process estimates to standard the Parametric Bayesian approach Plotting and knitr options, (can generally be ignored)
require(modeest) posterior.mode &amp;lt;- function(x) { mlv(x, method=&amp;quot;shorth&amp;quot;)$M }  Model and parameters Uses the model derived in citet(&amp;quot;10.1080/10236190412331335373&amp;quot;), of a Ricker-like growth curve with an allee effect, defined in the pdgControl package,
f &amp;lt;- RickerAllee p &amp;lt;- c(2, 8, 5) K &amp;lt;- 10 # approx, a li&#39;l&#39; less allee &amp;lt;- 5 # approx, a li&#39;l&#39; less  Various parameters defining noise dynamics, grid, and policy costs.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/06/03/admb-basic-example/</link>
      <pubDate>Mon, 03 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/06/03/admb-basic-example/</guid>
      <description>After a few iterations I have a working minimal example (below). Hoping that ADMB is a bit more robust than vanilla optim out of R as I loop over data sets for the sensitivity analysis (#32). Does not seem to hold in simple example here, not sure why.
 These notes correspond to script 84a102/admb-example.md  Learning ADMB Plotting and knitr options, (can generally be ignored)
Model and parameters f &amp;lt;- function(x,h,p) x * exp(p[1] * (1 - x / p[2]) * (x - p[3]) / p[2] ) p &amp;lt;- c(1, 10, 5) K &amp;lt;- 10 # approx, a li&#39;l&#39; less Xo &amp;lt;- 6 # approx, a li&#39;l&#39; less  Various parameters defining noise dynamics, grid, and policy costs.</description>
    </item>
    
    <item>
      <title>DOI != citable</title>
      <link>/2013/06/03/doi-citable/</link>
      <pubDate>Mon, 03 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/06/03/doi-citable/</guid>
      <description>I feel I see this kind of comment almost daily:
Is there a way to obtain DOI for a @github repository? (for citing #opensource software packages, similar to @figshare objects) #git
&amp;mdash; Ahmed Moustafa (@AhmedMoustafa) May 29, 2013 
Again and again, researchers suggest that DOI to makes something &amp;ldquo;citable&amp;rdquo;. And this frustrates me.
Don&amp;rsquo;t get me wrong. I love DOIs, and I love CrossRef. And I bang on the table when I have some old journal article that doesn&amp;rsquo;t yet have a DOI.</description>
    </item>
    
    <item>
      <title>Archiving the lab notebook on figshare</title>
      <link>/2013/05/31/notebook-features-archiving-with-figshare/</link>
      <pubDate>Fri, 31 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/31/notebook-features-archiving-with-figshare/</guid>
      <description>Robust archiving through CLOCKSS One of the most comprehensive approaches I have come across so far uses figshare. This offers the most promising avenue for content preservation, but is weakest in managing the URIs and associating them with the original content. All figshare content is archived by CLOCKSS, an international library cooperation providing redundant and geopolitically distributed backup of the archives around the world (and used by many academic journals, both subscription based &amp;amp; open access).</description>
    </item>
    
    <item>
      <title>Notebook features: digital archiving</title>
      <link>/2013/05/31/notebook-features-digital-archiving/</link>
      <pubDate>Fri, 31 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/31/notebook-features-digital-archiving/</guid>
      <description>Note: this entry is part of a series of posts which explain some of the technical features of my lab notebook.
Archival preservation of digital scholarly content is an important challenge throughout the research community. As the notebook is the permanent record of my regular scholarly endeavors, this provides the opportunity to experiment with tools and techniques for digital archiving while also better preserving the notebook. In the experimental spirit that drives all my exploration here, I am testing several ways to accomplish this.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/05/29/notes/</link>
      <pubDate>Wed, 29 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/29/notes/</guid>
      <description>nonparametric-bayes Not getting good convergence from jags models with uniformative priors without observation noise and arbitary starting postions. See examples:
 fixed myers_jags run, loads knitr_defaults 11:18 am 2013/05/29 trouble with MCMC convergence for process-noise-only: Now with longer runs and better posterior estimator. Set for run on zero. 11:01 am 2013/05/29  Also a few updates:
 slides for adp section of group meeting 11:44 am 2013/05/29 updated adp-intro 11:43 am 2013/05/29  prosecutor  Combine comment code into single file for both models: comment_reply.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/05/28/notes/</link>
      <pubDate>Tue, 28 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/28/notes/</guid>
      <description>Mangel group talk  Presented nonparametric-bayes slides ADP introduction / trouble-shooting (see yesterday&amp;rsquo;s entry), html5 slides  Notes  Decent convergence in the forward algorithm is hard. Consider basis function representation of value function to decrease the search space in the backwards-algorithm first. Also consider searching for policy function (under appropriate piecewise constraints). Starts to sound more and more similar to POMDP  Misc  Trouble with equations in slidify/214 Finishing up posts from last week</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/05/27/exploring-approximate-dynamic-programming-approaches/</link>
      <pubDate>Mon, 27 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/27/exploring-approximate-dynamic-programming-approaches/</guid>
      <description>Introductory examples in approximate dynamic programming Based on Powell 2006, page 97. I try to conform to that notation throughout. Haven&amp;rsquo;t really figured this out yet, so this is more a walk through of me thinking this out then a tutorial. My active copy of this analysis can be found in the adp-intro file of my nonparametric-bayes repo, see there for the most recent (or earlier) versions.
Setup my sample problem First we define the Beverton-Holt stock-recruitment relationship as a function of stock size x, harvest h and parameters p</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/05/24/notes/</link>
      <pubDate>Fri, 24 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/24/notes/</guid>
      <description>prosecutor  Bit more writing on comment reply. Sent to Alex and Alan for feedback.  nonparametric-bayes Demonstrating robustness of the GP approach is remarkably difficult ironically because the comparison methods are not particularly robust; most often due to poor initial conditions. Doing all I can to make the MLE and parametric Bayesian cases suitably automated such that the can give reasonable performance as I loop over various simulation parameters and models without much hand-holding of each of the estimators.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/05/23/notes/</link>
      <pubDate>Thu, 23 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/23/notes/</guid>
      <description>Added multiple chains, randomized starting points for each chain, and confirming Gelman-Rubin convergence criteron via autojags.
 Some edits to adapt the extraction of posteriors from the multiple chains.
 Stange behavior in jags.parallel SO/16723036, looks like an annoying bug. Ah-ha, and now a nice solution to this problem via do.call.
  When running on farm, try to remember: (yes it&amp;rsquo;s in the run.sh script already).
module load gcc R jags  This appears to result in greater uncertainty:</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/05/22/notes/</link>
      <pubDate>Wed, 22 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/22/notes/</guid>
      <description>Nonparametric-bayes  Establishing chunck dependencies, simplifying and abstracting code.
 still need to fix up Allen MCMC convergence when underlying model is Myers 10:18 am 2013/05/22
 replicate runs on data from allen and myers model 08:39 pm 2013/05/21
  Clean code for complicated scripts Pseudo-code somewhat captured by the chuncks. Ideal would be:
 Define models Define parameters Simulate data Estimate MLE Estimate under GPP Allen MCMC Ricker MCMC Myers MCMC Determine optimal policy for each&amp;hellip; Simulation Graphs  A preponderance of preprint servers Having sent in my review for IEE, do I also post it on the peerJ preprint?</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/05/21/comforting-trends-in-scientific-software-use/</link>
      <pubDate>Tue, 21 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/21/comforting-trends-in-scientific-software-use/</guid>
      <description>Author&amp;rsquo;s Note: Having refrained from actually posting this for 8 months, as I think I have quite mellowed more my critique. I do believe that education and peer review are the best way forward in tackling these issues, but cannot overstate how much of a long and rocky road that process will be. The Mozilla Science Foundation is really leading these efforts with their code review pilots (as I have discussed in posts since writing this), and through their work with Software Carpentry training.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/05/20/notes/</link>
      <pubDate>Mon, 20 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/20/notes/</guid>
      <description>EWS TE revisions  Finalized manuscript(?) Checking references, reply letter, closing remaining issues.
 Very annoying to submit to a journal system that takes LaTeX but not any external style or class file dependencies. For instance, how does one add two footnotes to the same author without adding any such dependencies (oh, and writing macros that do not involve pairs of $ which pandoc mistakes for its own macros&amp;hellip;) Reasonable author affiliations done otherwise using \and, \thanks, and \footnotemark; see [simple.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/05/17/null-distribution-width-minor-puzzle/</link>
      <pubDate>Fri, 17 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/17/null-distribution-width-minor-puzzle/</guid>
      <description>A quick foray into trying to understand why I see the wider distribution (though still symmetric) in the null of the OU model then in the null from the Allee model in the Prosecutor&amp;rsquo;s fallacy.
Load the original run of the ou model and increase the nulldt data frame to use all points instead of a sample of length 5000
load(&amp;quot;beer_run.rda&amp;quot;) ou_dat &amp;lt;- dat ou_null &amp;lt;- nulldat #ou_null_ts &amp;lt;- nulldt null &amp;lt;- timeseries #[1000:6010,] null &amp;lt;- as.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/05/16/notes/</link>
      <pubDate>Thu, 16 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/16/notes/</guid>
      <description>Prosecutor  Add figures for both examples with and without ASS text to accomidate both examples ROC curves? proof-reading  ews-review  looking over revisions, touch-ups See issues log for details  Links  Impressive set of tools provided by the Whitehouse open data project In particular, see the tool for generating a RESTful API from CSV files and the &amp;ldquo;common core&amp;rdquo; metadata definitions. Notebook complies with many of these (throught the Dublin core RDFa), but looks like I could benefit from adding some more terms from the Data Catalog Vocabulary.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/05/14/notes/</link>
      <pubDate>Tue, 14 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/14/notes/</guid>
      <description>Exploring potential plots that would allow for some visualization of the uncertainty in each of the models. Example follows up on analysis of e97043d/allen.md, as also in the script from b5d78b9/step_ahead_plots.md
One-step ahead predictor plots and forecasting plots Set our usual plotting options for the notebook
opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE, comment = NA, fig.width = 7, fig.height = 4) library(ggplot2) opts_knit$set(upload.fun = socialR::flickr.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/05/13/notes/</link>
      <pubDate>Mon, 13 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/13/notes/</guid>
      <description>Prosecutor&amp;rsquo;s Fallacy comment  Fallacy comment revisions Comment reply letter (draft) ROC curves instead? (examples) Add example of system with an alternative stable state?  Policy costs (pdg-control)  touched up tex document following Paul&amp;rsquo;s edits (mostly reflects comments and decisions from Meeting 3). Reminder of why collaborating on TeX documents can be annoying even when co-authors are tex-literate. Attempted quick conversion to markdown but mapping is troublesome.
  Misc  Some software providing rather impressive/high fidelity pdf to html conversion&amp;hellip; Not just rendering as images &amp;ndash; the text is searchable, though in the html source it just looks like a bunch of binary data URIs.</description>
    </item>
    
    <item>
      <title>Prep for ERE talk</title>
      <link>/2013/05/09/notes/</link>
      <pubDate>Thu, 09 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/09/notes/</guid>
      <description>Talk prep  Finished preparing slides for Environmental Resources Economics talk  Toying around with animations for final plots. Building up plot by subsetting progressively more of the data each time is a bit of a nuciance (both in coding and efficiency). Can convert replicates to characters and assign as a data.table key for fast join subsetting, but straight-forward subsetting seems best (e.g. once we want reps 1:5 from both &amp;ldquo;True&amp;rdquo; and &amp;ldquo;Ricker&amp;rdquo; models, dt[J(c(&amp;quot;True&amp;quot;, &amp;quot;Ricker&amp;quot;), as.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/05/07/notes/</link>
      <pubDate>Tue, 07 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/07/notes/</guid>
      <description>Monday  MacKenzie meeting paperwork to Marc paperwork to Karthik Writing  Tuesday Log  Weak thresholds example &amp;ndash; no cost but no profit if stocks are reduced below a certain threshold 09:31 pm 2013/05/07 example using short (20 pts) observation period 02:00 pm 2013/05/07 subset plotting of simulations (for slides potentially) 02:00 pm 2013/05/07 script for the parallel analysis based on policy thresholds 01:59 pm 2013/05/07 short vs long observation time runs 12:54 pm 2013/05/07 online example of replicates comparing all models 12:28 pm 2013/05/07  Misc  latex templates for UCSC AMS dept Gosh sometimes it&amp;rsquo;s nice to be officially in a department that understands tex.</description>
    </item>
    
    <item>
      <title>Notebook features: SHA Hashes</title>
      <link>/2013/05/03/notebook-features-hashes-providing-an-immutable-and-verifiable-research-record/</link>
      <pubDate>Fri, 03 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/03/notebook-features-hashes-providing-an-immutable-and-verifiable-research-record/</guid>
      <description>Note: this entry is part of a series of posts which explain some of the technical features of my lab notebook.
I version manage all changes to my entry using git. Each page is linked to its source history on Github, which will display a list of all previous edits to the post with an easy-to-read commit log and highlighted diffs. A version history is often considered an essential part of an open lab notebook, where changes to the notebook are documented and preserved.</description>
    </item>
    
    <item>
      <title>Reading and potential examples for talk to ERE next week</title>
      <link>/2013/05/03/notes/</link>
      <pubDate>Fri, 03 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/03/notes/</guid>
      <description>Parametric Bayesian comparisons  Added parameteric Bayesian version of Ricker to the set of comparisons, see allen.Rmd Adjusted thinning of posterior sample before determining optimum of GP  Reading / Examples Need a nice set of basic fisheries examples involving potential tipping points for ERE talk. hmm.
 As mentioned in Worm et al. (2009) . Algal-reef example from Aronson &amp;amp; Precht (2000) Fish collapse following reef distruction Paddack et al.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/05/02/musings-on-conservation-literature/</link>
      <pubDate>Thu, 02 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/02/musings-on-conservation-literature/</guid>
      <description>Just because I&amp;rsquo;m a theorist deeply entrenched in methodological concerns about uncertainty and decision making doesn&amp;rsquo;t mean I don&amp;rsquo;t think about practical conservation from time to time. Some musings from my comment here, copied over for my own reference.
Though I would like to believe the gap stems from the problems you discuss, I think that differing objectives between research and application may play a much larger role. I suspect that scientific papers that are most useful and influential for conservation practitioners and policymakers are those which confirm what they already believe, or whatever the interests opposed to them least want to hear.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/05/02/scholarly-infrastructure-thoughts/</link>
      <pubDate>Thu, 02 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/02/scholarly-infrastructure-thoughts/</guid>
      <description>Sustainable Research Happened across a provocative example of why we need a software ecosystem, though it was certainly not intended to be one, which led me to ask myself:
 How complex does an algorithm have to be before a talented researcher with expertise in both the relevant mathematics and computer science will make a significant mistake in their first release of the software?
 As a corollary we might also ask, &amp;ldquo;How much less care do we put into research code not destined for release?</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/05/01/bayesian-gp-regression-by-metropolis-hastings/</link>
      <pubDate>Wed, 01 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/01/bayesian-gp-regression-by-metropolis-hastings/</guid>
      <description>(Development version for reference; code functions now in R/gp_mcmc.R)
Function definitions library(mcmc) #&#39; Basic regression in Gaussian processes #&#39; #&#39; #&#39; @param x Observed x values, (vector or matrix with columns for each dimension of data) #&#39; @param y Vector of observed y values in the training data #&#39; @param init_pars the initial guesses for lengthscale l and process noise sigma_n #&#39; @param n iterations of the metropolis algorithm #&#39; @details Currently assumes the covariance function.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/05/01/integrating-over-posterior-gp/</link>
      <pubDate>Wed, 01 May 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/05/01/integrating-over-posterior-gp/</guid>
      <description>Added integration over the posterior distribution of the GP
 Added example of parametric Bayesian inference based on Ricker
  Log  varying parameters 06:07 pm 2013/05/01 example based on gp means 03:44 pm 2013/05/01 run means example as separate script 02:55 pm 2013/05/01 compare against just using means 02:52 pm 2013/05/01 Merge branch &amp;lsquo;master&amp;rsquo; of github.com:cboettig/nonparametric-bayes 02:26 pm 2013/05/01 Merge branch &amp;lsquo;master&amp;rsquo; of github.com:cboettig/nonparametric-bayes 02:23 pm 2013/05/01 add gp posteriors to package 02:16 pm 2013/05/01 staging run for integrating over GP posterior (large memory reqs) 02:13 pm 2013/05/01 updated example of gp basics includes mcmc and shows influence of the prior 01:15 pm 2013/05/01 example testing new routine 01:14 pm 2013/05/01 tidying repo 01:07 pm 2013/05/01 merge analyses back into allen.</description>
    </item>
    
    <item>
      <title>Difficulties with tgp; taking custom mcmc approach for GPs</title>
      <link>/2013/04/30/tgp-difficulties-and-custom-mcmc-for-gp/</link>
      <pubDate>Tue, 30 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/30/tgp-difficulties-and-custom-mcmc-for-gp/</guid>
      <description>Running into some unpredictable and not consistently replicable memory errors in the tgp function calls. Also rather troublesome that return object provides only posterior means for the process mean and covariance matrix.
Generic GP methods  Implemented MCMC sampler. Excerpt below based on my gaussian-process-basics.md script, as updated to include this case.
  Define some example priors
lpriors &amp;lt;- function(pars){ d.p &amp;lt;- c(5, 5) s2.p &amp;lt;- c(5, 5) prior &amp;lt;- unname( dgamma(exp(pars[1]), d.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/04/29/finishing-comparison-parametric-and-nonparametric/</link>
      <pubDate>Mon, 29 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/29/finishing-comparison-parametric-and-nonparametric/</guid>
      <description>Implemented in BUGS/allen.md
Inverse gamma priors on variances 36888da Uniform prior on standard deviations 75df941 Mean plot for parametric fit 75df941 [x] Convergence diagnostics for both parametric and nonparametric MCMC, using similar visual layout 75df941
 Oh, Jeromy Anglim has a rather nice collection of jags links
  On Variance Priors for the Parametric MCMC  Gelman recommends uniform priors on standard deviations for the noise terms: in the .</description>
    </item>
    
    <item>
      <title>A comparison of nonparametric Bayesian Gaussian process estimates to standard the parametric Bayesian approach</title>
      <link>/2013/04/27/comparison-of-nonparametric-and-parametric-approaches/</link>
      <pubDate>Sat, 27 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/27/comparison-of-nonparametric-and-parametric-approaches/</guid>
      <description>Load necessary libraries,
library(pdgControl) # custom SDP functions library(nonparametricbayes) # custom library(reshape2) # data manipulation library(data.table) # data manipulation library(plyr) # data manipulation library(ggplot2) # plotting library(tgp) # Gaussian Processes library(MCMCpack) # Markov Chain Monte Carlo tools library(R2jags) # Markov Chain Monte Carlo tools library(emdbook) # Markov Chain Monte Carlo tools library(coda) # Markov Chain Monte Carlo tools  Plotting and knitr options, (can generally be ignored)
library(knitcitations) opts_chunk$set(tidy = FALSE, warning = FALSE, message = FALSE, cache = FALSE) opts_knit$set(upload.</description>
    </item>
    
    <item>
      <title>Notebook features: an introduction</title>
      <link>/2013/04/26/notebook-features-introduction/</link>
      <pubDate>Fri, 26 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/26/notebook-features-introduction/</guid>
      <description>In keeping this open lab notebook, I have sought to address three goals (in addition to all the traditional reasons for keeping a lab notebook)
 Provide an educational resource Experiment with scientific infrastructure and tools for sharing and replicating research Facilitate the rapid and open dissemination of scientific research  which are coincidentally evocative of NSF&amp;rsquo;s Broader Impacts areas. In this series of posts I plan to explore and illustrate some of my experiments to address these goals through various web-based tools available for an open notebook platform.</description>
    </item>
    
    <item>
      <title>Notebook features: reproducible code</title>
      <link>/2013/04/26/notebook-features-reproducible-code/</link>
      <pubDate>Fri, 26 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/26/notebook-features-reproducible-code/</guid>
      <description>I now use the dynamic documentation software called knitr to write most entries that shore results and figures. The code to replicate the results is included automatically, ensuring that what I say I did and what code I actually ran to get the results are consistent. Though I have written about knitr before, both regarding its use in my notebook and in my manuscripts, here I provide a quick summary of how a reader might actually reproduce a figure or result they come across in the notebook, as well as some of the possible problems involved.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/04/25/notes/</link>
      <pubDate>Thu, 25 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/25/notes/</guid>
      <description>finish pmc post from Tuesday (done).
 Submit comment reply (done).  Nonparametric-bayes  Finishing up parametric vs nonparametric Bayes comparison runs Need to add parametric Bayesian mean to the state-space diagram, fig 1 Compare with uniform priors on inverse standard deviations (precision) Sensitivity analysis mcmc convergence analysis for both Bayesian approaches See allen.md example scripts in BUGS/, adapted to post soon  Code tricks Plotting tricks
 Selecting the order in the simulation legend requires declaring the model types as an ordered factor instead of a character,  dt$method = factor(dt$method, ordered=TRUE, levels=names(OPT))  and then set custom colors and match colors to the desired factor labels with scale_colour_manual, and override alpha for legends,</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/04/24/empirical-demonstration-of-that-clever-derivation/</link>
      <pubDate>Wed, 24 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/24/empirical-demonstration-of-that-clever-derivation/</guid>
      <description>Another unexpected gem from keeping an online notebook: Empirical evidence for the expected escape time problem! Getting to that in a moment&amp;hellip;.
After Marc pointed out to me that there is a clever analytic demonstration to back my claims about realized exit times being fast (posted earlier in my notebook under the title, a clever derivation of realized escape times, I&amp;rsquo;ve enjoyed a bit of a tangent in understanding this result that has long since been worked out by mathematicians but appears to be periodically rediscovered in ecological and evolutionary work in the most delightful ways.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/04/23/we-need-more-object-oriented-design-in-comparative-methods/</link>
      <pubDate>Tue, 23 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/23/we-need-more-object-oriented-design-in-comparative-methods/</guid>
      <description>The bad news is that the latest Geiger version (which is much improved in all respects) breaks my little pmc package, owing to changes in how fitContinuous output is structured. The good news is that the new geiger is much better than the old one, and that the pmc package is pretty trivial. So this should not be read as a complaint, but I think as a scientific developer community as a whole we could learn a few simple lessons here, which can help our code more reproducible and extensible.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/04/19/bayesian-parametric-uncertainty-sdp/</link>
      <pubDate>Fri, 19 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/19/bayesian-parametric-uncertainty-sdp/</guid>
      <description>Adapting the parametric uncertainty represented by the posterior distributions of the Bayesian estimate (see earlier notes) to the stochastic dynamic programming solution for the optimal policy. Simply requires evaluating the expectation over the distribution, but is computationally intensive given the spread and the three parameters.
f_transition_matrix &amp;lt;- function(f, p, x_grid, h_grid, sigma_g, pardist){ lapply(h_grid, par_F, f, p, x_grid, sigma_g, pardist) } par_F &amp;lt;- function(h, f, p, x_grid, sigma_g, pardist, n_mc = 100){ # Set up monte carlo sampling d &amp;lt;- dim(pardist) indices &amp;lt;- round(runif(n_mc,1, d[1])) # Compute the matrix F_true &amp;lt;- sapply(x_grid, function(x_t){ # For each x_t bypar &amp;lt;- sapply(indices, function(i){ # For each parameter value p &amp;lt;- unname(pardist[i,c(4,1,5)]) # parameters for the mean, at current sample mu &amp;lt;- f(x_t,h,p) est_sigma_g &amp;lt;- pardist[i,2] # Variance parameter if(snap_to_grid(mu,x_grid) &amp;lt; x_grid[2]){ # handle the degenerate case out &amp;lt;- numeric(length(x_grid)) out[1] &amp;lt;- 1 out } else { out &amp;lt;- dlnorm(x_grid/mu, 0, est_sigma_g) } }) ave_over_pars &amp;lt;- apply(bypar, 1, sum) # collapse by weighted average over possible parameters ave_over_pars / sum(ave_over_pars) }) F_true &amp;lt;- t(F_true) } snap_to_grid &amp;lt;- function(x, grid) sapply(x, function(x) grid[which.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/04/18/notes/</link>
      <pubDate>Thu, 18 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/18/notes/</guid>
      <description>Misc coding  knitcitations handling of html formatting in tooltip: html inside the tag must needs be escaped. knitcitations/#37
 pmc functions
  hmm.. how do we easily wrap a function such that it returns its arguments (given and default) in a named list (appropriate for do.call(function_name, args_list))? match.call() inside the function will give the literal string of how the function was called, which, if evaluated in the same environment with same variables in working space, will return the same results, but doesn&amp;rsquo;t lend itself to updating any one of those arguments.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/04/17/notes/</link>
      <pubDate>Wed, 17 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/17/notes/</guid>
      <description>warning-signals  Finishing up edits. Writing PRSB reply  Logistics  In tomorrow&amp;rsquo;s Marc meeting, check in about what to include for the CSTAR report manuscript / analysis updates Comments on recent lit?  ropensci  treebase/#4  Reading  Dai et. al. (2013) , with introductory piece by Carpenter (2013) . In this they look only at the spatial extent of a perturbation. Presumbably one might attempt to compare the spatial extent over time to establish a baseline, or otherwise identify a control system.</description>
    </item>
    
    <item>
      <title>a few notes on various projects</title>
      <link>/2013/04/16/notes/</link>
      <pubDate>Tue, 16 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/16/notes/</guid>
      <description>warning-signals  Working on revisions for ews-review Grr, the challenges of open science &amp;ndash; can&amp;rsquo;t stick confidential reviews in ews-review repo where they belong, or track them on the issues tracker, without disclosing their contents. What are the terms of use for these things anyhow&amp;gt;
  phylogentics / pmc  Apparently pmc does have users &amp;ndash; at least one recognized that my Vignette is broken following the latest Gieger update.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/04/15/notes/</link>
      <pubDate>Mon, 15 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/15/notes/</guid>
      <description> class=&#34;task-list&#34; TE revisions [x] PRSB reply
 [x] Finish bayes parametric example
 [x] Ideas in Ecology &amp;amp; Evolution Review
 [x] Finish recent posts for this week
 [x] Finish tutorial post for Vasilis
 [x] Move the Bayesian parametric example into project repo
 [x] Update CV for Susan for processing appt (see list)
 [x] Alistair review
 [ ] PMC update
  </description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/04/12/parametric-bayesian-example/</link>
      <pubDate>Fri, 12 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/12/parametric-bayesian-example/</guid>
      <description>As discussed with Marc in yesterday&amp;rsquo;s meeting, it would be useful to compare the Gaussian process, as a nonparametric Bayesian estimate, to the optimal management solution under a parametric Bayesian case, e.g. with the correct underlying model. This is implemented in BUGS (jags) through the R interface as described in Bolker B, Gardner B, Maunder M, Berg C, Brooks M, Comita L, Crone E, Cubaynes S, Davies T, de Valpine P, Ford J, Gimenez O, Kery M, Kim E, Lennert-Cody C, Magnusson A, Martell S, Nash J, Nielsen A, Regetz J, Skaug H and Zipkin E (2013).</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/04/11/tutorial-on-likelihood-and-roc-methods-for-early-warning-signals/</link>
      <pubDate>Thu, 11 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/11/tutorial-on-likelihood-and-roc-methods-for-early-warning-signals/</guid>
      <description>In this tutorial we walk through how to use the likelihood-based approach of Boettiger &amp;amp; Hastings (2012) to provide an early warning signal for a critical transition, and how to generate ROC curves discussed in the same paper for comparing different early warning signals. Context and details about the methodology are presented in the paper; here we focus on using the methodology provided in the accompanying R package. All of the examples shown here can be reproduced by pasting the code provided into an R terminal.</description>
    </item>
    
    <item>
      <title>nonparametric-bayes: framing the issues for the manuscript</title>
      <link>/2013/04/11/nonparametric-bayes-framing-the-issues/</link>
      <pubDate>Thu, 11 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/11/nonparametric-bayes-framing-the-issues/</guid>
      <description>Marc meeting: nonparametric-bayes manuscript Very good meeting today going over some big picture considerations in the presentation of the nonparametric-bayes manuscript with Marc. (Also see new entries in issues log on nonparametric-bayes.) Make it clear that we are making a point rather than providing a tool. Focus on the tipping point context rather than the general management context.
 Comparison against a parametric Bayesian model (40) Comparison against an active learning parametric model facing a tipping point (41)  Parametric Bayesian model Drafting parametric Bayesian case for comparison, following Marc&amp;rsquo;s suggestion.</description>
    </item>
    
    <item>
      <title>Notebook tweaks: APIs in Ruby, Github hosting</title>
      <link>/2013/04/10/fun-and-not-so-fun-with-bibliographic-apis/</link>
      <pubDate>Wed, 10 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/10/fun-and-not-so-fun-with-bibliographic-apis/</guid>
      <description>Crossref API and Faraday Looking at automating vita entries. The faraday gem looks like a nice general tool for API queries in Ruby (ht Martin Fenner)
 Example exploration  Mendeley API and omniauth  Omniauth appears to be a solution for Rails apps only? Not clear if it can be used in vanilla Ruby. Still stumped by this case; question on SO  Bisonomy and its API  RSS feeds too, e.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/04/05/a-clever-derivation-on-realized-escape-times/</link>
      <pubDate>Fri, 05 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/05/a-clever-derivation-on-realized-escape-times/</guid>
      <description>I have often observed (e.g. Boettiger &amp;amp; Hastings (2012) ) that if purely stochastic transitions out of a potential well happen, then they happen fast (dispite the fact that waiting time for them to happen is very long). Yesterday Marc mentioned an interesting proof of this from Don Ludwig, who was able to show that the waiting time to reach a large deviation in a time $t$, given that it reaches it at all, is of the same order as the return time from the large deviation to the equilibrium, $\log(L/\sigma)$.</description>
    </item>
    
    <item>
      <title>Notebook Features: parsing linked data in the semantic notebook</title>
      <link>/2013/04/04/notebook-parsing/</link>
      <pubDate>Thu, 04 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/04/notebook-parsing/</guid>
      <description>In a post a while back I originally put forward the idea of a semantic lab notebook. Semantics, or linked data, are among the most powerful concepts to emerge in online science for scholarly data organization and communication. I have slowly been adding and exploring new ways to introduce semantic concepts into the notebook, which I have documented along the way under my #semantics tag. In this post, rather than discuss how to generate the semantic data, I try to focus on some of the things we can do with it.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/04/03/further-examples-managing-tipping-points-with-gp/</link>
      <pubDate>Wed, 03 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/03/further-examples-managing-tipping-points-with-gp/</guid>
      <description>See also:
 http://www.carlboettiger.info/2012/12/20/results-comparing-gp-to-parametric.html  Example with fixed priors on hyperparameters, fixed model type.
#inv gamma has mean b / (a - 1) (assuming a&amp;gt;1) and variance b ^ 2 / ((a - 2) * (a - 1) ^ 2) (assuming a&amp;gt;2) s2.p &amp;lt;- c(5,5) tau2.p &amp;lt;- c(5,1) d.p = c(10, 1/0.1, 10, 1/0.1) nug.p = c(10, 1/0.1, 10, 1/0.1) # gamma mean s2_prior &amp;lt;- function(x) dinvgamma(x, s2.p[1], s2.p[2]) tau2_prior &amp;lt;- function(x) dinvgamma(x, tau2.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/04/02/monday---tuesday/</link>
      <pubDate>Tue, 02 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/04/02/monday---tuesday/</guid>
      <description>Writing  still working on non-parametric bayes draft today..  Reviewing  review sent to PRSB  Reading  Came across this rather nice summary of big data in Ecology through some buzz in the twittersphereHampton et. al. (2013) .
 More fishery managment controversy with Halpern et. al. (2013) critiquing the &amp;lsquo;ocean food provision index&amp;rsquo; from Nature last year, and a subset of that team replying Halpern et. al.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/03/26/research/</link>
      <pubDate>Tue, 26 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/03/26/research/</guid>
      <description>nonparametric-bayes writing writing &amp;hellip;
multiple-uncertainty Fixed matlab implementation. (Some fun with matrix transposes in translating from R. #4) See:
 multiple-uncertainty.m example  Compare to
 R algorithm example  Matlab code shows the same pattern in which growth noise results in constant escapement, but either implementation or measurement noise cause deviations from this rule (most dramatic in the case of implementation uncertainty).
Notebook Some feedback and ideas from Noam, such as landing pages #77 and inline intro #78.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/03/25/research/</link>
      <pubDate>Mon, 25 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/03/25/research/</guid>
      <description>Reading  (Schreiber &amp;amp; Killingback, 2013 ) (Warren, 2013 )  Notebook  Added SHA hashes. See notebook Issues #67 for details. modification date. #74, also involved resolving page path robustly, #73 analytics on history button, layout #72 push dreamhost-based images to flickr See #75  prosecutor Run with OU based data. Draw from sde package.
Packages Knitcitations  Feature request for additional markup for page ranges #32  rfigshare  Handle pull request for rfigshare  code-tricks: notes on merging select files from pull request Pull request included changes to files we don&amp;rsquo;t want to change.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/03/22/research/</link>
      <pubDate>Fri, 22 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/03/22/research/</guid>
      <description>multiple-uncertainty  Fixed issues with translation to matlab and applyfun. Element-wise calls can use meshgrid arguments directly, and one can force functions to use element-wise operations with bxfun. So the following are equivalent: :  [X, Y] = meshgrid(x,y) applyfun(@min, X, Y)  or
function out = element_min(x,y) bxfun(@min, x, y) element_min(X, Y)  Meanwhile my challenge with additional arguments to applyfun can be circumvented with an inline function,</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/03/20/research/</link>
      <pubDate>Wed, 20 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/03/20/research/</guid>
      <description>pomp Exploring pomp for examples tomorrow. See pomp-example
 To access help on S4 methods  print method source code: getMethod(&amp;quot;simulate&amp;quot;, &amp;quot;pomp&amp;quot;) access help file on available methods: method?show(&amp;quot;pomp&amp;quot;)  pomp simulate method returns object of class pomp with data in object@data, unless user sets either/both of obs=TRUE and state=TRUE to return the observed and true state data (in list objects). Seems to be the only way to get the true state data out of the simulate routine (other than shortcutting the observation method rmeasure).</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/03/19/prosecutor-fallacy-as-large-deviations/</link>
      <pubDate>Tue, 19 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/03/19/prosecutor-fallacy-as-large-deviations/</guid>
      <description>(Corresponds to commit 4bd8422107 in earlywarning repo)
For the individual-based simulation, the population dynamics are given by
$$\begin{align} \frac{dP(n,t)}{dt} &amp;amp;= b{n-1} P(n-1,t) + d{n+1}P(n+1,t) - (b_n+d_n) P(n,t), b_n &amp;amp;= \frac{e K n^2}{n^2 + h^2}, d_n &amp;amp;= e n + a, \end{align}$$
which is provided by the saddle_node_ibm model in populationdynamics.
For each of the warning signal statistics in question, we need to generate the distibution over all replicates and then over replicates which have been selected conditional on having experienced a crash.</description>
    </item>
    
    <item>
      <title>Collected notes from past few days</title>
      <link>/2013/03/19/collected-notes/</link>
      <pubDate>Tue, 19 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/03/19/collected-notes/</guid>
      <description>Friday  some ropensci coordination Adapt basic science abstract and broader impacts statement some writing on notebook features draft nonparametric writing!  Monday  nonparametric-bayes writing. Combining my generic position piece (beyond-mechanistic-models.Rmd) with the technical nonparametric-bayes writeup (nonparametric-bayes.Rmd) to get a more general-audience paper.
 ropensci reviewing Note: annoying feature of knitr&amp;rsquo;s purl: appears to generate valid &amp;ldquo;external&amp;rdquo; knitr code, but includes all options in comment headers instead of just the chunk names.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/03/14/notes/</link>
      <pubDate>Thu, 14 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/03/14/notes/</guid>
      <description>Writing  Meeting with Steve over outline Writing on nonparametric-bayes manuscript A few notes on notebook-features draft  Reading  EasyABC by Jabot et. al. (2013). While it&amp;rsquo;s great that MEE publishes this stuff, this is unique in that the authors are updating and improving upon an existing package published by MEE the year before, Brook et. al. (2013). The authors of the recent manuscript have certainly made an important contribution which deserves the traditional recognition provided by a separate publication, but one must wonder why we need another package instead of building on the existing one.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/03/13/notes/</link>
      <pubDate>Wed, 13 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/03/13/notes/</guid>
      <description>Multiple-uncertainty  Created smaller version of table to simplify comparisons Switched to stationary policy comparisons only. (Running out over longer time shifts total value a bit but doesn&amp;rsquo;t amplify scale of the differences much) Larger noise amplifies the effects (compare 0.3 levels to 0.5 levels) note that averaging over replicates gives rather consistent means. The differences between successive runs of the algorithm give results agreeing to the tenths place at least.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/03/12/notes/</link>
      <pubDate>Tue, 12 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/03/12/notes/</guid>
      <description>Monday  multiple_uncertainty abstract Meeting with Robin Snyder application writing  Tuesday Morning  applications Coordinating summer conference travel ropensci proposals EML is not an ontology, not analgous to Dublin Core, etc. Just an XML schema. see OBOE for an ecological ontology. to explore later.
  Afternoon multiple-uncertainty  Revisiting multiple-uncertainty runs. Running smaller table example. Recoded script to allow arbitrary set of noise configurations to be consistently compared.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/03/08/notes-from-the-week/</link>
      <pubDate>Fri, 08 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/03/08/notes-from-the-week/</guid>
      <description>(Working from Galveston this week while at Louise&amp;rsquo;s conference, looking after little one. some progress below.)
Monday Alan Skype meeting  Comment piece / reply ews-review Comments on TE review? IARPA Conference, funding options?  Tasks  On Marc&amp;rsquo;s suggestion, writing comparison of pattern-based and mechanism based approaches to modeling, particularly in decision theory context. draft in nonparametric-bayes Review edits and writing on ews-review  Tuesday Kathy Skype  Decision theory in early warning signals?</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/03/02/delayed-release-archives/</link>
      <pubDate>Sat, 02 Mar 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/03/02/delayed-release-archives/</guid>
      <description>Today I dug out a handful (37) posts from the past two years that were published as #delayed-release content (and have all been tagged as such to indicate they were not public at their publication date). Many of these were connected to the #warning-signals project but involved results that I or Alan weren&amp;rsquo;t ready to provide ahead of publication, as I discussed in a post when I first began marking some posts for delayed release, challenges with collaboration in open science These posts were created while on the Wordpress platform and had been marked private, so that they would be invisible to public browsing.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/02/28/notes/</link>
      <pubDate>Thu, 28 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/02/28/notes/</guid>
      <description>Meeting with Marc Selection of problem: consider simpler models only. Sep through complexity hierarchy at the beginning:
 classical approaches are to fix relationship of stock recruitment.
 parameter uncertainty Gaussian processes for model uncertainty  The Discussion section can deal with model uncertainty model choice approaches.
 A method where we don&amp;rsquo;t have to assume the stock recuritment relationship How well we can do with that.
 How much data we need.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/02/27/notes/</link>
      <pubDate>Wed, 27 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/02/27/notes/</guid>
      <description>Reviewing arg, reviewing. so much time.
Seminar Kate Richerson gave a fanstastic presentation to mega group yesterday showing her integration of behavior and dispersal in krill dynamics. She derives the krill&amp;rsquo;s behavioral movement patterns through a stochastic dynamic programming solution rather than just dictate it to the dispersal model directly.
Reading .
 Provicative stuff in PNAS Perretti et. al. (2013). It would be nice to see the comparison against the generating model.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/02/22/semantic-citations-for-the-notebook-and-knitr/</link>
      <pubDate>Fri, 22 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/02/22/semantic-citations-for-the-notebook-and-knitr/</guid>
      <description>I have on ocassion been exploring the use of semantic markup in the notebook. In this post I illustrate how I am handling semantic citations. One of the more intriguing ideas is the ability to add semantic meaning to citations through the CITO ontology of Shotton (2010). Citation counts form a central part of academic discourse, but contain very little information regarding the reason for the citation. Most notably, &amp;lsquo;negative&amp;rsquo; citations refuting a claim carry just the same weight as those confirming or relying upon a claim.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/02/21/notes/</link>
      <pubDate>Thu, 21 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/02/21/notes/</guid>
      <description>Applied Math Club meeting (See reading material from Tuesday.
 Start with stable age distribtution (indep of stock-recrutiment) Consider the Entropy of that probability distribution, as function of mortality, by max age Now consider the same for fecundity: the fraction/density of the population von Bertalanffy growth (fecundity) effective mortality rate - mortality rate in an unfished population, distributed with same entropy as the fished population, Kullback-Leibler distance to measure fishing influence?</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/02/20/seminar-notes/</link>
      <pubDate>Wed, 20 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/02/20/seminar-notes/</guid>
      <description>Leo Polansky Seminar (all notes cover published results only)
 Wavelet analysis does a nice trick of seeing frequency-domain spectra change over time, rather than being entirely in frequency space or entirely in time space.
 higher rank elephants decrease their movement more in dry, resource-poor season than low rank. Guarding the good territory? I wonder if this is a stochastic effect - asset protection, where you take more risk when you have low assets than when you have higher assets, a feature that would dissappear in a deterministic environment.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/02/19/notes/</link>
      <pubDate>Tue, 19 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/02/19/notes/</guid>
      <description>Fixed notebook compile error, and adjusted timeouts on pageviews / google-analytics API Some minor fixes in knitcitations (thanks to another user bug report). NEWS Accepted TE review request; better finish up ENMO review soon. Generating data tables for published figures for Dryad (from prosecutor&amp;rsquo;s fallacy). Data in Dryad  Applied Math club reading  with Marc and Mike Bonsall on Thurs, reading:   Strevens, C. M. J. &amp;amp; Bonsall, M.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/02/14/notes/</link>
      <pubDate>Thu, 14 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/02/14/notes/</guid>
      <description>Research  consolidate and revise EWS text(?) replies to Luke and Brian on model choice  Notebook meta  fix google-analytics plugin (still needs to get toggle working?) tests of notebook-parsing.Rmd. New errors on ; somehow in straight XML parsing, ignoring for the moment. Opened a few new issues around improving site semantics. (#59, #60)  ropensci  Resubmit rfishbase &amp;ndash; silently load to local, not global namespace. Updated data cache (and ASCII-ify and compress).</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/02/13/notes/</link>
      <pubDate>Wed, 13 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/02/13/notes/</guid>
      <description>ropensci  rfishbase: 0.1-1 released to CRAN: bugfix updating server address. (Broke updateCache()). See NEWS for details.
 rfigshare: 0.2-4 released to CRAN: added method to remove attached files (issue #42), see NEWS for details  Misc  My reply to John on Prosecutor&amp;rsquo;s Fallacy piece. Thinking about a better way to provide convenient, stable access to code and data. Should provide csv versions of data.table outputs used to create each of the figures.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/02/12/notes/</link>
      <pubDate>Tue, 12 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/02/12/notes/</guid>
      <description>Writing  Working on nonparametric-bayes.  Reading Interesting PNAS comment from Doney &amp;amp; Sailley, (2013) (&amp;ldquo;When an ecological regime shift is really just stochastic noise&amp;rdquo;) on the Di Lorenzo &amp;amp; Ohman, (2013) piece in the same issue, showing that time integrated zooplankton data correlates closely with environmental drivers: in this case, the pacific decadal oscillation (PDO) index, which would be missed by the traditional approach of direct correlations. This refutes the previous explanation of such shifts observed in the krill populations as being driven by nonlinear ecological interactions, rather than merely linearly tracking the environment ((Hare &amp;amp; Mantua, 2000)).</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/02/11/ews-review-paper-chat/</link>
      <pubDate>Mon, 11 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/02/11/ews-review-paper-chat/</guid>
      <description>Skype with Alan and Noam on EWS  Expand section on statistical power and noise (following draft of Alan&#39;s intro)  Flush out unfinished sections in main body  Write discussion (after intro is done)  Discussion with Alan - misc notes  edit introduction  Schreiber figure  Kefi figure  Venn Diagram figure should have numbers corresponding to the references that examine each area  Finalize edits before sending for internal review  Other  Some updates to knitcitations addressing special cases.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/02/04/updates-across-various-projects/</link>
      <pubDate>Mon, 04 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/02/04/updates-across-various-projects/</guid>
      <description>At home after birth of Edward since Jan 19th, leaving little time for research. Assembled notes from a few side projects I&amp;rsquo;ve moved forward in the wee hours. Covers the past several days.
XML and RDFa parsing I have been using the lab notebook to explore technology for scientific communication, including making use of semantic and linked data concepts. To illustrate some of the potential these tools can offer I&amp;rsquo;ve started working on a short post with examples parsing and exploring the XML and RDFa data in the notebook.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/01/24/data-uris-for-image-archives/</link>
      <pubDate>Thu, 24 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/01/24/data-uris-for-image-archives/</guid>
      <description>Figures have been one of the standing challenges of the open notebook. Displaying figures online requires that they are first uploaded to a server somewhere. Recently I have used automated uploads to external servers such as figshare to host all images generated in the course of my research, and simply point to those graphs which I wish to include in a notebook page using an image link. Unfortunately, this means that the images themselves are not being permanently archived when I deposit my notebook entries into their annual archives on figshare.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/01/12/tipping-points-comment-in-nature/</link>
      <pubDate>Sat, 12 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/01/12/tipping-points-comment-in-nature/</guid>
      <description>On Wednesday my comment piece with Alan, Tipping points: from patterns to predictions appeared in Nature (next to a nice comment by Heather Piwowar on NSF&amp;rsquo;s move to recognizing products of research more broadly than publications alone).
Heather has written an excellent post on the process of writing, which rings true with my own experience. Working with an editor with clear expertise in science writing and communication who was otherwise unfamiliar with the details of this field was an immensely rewarding experience, and her contributions really ought to be recognized more clearly.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2013/01/08/haldanes-sieve-guest-post/</link>
      <pubDate>Tue, 08 Jan 2013 00:00:00 +0000</pubDate>
      
      <guid>/2013/01/08/haldanes-sieve-guest-post/</guid>
      <description>Consider public archiving for your dissertation As researchers we spend an immense amount of time generating products other than papers. While we go through great lengths to see that our papers are published in just the right place to be seen by our colleagues (fretting about the different impact factors, percieved audience, editorial boards, open access policies, and many other factors that determine just how a paper will see the light of day), other products of our labors largely languish on forgotten hard-drives from long ago.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/12/27/notes/</link>
      <pubDate>Thu, 27 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/12/27/notes/</guid>
      <description>Nonparametric Bayes Continuing sensitivity analysis The commit log to sensitivity.md and earlier to myer-exploration.md (now depricated) capture the summary figures for replicate runs of the observation data, with commits corresponding to various parameter configurations, etc. Here is a nice collection of replicates from sensitivity.md
 Harvest during observations Tweaked calculation of observation data given the harvest regime under which observations were taken (simulation was not implementing all harvests).
 Also adjusted norm used in GP (the parametric use log-normal densities in calculating the transition function on the untransformed data.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/12/23/notes/</link>
      <pubDate>Sun, 23 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/12/23/notes/</guid>
      <description> added generation of observational data under varying harvest conditions (issue #19)
 added MLE fit based on the data-generating model (issue #20)
 GP plot with and without nugget variance (issue #17)
 Run longer simulations under policy such that sustainable profits clearly beat out collapsing the fishery (part of issue #22)
  </description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/12/21/progress-summary/</link>
      <pubDate>Fri, 21 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/12/21/progress-summary/</guid>
      <description>Progress mid-October through mid-December 80% Time: nonparametric-bayes The bulk of my time has been spent becoming familiar with the literature on Gaussian Processes and their numerical implementation. I have written my own Gaussian process code from scratch to convince myself of my understanding of the methodology, and explored some of the related numerical issues addressing computational speed and stability.
I then developed an algorithm for applying the Gaussian process inference of the state dynamics to stochastic dynamic programming methods for determining an optimal harvesting policy.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/12/20/results-comparing-gp-to-parametric/</link>
      <pubDate>Thu, 20 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/12/20/results-comparing-gp-to-parametric/</guid>
      <description>Comparison of the Gaussian process inference to the true optimum and a parametric estimate.
Comparison across 100 simulations under the policies inferred from each approach show the nearly optimal performance of the GP and the tragic crashes introduced by the parametric management.
Sensitivity analysis Working through an exploratory sensitivity analysis to see GP performance over different parameters.
 Example from 32 replicates   Distribution of yield over replicates shows the parametric model performing rather poorly, while most of the GP replicates perform nearly optimally.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/12/19/exploring-gp-model-space/</link>
      <pubDate>Wed, 19 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/12/19/exploring-gp-model-space/</guid>
      <description>Trying to think about a more systematic way to go about varying the parameters: the underlying parametric model has 3 parameters for the stock-recruitment curve&amp;rsquo;s deterministic skeleton, plus growth noise. (My first exploratory phase has been just to try different things. See my various tweaks in the history log Clearly time to be more systematic about both running and visualizing the various cases.)
Should I just choose a handful of parameter combinations to test?</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/12/17/random_ews_example/</link>
      <pubDate>Mon, 17 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/12/17/random_ews_example/</guid>
      <description>ENSO EWS Let&amp;rsquo;s just see what happens with the MEI data for PDO:
dat &amp;lt;- read.table(&amp;quot;http://www.carlboettiger.info/assets/data/mei.csv&amp;quot;, header=TRUE)  For the moment let&amp;rsquo;s ignore annual structure and just collapse this into timeseries sampled bimonthly.
require(reshape2) dt &amp;lt;- melt(dat, id=&amp;quot;YEAR&amp;quot;) X &amp;lt;- dt$value Z &amp;lt;- X[!is.na(X)] Z &amp;lt;- data.frame(1:(length(Z)-1), Z[1:(length(Z)-1)])  png(&amp;quot;mei.png&amp;quot;) require(earlywarnings) a &amp;lt;- generic_ews(Z, detrending=&amp;quot;gaussian&amp;quot;)  How about the data from MacDonald (2005)
original data link
dat &amp;lt;- read.table(&amp;quot;http://www.carlboettiger.info/assets/data/pdo-macdonald2005.csv&amp;quot;, header=TRUE)  png(&amp;quot;macdonald2005.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/12/15/nonparametric-bayes-comparisons/</link>
      <pubDate>Sat, 15 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/12/15/nonparametric-bayes-comparisons/</guid>
      <description>Notes on structure of examples Externalized code so that different example scripts call identical commands for fitting and plotting to avoid duplication of code. Example scripts tend to be pretty text poor at the moment, would probably benefit by better descriptions in the markdown. May still involve redundant and potentially out of date descriptions though.
Currently, externalized code for GP comparison experiments is in gaussian-process-control.R, and is called by may79-example.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/12/11/nonparametric-bayes-notes/</link>
      <pubDate>Tue, 11 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/12/11/nonparametric-bayes-notes/</guid>
      <description>Code gp_transition_matrix for generic multi-dimensional case  Understanding Gaussian Process performance If the estimated recruitment dynamics correspond to population dynamics that are non-persistent (might call this non self-sustaining, but in a rather stricter sense than when Reed (1979) introduced that term), and if no reward is offered at the terminal time point for a standing stock (zero scrap value), the GP dictates the rather counter-intuitive practice of simply removing the stock entirely.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/12/10/prior-distributions-for-tgp-mcmc/</link>
      <pubDate>Mon, 10 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/12/10/prior-distributions-for-tgp-mcmc/</guid>
      <description>I am trying to understand the interface for tgp method, but much of it is not well documented (yes, despite reading through the package R manual, two nice vignettes, and a the PhD Thesis describing it.)
Just to get some consistent notation down: consider the case of a Gaussian process with a Gaussian/radial basis function kernel, parameterized as:
$$K(X, X&amp;rsquo;) = \sigma^2 e^{\frac{(X-X&amp;rsquo;)^2}{d}}$$
And observations from $Z = f(X) + \varepsilon$, for which we seek to approximate $f$ as a (multivariate) Gaussian process, $Z | X ~ N(\mu, C)$.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/12/06/github-issues-tracker-the-perfect-research-todo-list/</link>
      <pubDate>Thu, 06 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/12/06/github-issues-tracker-the-perfect-research-todo-list/</guid>
      <description>Github issues tracker has increasingly become my research to-do list. Far beyond bugs and features of the code associated with the project, the issues sign-post different directions for investigation and the progress I&amp;rsquo;ve made in each. Tags serve to group issues related to a common sub-project (as in my pdg-control) repo or priotize tasks (as in my nonparametric-bayes repo.
Issues not only have title and tags, but support a comment thread for progress and discussion of the issue.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/12/05/notes/</link>
      <pubDate>Wed, 05 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/12/05/notes/</guid>
      <description>pdg-control Call  Send Figure 3 and 4 with stock dynamics to Paul.  Detailed to do items coming out of talk filed as Github Issues for pdg-control (policycosts)
 Comparisons between assumed and true policy costs (Figure 5 style but as a Table) Snappier, more meaningful names for &amp;ldquo;L1&amp;rdquo;, &amp;ldquo;L2&amp;rdquo; etc Write real-world context/significance of L1, L2, fixed, etc. Add graph &amp;amp; discussion of stock dynamics for Fig 3 &amp;amp; 4 Figure 5 interpretation Fix boundary issues in Figure 4 Resolve confusion about apples-to-apples / definition of NPV0 Resolve cost structure question On functional forms, drop ALL asymmetric cases for now.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/12/04/tgp-mcmc-for-gaussian-processes/</link>
      <pubDate>Tue, 04 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/12/04/tgp-mcmc-for-gaussian-processes/</guid>
      <description>Exploring implementation through tgp package MCMC routine and background reading (manual, vignettes, thesis).
Example call:
gp &amp;lt;- bgp(X=X, XX=XX, Z=Z, meanfn=&amp;quot;constant&amp;quot;, bprior=&amp;quot;b0&amp;quot;, BTE=c(1000,6000,2), m0r1=TRUE, verb=4, corr=&amp;quot;exp&amp;quot;, trace=TRUE, s2.p=c(5,10), tau2.p=c(5,10), s2.lam=&amp;quot;fixed&amp;quot;, tau2.lam=&amp;quot;fixed&amp;quot;)  Verbose return:
n=39, d=1, nn=101 BTE=(1000,6000,2), R=1, linburn=0 RNG state RK using rk_seed preds: data krige T[alpha,beta,nmin,smin,bmax]=[0,0,10,1,1] mean function: constant beta prior: b0 hierarchical s2[a0,g0]=[5,10] s2 prior fixed tau2[a0,g0]=[5,10] tau2 prior fixed corr prior: isotropic power nug[a,b][0,1]=[1,1],[1,1] nug prior fixed gamlin=[0,0.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/12/03/figures-3-and-4-for-policycosts/</link>
      <pubDate>Mon, 03 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/12/03/figures-3-and-4-for-policycosts/</guid>
      <description>Straight-forward tasks can sometimes take forever. In advance of our upcoming conference call for the Pretty Darn Good Control (pdg-control) NIMBioS working group, I had a few remaining issues to touch up in Figures 3 and 4.
Figure 3 shows harvest and stock dynamics under the different functional forms fo the cost. The goal is to provide a very intuitive, visual sense of how the policies differ under these different functional forms, such as a fixed &amp;ldquo;transaction fee&amp;rdquo; (fixed) or a cost that is proportional to the size of the change in policy (L1), or the square of that change (L2), etc.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/11/30/note-on-notebook-figures/</link>
      <pubDate>Fri, 30 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/11/30/note-on-notebook-figures/</guid>
      <description>plots for the notebook I have started uploading images to my own server, rather than flickr. Programmatically, this is just a matter of switching the knitr upload function:
opts_knit$set(upload.fun = socialR::notebook.url)  from my custom flickr.url function (a wrapper to Rflickr) to a custom function notebook.url using a system call to cp (to my local jekyll notebook) and rsync (so the figure displays before my next jekyll push).
The new script names image by date and the first 10 characters of the sha hash, as well as the knitr chunk name.</description>
    </item>
    
    <item>
      <title>early results in nonparametric-bayes approaches to optimal policy</title>
      <link>/2012/11/28/nonparametric-bayes-work/</link>
      <pubDate>Wed, 28 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/11/28/nonparametric-bayes-work/</guid>
      <description>Resolving Numerical and Computational issues Sequential approach? (issue #4) Thinking through whether or not it is worth optimizing the computational performance of the sequential approach.
Can it be demonstrated that this actually has higher numerical stability? Alternatively, can it be demonstrated that this is (or is not) equivalent to the calculation performed by the direct inversion? What is the difference in computational complexity between these approaches? e.g. the inverse ends up effectively O(n^3), but what is the recursion?</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/11/27/policy-costs-work/</link>
      <pubDate>Tue, 27 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/11/27/policy-costs-work/</guid>
      <description>Scripts to estimate apples to apples comparisons for different penalty functions and plot instances of the resulting policy. Example run with fixed linear costs on effort.
 Double the actual variance leads to terminal overfishing 11:16 am 2012/11/28 use fixed seed. 09:45 am 2012/11/28 Compare GP to Reed optimum for BH (successful run this time) 09:37 am 2012/11/28 basic GP example in BH system, compared to Reed Optimum 09:17 am 2012/11/28  Content of current working example, run on server zero.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/11/23/citing-lab-notebook-entries/</link>
      <pubDate>Fri, 23 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/11/23/citing-lab-notebook-entries/</guid>
      <description>C. Titus Brown has an excellent post discussing his exploration into the merits and technicalities cross-posting his blog posts to figshare. The rfigshare package written by Ted Hart and myself can do just this, once we puzzled out some of the same challenges (Notes to Titus: though the documentation doesn&amp;rsquo;t mention it, you can get a programmatic list of available categories from http://api.figshare.com/v1/categories. Figshare can also take code as a fileset or dataset, and may soon add a type for it.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/11/22/notes/</link>
      <pubDate>Thu, 22 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/11/22/notes/</guid>
      <description>multiple-uncertainty Working out the multiple uncertainty computational performance and noise forms. Fixing a few things in the way log-normal noise was calculated. Uniform noise in particular can still give rather non-smooth policy, needs a bit of digging. Uniform noise doesn&amp;rsquo;t show the non-monotonicity of the log-normal noise in measurement uncertainty though.
Uniform lognormal log  A few small tweaks to probability calculations
 Handle the case of mu = grid zero, not just exactly zero, to avoid introducing NAs Calculate dlnorm as (x_grid/mu, 0, sigma), rather than as (x_grid, mu, sigma).</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/11/21/notes/</link>
      <pubDate>Wed, 21 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/11/21/notes/</guid>
      <description>writing comment piece. writing writing writing.
  Also today (misc):  Check in with Peter re: Labrids paper Fix issue #32 rfigshare Follow up with Nina about improved FishBase API pay ESA and SSE dues Santa Cruz SOE email lists uniform growth noise version on corrected multiple-uncertainty run transparent plots in new ggplot theme? Set in dev.args=list(bg=&amp;quot;transparent&amp;quot;) Consider SOE AMS lecturer pool? Description, Application  CV, Letter of application with course list.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/11/19/sequential-updating/</link>
      <pubDate>Mon, 19 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/11/19/sequential-updating/</guid>
      <description>Fixed the sequential updating algorithm (avoids numerical instabilities associated with matrix inversion). Currently defined as the function recursion:
for the covariance:
C_seq &amp;lt;- function(X, X_prime, i){ if(i &amp;lt;= 1) cov(X, X_prime) - mmult(cov(X,x[i]), cov(x[i], X_prime)) / as.numeric( cov(x[i], x[i]) + sigma_n^2) else C_seq(X, X_prime, i-1) - mmult(C_seq(X,x[i], i-1), C_seq(x[i], X_prime, i-1)) / as.numeric( C_seq(x[i], x[i], i-1) + sigma_n^2 ) }  for the mean:
mu_seq &amp;lt;- function(X, i){ if(i &amp;lt;= 1) cov(x[i], X) * (y[i]-mu[i]) / as.</description>
    </item>
    
    <item>
      <title>Multiple uncertainty corrected</title>
      <link>/2012/11/16/mult-uncertainty/</link>
      <pubDate>Fri, 16 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/11/16/mult-uncertainty/</guid>
      <description>Fixed the multiple uncertainty calculation implementation. Code had transposed $\mathbb{I}$, also one of the $\mathbb{M}$ matrices. Should still confirm final implementation. In the below example each case has log-normal growth noise present. The non-monotonic section of the measurement uncertainty
See notes on code changes inline.
Additional notes from walking through algoritm step by step.  $x$ index in the true state space $y$ index in the observed state space $h$ index in the true action $q$ index in the policy/decision space</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/11/15/notes/</link>
      <pubDate>Thu, 15 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/11/15/notes/</guid>
      <description>Stuck on many things  Have not correctly defined the recursion in the sequential updating approach. Can I really calculate $P(y_3 | (y2 | y_1))$ in place of $P(y_3 | y2, y1)$? e.g. instead of calculating:  $$V_3 = K(y_3, y3) - K(y{1:2}, y3) K(y{1:2}, y_{1:2})^{-1} ) K(y3, y{1:2}) $$
Is there some scalar $v_2$ such that
$$V_3 = K(y_3, y3) - K(y{1:2}, y_3) K(y3, y{1:2}) / v_2$$
e.g. a term like:</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/11/09/better-tagging-practices/</link>
      <pubDate>Fri, 09 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/11/09/better-tagging-practices/</guid>
      <description>Better tagging practices  Standardize use of tags: Match tags in notebook to project repository name. Tag papers in Mendeley by these tags as well.  I have also started tracking the medium of discovery for each paper I add to my Mendeley collection through a little set of Mendeley tags. I am curious to see through which mediums I obtain the most content, and what content. As with any ontology, I will struggle to select a vocabulary that is precise enought to be useful without being too verbose (b) to bother to continue to use this.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/11/08/notes/</link>
      <pubDate>Thu, 08 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/11/08/notes/</guid>
      <description>Complete IACUC training for fish room. File forms: http://ehs.ucsc.edu/programs/research-safety/animal-research/index.html Online training &amp;ndash; possibly see https://www.citiprogram.org/Default.asp? Shiny: http://www.rstudio.com/shiny/
 Comment piece
 Prep exit seminar
 Applied math club: Networks. Reading http://dx.doi.org/10.1155/2011/284909
  Discussion of when network structure has made an important difference on our understanding of a problem. When have the common summary statistics of a network (degree-distribution) allowed us to compte network dynamics without fully resolving the network?</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/11/06/notes/</link>
      <pubDate>Tue, 06 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/11/06/notes/</guid>
      <description>Monday  altmetrics post post for multiple uncertainty, email to Steve, Marc Marc meeting ropensci proposals Phylotastic  Notebook configuration  trying out http://greycite.knowledgeblog.org/. Add to knitcitations. Add Greycite recommended opengraph and google scholar metadata metadata.html Import metadata from _config.yml. Any custom variable defined in config can be accessed at site.varname. See updated _config.yml  Reading  Schnitzler, J., Graham, C. H., Dormann, C. F., Schiffers, K., &amp;amp; Peter Linder, H.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/11/03/altmetrics-conference/</link>
      <pubDate>Sat, 03 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/11/03/altmetrics-conference/</guid>
      <description>From Thursday Nov 1 through Saturday Nov 3 I attended the PLoS Altmetrics workshop as a member of the ROpensci project. An exciting meeting driven mostly by the opportunity to interact with a small and incredibly creative and innovative group of science publishers, funders, start-ups, and other researchers. Details of the event are largely recorded on the altmetrics 2012 workshop website. We also have a few slides addressing the ropensci slant.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/11/01/multiple-uncertainty-corrections/</link>
      <pubDate>Thu, 01 Nov 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/11/01/multiple-uncertainty-corrections/</guid>
      <description>Consider a stock $x_t$ at time $t$ that recruits stochastically following harvest $h_t$ from the escaped population ($s_t := x_t - ht$), $x{t+1} = z_g f(s_t)$, where $z_g$ is a multiplicative stochastic shock to the growth. We imagine the decision maker sets a policy determining the harvest quota $q_t$ each year, which is implemented as the real harvest with some error $z_i$, $h_t = z_i q_t$. Before setting a quota, the decision maker assesses the stock $y_t = z_m x_t$, so $y$ is a noisy measurement of the true stock $x$.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/10/31/notes/</link>
      <pubDate>Wed, 31 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/31/notes/</guid>
      <description>I enjoyed an excellent meeting with Annette Thomas, CEO of MacMillian Publishing and Nature Publishing group at UC Davis. It was impressive to here that Annette wanted to meet with UC Davis faculty and graduate students interested in open access and open science to discuss our opinions, desires and frustrations in the scientific publishing process. It was particularly valuable to discuss some of the failed experiments in open science at Nature.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/10/29/notes/</link>
      <pubDate>Mon, 29 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/29/notes/</guid>
      <description>Misc  Mostly writing application today&amp;hellip; Review for EcoLet looking over pomdp/momdp
 Notebook archives now on figshare (plain-txt versions). Can now also cite entries by doi, e.g.: Lab Notebook (2010) doi:10.6084/m9.figshare.96916, and Lab Notebook, (2011) doi:10.6084/m9.figshare.96919. Would publishing individual entries and individual figshare objects be preferable or just annoying?
 Meeting tomorrow with Annette Thomas, CEO NPG/MacMillian. review interview with David Worlock  Munch data project  Data extraction for geospatial life history project (file  R script for converting place names into latitude/longitude:</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/10/25/stochastic-dynamic-programming-with-gaussian-process-approx/</link>
      <pubDate>Thu, 25 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/25/stochastic-dynamic-programming-with-gaussian-process-approx/</guid>
      <description>Here we work out an SDP solution of the Reed (1979) using a Gaussian process approximation. In this example the Gaussian process hyper-parameters haven&amp;rsquo;t been tuned, so in principle the solution would perform even better, but this is just for illustrative purposes.
We simulate 40 points under a stochastic growth (lognormal multiplicative noise) Beverton-Holt model and infer the Gaussian process. We start the simulation from a low stock value, giving reasonable but not perfect coverage of the state-space.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/10/24/evolutionary-covariance/</link>
      <pubDate>Wed, 24 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/24/evolutionary-covariance/</guid>
      <description>Thinking through disparity measures while writing my thoughts in R&amp;hellip;
Load some sample data
library(geiger) data(geospiza) dat &amp;lt;- treedata(geospiza$geospiza.tree, geospiza$geospiza.data$wingL)  To find the disparity relative to a particular model, we must compute the variance-covariance matrix for that model
X &amp;lt;- dat$data V_bm &amp;lt;- vcv(dat$phy) mean_X &amp;lt;- geiger:::phylogMean(V_bm, X) bm_disparity &amp;lt;- t(X-mean_X) %*% V_bm %*% (X-mean_X)  I believe this needs to be scaled by the Brownian rate parameter of the trait, e.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/10/24/multiple-uncertainty-value-function-iteration/</link>
      <pubDate>Wed, 24 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/24/multiple-uncertainty-value-function-iteration/</guid>
      <description>Multiple Uncertainty algorithm Define each of the transition matrices:
D &amp;lt;- matrix(NA, nrow=length(x_grid), ncol=Tmax) P &amp;lt;- outer(x_grid, h_grid, profit) F &amp;lt;- outer(x_grid, f(x_grid, 0, p), pdfn, sigma_g) M &amp;lt;- outer(x_grid, x_grid, pdfn, sigma_m) I &amp;lt;- outer(h_grid, h_grid, pdfn, sigma_i)  Probably row-normalize each:
rownorm &amp;lt;- function(M) t(apply(M, 1, function(x) x/sum(x))  (Note the transpose is needed since the silly function of a vector turns the column into a row. Not an issue of margin 2)</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/10/23/semantic-markup-examples-for-the-lab-notebook/</link>
      <pubDate>Tue, 23 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/23/semantic-markup-examples-for-the-lab-notebook/</guid>
      <description>All notebook entries are formatted with XHTML compliant (polyglot) HTML5 semantic structure. This means that any entry can be parsed with a generic XML parser to extract the entry content in &amp;lt;article&amp;gt;, the &amp;lt;header&amp;gt;, &amp;lt;footer&amp;gt;, &amp;lt;aside&amp;gt;, etc. The &amp;lt;head&amp;gt; section provides &amp;lt;title&amp;gt; and essential &amp;lt;meta&amp;gt; tags declaring the character encoding (which also sets the MIME type for HTML5).
Head In _includes/header.html we introduce some basic academic archive metadata using the Dublin Core ontology.</description>
    </item>
    
    <item>
      <title>Gaussian process inference on sample functions</title>
      <link>/2012/10/23/notes/</link>
      <pubDate>Tue, 23 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/23/notes/</guid>
      <description>This example uses the direct inversion of the covariance function. I have also been exploring the potentially faster Cholksy decomposition without success. Sometimes the match is very good, other times not, see compare-cholsky.md This example also on github as reed-example.md.
 Basic likelihood optimization needs to be checked. See commits estimating sigma_n and estimating l. Compare the example below to a different set of fixed hyperparameters here  Example require(pdgControl) require(ggplot2)  Simulate some training data under a stochastic growth function with standard parameterization,</description>
    </item>
    
    <item>
      <title>Comparing numerical methods</title>
      <link>/2012/10/22/notes/</link>
      <pubDate>Mon, 22 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/22/notes/</guid>
      <description>require(MASS) require(ggplot2) require(kernlab)  Parameterization-specific
X &amp;lt;- seq(-5,5,len=50) obs &amp;lt;- data.frame(x = c(-4, -3, -1, 0, 2), y = c(-2, 0, 1, 2, -1)) l &amp;lt;- 1 sigma_n &amp;lt;- 0.8  Radial basis function/Gaussian kernel:
SE &amp;lt;- function(Xi,Xj, l) exp(-0.5 * (Xi - Xj) ^ 2 / l ^ 2) cov &amp;lt;- function(X, Y) outer(X, Y, SE, l)  Cholksy method
n &amp;lt;- length(obs$x) K &amp;lt;- cov(obs$x, obs$x) I &amp;lt;- diag(1, n) L &amp;lt;- chol(K + sigma_n^2 * I) alpha &amp;lt;- solve(t(L), solve(L, obs$y)) k_star &amp;lt;- cov(obs$x, X) Y &amp;lt;- t(k_star) %*% alpha v &amp;lt;- solve(L, k_star) Var &amp;lt;- cov(X,X) - t(v) %*% v loglik &amp;lt;- -.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/10/19/notes/</link>
      <pubDate>Fri, 19 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/19/notes/</guid>
      <description>Semantic Notebook notes Reading
 Nice collection of posts on scholarly html, but too little mention of the serious linked data stuff coming out of biscol, ievobio/nescent, etc. In particular, Martin&amp;rsquo;s history gives some nice perspective.
 The war for schema. Which ontologies should we choose? (e.g. schema.org&amp;rsquo;s take  Puzzles
 How do we mix ontologies How do we meet Google Rich Snippets requirements using FOAF? How do we avoid redundant vocabulary terms?</description>
    </item>
    
    <item>
      <title>Basic regression in Gaussian processes</title>
      <link>/2012/10/17/basic-regression-in-gaussian-processes/</link>
      <pubDate>Wed, 17 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/17/basic-regression-in-gaussian-processes/</guid>
      <description>Working out coded examples for basic Gaussian process regression using R. I&amp;rsquo;ve just read through the first few chapters of Rasmussen &amp;amp; Williams (2006), this implements the examples discussed in Chapter 2.1-2.5.
Required R libraries (for multivariate normal, also for plotting):
require(MASS) require(reshape2) require(ggplot2)  Set a seed for repeatable plots
set.seed(12345)  Define the points at which we want to compute the function values (x values of the prediction points or test points), and the scale parameter for the covariance function $\ell=1$</description>
    </item>
    
    <item>
      <title>Notes</title>
      <link>/2012/10/17/talkingpoints/</link>
      <pubDate>Wed, 17 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/17/talkingpoints/</guid>
      <description>Talking points for phone interview with Lucy
Finding warning signals in the wild
 Gold standard &amp;ndash; experimental group, control group Real world: We have no control group.
  Would we know a warning signal when we saw it?
From statistics to models: We fit a generalized models of the processes that are and aren&amp;rsquo;t approaching a tipping point, and compare the models. The modeling approach is also more sensitive than the simple statistics.</description>
    </item>
    
    <item>
      <title>Gaussian processes</title>
      <link>/2012/10/16/gaussian-processes/</link>
      <pubDate>Tue, 16 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/16/gaussian-processes/</guid>
      <description>Great methods tutorial/overview with Steve. Now getting up to speed on background reading in both Gaussian processes and embedding dimensions.
 Will also want to look into basis approximations for SDP acceleration.
  Gaussian Processes  New project, New tag: nonparametric-bayes, and associated github repostitory  Reading  Rasmussen &amp;amp; Williams (2006) 2nd ed, full text avialable online. read Ch 1 &amp;amp; 2.   Can be thought of as a Bayesian version of Support Vector Machines</description>
    </item>
    
    <item>
      <title>Semantic Lab Notebook</title>
      <link>/2012/10/14/semantic-lab-notebook/</link>
      <pubDate>Sun, 14 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/14/semantic-lab-notebook/</guid>
      <description>As the lab notebook grows, to make the maximum use of content it would be particularly useful to maximize the ability for a computer to understand the content, allowing us to identify, manipulate, and connect data using scripts and software. This is the concept of linked data, or a semantic notebook. I have explored this this idea before in the context of a wordpress-based platform, but now that Jekyll has let me strip away some of the abstraction of Wordpress it seems a good time to revisit this idea.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/10/11/notes/</link>
      <pubDate>Thu, 11 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/11/notes/</guid>
      <description>EWS review Composing a simple EWS review highlighting where signals are and are not expected and what this means for the system dynamics. With Alan and Noam. See manuscript repository, cboettig/ews-review.
pdg control  Does the matrix formulation fail to account for the treating profits as a function of realized harvest and true stock size rather than quota and measured size?  notebook  fixing some inline equations 04:34 pm 2012/10/09 Updated Readme 02:57 pm 2012/10/09  scicomp discussions on reproducibility  Asked about longevity of code (re: data managment plan) Replied to best practices for linking code to publications  discussions/tweets  @hylopsar @mwpennell thanks - I always find it tricky to explain conditional probabilities clearly, so that&amp;rsquo;s nice to hear Nice paper by +Matt Pennell, Saver &amp;amp;@lukejharmon on biases in inferring early bursts of evolution.</description>
    </item>
    
    <item>
      <title>My Prosecutor&#39;s Fallacy paper and other recent warning signals literature</title>
      <link>/2012/10/10/prosecutors-fallacy/</link>
      <pubDate>Wed, 10 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/10/prosecutors-fallacy/</guid>
      <description>My recent paper with Alan Hastings, &amp;ldquo;Early warning signals and the prosecutor&amp;rsquo;s fallacy&amp;rdquo;, is now out in PRSB. An open access preprint can be found on the (arXiv) and accompanying (source code) for the analysis can be found on Github.
Recent papers in early warning signals This invistigation is in a very similar spirit to two other recent papers on the subject. Kéfi et al. addresses a different kind of false positive for early warning signals, arising in systems approaching other transitions or bifurcations than the intended culprit, the saddle-node bifurcation.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/10/09/data-management-plan/</link>
      <pubDate>Tue, 09 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/09/data-management-plan/</guid>
      <description>Writing out a data management plan for myself. Suggestions and feedback welcome.
Data Types and Structure All source code, documentation, scripts and data for the analyses performed in the course of this research shall be maintained in a digital compendium using the R package structure as recommended in Gentleman and Lang (2007). The progress and results of this research shall be regularly chronicled in an electronic lab notebook, maintained openly at carlboettiger.</description>
    </item>
    
    <item>
      <title>Automated feeds in notebook entries</title>
      <link>/2012/10/05/notes/</link>
      <pubDate>Fri, 05 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/05/notes/</guid>
      <description>Exploring the use of automated feeds in my notebook entries, which would make writing posts both faster and more complete. I had recently modified my Jekyll plugins to include commits on the day of the post. Consequently, I could add a bit of liquid code to any post, such as:
{% raw %}
{% octokit_commits pdg_control%}  {% endraw %}
(or even to the post template) and have the commit log for the specified repository automatically imported.</description>
    </item>
    
    <item>
      <title>Solarized Colors with Twitter-Bootstrap?</title>
      <link>/2012/10/02/solarized-colors/</link>
      <pubDate>Tue, 02 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/02/solarized-colors/</guid>
      <description>Trying out rendering my notebook using Ethan Schoonover&amp;rsquo;s Solarized color scheme. The solarized palette has been selected according to Ethan&amp;rsquo;s exacting standards for contrast, symmetry, and readability.
My site CSS is built with Twitter-Bootstrap, which uses LESS to generate CSS files. Normal CSS is valid LESS code too, but doesn&amp;rsquo;t have the concept of a variable. So changing colors in CSS requires changing each and every occurance of some hex colorcode.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/10/01/multiple-uncertainty/</link>
      <pubDate>Mon, 01 Oct 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/10/01/multiple-uncertainty/</guid>
      <description>Let
 y be measured stock size, subject to measurement error from true stock x q be harvest quota, subject to implementation error from actual harvest, h  Stock next year is also subject to stochastic growth shock $z_g$, (note that $f$ will also depend on the harvest, h, unless $x_t$ is taken as the escapement population, $x-h$).
$$ x_{t+1} = z_g f(x_t) $$
In discrete space, let X be a vector representing the probability distribution of having stock $x$ at time $t$, restricted to some finite grid of dimension $n$.</description>
    </item>
    
    <item>
      <title>Welcome to my Lab Notebook - Reloaded</title>
      <link>/2012/09/28/welcome-to-my-lab-notebook/</link>
      <pubDate>Fri, 28 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/09/28/welcome-to-my-lab-notebook/</guid>
      <description>Welcome to my lab notebook, version 3.0. My original open lab notebooks began on the wiki platform OpenWetWare, moved to a personally hosted Wordpress platform, and now run on a Jekyll-powered platform (site-config), but the basic idea remains the same. For completeness, earlier entries from both platforms have been migrated here. Quoting from my original introduction to the Wordpress notebook:
 Disclaimer: Not a Blog  Welcome to my open lab notebook.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/09/27/migrating-oww-posts-to-jekyll/</link>
      <pubDate>Thu, 27 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/09/27/migrating-oww-posts-to-jekyll/</guid>
      <description>This Open Lab Notebook started on a public MediaWiki-based site, OpenWetWare (OWW), which was created with the ambitious vision of having a single wiki for biological sciences (or at least, synthetic microbiology, since such the wiki grew out of a collection of such labs). Users could have their own pages that served as a personal website or lab group site, contribute pages on specific protocols, host course websites, and most interestingly, were encouraged to create open lab notebooks using specially designed templates for the purpose.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/09/19/migrating-from-wordpress-to-jekyll/</link>
      <pubDate>Wed, 19 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/09/19/migrating-from-wordpress-to-jekyll/</guid>
      <description>Thanks to a recent bugfix in the exitwp scripts I was able to export all my Wordpress entries. The script pulls the entries from the Wordpress database and formats them in markdown, along with extracting all metadata such as timestamp, tags, categories, publication status, and Wordpress id number, which are all embedded as YAML header information.
Why migrate the old entries? When I moved to the Jekyll notebook, I left the Wordpress site standing with all its existing content and simply remapped the home pages.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/09/19/prosecutors-fallacy/</link>
      <pubDate>Wed, 19 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/09/19/prosecutors-fallacy/</guid>
      <description>Two years ago, I scribbled an entry into my notebook entitled Wrong Picture, Wrong Model: Why warning signals don&amp;rsquo;t look like rare events. Months later I made some off-hand remark to Alan (my Ph.D. mentor) about how transitions found in historical records, such as the Climate examples in Dakos et. al. (2008), could actually be selecting for stochastic transitions, and this selection process might make them look like traditional warning signals &amp;ndash; i.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/09/14/analytic-solution-to-multiple-uncertainty/</link>
      <pubDate>Fri, 14 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/09/14/analytic-solution-to-multiple-uncertainty/</guid>
      <description>No idea where I went wrong, but the final graphs are not what I expected Update: Integrated out some uncertainty in the expectation step, need to preserve full set of transtions
We consider adding additional sources of noise through observation error and implementation error to the orginal model of Reed (1979), which considers only growth error. This follows in the line of exploration taken by Clark and Kirkwood (1987), Roughgarden (1996) and Sethi (2006).</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/09/12/notes/</link>
      <pubDate>Wed, 12 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/09/12/notes/</guid>
      <description>See github for pdg_control</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/09/05/esa-changes-arxiv-policy-following-community-comments/</link>
      <pubDate>Wed, 05 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/09/05/esa-changes-arxiv-policy-following-community-comments/</guid>
      <description>Earlier today, Scott Collins, the president of the Ecological Society of America has announced that the society will now accept articles that have previously been posted on preprint servers. This comes on the heels of a growing discussion in our community. Ethan White has a good summary over on Jabberwocky Ecology.
Many voices have joined the discussion over the past month, and it is exciting and vindicating to see the Society engage and discuss these questions.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/09/04/notes/</link>
      <pubDate>Tue, 04 Sep 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/09/04/notes/</guid>
      <description>Fallacy paper done Dissertation filing Decision theory from the ROC curve.
 Working group paper Jim/Mike paper
 wrightscape paper?
 Signature page two copies, archival paper?
 ropensci emails: Position paper: Goals
 misc emails
  Fallacy paper finalizing appendices  Commit images and runs from yesterday (ibm simulation still running&amp;hellip;)
 clean up appendix code
 clean up appendix text
  Code tricks for today vim set sytnax language, useful for getting R highlighting in .</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/08/29/santa-cruz-postdoc/</link>
      <pubDate>Wed, 29 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/08/29/santa-cruz-postdoc/</guid>
      <description>Spent Monday and Tuesday visiting Santa Cruz, where I have recently accepted a post-doctoral position with Steve Munch, Marc Mangel, and Alec MacCall. I will be based primarily at the National Marine Fisheries Service building, here: ` Five fantastic years of graduate school are coming to an end: I will start officially later this fall, where I will
 join an exciting team of ecologists and applied mathematicians who work collaboratively on cutting-edge problems in ecological and evolutionary modeling through the Center for Stock Assessment Research.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/08/23/notes/</link>
      <pubDate>Thu, 23 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/08/23/notes/</guid>
      <description>Fallacy with May model runs
 $$ X_{t+1} = X_t \exp\left( r \left(1 - \frac{ X_t }{ K } \right) - \frac{ a * X_t ^ {Q - 1} }{s ^ Q + H ^ Q} \right) $$  Working on unmanaged warning. (see #21)</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/08/22/warning-signals-in-management/</link>
      <pubDate>Wed, 22 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/08/22/warning-signals-in-management/</guid>
      <description>Tour of existing files (version stable links)
 managed warning is the current direct test of this, but needs decently ranged input example where detection has a good chance to succeed.
 criticaltransition Statistics across replicate crashes that don&amp;rsquo;t show much promise for detection.
 A heuristic implementation in response to the detection of a signal might use a simple rule like a fraction of the optimal harvest of a stable system.</description>
    </item>
    
    <item>
      <title>Revisions on Prosecutors Fallacy</title>
      <link>/2012/08/22/notes/</link>
      <pubDate>Wed, 22 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/08/22/notes/</guid>
      <description>Email Alan re: Prosecutor&amp;rsquo;s fallacy manuscript. Schedule meeting.
 Proof corrections for rfishbase manuscript. Done.
 Fallacy simulations: calibration range for May model: expect small fraction of runs to transition by chance from stable state.
  Here we&amp;rsquo;re getting a bit less than 2% chance transitions in 5000 steps.
&amp;gt; sn &amp;lt;- + sapply(1:1000, function(rep){ + x &amp;lt;- vector(mode=&amp;quot;double&amp;quot;, length=n) + x[1] &amp;lt;- 8 # positive equilibrium + z &amp;lt;- rlnorm(n, 0, .</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/08/21/pdg-control-updates/</link>
      <pubDate>Tue, 21 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/08/21/pdg-control-updates/</guid>
      <description>Resolving S &amp;lt; D Code updates octokit
Reading  Macksamie, K., Cockburn, J., &amp;amp; Wagner, J. (2012). Robust control amidst stock and flow benefits: The case of wolf-elk-hunting dynamics in the US Mountain West. 2012 AERE Summer Conference, Asheville, NC (pp. 1-33). Retrieved from http://www.webmeets.com/files/papers/AERE/2012/3/AEREConfPaper05172012.pdf  The Linear parameter varying (LPV) approach which allows this problem to leverage a standard LMI (linear matrix inequality) solver seeems like a clever route, but unclear if this would be restricted to the additive noise models such as they consider?</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/08/20/notes/</link>
      <pubDate>Mon, 20 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/08/20/notes/</guid>
      <description>Writing  Draft outline of policy costs paper sent to Paul.
  Misc  ropensci NCEAS proposal - contacts
 MEE supplement follow-up: Wow, MEE promotes video podcasts along with publications.
 Hadley to join RStudio full time.
 A gist by Hadley on storing things like API keys across R packages.
 Joined fisheries-science mailing list
  Reading Warning signals  Critical transitions at Amer Fisheries Society</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/08/10/esa-2012-conference/</link>
      <pubDate>Fri, 10 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/08/10/esa-2012-conference/</guid>
      <description>My Schedule Meetings/discussion with Don Strong, Tony Ives, Marten Scheffer, Justin Yeakel, Karen Abbott, Jarrett Byrnes, Christopher Lortie.
 Check in with Paul Armsworth on working group rOpenSci tutorial session (below) tweetup My contributed talk (below)  rOpenSci tutorial, Thursday A year out from our launch at ESA last year, we presented an introduction and tutorial on rOpenSci. Slides and links to more information are all available at esa.</description>
    </item>
    
    <item>
      <title>Deviations from S = D</title>
      <link>/2012/07/30/notes/</link>
      <pubDate>Mon, 30 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/07/30/notes/</guid>
      <description>pdg-control Value of information Exploring causes for deviation from S = D in the Reed model: arises from self-sustaining assumption. Working out the interpretation of the self-sustaining clause, which sounds like it needs to ensure that the stock is non-decreasing in the absence of harvest,
$$ P(X_{t+1} \geq x | X_n = x ) = 1 $$
This sounds like a very awkward condition to enforce for a non-trivial escapement level \( x = S \).</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/07/27/csgf-conference/</link>
      <pubDate>Fri, 27 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/07/27/csgf-conference/</guid>
      <description>Conference Agenda Alumni-organized Plus-One Day Agenda Great chance to talk with US Secretary of the Department of Energy Stephen Chu Interesting leadership training session lead by improv acting professional Raquel Holmes of ImprovScience
  Video recording of my talk  Slides:</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/07/23/notes/</link>
      <pubDate>Mon, 23 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/07/23/notes/</guid>
      <description>Reading Vasilis&amp;rsquo;s PLoS ONE warning signals methods out, listing different methods and announcing the earlywarings R package: 10.1371/journal.pone.0041010, and another comparing methods on some various data sets 10.1371/journal.pone.0038410, which (like Drake) advocates for a mixed method approach.
Modeling extreme risks in ecology 10.1111/j.1539-6924.2012.01871.x
Which is kinda like Richard Katz&amp;rsquo;s extreme value theory in ecology article.
NSF call for Decision, Risk and Management Science, see previously funded examples.
A paper in Eco Lett suggests model-guided field work 10.</description>
    </item>
    
    <item>
      <title>Evolution and iEvobio conference notes</title>
      <link>/2012/07/09/evolution-conf-summary/</link>
      <pubDate>Mon, 09 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/07/09/evolution-conf-summary/</guid>
      <description>Saturday  Jeremy Brown Graham Slater (Education Data Symposium) Cecile Ane Joe Felsenstein Lars Schmitz Carl Boettiger Liam Revell Brian O&amp;rsquo;Meara (Leithan McGonigle)  Sunday  Marie-Josee Fortin Emma Goldberg 10:45 rm 209 Networks Symposium Jeremy Fox 1.30p Rm 201 (Adaptation B) Schluter 2:15p Canada 2-3 Rosie Redfield public lecture  Monday  9:00 Michael Landis, 203 9:30 Dick Gumolkiowicz 214 10:30 Dean Adams 11 (Cavender-Bares, 214) (Bolnick, 213) 11:30 Mark McPeek 214  Tuesday  Luke Harmon 9am rm 214 Luke Mahler 9am rm 210 Rafael Maia 9:15a rm 210 Sam Price 11:15a rm 210 Liam Revell 11:30 Canada 2-3 Dan Rabosky 2:30pm Canada 2-3 Tanja Stadler 3pm Canada 2-3 Chris Martin 3pm rm 213  Also: ievobio Day 1.</description>
    </item>
    
    <item>
      <title>Evolution 2012 Conference, Day 1</title>
      <link>/2012/07/08/evolution-day1/</link>
      <pubDate>Sun, 08 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/07/08/evolution-day1/</guid>
      <description>Fantastic first day at Evolution. Spent the morning in the SSB Sympossium organized by Jeremy Brown, &amp;ldquo;Predictive approaches for assessing the fit of evolutionary models&amp;rdquo;. Really covered both methods assessing model fit (posterior predictive simulations) and approximate likelihood approaches, which are also simulation-based. Then the afternoon in the second SSB Symposium on emerging methods for comparative phylogenetics, organized by Liam Revell and Cecile Ane, which included my talk. Lots of great talks, but Cecile&amp;rsquo;s was perhaps the most striking results I saw presented all day.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/07/04/notes/</link>
      <pubDate>Wed, 04 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/07/04/notes/</guid>
      <description>Value of information  bias table with measurement noise Fix deterministic. Run scenarios with very low noise rather than deterministic Reed S vs. D theorem Reed theorem extended to Sethi cases simulation values should import scenario list. (done for bias table).
  Reed theorem  Not showing S = D for cost free. hmm&amp;hellip; Not showing S constant for different profit functions?!  impact of management on warning signals Compare the probability of detection in managed and unmanaged models.</description>
    </item>
    
    <item>
      <title>wrightscape / release of constraint</title>
      <link>/2012/07/03/notes/</link>
      <pubDate>Tue, 03 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/07/03/notes/</guid>
      <description>Here&amp;rsquo;s a table of all the comparisons, indicating which is the preferred model in each pairwise comparison. (In my outline, Figure 4 shows the bm3 v a3 for KT and open lever ratio, and Fig 3 shows the actual parameter values for those models). This table is all for the case that allows shifts at both pharyngeal and the intramandibular transitions. I have graphs of the actual parameter values as well (which we need to see if the constraint has increased or decreased at the transition, and by how much), but gets complex quickly.</description>
    </item>
    
    <item>
      <title>varying recruitment function, noise form, and harvesting cost</title>
      <link>/2012/07/02/notes/</link>
      <pubDate>Mon, 02 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/07/02/notes/</guid>
      <description>Seems that the level of caution observed in the deterministic scenario relative to the increasing noise scenarios comes, perhaps not surprisingly, from the addition of harvesting costs, rather than from overcompensatory dynamics or the asymmetric forms of the noise, which seem to have quantitative but not qualitative differences.
Table for NPV under biased parameters
 Beverton-Holt recruitment, lognormal noise, cost-free BH, lognormal, costs BH, uniform, free BH, uniform, costs logistic, lognormal, free logistic, lognormal, costs logistic, uniform, free logistic, uniform, costs  </description>
    </item>
    
    <item>
      <title>Progress this week, by project</title>
      <link>/2012/06/29/notes/</link>
      <pubDate>Fri, 29 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/06/29/notes/</guid>
      <description>Critical transitions Must determine the correct set of comparisons:
 Solve the SDP optim using the exact time dependent
 Simulate under an f with the same escapement policy but different functional form, i.e. logistic with K &amp;amp; r estimated from the May example, either analytically or directly from the data.
 Considering the costs of &amp;ldquo;cautious policy&amp;rdquo; (calculates optimal harvest recursively but always selects a fraction P of the optimal.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/06/24/ievobio-lightning-talk-proposal/</link>
      <pubDate>Sun, 24 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/06/24/ievobio-lightning-talk-proposal/</guid>
      <description>The rOpenSci Project Carl Boettiger, Scott Chamberlain, Karthik Ram Sharing scientific data is a win for individual scientists as well as for the larger enterprise of other researchers, publishers, funders, educators, and the general public. Despite the rapid increase of public data, most researchers continue to work on their own data just as before. We lack the both the tools and training to quickly and easily leverage such data. To address some of these challenges, we have created the rOpenSci project.</description>
    </item>
    
    <item>
      <title>Notes on value of information runs with uniform noise</title>
      <link>/2012/06/22/notes/</link>
      <pubDate>Fri, 22 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/06/22/notes/</guid>
      <description>Debug Sethi with large uniform noise: needed to avoid havest &amp;gt; stock in definition of f.
  I ran the value of information calculations using the Sethi settings of a logistic map and uniform noise, which does indeed replicate their results, where the measurement error escapement is lower than the &amp;ldquo;all low noise&amp;rdquo; (&amp;ldquo;deterministic&amp;rdquo;) escapement until stock get above carrying capacity. results
Kinda of interesting that this patterns isn&amp;rsquo;t robust to the noise distribution; I still find the lognormal noise pattern a bit more intuitive.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/06/21/notes/</link>
      <pubDate>Thu, 21 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/06/21/notes/</guid>
      <description>Value of information  Reed with uniform large noise, logistic map Reed with uniform large noise Reed with uniform small noise Sethi with uniform small noise, logistic map. Sethi with large noise Doesn&amp;rsquo;t work. hmm.. voi_sethi_parameters.md , running value of information setup but with small noise &amp;amp; logistic map. Whoops, this example solves uniform noise but simulates log-normal noise, which probably explains the positive effect of growth noise once again.</description>
    </item>
    
    <item>
      <title>the week so far</title>
      <link>/2012/06/19/notes/</link>
      <pubDate>Tue, 19 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/06/19/notes/</guid>
      <description>Sunday  Sent in my review for PLoS ONE. No way to attach pdf files, had to create and send a secure link instead to provide comments on the pdf.
 AIC discussion on r-sig-phylo. For a derivation I refer to Cavanaugh, (1997), also see Daniel Schmidt&amp;rsquo;s slides. Aikaike&amp;rsquo;s original paper does the derivation less deliberately than Cavanaugh but does discuss this Frequentist intepretation as the maximum expected log likelihood (Akaike, 1974).</description>
    </item>
    
    <item>
      <title>Policy functions and value functions under multiple uncertainty</title>
      <link>/2012/06/13/sethi-policy-functions/</link>
      <pubDate>Wed, 13 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/06/13/sethi-policy-functions/</guid>
      <description>Implements a numerical version of the SDP described in (Sethi et. al. 2005).
## Clear the workspace and load package dependencies: rm(list=ls()) require(pdgControl) require(reshape2) require(ggplot2) require(data.table)  We consider a Beverton Holt state equation governing population dynamics, $f(x,h) = \frac{A x}{1 + B x}$
f &amp;lt;- BevHolt  With parameters A = 1.5 and B = 0.05.
pars &amp;lt;- c(1.5, 0.05) K &amp;lt;- (pars[1] - 1)/pars[2]  Note that the positive stationary root of the model is given by \( \frac{A-1}{B} \), or carring capacity K = 10.</description>
    </item>
    
    <item>
      <title>Notes</title>
      <link>/2012/06/08/notes/</link>
      <pubDate>Fri, 08 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/06/08/notes/</guid>
      <description>pdg-control Working group  send summary briefing for stochastic policy costs paper &amp;ndash; DONE send latex/pdf to group  Value of information  To better get at Jim&amp;rsquo;s question, should compare (profit from growth only noise) - (profit from deterministic) + ((profit from measurement only) - (profit from deterministic)) to (profit from growth+measurement) - (determinsitic), i.e. is (growth+measurement) greater/less than (growth) + (measurement) - deterministic?
 Clarify this! is (profit from growth only) the case in which (a) the manager includes growth noise in the solution when in reality it is absent (hence the deterministic solution is optimal), (b) the case where the manager includes growth noise and it is present (i.</description>
    </item>
    
    <item>
      <title>knitcitations</title>
      <link>/2012/05/30/knitcitations/</link>
      <pubDate>Wed, 30 May 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/05/30/knitcitations/</guid>
      <description>EDIT: Note that this package has evolved quite a bit from this initial post. While the basic interface is the same, support for additional features and some choices in formatting differ from what is presented here. Please see the README for the latest introduction to the package. Readers may also be interested in the more recent post discussing the introduction of several new features including semantic tools in the knitcitations package</description>
    </item>
    
    <item>
      <title>Exploring Jekyll layout</title>
      <link>/2012/05/26/exploring-jekyll-layout/</link>
      <pubDate>Sat, 26 May 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/05/26/exploring-jekyll-layout/</guid>
      <description>Jekyll works wonderfully with little knowledge beyond basic html/css to create _layout templates and then you&amp;rsquo;re free to write beautiful pages and posts in markdown. But adding more dynamic content, the kind of cool stuff avialable in so many wordpress plugins, tends to require a little understanding of the template formatting language, Liquid. Liquid is actually super simple and powerful way to build a dynamic website. The project&amp;rsquo;s wiki provides a great introduction, starting with</description>
    </item>
    
    <item>
      <title>Limits to the detection of early warning signals</title>
      <link>/2012/05/21/limits-to-detection-of-early-warning-signals/</link>
      <pubDate>Mon, 21 May 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/05/21/limits-to-detection-of-early-warning-signals/</guid>
      <description>Our paper, limits to the detection of early warning signals for critical transitions, has now appeared in the Proceedings of the Royal Interface. An open-access copy is available under CC-by license on the ArXiv. The essence of the paper is to bring a more model-based approach to early warning signals, while seeking to remain as general as possible.
Without a model-based approach, it is difficult to leverage statistically meaningful comparisons to identify what is a real warning signal and what is just noise.</description>
    </item>
    
    <item>
      <title>notes</title>
      <link>/2012/05/18/notes/</link>
      <pubDate>Fri, 18 May 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/05/18/notes/</guid>
      <description> Wrote short talk for Adaptive Management class Adaptive management class short talks. teary Confirmed model-based estimation avoids fallacy on newly zoomed data. Updated cost-of-bias comparison Policy-costs: added adjustment free distribution to highlight double-cost effect  </description>
    </item>
    
    <item>
      <title>Value of information, cost of bias</title>
      <link>/2012/05/16/value-of-information/</link>
      <pubDate>Wed, 16 May 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/05/16/value-of-information/</guid>
      <description>Value of information The motivation for this &amp;ldquo;value of information&amp;rdquo; excercise comes from Costello et al. (2010), which essentially compares two scenarios: the value of a marine protected area when you the dispersal kernel is unknown (one of a discrete set of possible kernels you sum over), to the value of the protected area when the kernel is known perfectly. No intrinsic stochasticity, single time step, no learning.
The model I&amp;rsquo;m looking at comes from Reed (1979), and a modification by Sethi et al.</description>
    </item>
    
    <item>
      <title>Notes</title>
      <link>/2012/05/15/fallacy/</link>
      <pubDate>Tue, 15 May 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/05/15/fallacy/</guid>
      <description>Prosecutors Fallacy Running the null distribution and add to plots
 generate nulls add to fallacy Questions on plots &amp;ndash; show the full replicates plot? Emphasize the two different distributions that result. Additional replicates narrow the null distribution further. hmm&amp;hellip; run model fit part again modelfallacy.Rmd. Need to add the model fit data analysis section into this script.
 knitr&amp;rsquo;s caching really is the way to go with debugging things that need HPC.</description>
    </item>
    
    <item>
      <title>notes</title>
      <link>/2012/05/14/notes/</link>
      <pubDate>Mon, 14 May 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/05/14/notes/</guid>
      <description>Added results into prosecutors fallacy and sent to Alex, Noam, Marissa. Ran pdf copy and sent Treebase to Duncan README added to knitcitations staticdoc documentation for knitcitations (and filed a few issues on staticdocs) Updated documentaiton on treebase, rfishbase. updated their staticdocs documentation as well. rfishbase 0.0-9 update pushed to CRAN Working on prosecutor&amp;rsquo;s fallacy edits from Alex  Alan meeting Discuss management example with ROC curve instead of hypothesis test</description>
    </item>
    
    <item>
      <title>Prosecutor&#39;s fallacy notes</title>
      <link>/2012/05/12/notes/</link>
      <pubDate>Sat, 12 May 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/05/12/notes/</guid>
      <description>Mostly getting Prosecutor&amp;rsquo;s Fallacy example to run with large enough sample sizes. Finer sampling or more replicates than current settings seems to crash MPI connections over farm cluster, probably a memory issue. Oh well, looks like I&amp;rsquo;ve got a good enough sample size here.
 Prosecutor&amp;rsquo;s Fallacy  Citations on Jekyll No ideal solution here at the moment, a couple options:
 Pandoc: My intended solution, Disadvantages: converts everything to it&amp;rsquo;s own markdown format, which messes up my PHP Markdown tables and YAML frontmatter.</description>
    </item>
    
    <item>
      <title>Computing the value of information in management of a stochastic resource</title>
      <link>/2012/05/11/notes/</link>
      <pubDate>Fri, 11 May 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/05/11/notes/</guid>
      <description>pdg-control After reading Costello et. al. (2010), taking a look at value of information in a dynamic context. Consider the model of Sethi et. al. (2005) (Costello is part of et al); a dynamic fisheries model with stochastic growth (a la Reed, (1979)), stochastic measurement assessing the stock size, and stochastic implementation of the harvest. I first imagine the case where the real system is quite deterministic, say, with a tiny amount of growth stochasticity only.</description>
    </item>
    
    <item>
      <title>Notes</title>
      <link>/2012/05/10/notes/</link>
      <pubDate>Thu, 10 May 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/05/10/notes/</guid>
      <description>Partially Observable Stochastic Processes (cont.)  Reading a bit more about pomp. Looks like SCM and PMCMC offer nicely Bayesian inference tools using the same framework (rprocess and dmeasure), making a nice platform for implementing multiple methods. Almost feels like having the likelihood equation in hand again. A bit more skeptical about nonlinear forecasting and probe matching, as they feel even more heuristic or arbitrary. I suppose that&amp;rsquo;s just the price of having only rmeasure instead of dmeasure available though.</description>
    </item>
    
    <item>
      <title>Infering Partially Observable Markov Processes with Iterative Particle Filtering</title>
      <link>/2012/05/09/notes/</link>
      <pubDate>Wed, 09 May 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/05/09/notes/</guid>
      <description>Excellent talk by Ed Ionides at UC Davis today (led me to miss Weds session of Data to Knowledge).
Ed Ionides six problems of Bjonstead and Grenfell: an appeal for arbitrary nonlinear partially observed vector valued stochastic models.
POMP doesn&amp;rsquo;t mix well in the winbugs.
simulation-based algorithm (plug-and-play)
Think of a process being defined by:
 rprocess() dprocess() rmeasure() dmeasure()  In general we need some subset of these processes:</description>
    </item>
    
    <item>
      <title>Data to Knowledge Day II and other notes</title>
      <link>/2012/05/08/notes/</link>
      <pubDate>Tue, 08 May 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/05/08/notes/</guid>
      <description>Great second day at the Data to Knowledge conference (a few notes below).
Also I have been trying to move a few projects forward during the commute and break. I&amp;rsquo;ve sent Alan my revisions on the prosecutor&amp;rsquo;s fallacy manuscript, getting pretty close. Following up on a query from John, ran a simulation showing the impact of having a delay in the timeseries before the slow change towards the bifurcation begins.</description>
    </item>
    
    <item>
      <title>Data to Knowledge Day 1</title>
      <link>/2012/05/07/notes/</link>
      <pubDate>Mon, 07 May 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/05/07/notes/</guid>
      <description>Scaling Time Series Data Mining to trillions of series Eamonn Keogh
 Similarity search is the fundamental problem for any task This problem is now solved. As effective as possible, as efficient as possible.  What is similarity search? All about required invariances: Looking at ancient manuscripts of fish &amp;ndash; identify multiple drawings of the same species. Invariant to color, scale, and orientation.
(Note that rotation becomes phase, easy to handle).</description>
    </item>
    
    <item>
      <title>My research workflow, based on Github</title>
      <link>/2012/05/06/research-workflow/</link>
      <pubDate>Sun, 06 May 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/05/06/research-workflow/</guid>
      <description>This post outlines my current research workflow. This has evolved over time, so only my most recent projects hold completely to it, though almost all my projects follow the general R package structure. Two main differences are visible in my earlier projects: I used to keep scripts in demo before they became the more complete knitr markdown in inst/examples. I previously relied on a custom package called socialR to post results from those scripts to flickr, and would then embed the results in my Wordpress notebook, linking back to the demo file in Github.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/05/04/notes/</link>
      <pubDate>Fri, 04 May 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/05/04/notes/</guid>
      <description>Chris Costello Talk Presents unpublished work on value of (behavioral) adaptation, using forestry practices changing under climate change as the example. If we ignore adaptive responses, we overestimate costs and underestimate benefits.
 Effect w/ adaptation:  $$ \frac{d V}{d \theta} = \frac{\partial f}{\partial r} \frac{\partial r }{\partial \theta} + \frac{\partial f}{\partial \theta} $$
 Envelope theorem: optimal point is at ( df/dr = 0 ), so no value of adaptation after optimizing with respect to r.</description>
    </item>
    
    <item>
      <title>Testing out a Jekyll-based notebook</title>
      <link>/2012/05/03/testing-out-a-jekyll-based-notebook/</link>
      <pubDate>Thu, 03 May 2012 10:50:13 +0000</pubDate>
      
      <guid>/2012/05/03/testing-out-a-jekyll-based-notebook/</guid>
      <description>I am trying out Jekyll as an alternative to Wordpress for powering this site and my open lab notebook. If you subscribe, the new RSS (atom) feed for the new notebook is at http://carlboettiger.info/atom.xml. I&amp;rsquo;d love to hear any feedback, good or bad, about the switch. A recent post gives my own reflections. The site&amp;rsquo;s source-code is available on github.
Navigating two platforms The Wordpress site now lives at http://carlboettiger.</description>
    </item>
    
    <item>
      <title>Notes</title>
      <link>/2012/05/03/notes/</link>
      <pubDate>Thu, 03 May 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/05/03/notes/</guid>
      <description>Returned proofs for warning signals paper. Wrightscape figures sent to Peter. move fallacy to a branch off of main in earlywaring package? Running knit on the large clusters means images cannot be uploaded as they are created, since compute nodes don&amp;rsquo;t have internet access. Saving files locally, I&amp;rsquo;ve created a little script to parse the output file.md to find the and upload the local images, and swap the local paths for the url paths.</description>
    </item>
    
    <item>
      <title>Stochastic policy costs</title>
      <link>/2012/05/02/stochastic-policy-costs/</link>
      <pubDate>Wed, 02 May 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/05/02/stochastic-policy-costs/</guid>
      <description>Updated runs for various norms, added profit plots.
 L1 L2 asymmetric: differs on the sign of the asymmetry? Penalty only for decreasing quotas. Penalty only for increasing quotas. check implementation. fixed transaction fee &amp;ndash; whoops, fixed cost should still be free when h == h_prev.  We need to determine a the magnitude of penalty coefficient to compare between the different functional forms. For instance, for what value of c is an L2 penalty, $ c ( h_t - h_p )^2 $ comparable to the L1 penalty, $ c \operatorname{abs}(h_t - h_p ) $ ?</description>
    </item>
    
    <item>
      <title>Jekyll vs Wordpress</title>
      <link>/2012/05/01/jekyll-vs-wordpress/</link>
      <pubDate>Tue, 01 May 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/05/01/jekyll-vs-wordpress/</guid>
      <description>I am now trying out a Jekyll-based platform rather than a Wordpress based for my website and lab notebook. Don&amp;rsquo;t worry, the Wordpress site still remains where it was with links intact, I&amp;rsquo;ve simply remapped the homepage. For now this is an experiment, we&amp;rsquo;ll see how it goes.
Why switch? Speed Wordpress was great, meeting most of my needs for a customizable site that I couldn&amp;rsquo;t really accomplish in my first online notebook on OpenWetWare.</description>
    </item>
    
    <item>
      <title>Additional sources of noise (Sethi 2005)</title>
      <link>/2012/04/30/sethi/</link>
      <pubDate>Mon, 30 Apr 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/04/30/sethi/</guid>
      <description>Sethi Model  author Carl Boettiger, cboettig@gmail.com license: CC0  Implements a numerical version of the SDP described in (Sethi et. al. 2005).
Clear the workspace and load package dependencies:
Define noise parameters
sigma_g &amp;lt;- 0.1 # Noise in population growth sigma_m &amp;lt;- 0.1 # noise in stock assessment measurement sigma_i &amp;lt;- 0.1 # noise in implementation of the quota  we&amp;rsquo;ll use log normal noise functions. For Reed, only z_g will be random.</description>
    </item>
    
    <item>
      <title>Project tracking (Ecology)</title>
      <link>/2012/04/27/ecology-notes/</link>
      <pubDate>Fri, 27 Apr 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/04/27/ecology-notes/</guid>
      <description>pdg-control Has become a variety of different directions:
Policy Costs  Considering different norms. L1 L2 Assymetric fixed When can policy costs pay for themselves? notes  Additional Noise  Starts with replicating Sethi et al. (2005). Consider the performance of various non-optimal solutions, particularly regarding imperfect implementation These are losely collected in Robustness examples, needs some evaluation of the most interesting.  Approaches to parameter, structural, and state uncertainty  (Morph of) Training problem II from the working group.</description>
    </item>
    
    <item>
      <title>Project tracking (Evolution)</title>
      <link>/2012/04/27/evolution-notes/</link>
      <pubDate>Fri, 27 Apr 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/04/27/evolution-notes/</guid>
      <description>Evolution I&amp;rsquo;m also still wrapping up a variety of projects on the Evolution front.
treebase  Dynamic manuscript. Reorganize, simplify? add, document, employ the additional functions to avoid sapply commands. Prune examples? iEvoBio challenge entry?  Wrightscape  Start synthesizing documents Evidence for release in open lever ratio and kt Illustrating the different models Consider updated data format outputs and graphical processing functions for the model choice steps  fishbase  submitted!</description>
    </item>
    
    <item>
      <title>2012-04-20</title>
      <link>/2012/04/26/2012-04-20/</link>
      <pubDate>Thu, 26 Apr 2012 13:32:18 +0000</pubDate>
      
      <guid>/2012/04/26/2012-04-20/</guid>
      <description>Warning Signals Warning signals paper accepted. Making minor edits before submitting final copy.
Added Alan&amp;rsquo;s edits.
 Review model section again Letter: Response to reviewers Create Diff Media Summary Submit  Done!
Database papers  rfishbase edits made, reformatting in word, sent to Peter Ethics form, recommended reviewers, cover letter. Submit  Done!
Misc NERSC web directory: create www in /project/projectdirs/m1366 NSF Arctic SEES grants
 These larger, integrated efforts would promote understanding of Arctic systems and would develop optimized models, multiple stable state scenarios, sustainable pathways, decision matrices, visualization techniques and data infrastructure to aid decision making and communication, and structural, energy and communications technology solutions which would inform community practices, management, and policy for a more sustainable Arctic environment.</description>
    </item>
    
    <item>
      <title>Notes</title>
      <link>/2012/04/25/notes/</link>
      <pubDate>Wed, 25 Apr 2012 00:00:00 +0000</pubDate>
      
      <guid>/2012/04/25/notes/</guid>
      <description>Working on IGPS Presentation.
Experimenting with recent tools for Amazon cloud computing via R. Whit Armstrong&amp;rsquo;s packages seem like a good place to start, but some trouble with credentials on both this and on Segue at the moment.
Submitted nominations for EVE Seminar. Splitting nominations among the theory group, this year I&amp;rsquo;ve filed nominations for
 Marten Scheffer (profile) Hugh Possingham (profile) John Drake  </description>
    </item>
    
    <item>
      <title>Catching up</title>
      <link>/2012/04/19/catching-up/</link>
      <pubDate>Thu, 19 Apr 2012 10:39:06 +0000</pubDate>
      
      <guid>/2012/04/19/catching-up/</guid>
      <description>Catching up on notebook entries for last week and the beginning of this week in one go here. In the process of wrapping up a variety of older projects, so this is kinda all over the place.
rfishbase  Create function table, finalize functions Add support for references. Done, see getRefs. (And isn&amp;rsquo;t it awesome that you can link to a specific linenumber (i.e. line 280) in github by adding #L280 to the end of the url?</description>
    </item>
    
    <item>
      <title>Monday / Tuesday</title>
      <link>/2012/04/10/monday-tuesday/</link>
      <pubDate>Tue, 10 Apr 2012 23:09:06 +0000</pubDate>
      
      <guid>/2012/04/10/monday-tuesday/</guid>
      <description>rfishbase updated to Duncan&amp;rsquo;s feedback writing intro section on Prosecutor&amp;rsquo;s Fallacy. wrightscape update project repository. Scripts mostly in demos, results in notebook. Notebook makes is easy to get the most recent writeup on the topic, from where I can start to track back the history, but doesn&amp;rsquo;t provide a good at-a-glance view of the analyses I&amp;rsquo;ve run side-by-side. Moving the R script demos/ into markdown knitted files in inst/examples/ and rerunning.</description>
    </item>
    
    <item>
      <title>Writing reproducibly in the open with knitr</title>
      <link>/2012/04/07/writing-reproducibly-in-the-open-with-knitr/</link>
      <pubDate>Sat, 07 Apr 2012 14:58:36 +0000</pubDate>
      
      <guid>/2012/04/07/writing-reproducibly-in-the-open-with-knitr/</guid>
      <description>Sweave is something of a gold standard in reproducible research. It creates a dynamic document, written in a mix of LaTeX and R code where the results of the analysis (numbers, figures, tables) are automatically generated from the code and inserted into the resulting pdf document, making them easy to update if the data or methods change. It&amp;rsquo;s a nice idea, in principle.
However, the practical troubles are many. Coauthors don&amp;rsquo;t know LaTeX, publishers who don&amp;rsquo;t accept LaTeX or pdfs.</description>
    </item>
    
    <item>
      <title>Friday</title>
      <link>/2012/04/06/friday-8/</link>
      <pubDate>Fri, 06 Apr 2012 21:01:16 +0000</pubDate>
      
      <guid>/2012/04/06/friday-8/</guid>
      <description>Fishbase  Revisions based on Duncan&amp;rsquo;s feedback Formatting to Journal of Fish Biology guidelines Updated formatting   fixed footnotes issue in pdf version. Externalize tables in word version.
  knit_hooks$set(chunk = function(x, options) { if (!options$split) return(x) cat(x, file = fig_path(&#39;.md&#39;, options)) }   Consider more intuitive function names rather than function arguments?  TreeBase  Needs additional functions replacing sapply queries and argument queries. Table of functions re-organize presentation  rOpenSci GSOC GSoC applications were due at noon today.</description>
    </item>
    
    <item>
      <title>Jordan&#39;s bigdata talk in Math/Stats series</title>
      <link>/2012/04/05/jordans-bigdata-talk-in-mathstats-series/</link>
      <pubDate>Thu, 05 Apr 2012 15:48:44 +0000</pubDate>
      
      <guid>/2012/04/05/jordans-bigdata-talk-in-mathstats-series/</guid>
      <description>Really excellent talk by Professor Michael Jordan from the Berkeley Statistics department visiting us at Davis yesterday. Haven&amp;rsquo;t seen a talk cover technical content with remarkable clarity for the algorithms and insights involved, while also covering such a breadth of material. My notes didn&amp;rsquo;t really keep up, but transcribing some of my scribbling into electronic form will have to wait until I have more time. (Their pubs are probably a better reference anyway.</description>
    </item>
    
    <item>
      <title>Monday/Tuesday</title>
      <link>/2012/04/03/mondaytuesday/</link>
      <pubDate>Tue, 03 Apr 2012 15:59:22 +0000</pubDate>
      
      <guid>/2012/04/03/mondaytuesday/</guid>
      <description>knitr + markdown + pandoc + latex Troubleshooting this workflow still&amp;hellip;
 Fonts xtable for html &amp;amp; latex/pdf xtable comments display tikz device trouble Pandoc table trouble pandoc footnotes Getting a satisfactory LaTeX template.
 Makefile   writing writing writing: Mostly writing this week, so my notebook has been lacking in entries. Trying to move several manuscripts forward: two are papers accompanying software packages for extracting, manipulating and visualizing data from online repositories (TreeBase and FishBase); part of the rOpenSci project.</description>
    </item>
    
    <item>
      <title>Relevant initiatives from today&#39;s Big Data press release</title>
      <link>/2012/03/29/relevant-initiatives-from-todays-big-data-press-release/</link>
      <pubDate>Thu, 29 Mar 2012 22:01:54 +0000</pubDate>
      
      <guid>/2012/03/29/relevant-initiatives-from-todays-big-data-press-release/</guid>
      <description>An exciting day for Big Data (particularly if your Berkeley).
NSF  Encouraging research universities to develop interdisciplinary graduate programs to prepare the next generation of data scientists and engineers; Funding a $10 million Expeditions in Computing project based at the University of California, Berkeley, that will integrate three powerful approaches for turning data into information - machine learning, cloud computing, and crowd sourcing; Providing the first round of grants to support “EarthCube” - a system that will allow geoscientists to access, analyze and share information about our planet; Convening researchers across disciplines to determine how Big Data can transform teaching and learning.</description>
    </item>
    
    <item>
      <title>Data to Knowledge Conference, UC Berkeley: application </title>
      <link>/2012/03/29/data-to-knowledge-conference-uc-berkeley-application-abstract/</link>
      <pubDate>Thu, 29 Mar 2012 12:08:51 +0000</pubDate>
      
      <guid>/2012/03/29/data-to-knowledge-conference-uc-berkeley-application-abstract/</guid>
      <description>I&amp;rsquo;ve just been accepted to the Data to Knowledge Conference in Berkeley this May. I think this conference will address some of the key issues facing us in Big Data today across many different fields, and I hope to learn much that could be useful to ecology and evolution. Given the audience I look forward to being a source of questions rather than answers as I put on my biologist&amp;rsquo;s cap.</description>
    </item>
    
    <item>
      <title>Tuesday: pandoc citations notes, various</title>
      <link>/2012/03/27/tuesday-pandoc-citations-notes-various/</link>
      <pubDate>Tue, 27 Mar 2012 22:22:14 +0000</pubDate>
      
      <guid>/2012/03/27/tuesday-pandoc-citations-notes-various/</guid>
      <description>Markdown over latex? knitr may have solved the fundamental challenge of all Sweave/latex users with Markdown. Too many of us must be able to work with collaborators who don&amp;rsquo;t know LaTeX and journals that won&amp;rsquo;t accept LaTeX. It&amp;rsquo;s a sad state of the affairs, and has improved slowly for journals (at least many will take pdfs for initial submissions) if not for collaborators. Consequently getting away from LaTeX would be nice, but Word or Google docs just won&amp;rsquo;t cut it.</description>
    </item>
    
    <item>
      <title>Active adaptive management solutions: Belief SDP</title>
      <link>/2012/03/26/active-adaptive-management-solutions-belief-sdp/</link>
      <pubDate>Mon, 26 Mar 2012 14:46:52 +0000</pubDate>
      
      <guid>/2012/03/26/active-adaptive-management-solutions-belief-sdp/</guid>
      <description>Have finally gotten my active adaptive management solutions working.
The active adaptive management solution learns very quickly and rather monotonically which model is correct, even when models differ by small amounts and the initial belief is heavily skewed to the wrong model. I&amp;rsquo;ve implemented examples with Myers model, but in this parameter space the allee effect is well below the Reed escapement level of the alternative Beverton Holt model, so it doesn&amp;rsquo;t exert itself.</description>
    </item>
    
    <item>
      <title>Citations in markdown using knitr</title>
      <link>/2012/03/24/citations-in-markdown-using-knitr/</link>
      <pubDate>Sat, 24 Mar 2012 21:33:27 +0000</pubDate>
      
      <guid>/2012/03/24/citations-in-markdown-using-knitr/</guid>
      <description>I am finding myself more and more drawn to markdown rather then tex/Rnw as my standard format (not least of which is the ease of displaying the files on github, particularly now that we have automatic image uploading). One thing I miss from latex is the citation commands. (I understand these can be provided to markdown via Pandoc, but I&amp;rsquo;d like to simply have to knit the document, and not then run it through pandoc, latex, or another interpreter).</description>
    </item>
    
    <item>
      <title>Robust control &amp; uncertainty - reading notes</title>
      <link>/2012/03/22/robust-control-uncertainty-reading-notes/</link>
      <pubDate>Thu, 22 Mar 2012 18:19:17 +0000</pubDate>
      
      <guid>/2012/03/22/robust-control-uncertainty-reading-notes/</guid>
      <description>Ecologists/TREE (Fischer et. al. 2009), (Polasky et. al. 2011) give a nice overview/introduction to the problem. Perhaps most interestingly, both set up resilience approaches as a foil or alternate approach in contrast to a decision-theoretic problem. Fischer&amp;rsquo;s group does a particularly nice job handling the case that these two are separate approaches &amp;ndash; it&amp;rsquo;s easy to dismiss resilience thinking as fuzzy optimization of fuzzy objective functions.
The Polasky piece does a nice job refocusing us on the obvious but brushed-over question of the objective function.</description>
    </item>
    
    <item>
      <title>Policy costs to changing mangement, TP 1b: Apples to Apples</title>
      <link>/2012/03/21/policy-costs-to-changing-mangement-tp-1b-apples-to-apples/</link>
      <pubDate>Wed, 21 Mar 2012 14:42:57 +0000</pubDate>
      
      <guid>/2012/03/21/policy-costs-to-changing-mangement-tp-1b-apples-to-apples/</guid>
      <description>A central question of training problem 1b addressed at the working group was how to compare the different penalties. Following up on those discussions, here are a few notes on how far I&amp;rsquo;ve gotten in the analysis regarding the best way to make these comparisons.
 simulate_npv_curves Nice job of showing the performance of the variance ratio, clear example for L2. Correlation test should probably be applied to differences, pattern is much less clear.</description>
    </item>
    
    <item>
      <title>knitr, github, and a new phase for the lab notebook</title>
      <link>/2012/03/21/knitr-github-and-a-new-phase-for-the-lab-notebook/</link>
      <pubDate>Wed, 21 Mar 2012 12:13:42 +0000</pubDate>
      
      <guid>/2012/03/21/knitr-github-and-a-new-phase-for-the-lab-notebook/</guid>
      <description>I have recently modified the basic workflow of my lab notebook since discovering knitr. Before, I would write code files which I could track on github, push figures created by the code to flickr, and then write a notebook entry on wordpress describing what I was doing. I&amp;rsquo;d embed each figure I wanted into the entry, and each figure got an automatic link to github for the script that created it (which usually worked, though it didn&amp;rsquo;t say where in the script the command came from, and it required manually specifying the script name).</description>
    </item>
    
    <item>
      <title>Tuesday: active adaptive management, a first solution</title>
      <link>/2012/03/20/tuesday-active-adaptive-management-a-first-solution/</link>
      <pubDate>Tue, 20 Mar 2012 22:31:42 +0000</pubDate>
      
      <guid>/2012/03/20/tuesday-active-adaptive-management-a-first-solution/</guid>
      <description>Spent way more of today than I wanted to hammering out the active adaptive management implementation for a trivial model-choice problem using the discretized belief-SDP approach.
We have alternate models $f_1$ and $f2$ of the state equations (population growth dynamics) $$ x{t+1} = z_t f(x_t) $$ and introduce a continuously valued belief probability $p$ that model 1 is correct. This lends itself to a Bayesian updating rule for our belief based on observing a transition from $x$ to $y$,</description>
    </item>
    
    <item>
      <title>Friday: some random notes</title>
      <link>/2012/03/20/friday-some-random-notes/</link>
      <pubDate>Tue, 20 Mar 2012 16:53:08 +0000</pubDate>
      
      <guid>/2012/03/20/friday-some-random-notes/</guid>
      <description>Computational tricks  tables in github markdown via knitr. clever Getting custom C/C++ CUDA working in R  Data management and sharing solutions for large files  NERSC uses globus online for interface for transferring terabytes/hr, pretty clever. NERSC also enables web hosting to share data.
 Software-Carpentry style Data management a nice start. An open solution could stick the data on figshare (or elsewhere), write the readmes in markdown and keep them on github with links to the data.</description>
    </item>
    
    <item>
      <title>Citing R packages</title>
      <link>/2012/03/20/citing-r-packages/</link>
      <pubDate>Tue, 20 Mar 2012 10:02:09 +0000</pubDate>
      
      <guid>/2012/03/20/citing-r-packages/</guid>
      <description>I&amp;rsquo;m not always careful in citing all the R packages I use. R actually has some rather nice built-in mechanisms to support this, so I really have no excuse. Here&amp;rsquo;s some quick examples:
citation(&amp;quot;ouch&amp;quot;)  To cite the ouch package in publications use: Aaron A. King and Marguerite A. Butler (2009), ouch: Ornstein-Uhlenbeck models for phylogenetic comparative hypotheses (R package), http://ouch.r-forge.r-project.org Butler, M. A. and King, A. A. (2004) Phylogenetic comparative analysis: a modeling approach for adaptive evolution Am.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2012/03/19/monday-treebase-manuscript-writing/</link>
      <pubDate>Mon, 19 Mar 2012 20:21:09 +0000</pubDate>
      
      <guid>/2012/03/19/monday-treebase-manuscript-writing/</guid>
      <description>Catching up on unfinished work: today has been spent mostly working over my little treebase applications note. I&amp;rsquo;m still deciding what/how to present in terms of the meta-analysis section &amp;ndash; looking at the classic trends on diversification rate statistics: $\gamma$ statistic (Pybus &amp;amp; Harvey, 2000) and diversification rate, and dependence on number of taxa. Not sure how best to handle issues of data choice, quality, or to just average over the available data.</description>
    </item>
    
    <item>
      <title>pdg-control Day 1 goals by training problem</title>
      <link>/2012/03/13/pdg-control-day-1-goals-by-training-problem/</link>
      <pubDate>Tue, 13 Mar 2012 21:23:56 +0000</pubDate>
      
      <guid>/2012/03/13/pdg-control-day-1-goals-by-training-problem/</guid>
      <description>Training Problem I / Theme 1 Policy costs  Functional forms of cost &amp;amp; Structure of the paper Comparability (view over all costs? view expected economic benefit?)
 Visualizations Dan&amp;rsquo;s L1 norm story (vs stochastic, discrete time?)  Transaction Fee details in cts time, deterministic Advanced problem 1 How many spatially differentiated policies are optimal 1. formulate bioeconomic model 2. modularity methods 3. comparison of GBR &amp;amp; Caribbean examples</description>
    </item>
    
    <item>
      <title>pdg-control, Training Problem 2 update to group</title>
      <link>/2012/03/13/pdg-control-training-problem-2-update-to-group/</link>
      <pubDate>Tue, 13 Mar 2012 20:17:25 +0000</pubDate>
      
      <guid>/2012/03/13/pdg-control-training-problem-2-update-to-group/</guid>
      <description>Intrinsic Stochasticity $$ x_{t+1} = z_t f(x_t, ht) $$ $$ max{h_t} \textrm{E} \left( \sum_t \Pi(h_t, x_t) \delta^t \right) $$ Measurement error $ m_t = z_m x_t $ Implementation error $ i_t = z_i h_t $
Next: Uncertainty = we can learn and hence decrease the uncertainty. But state-space grows exponentially.
Parametric Uncertainty Biological state equation $$ x_{t+1} = z_t f(x_t, h_t, a_t) P(a_t, \hat a_t, \sigmat) $$ Bayesian Learning state equations $$ \hat a{t+1} = \textrm{Posterior}(a | x) = \frac{ L(x|a) \textrm{Prior}(a)}{\int L(x|a) \textrm{Prior}(a) da } $$</description>
    </item>
    
    <item>
      <title>Parameter uncertainty in stochastic control problems</title>
      <link>/2012/03/11/parameter-uncertainty-in-stochastic-control-problems-2/</link>
      <pubDate>Sun, 11 Mar 2012 23:52:23 +0000</pubDate>
      
      <guid>/2012/03/11/parameter-uncertainty-in-stochastic-control-problems-2/</guid>
      <description>Day 3 of my short-term visitor stay before the working group starts.
 Wednesday: Travel
 Thursday: 8:45 Group Meeting: Paul, Michael, Lance, Dan, Jake, Carl.
  Training problem II discussion &amp;ndash; problem taxonomy: stochastic , model uncertainty, parameter uncertainty, state uncertainty. Learning on uncertainty (passive/adaptive active management) in the uncertainty cases, all of which increase the parameter space. Evening with Paul&amp;rsquo;s students.
 Friday Writing up Training problem II with Jake, Michael.</description>
    </item>
    
    <item>
      <title>Alex Pfaff seminar, meeting</title>
      <link>/2012/03/09/alex-pfaff-seminar-meeting/</link>
      <pubDate>Fri, 09 Mar 2012 10:34:20 +0000</pubDate>
      
      <guid>/2012/03/09/alex-pfaff-seminar-meeting/</guid>
      <description>Notes from Alex Pfaff talk at UTK (during my visit for pdg-control meeting).
 average impact vs differential impact &amp;ndash; must compare against what would have happened to the area if unprotected (at current time/short-timescale, or in future?)
 Proximity is not a good proxy of similarity (i.e. bc we protect steep slopes but farm the flat land nearby)
 Instead use simple metrics available in GIS layers - distance from nearest road, etc.</description>
    </item>
    
    <item>
      <title>Stability analysis on fished and unfished dynamics.  </title>
      <link>/2012/03/06/stability-analysis-on-fished-and-unfished-dynamics/</link>
      <pubDate>Tue, 06 Mar 2012 22:18:16 +0000</pubDate>
      
      <guid>/2012/03/06/stability-analysis-on-fished-and-unfished-dynamics/</guid>
      <description>In this example, we compute the distribution of the stability coefficients estimated from the fished and unfished simulations. Overall this shows little success in distinguishing between the stability of the fished and unfished populations &amp;ndash; i.e. no hint that we are managing near an edge.
(Originally run and posted in github notebook, but cross posting for reference here since I had trouble recalling if this was filed with the control project or the warning signals project directory.</description>
    </item>
    
    <item>
      <title>Tuesday</title>
      <link>/2012/03/06/tuesday-14/</link>
      <pubDate>Tue, 06 Mar 2012 19:58:20 +0000</pubDate>
      
      <guid>/2012/03/06/tuesday-14/</guid>
      <description>Confirm travel plans for tomorrow  pdg-control  Stability analysis speeding up policycosts (extra loop) will probably require some C coding. Meanwhile could hard-code in the profit function to accelerate things.
 model averaging (mimic the fisheries science work &amp;amp; climate models that present distribution of outcomes over different models as the range of possibilities, lacking probabilities assigned to those models&amp;hellip;). work on model estimation externalization: Note that we can tangle a file to create a .</description>
    </item>
    
    <item>
      <title>Monday</title>
      <link>/2012/03/05/monday-17/</link>
      <pubDate>Mon, 05 Mar 2012 16:17:34 +0000</pubDate>
      
      <guid>/2012/03/05/monday-17/</guid>
      <description>Trivial example of a non-optimal but more robust policy by editing the optimal strategy directly. Note in particular that this outperforms the optimal strategy economically as well as ecologically (fewer crashed populations).
 Running the policy-costs model with Beverton Holt instead of the Myers function seems to give a clearer picture of a system responding to policy costs. The single-replicate picture probably captures this better than the policy/replicate visualizations.</description>
    </item>
    
    <item>
      <title>Thursday, Friday, Saturday</title>
      <link>/2012/03/03/thursday-friday-saturday/</link>
      <pubDate>Sat, 03 Mar 2012 22:21:36 +0000</pubDate>
      
      <guid>/2012/03/03/thursday-friday-saturday/</guid>
      <description>forage fish seminar - Patrick and Jay with interesting stuff. Sounds like compensating benefits due to quality-response (larger fish) and stock effect (easier to find) will be more minor in this fishery, but demand response be compensating.  knit hooks externalization example working (based on Reed.R). Still unsure how I feel about externalization vs fully literate code. Redundant typing is bad but isn&amp;rsquo;t that why common tasks are functionalized?</description>
    </item>
    
    <item>
      <title>Warning Signals in Fish Collapse</title>
      <link>/2012/02/28/warning-signals-in-fish-collapse/</link>
      <pubDate>Tue, 28 Feb 2012 15:01:42 +0000</pubDate>
      
      <guid>/2012/02/28/warning-signals-in-fish-collapse/</guid>
      <description>Description: an example trying to detect early warning signals in data from fisheries collapses
Set up markdown format and image uploads.
render_wordpress() opts_knit$set(upload = TRUE) opts_knit$set(imgur.key = getOption(&amp;amp;amp;quot;imgur&amp;amp;amp;quot;))  Load required libraries
require(warningsignals) require(ggplot2) require(reshape2)  Load the data scotia &amp;amp;amp;lt;- read.csv(&amp;amp;amp;quot;../../data/rawdata/sau_scotia.csv&amp;amp;amp;quot;)  Visualize data dat_scotia &amp;amp;amp;lt;- melt(scotia, id = &amp;amp;amp;quot;Year&amp;amp;amp;quot;) p_scotia &amp;amp;amp;lt;- ggplot(dat_scotia, aes(Year, value, fill = variable)) + geom_area() print(p_scotia)  Compute some indicators Define some indicators</description>
    </item>
    
    <item>
      <title>Knitr with flickr and wordpress</title>
      <link>/2012/02/28/knitr-with-flickr-and-wordpress/</link>
      <pubDate>Tue, 28 Feb 2012 14:59:21 +0000</pubDate>
      
      <guid>/2012/02/28/knitr-with-flickr-and-wordpress/</guid>
      <description>It&amp;rsquo;s amazing how nice it is to work with well-developed software. It took me about 20 minutes to extend Yuhui&amp;rsquo;s interface to allow me to upload images through flickr instead of imgur, and embed them into a wordpress blog using the shortcode from the flickr gallery plugin.
To do this, I just modified the hook used by the markdown format. First, I define a quick R function that uploads to flickr and returns the flickr identifier number.</description>
    </item>
    
    <item>
      <title>Using knitr and RWordPress to publish results directly from R</title>
      <link>/2012/02/27/using-knitr-and-rwordpress-to-publish-results-directly-from-r-6/</link>
      <pubDate>Mon, 27 Feb 2012 18:31:51 +0000</pubDate>
      
      <guid>/2012/02/27/using-knitr-and-rwordpress-to-publish-results-directly-from-r-6/</guid>
      <description>Update: The original source file for this post, generates this output file formatted for wordpress. The source file has been knitted for markdown formatting so this post displays in Jekyll. The rendered post relies on Wordpress shortcodes, as raw the output file shows above. The markdown-based rendering shows the images and the shortcodes wordpress uses for codeblocks.
One of the great things about knitr is its flexibility. Here I set knitr up to publish to Wordpress.</description>
    </item>
    
    <item>
      <title>Monday</title>
      <link>/2012/02/27/monday-14/</link>
      <pubDate>Mon, 27 Feb 2012 15:20:04 +0000</pubDate>
      
      <guid>/2012/02/27/monday-14/</guid>
      <description>Warning Signals  Added resulting indicator distributions on finer sampling results.
 Re-running now excluding the final dive (population below 300).
  Treebase working on manuscript. A few examples using the improved meta-data queries:
Computing configuration vim and R  install vim-r-plugin. Download, then run vim-addons install r-plugin install screen plugin add to .vimrc:   set nocompatible syntax enable filetype plugin on filetype indent on let vimrplugin_underscore = 0   learn some key bindings Really \rf to launch, and \d Also see this post for configuration with vim-latex-suite.</description>
    </item>
    
    <item>
      <title>Visuals for Communicating Uncertainty </title>
      <link>/2012/02/24/visuals-for-communicating-uncertainty/</link>
      <pubDate>Fri, 24 Feb 2012 20:20:16 +0000</pubDate>
      
      <guid>/2012/02/24/visuals-for-communicating-uncertainty/</guid>
      <description>Visiting the question of communicating uncertainty in Marissa&amp;rsquo;s lab meeting, focusing on this excellent Science article (Spiegelhalter et. al. 2011). Noam and Jamie are leading the discussion, and suggested we pick a few favorite examples. None on my list really address the challenge of communicating uncertainty directly, though the first one probably comes closest. I think they do highlight some of the potential and the challenges of good data visualization though, which is certainly one of the essential building blocks to visual communication of uncertainty.</description>
    </item>
    
    <item>
      <title>ESA 2012 Abstract</title>
      <link>/2012/02/23/esa-2012-abstract/</link>
      <pubDate>Thu, 23 Feb 2012 21:44:16 +0000</pubDate>
      
      <guid>/2012/02/23/esa-2012-abstract/</guid>
      <description>Submitted my abstract for ESA 2012, in Portland. Getting a title and abstract pinned down about seven months in advance is itself an exercise in decision making under uncertainty. I&amp;rsquo;ve added some further background below.
Unknown unknowns: management strategies under uncertainty &amp;amp; alternate stable states Background/Question/Methods The effective management of natural resource populations such as fisheries or forests and the ecosystems in which they are embedded is a central goal of much work in both theoretical and applied ecological research.</description>
    </item>
    
    <item>
      <title>Stochastic optimization </title>
      <link>/2012/02/22/stochastic-optimization/</link>
      <pubDate>Wed, 22 Feb 2012 21:44:35 +0000</pubDate>
      
      <guid>/2012/02/22/stochastic-optimization/</guid>
      <description>Surprising heterogeneity of profit distribution under a simple Beverton-Holt model Usually I expect the alternate stable state dynamics to be the ones producing bimodal distribution of profit:
The pattern is driven by a costs to harvesting making harvest unprofitable most of the time, while chance fluctuations push some populations across this threshold again and again. The ensemble variation in harvest is suggestive of this:
but we really see what is going on when we color-code the population dynamics of the most profitable and least profitable realizations of the stochastic dynamics:</description>
    </item>
    
    <item>
      <title>Wednesday</title>
      <link>/2012/02/22/wednesday-12/</link>
      <pubDate>Wed, 22 Feb 2012 20:20:07 +0000</pubDate>
      
      <guid>/2012/02/22/wednesday-12/</guid>
      <description>CC0 license approved for use on CRAN
 Update my DESCRIPTION files, use the new Author@R convention.
 Rebecca&amp;rsquo;s comment on mntd in comparative methods
 This lab notebook gets mentioned for good practices in academic workflow.
 Working on treebase paper
 ESA registration
 Lecture notes for tomorrow
 forage fish writing
  Reading Reading over (Munch et. al. 2005). I think this is a very nice treatment, a lot clearer I think than lots of other stuff I&amp;rsquo;ve looked at (thanks Tim &amp;amp; Jim!</description>
    </item>
    
    <item>
      <title>Tues: Research, seminar (managing for resilience), talk (future of libraries), etc...</title>
      <link>/2012/02/21/tues-research-seminar-managing-for-resilience-talk-future-of-libraries-etc/</link>
      <pubDate>Tue, 21 Feb 2012 19:20:40 +0000</pubDate>
      
      <guid>/2012/02/21/tues-research-seminar-managing-for-resilience-talk-future-of-libraries-etc/</guid>
      <description>research Stuff warningsignals  Exceeded wall time on NERSC, readjusting and running this again.  treebase  Working on treebase manuscript. Treebase Rewrote handling of server errors, added pauses to reduce load, etc.  PMC  A user pointed out my support for &amp;ldquo;white&amp;rdquo; model was incomplete. Fix is now on github (install instructions for development version are also now on github), will push to CRAN soon.
 Another user points out that pmc support for additional functions would be nice, such as rbrownie, fit.</description>
    </item>
    
    <item>
      <title>finer sampling in prosecutor&#39;s fallacy</title>
      <link>/2012/02/20/finer-sampling-in-prosecutors-fallacy/</link>
      <pubDate>Mon, 20 Feb 2012 19:12:13 +0000</pubDate>
      
      <guid>/2012/02/20/finer-sampling-in-prosecutors-fallacy/</guid>
      <description>Create the data. We&amp;rsquo;ll save files as some of these code chunks need to be run on the cluster for large memory use.
require(populationdynamics) pars = c(Xo = 500, e = 0.5, a = 180, K = 1000, h = 200, i = 0, Da = 0, Dt = 0, p = 2) sn &amp;lt;- saddle_node_ibm(pars, times=seq(0,5000, length=50000), reps=1) save(&amp;quot;sn&amp;quot;, &amp;quot;file=prosecutor.rda&amp;quot;)  Subset the chance transitions
d &amp;lt;- dim(sn$x1) crashed &amp;lt;- which(sn$x1[d[1],]==0) dat &amp;lt;- melt( sn$x1[,crashed] ) names(dat) = c(&amp;quot;time&amp;quot;, &amp;quot;reps&amp;quot;, &amp;quot;value&amp;quot;) save(&amp;quot;dat&amp;quot;, file=&amp;quot;crashed.</description>
    </item>
    
    <item>
      <title>prosecutor&#39;s fallacy initial look</title>
      <link>/2012/02/16/prosecutors-fallacy-initial-look/</link>
      <pubDate>Thu, 16 Feb 2012 20:02:49 +0000</pubDate>
      
      <guid>/2012/02/16/prosecutors-fallacy-initial-look/</guid>
      <description>So I&amp;rsquo;ve simulated 1000 replicates of a system that has alternative stable states, but is not approaching the bifurcation. I&amp;rsquo;ve added enough noise (demographic stochasticity in this case, but doesn&amp;rsquo;t matter what) that 129&amp;frasl;1000 transition stochastically to the bad state, so I have decent sample sizes in each. Here&amp;rsquo;s what I&amp;rsquo;m finding: If I condition on having crashed (i.e. take the 129 that transition) and apply our model-based early warning signal, it doesn&amp;rsquo;t detect any early warning sign.</description>
    </item>
    
    <item>
      <title>Squiggles</title>
      <link>/2012/02/16/squiggles/</link>
      <pubDate>Thu, 16 Feb 2012 19:34:55 +0000</pubDate>
      
      <guid>/2012/02/16/squiggles/</guid>
      <description>Variability in the appearance of a trend
nreps &amp;lt;- 64  require(populationdynamics) pars = c(Xo = 730, e = 0.5, a = 100, K = 1000, h = 200, i = 0, Da = 0.09, Dt = 0, p = 2) time = seq(0, 990, length = 100) sn &amp;lt;- saddle_node_ibm(pars, time, reps = nreps)  We reformat the replicates into long form,
X &amp;lt;- data.frame(time = time, value = sn$x1) require(reshape) dat &amp;lt;- melt(X, id = &amp;quot;time&amp;quot;) names(dat)[2] &amp;lt;- &amp;quot;reps&amp;quot;  require(plyr) window &amp;lt;- length(X[[&amp;quot;time&amp;quot;]])/2 tmp &amp;lt;- ddply(dat, &amp;quot;reps&amp;quot;, function(X) window_autocorr(X$value, windowsize = window))  Tidy up the warning signal data</description>
    </item>
    
    <item>
      <title>getting signal from autocorrelation</title>
      <link>/2012/02/15/getting-signal-from-autocorrelation/</link>
      <pubDate>Wed, 15 Feb 2012 19:40:26 +0000</pubDate>
      
      <guid>/2012/02/15/getting-signal-from-autocorrelation/</guid>
      <description>This example goes through the steps to demonstrate that in a sufficiently-frequently sampled timeseries, autocorrelation does contain some signal of early warning. ((Post markdown generated automatically from knitr.))
Run the individual based simulation
require(populationdynamics)  [code] Loading required package: populationdynamics
 ```R pars = c(Xo = 730, e = 0.5, a = 100, K = 1000, h = 200, i = 0, Da = 0.09, Dt = 0, p = 2) time = seq(0, 500, length = 500) sn &amp;lt;- saddle_node_ibm(pars, time) X &amp;lt;- data.</description>
    </item>
    
    <item>
      <title>Further examples for appendices</title>
      <link>/2012/02/14/further-examples-for-appendices/</link>
      <pubDate>Tue, 14 Feb 2012 16:35:06 +0000</pubDate>
      
      <guid>/2012/02/14/further-examples-for-appendices/</guid>
      <description>Going through additional examples of things I&amp;rsquo;d like to see / demonstrate but do not fit into the narrative of the manuscript. Writing these in knitr/dynamic documentation to confirm code produces the examples listed, and give a bit tighter integration between text and code examples.
Show the parameter distributions: We can also look at the bootstraps of the parameters. Another helper function will reformat this data from reps list. The fit column uses a two-letter code to indicate first what model was used to simulate the data, and then what model was fit to the data.</description>
    </item>
    
    <item>
      <title>Monday</title>
      <link>/2012/02/13/monday-16/</link>
      <pubDate>Mon, 13 Feb 2012 23:29:36 +0000</pubDate>
      
      <guid>/2012/02/13/monday-16/</guid>
      <description>I&amp;rsquo;ve created the more extend-able earlywarning package out of my warningsignals package. The individual-based simulations are carried out separately via my new populationdynamics package.
Fallacy plots Appendices Trying a knitr-based platform for tighter integration of code, figures, and text. See today&amp;rsquo;s analysis in markdown generated by knitr, posted as a github wiki page.</description>
    </item>
    
    <item>
      <title>Sunday </title>
      <link>/2012/02/12/sunday-6/</link>
      <pubDate>Sun, 12 Feb 2012 22:14:43 +0000</pubDate>
      
      <guid>/2012/02/12/sunday-6/</guid>
      <description>phylogenetics  Exploring display of phylogeny. Unlabled, painted fan?   tweaking release-of-constraint plot - vary alpha, less strong? release at T/2? Animated version?  Creating paintings of phylogenies Creating from a specified set of taxa is a somewhat common task for me. Wrightscape supports doing this for both ouch and ape trees.
 ape-based phylogenies ouch-based phylogenies use some legacy maticce functions  intra_ancestor &amp;lt;- mrcaOUCH(c(&amp;quot;Chlorurus_sordidus&amp;quot;, &amp;quot;Hipposcarus_longiceps&amp;quot;), labrid$tree) intramandibular &amp;lt;- paintBranches(intra_ancestor, labrid$tree, c(&amp;quot;other&amp;quot;,&amp;quot;intramandibular&amp;quot;)) pharyngeal_ancestor&amp;lt;-mrcaOUCH(c(&amp;quot;Bolbometopon_muricatum&amp;quot;, &amp;quot;Sparisoma_radians&amp;quot;), labrid$tree) pharyngeal &amp;lt;- paintBranches(pharyngeal_ancestor, labrid$tree, c(&amp;quot;other&amp;quot;,&amp;quot;pharyngeal&amp;quot;)) two_shifts &amp;lt;- paintBranches(c(pharyngeal_ancestor, intra_ancestor), labrid$tree, c(&amp;quot;wrasses&amp;quot;, &amp;quot;pharyngeal&amp;quot;, intramandibular&amp;quot;) )  The ouch-trees can be converted back to ape trees in a way that can plot them, but for some reason break the fan-plot mode but not the standard phylogram plot mode.</description>
    </item>
    
    <item>
      <title>Saturday: projects, reading, markdown notebook-technology</title>
      <link>/2012/02/12/saturday-projects-reading-markdown-plugins/</link>
      <pubDate>Sun, 12 Feb 2012 13:40:37 +0000</pubDate>
      
      <guid>/2012/02/12/saturday-projects-reading-markdown-plugins/</guid>
      <description>Greatly enjoyed seeing this perspective on power laws (Stumpf &amp;amp; Porter, 2012) Or as Richard McElreath put even more concisely,
 People get amazed by power laws but never by normal distributions. Seems like some max ent outcomes astonish while others don&amp;rsquo;t. When so many mechanisms aggregate to common densities, I&amp;rsquo;d hope we&amp;rsquo;d stop trying to argue that we can go backwards from pattern to process so easily.
 Projects  fishbase example query for Peter Commit edits to warningsignals paper, send to Alan.</description>
    </item>
    
    <item>
      <title>Elegant &amp; fast data manipulation with data.table</title>
      <link>/2012/02/12/elegant-fast-data-manipulation-with-data-table/</link>
      <pubDate>Sun, 12 Feb 2012 13:39:03 +0000</pubDate>
      
      <guid>/2012/02/12/elegant-fast-data-manipulation-with-data-table/</guid>
      <description>Just learned about the R data.table package (ht @recology_) makes R data frames into ultra-fast, SQL-like objects.
One thing we get is some very nice and powerful syntax. Consider some simple data of replicate time series:
time &amp;lt;- rep(1:10, 10) replicate &amp;lt;- sort(time) value &amp;lt;- rnorm(100) df &amp;lt;- data.frame(replicate, time, value)  To apply a function to each set of replicates, instead of
sapply(1:max(df$replicate), function(i) mean( df[df$replicate == i,]$value) )  We can use</description>
    </item>
    
    <item>
      <title>Thursday: writing; some latexdiff notes</title>
      <link>/2012/02/10/thursday-writing-some-latexdiff-notes/</link>
      <pubDate>Fri, 10 Feb 2012 10:06:11 +0000</pubDate>
      
      <guid>/2012/02/10/thursday-writing-some-latexdiff-notes/</guid>
      <description>Forage fish writing See doc, FF dropbox PopDyn
Warning signals edits  Alan edits Figure captions, titles.
 Text changes from Noam.
  A better git latexdiff solution Placing the script below somewhere in the path like /usr/local/bin and modify ~/.gitconfig as indicated in the header comments. Then oen can view pdf-diffs of the latex of the current version against previous versions with commands such as
git latexdiff HEAD  shows the differences between the last commit and the current (uncommitted) changes.</description>
    </item>
    
    <item>
      <title>UC Davis graduate student symposium proposal</title>
      <link>/2012/02/08/uc-davis-graduate-student-symposium-proposal/</link>
      <pubDate>Wed, 08 Feb 2012 12:35:15 +0000</pubDate>
      
      <guid>/2012/02/08/uc-davis-graduate-student-symposium-proposal/</guid>
      <description>Abstract The recog­ni­tion that ecosys­tems can undergo sud­den shifts to alter­nate, less desir­able sta­ble states has led to the desire to iden­tify early warn­ing signs of these impend­ing col­lapses. Motivated by the math­e­mat­ics of bifur­ca­tions, the search for early warn­ing signs seeks to detect subtle patterns that may precede these shift. Faced with limited and imperfect data, such forecasting is fraught with uncertainty. I will present work illustrating how we can quantify the risks of false alarms and missed detection of these early warning signals, and illustrate how this information can be used to inform robust decision-making that may avoid collapse.</description>
    </item>
    
    <item>
      <title>Some Collaborative Tools for Science</title>
      <link>/2012/02/06/some-collaborative-tools-for-science/</link>
      <pubDate>Mon, 06 Feb 2012 15:30:06 +0000</pubDate>
      
      <guid>/2012/02/06/some-collaborative-tools-for-science/</guid>
      <description>Ania Truszczynski invited me to give a little talk on the use of various collaborative tools for scientists. I enjoyed presenting this as a chalk-talk, but alas no slides to link so here&amp;rsquo;s a list of reference. Rather than the impossible attempt to be comprehensive, this is restricted to resources I use regularly and have found to be the best of their class. All are freely available.
Tools   Science Blogs (e.</description>
    </item>
    
    <item>
      <title>Different ways of visualizing distribution overlap</title>
      <link>/2012/02/03/different-ways-of-visualizing-distribution-overlap/</link>
      <pubDate>Fri, 03 Feb 2012 10:13:51 +0000</pubDate>
      
      <guid>/2012/02/03/different-ways-of-visualizing-distribution-overlap/</guid>
      <description>I spend a lot of time comparing distributions. There&amp;rsquo;s lots of different ways to visualize these comparisons, I&amp;rsquo;m not sure what is the most effective &amp;amp; intuitive way to indicate their overlap.
Distributions Boxplot Violinplot Beanplot ROC Curve These images in gallery format with examples from two other data sources as well (click on image to zoom into gallery).
[flickr-gallery mode=&amp;ldquo;search&amp;rdquo; tags=&amp;ldquo;warningsignals&amp;rdquo; min_upload_date=&amp;ldquo;2012-02-03 00:00:00&amp;rdquo; max_upload_date=&amp;ldquo;2012-02-03 11:00:00&amp;rdquo;]</description>
    </item>
    
    <item>
      <title>Thursday</title>
      <link>/2012/02/02/thursday-13/</link>
      <pubDate>Thu, 02 Feb 2012 22:14:42 +0000</pubDate>
      
      <guid>/2012/02/02/thursday-13/</guid>
      <description>rOpenSci  Dryad submission xml parsing example to Scott essentially see (fishbase example , and xpath tutoral ) knitr and latex figure placement (use float package with H to enforce placement). cc0 &amp;amp; OSI &amp;hellip; pmc purchase order, dryad data id approval. &amp;amp; writing writing writing&amp;hellip; Re-formating data for ggplot version of graphs, realized I should be specifying id.vars to melt (example from my Q on SO)  Reading  Great special feature on the data era in TREE ((which I mention despite it&amp;rsquo;s misfortune of being connected to Elsivier right now)) (Page, 2012), (Michener &amp;amp; Jones, 2012), (Porter et.</description>
    </item>
    
    <item>
      <title>Journey to freedom - a code&#39;s tale of open source license migration</title>
      <link>/2012/01/31/journey-to-freedom-a-codes-tale-of-open-source-license-migration/</link>
      <pubDate>Tue, 31 Jan 2012 17:58:08 +0000</pubDate>
      
      <guid>/2012/01/31/journey-to-freedom-a-codes-tale-of-open-source-license-migration/</guid>
      <description>My software wants to be free. It wants to be seen and used and loved by as many people as possible. When first it heard of open source licenses, it set sail to join the company of great software in the promised land, but finding true freedom has been a tortured journey.
In the clutches of the GPL Created and defended by the Free Software Foundation and used by such venerable institutions as the Linux Kernel, the gcc compiler, and the R statistical environment, the GNU&amp;rsquo;s General Public License seemed like a gold standard to call home.</description>
    </item>
    
    <item>
      <title>Monday</title>
      <link>/2012/01/30/monday-15/</link>
      <pubDate>Mon, 30 Jan 2012 19:38:23 +0000</pubDate>
      
      <guid>/2012/01/30/monday-15/</guid>
      <description>pdg-control, aside exercise Lab group commented that optimum in Reed model looks unrealistic due to frequency with which it shuts down all fishing. This is an artifact of not having extraction costs increase sufficiently for small catch, and can be easily fixed by increasing that cost (c in the profit eq, profits-costs = p*x-c/x)
view sourcecode, Reed.R
NIMBioS short visitor application Have been thinking that it would be really useful to have some extra time at Nimbios to meet with folks at the time of our next working group meeting (March 12-15).</description>
    </item>
    
    <item>
      <title>pdg-control Training Problem II update</title>
      <link>/2012/01/24/pdg-control-training-problem-ii-update/</link>
      <pubDate>Tue, 24 Jan 2012 16:55:18 +0000</pubDate>
      
      <guid>/2012/01/24/pdg-control-training-problem-ii-update/</guid>
      <description>Basically we&amp;rsquo;ve done some simple stuff and now would be a good time to think about tools for some heavy-lifting computational challenges standing in the way. Michael &amp;amp; Jim have been a great help on this, and Jake has also helped with theoretical underpinnings.
Statement of problem
We consider the impact of uncertainty in the harvesting of fisheries which involve alternative stable state dynamics.
Current Findings
 Adding uncertainty in current state means optimal escapement isn&amp;rsquo;t the optimal solution (contrary to Reed model) (Sethi et.</description>
    </item>
    
    <item>
      <title>Tuesday</title>
      <link>/2012/01/24/tuesday-11/</link>
      <pubDate>Tue, 24 Jan 2012 15:04:41 +0000</pubDate>
      
      <guid>/2012/01/24/tuesday-11/</guid>
      <description>Resilience seminar  the unhelpful resilience of invaded systems (ecosystem engineers anyone? Cheatgrass change the fire regime, salt-cedar ) Examples in cheatgrass invading sagebrush, and saltcedar invading cottonwoods. Variables on axes? Problem of dimensionality? resilient to what? Carpenter&amp;rsquo;s rigidity trap (need to eliminate something) vs poverty trap (something is missing) promote a small disturbance to reset the system &amp;ndash; when are small disturbances stabilizing? (escape the rachet?)  pdg-control  Summary for Training Problem II  Warning Signals  Figures for Alan paper.</description>
    </item>
    
    <item>
      <title>Friday (lab group meeting notes)</title>
      <link>/2012/01/20/friday-lab-group-meeting-notes/</link>
      <pubDate>Fri, 20 Jan 2012 17:09:09 +0000</pubDate>
      
      <guid>/2012/01/20/friday-lab-group-meeting-notes/</guid>
      <description>Theme inspired by Jane Lubchenco&amp;rsquo;s talk last week: how do we connect science to management? We&amp;rsquo;re breaking down this topic, with individual leaders for each week, as follows:
 1&amp;frasl;27: Carl: optimal vs. actionable management recommendations 2&amp;frasl;3: Jaime/Noam(?): monitoring for management 2&amp;frasl;10: Allison: informing management vs. advocacy 2&amp;frasl;17: Lewis: what types of research are must useful to management 2&amp;frasl;24: Noam/Jaime: communicating uncertainty 3&amp;frasl;2: Marissa: funding sources for applied research, building collaborations outside academia, and service opportunities ((this is one of the days of the PFMC meeting in Sacramento, which would be rather relevant to our theme, so we might push this topic to next quarter)) 3&amp;frasl;9: Emil: obstacles to implementing scientific advise 3&amp;frasl;16: Scott: the quality of science along the basic-applied spectrum (perceptions and reality)  Also shared some coding tricks and ways to share them.</description>
    </item>
    
    <item>
      <title>Is your phylogeny informative?</title>
      <link>/2012/01/19/is-your-phylogeny-informative/</link>
      <pubDate>Thu, 19 Jan 2012 14:10:49 +0000</pubDate>
      
      <guid>/2012/01/19/is-your-phylogeny-informative/</guid>
      <description>Yesterday my paper (Boettiger et. al. 2012) appeared in early view in Evolution (author&amp;rsquo;s preprint),As the open access copy doesn&amp;rsquo;t appear on pubmed for a while, you can access my author&amp;rsquo;s copy here. so I&amp;rsquo;d like to take this chance to share the back-story and highlight my own view on some of our findings, and the associated package on CRAN.Just submitted, meanwhile, the code is always on github.
I didn&amp;rsquo;t set out to write this paper.</description>
    </item>
    
    <item>
      <title>Wednesday -- meetings</title>
      <link>/2012/01/18/wednesday-meetings/</link>
      <pubDate>Wed, 18 Jan 2012 23:22:49 +0000</pubDate>
      
      <guid>/2012/01/18/wednesday-meetings/</guid>
      <description>Alan meeting write write write
Duncan Meeting Troubleshooting S3 and S4 Try adding methods? Changing order on NAMESPACE?
Leaving ouch off the import list: no errors, but within functions, don&amp;rsquo;t get S4 method. import but don&amp;rsquo;t depend on ouch: error. accurate, since simulate is left as an s3 function at the user level.
What a headache. See stackQ.
manuscript Duncan&amp;rsquo;s feedback
Meredith Meeting Run a science policy workshop with Davis open science group?</description>
    </item>
    
    <item>
      <title>Are open lab notebooks considered prior publication?</title>
      <link>/2012/01/16/are-open-lab-notebooks-considered-prior-publication/</link>
      <pubDate>Mon, 16 Jan 2012 10:47:17 +0000</pubDate>
      
      <guid>/2012/01/16/are-open-lab-notebooks-considered-prior-publication/</guid>
      <description>This question invariably comes up at some point in any discussion of open notebook science. This concern is usually voiced in reference to the high-visibility magazines, which many scientists seem to assume will have very restrictive conditions. A quick read of their policies shows otherwise. Here are the links to pre-publication policies of major journals, with my short summaries &amp;amp; comments.
Nature - Go right ahead. Explicit protection clause for open/collaborative blogs/wikis.</description>
    </item>
    
    <item>
      <title>Forage Fish course plan</title>
      <link>/2012/01/12/forage-fish/</link>
      <pubDate>Thu, 12 Jan 2012 13:49:29 +0000</pubDate>
      
      <guid>/2012/01/12/forage-fish/</guid>
      <description>Forage fish winter quarter session starts, attempting to write the synthesis manuscript based on Fall quarter. Broke into groups to write sub-sections (2-4pgs) by 15 Feb.
 wk 3 FF Pop Dyn Carl* &amp;amp; Allison
 wk 4 FF Fisheries: Patrick*, Jay, Carl
 wk 5 Mammals &amp;amp; birds: Angee,* Jamie
 wk 6 Predator fisheries:_ Jamie,* Kailin,* Angee_
 wk 7 Fishmeal/oil: Jay* &amp;amp; Patrick
 wk 8 human consumption/pet food: _ Allison* &amp;amp; David_</description>
    </item>
    
    <item>
      <title>Resilience seminar course plan</title>
      <link>/2012/01/10/resilience-seminar-course-plan/</link>
      <pubDate>Tue, 10 Jan 2012 15:17:42 +0000</pubDate>
      
      <guid>/2012/01/10/resilience-seminar-course-plan/</guid>
      <description>Resilience Monte Carlo Seminar, 11am Tuesdays. Val Eviner.
 Jan 17 Resilience of coral reefs/mangrove systems, Alexander Gaos Jan 24 Resilience of degraded vs. intact systems, Erica Case and Alex Webster Jan 31 Novel ecosystems, Ania Truszczynski and Mark Noyes Feb 7 Landscape configuration, Julia Moore Feb 14 Assisted Migration, Anna O&amp;rsquo;Brien Feb 21 Designing and managing for resilience, Sarah McCullough and Caroline Wright Feb 28 Thresholds/ uncertainty, Matt Meisner and Carl Boettiger March 6 Managing for evolutionary potential, Jaime Ashander March 13 ?</description>
    </item>
    
    <item>
      <title>Monday - Sweave workflow</title>
      <link>/2012/01/09/monday-13/</link>
      <pubDate>Mon, 09 Jan 2012 22:09:03 +0000</pubDate>
      
      <guid>/2012/01/09/monday-13/</guid>
      <description>Bibtex, Mendeley &amp;amp; Sweave Mendeley&amp;rsquo;s repeated entries in the bibfile is particularly annoying with my sweave workflow, as it throws an error from bibtex command that Make doesn&amp;rsquo;t want to ignore.
Also, in writing the documentation I&amp;rsquo;d like to point the .Rnw file to my global library&amp;rsquo;s bibtex document, but then this means having the .Rnw/tex file generated to by the package pointing to a file that&amp;rsquo;s outside the package.</description>
    </item>
    
    <item>
      <title>Optimal policy with assymetric costs to changing harvest quotas</title>
      <link>/2012/01/06/optimal-policy-with-assymetric-costs-to-changing-harvest-quotas/</link>
      <pubDate>Fri, 06 Jan 2012 13:52:22 +0000</pubDate>
      
      <guid>/2012/01/06/optimal-policy-with-assymetric-costs-to-changing-harvest-quotas/</guid>
      <description>The optimal policy with symmetric L1 costs to changing the quotas results in the solutions that stop changing, sometimes at no harvest (if there&amp;rsquo;s scrap value), or at some fixed high harvest if no scrap value. (See earlier notes). Asymmetric costs of comparable magnitude result in more crashes.
When we apply an L1 norm cost of the same magnitude as before for decreasing quotas, but allow increasing quotas to be free (no cost to environmental lobby), the solution follows the Reed optimum is in purple (harvest_alt) (cost-free adjustment), while the blue is the harvest level being implemented with a cost:</description>
    </item>
    
    <item>
      <title>wrightscape examples</title>
      <link>/2012/01/04/wrightscape-examples/</link>
      <pubDate>Wed, 04 Jan 2012 12:48:29 +0000</pubDate>
      
      <guid>/2012/01/04/wrightscape-examples/</guid>
      <description>[flickr-gallery mode=&amp;ldquo;search&amp;rdquo; tags=&amp;ldquo;phylogenetics&amp;rdquo; min_upload_date=&amp;ldquo;2012-01-03 7:00:37&amp;rdquo; max_upload_date=&amp;ldquo;2012-01-03 22:23:37&amp;rdquo;]
 kt and open seem the best focal traits. Unclear what good null traits to use would be.
 Unclear if anything is gained by indep thetas in this example.
 Performance of alpha v theta?
  Edited plotting of likelihood comparisons, just grouped by trait to get common axis. (Difficult to get intelligent zooming on facet_grid to ignore the outliers). Trying such as:</description>
    </item>
    
    <item>
      <title>Tuesday: pmc package, latex to word attempts</title>
      <link>/2012/01/03/tuesday-pmc-package-latex-to-word-attempts/</link>
      <pubDate>Tue, 03 Jan 2012 18:49:10 +0000</pubDate>
      
      <guid>/2012/01/03/tuesday-pmc-package-latex-to-word-attempts/</guid>
      <description>Back from Oz.
Evolution submission: Latex to word Final submission needs editable copy. No great solutions for latex to word, despite quite a few options:
 tex2rtf is a fast solution to get something, but not successful on images or equations. Ended up going with this after all.
 pandoc is a generic converter to many types, but has only partial support for latex input. Does okay on text, but fails on even simple things like italics and natbib citations</description>
    </item>
    
    <item>
      <title>Monday</title>
      <link>/2011/12/12/monday-12/</link>
      <pubDate>Mon, 12 Dec 2011 19:00:50 +0000</pubDate>
      
      <guid>/2011/12/12/monday-12/</guid>
      <description>Wrote method2 test functions out in knitr/sweave. Sent document to Peter. Move my ropensci git origins to the ropensci github page. Ropensci comments on \dontrun: recommended for anything non-trivial, including web calls. Richer tests should be put into testthat. Reply to Charles Jervis, biology high school teacher interested in tools to teach math/modeling in ecology. Sounds like he&amp;rsquo;s already doing some cool stuff with phylogenies with his students. prepare vignette for rfishbase based on tutorial.</description>
    </item>
    
    <item>
      <title>Better dynamic documents (Sweave) with syntax highlighting, caching, etc</title>
      <link>/2011/12/12/better-sweave-dynamic-documents-with-syntax-highlighting-easier-tools/</link>
      <pubDate>Mon, 12 Dec 2011 17:26:47 +0000</pubDate>
      
      <guid>/2011/12/12/better-sweave-dynamic-documents-with-syntax-highlighting-easier-tools/</guid>
      <description>The highlight package is a simple solution for very nice syntax highlighted code boxes in latex documents. Requires switching the driver, which is best done from within R and requires creating a makefile though. Needs the &amp;ldquo;highlight&amp;rdquo; package installed. Here&amp;rsquo;s a simple makefile.
A wealth/mess of Sweave related packages on the CRAN taskview for Reproducible Research (now what other software platform has a the equivalent of a Reproducible Research task view?</description>
    </item>
    
    <item>
      <title>Some Notes on Open Notebooks, Open peer review practices.</title>
      <link>/2011/12/11/some-notes-on-open-notebooks-open-peer-review-practices/</link>
      <pubDate>Sun, 11 Dec 2011 22:45:54 +0000</pubDate>
      
      <guid>/2011/12/11/some-notes-on-open-notebooks-open-peer-review-practices/</guid>
      <description>What follows is a collection of notes, examples, and reflections I&amp;rsquo;ve been meaning to write down.
Revealing Revisions Sharing version history is an important part of an open notebook really being open, and one reason why wikis have remained so popular for Open Notebook Science. Wordpress (this platform) does version management internally, and thepost-revision display plug-in makes this visible on posts. I had experimented but disabled this a while ago because I didn&amp;rsquo;t like visual impact of the long list at the end of my posts.</description>
    </item>
    
    <item>
      <title>Friday</title>
      <link>/2011/12/09/friday-9/</link>
      <pubDate>Fri, 09 Dec 2011 13:42:30 +0000</pubDate>
      
      <guid>/2011/12/09/friday-9/</guid>
      <description>Wrightscape/pmc  Writing up derivation from Thursday properly / for manuscript. Writing up test cases for method2, direct evaluation of covariance matrix for comparisons Minor revisions submitted to Evolution  pdg-control To Do  Implement the NCO. Implement HS SDP Closer read of (Sethi et. al. 2005), (Su &amp;amp; Peterman, 2012) and Woodward &amp;amp; Tomberlin  Warning signals  Allee effects in linear programming with different classes. Timescales of noise using van Kampen expansion.</description>
    </item>
    
    <item>
      <title>Thursday</title>
      <link>/2011/12/08/thursday-11/</link>
      <pubDate>Thu, 08 Dec 2011 11:06:00 +0000</pubDate>
      
      <guid>/2011/12/08/thursday-11/</guid>
      <description>Another day of working on 4 different projects at once.
Warning signals  review Alan pulses manuscript
 review (Dulvy et. al. 2003) Paper discussing the data you want $ \neq $ the data you want
  No way in Anchoveta data, look at time series:
Example in the cod data using only up until 1991 data:
 Way forward &amp;ndash; construct the step-wise predictor of probabilities. Add the economic costs of both.</description>
    </item>
    
    <item>
      <title>Wednesday - wrightscape runs and various other things</title>
      <link>/2011/12/07/wednesday-11/</link>
      <pubDate>Wed, 07 Dec 2011 18:01:07 +0000</pubDate>
      
      <guid>/2011/12/07/wednesday-11/</guid>
      <description>pdg-control  plots for changing costs Report out to Training Problem II group.  ggplot note defining functions that return a ggplot object can be tricky. If you compute some objects in the plot function (stats etc), those stats are not stored by the object (due to lazy evaluation, usually a very nice time-saving feature), so the plot cannot be produced unless the function returns those things to the global environment (or from wherever the plot will be printed/evaluated).</description>
    </item>
    
    <item>
      <title>Optimal control -- costs to policy shifts</title>
      <link>/2011/12/07/optimal-control-costs-to-policy-shifts/</link>
      <pubDate>Wed, 07 Dec 2011 09:11:36 +0000</pubDate>
      
      <guid>/2011/12/07/optimal-control-costs-to-policy-shifts/</guid>
      <description>Considering the case where there is a cost to changing the harvest quota (representing the cost of efforts to change policy). We can imagine several scenarios that could introduce this:
 Fixed cost to change
 Cost proportional to the size of the change (L1 norm)
 Cost proportional to the square of the size (L2 norm, i.e. small changes aren&amp;rsquo;t expensive, large ones are very expensive)
 asymmetric costs &amp;ndash; lowering quotas may be harder than raising them</description>
    </item>
    
    <item>
      <title>Tuesday -- two insights</title>
      <link>/2011/12/06/tuesday-two-insights/</link>
      <pubDate>Tue, 06 Dec 2011 21:46:16 +0000</pubDate>
      
      <guid>/2011/12/06/tuesday-two-insights/</guid>
      <description>Control &amp;amp; Optimization Dominique Bonvin visit  two-step control (optimize parameters, optimize mean-square error between model and measurement also by parameter adjustment) fails when reality isn&amp;rsquo;t in the model set. Problem is under-determined (N free variables, 4N equations). (converges, but onto the wrong optimum).
 Better solution &amp;ndash; adjust the penalty/regularization terms to to get better agreement between model and data
 Bonvin approach &amp;ndash; adjust the control instead (NCO Control).</description>
    </item>
    
    <item>
      <title>Monday - wrightscape meetings, PDG meeting</title>
      <link>/2011/12/05/monday-wrightscape-meetings-pdg-meeting/</link>
      <pubDate>Mon, 05 Dec 2011 18:45:32 +0000</pubDate>
      
      <guid>/2011/12/05/monday-wrightscape-meetings-pdg-meeting/</guid>
      <description>Wrightscape &amp;ndash; added a user utility to to specify custom model types, such that some subset of the total number of regimes can share certain parameters.
Peter Meeting  Derivation &amp;ndash; provide clear examples of the differences and by how much it matters. Expected result from the biology: the jaw lever traits should show greater changes than the other traits after a release of constraint. Based on previous studies, expect most of the action to be around the intramandibular joint innovation.</description>
    </item>
    
    <item>
      <title>More labrid plots</title>
      <link>/2011/12/05/more-labrid-plots/</link>
      <pubDate>Mon, 05 Dec 2011 10:24:36 +0000</pubDate>
      
      <guid>/2011/12/05/more-labrid-plots/</guid>
      <description>Intramandibular likelihood comparisons
Parameter zooms:
Pharyngeal likelihood comparisons
Both shifts:
[flickr-gallery mode=&amp;ldquo;search&amp;rdquo; tags=&amp;ldquo;phylogenetics&amp;rdquo; min_upload_date=&amp;ldquo;2011-12-03 8:00:37&amp;rdquo; max_upload_date=&amp;ldquo;2011-12-04 23:23:37&amp;rdquo;]</description>
    </item>
    
    <item>
      <title>Release of constraint</title>
      <link>/2011/12/04/release-of-constraint/</link>
      <pubDate>Sun, 04 Dec 2011 13:41:47 +0000</pubDate>
      
      <guid>/2011/12/04/release-of-constraint/</guid>
      <description>(uncertainty estimation to follow).</description>
    </item>
    
    <item>
      <title>Friday - updated wrightscape results - simulated examples</title>
      <link>/2011/12/02/friday-updated-wrightscape-results/</link>
      <pubDate>Fri, 02 Dec 2011 22:35:24 +0000</pubDate>
      
      <guid>/2011/12/02/friday-updated-wrightscape-results/</guid>
      <description>Consider two simulated datasets, one under a release of constraint (left) one under an increase in sigma (right). Can we correctly discriminate between these models?
Parameter differences:
Likelihood differences:
Yup.
Repeated with effect-size scaled to be roughly equivalent for both traits. Wondering if it&amp;rsquo;s easier to plot parameters out separately like this. Error bars show median and 25&amp;frasl;75 % quantile range, with barplots showing the means (note that high outliers makes mean often larger than median).</description>
    </item>
    
    <item>
      <title>Thrusday - corrected calculation, implementing.  </title>
      <link>/2011/12/01/thrusday-corrected-calculation-implementing/</link>
      <pubDate>Thu, 01 Dec 2011 23:33:55 +0000</pubDate>
      
      <guid>/2011/12/01/thrusday-corrected-calculation-implementing/</guid>
      <description>Implementing Wednesday night&amp;rsquo;s calculations. Should transcribe full derivation from paper notebook, meanwhile (revealing how chaotic my work process really is):
[flickr-gallery mode=&amp;ldquo;search&amp;rdquo; tags=&amp;ldquo;equations&amp;rdquo; min_upload_date=&amp;ldquo;2011-12-04 11:00:37&amp;rdquo; max_upload_date=&amp;ldquo;2011-12-04 11:39:37&amp;rdquo;]
Day&amp;rsquo;s log of plots:
[flickr-gallery mode=&amp;ldquo;search&amp;rdquo; tags=&amp;ldquo;phylogenetics&amp;rdquo; min_upload_date=&amp;ldquo;2011-12-01 8:00:37&amp;rdquo; max_upload_date=&amp;ldquo;2011-12-01 23:23:37&amp;rdquo;]</description>
    </item>
    
    <item>
      <title>Wednesday - various logistics, then checking likelihood calculation</title>
      <link>/2011/11/30/wednesday-various-logistics-then-checking-likelihood-calculation/</link>
      <pubDate>Wed, 30 Nov 2011 20:20:42 +0000</pubDate>
      
      <guid>/2011/11/30/wednesday-various-logistics-then-checking-likelihood-calculation/</guid>
      <description>rOpenSci  rOpenSci wins runner up prize in PLoS + Mendeley&amp;rsquo;s Binary Battle! Write replies to interview questions with Mendeley. roxygenizing documentation for RMendeley &amp;ndash; about half done  pdg-control  Call with Jake scheduled for tomorrow Emails with Michael. I&amp;rsquo;ll implement delay intervals, he&amp;rsquo;ll add costs to adjustment. Need to fix/finish delay interval optimization calculation (exponent of matrix &amp;amp; beta)  Warning Signals Meeting with Alan
 Regime shifts Emphasize the RO curve in uncertainty analysis See (Dulvy et.</description>
    </item>
    
    <item>
      <title>Tuesday debugging</title>
      <link>/2011/11/29/tuesday-debugging/</link>
      <pubDate>Tue, 29 Nov 2011 10:13:35 +0000</pubDate>
      
      <guid>/2011/11/29/tuesday-debugging/</guid>
      <description>Wrote seven unit tests to identify source of how/why I can get $ \alpha $&amp;rsquo;s to be larger in the parrotfish group than wrasses (when only $alpha $ varies across regimes) on the same trait for which $ \sigma $&amp;rsquo;s are larger (when only they vary). Tests successively restrict pattern into the likelihood equation, some treatment of the regimes must be wrong.
Unit tests.
Nov 29, 2011  also need to double-check calc of lca_matrix &amp;ndash; needs to obey same sc… …  52a5d0bf12  Browse code</description>
    </item>
    
    <item>
      <title>Monday: submodels for full traits</title>
      <link>/2011/11/28/monday-11/</link>
      <pubDate>Mon, 28 Nov 2011 11:00:24 +0000</pubDate>
      
      <guid>/2011/11/28/monday-11/</guid>
      <description>Two shifts alpha sigma likelihood Pharyngeal shift alpha sigma likelihood Intramandibular shift alpha sigma likelihood Intramandibular shift (parrotfish only) alpha sigma likelihood Troubleshooting It seems alpha is often higher in the regime that has a the higher sigma when variance is restricted to sigma. This cannot be right.
Creating unit tests:
Sigma behaves correctly in the following way. Simulate data where regimes have different sigmas.
require(wrightscape) data(labrids) s1_spec &amp;lt;- list(alpha = &amp;quot;global&amp;quot;, sigma = &amp;quot;indep&amp;quot;, theta = &amp;quot;global&amp;quot;) s1 &amp;lt;- multiTypeOU(data = dat[&amp;quot;close&amp;quot;], tree = tree, regimes = pharyngeal, model_spec = s1_spec, control = list(maxit=5000)) # Order of entries in sigma is the order regime names are given by levels (alphabetical) names(s1$sigma) &amp;lt;- levels(pharyngeal) s1$sigma[&amp;quot;other&amp;quot;] &amp;lt;- .</description>
    </item>
    
    <item>
      <title>Handling other sources of noise</title>
      <link>/2011/11/28/handling-other-sources-of-noise/</link>
      <pubDate>Mon, 28 Nov 2011 09:16:28 +0000</pubDate>
      
      <guid>/2011/11/28/handling-other-sources-of-noise/</guid>
      <description>I&amp;rsquo;m now computing the optimal solution under three sources of noise (compare with my earlier examples of calculating the optimal solution assuming only growth noise, but simulating dynamics with other noise sources). See the statement of problem details, essentially:
$$ \max_{ { q_t } \leq 0 } \mathbb{E} \left{ \sum_0^{\infty} \alpha^t h_t \right} $$ s.t. Fish population follows: $ x_t = zt^g f( x{t-1} - h_{t-1} ) $ and measured stock is given by: $ m_t = z_t^m x_t $ while harvest is: $ h_t = \min (x_t, z_t^i q_t) $ Where $ z^g $ denotes uncertainty in population growth, $ z^m $ denotes uncertainty in measurement for the stock assessment, and $ z^i $ denotes uncertainty in harvest implementation.</description>
    </item>
    
    <item>
      <title>Friday: wrightscape, ggplot, wp memory</title>
      <link>/2011/11/25/friday-wrightscape-ggplot-wp-memory/</link>
      <pubDate>Fri, 25 Nov 2011 20:32:59 +0000</pubDate>
      
      <guid>/2011/11/25/friday-wrightscape-ggplot-wp-memory/</guid>
      <description>more sub-model comparisons wrightscape sub-models:
 a1 independent alphas, global theta, sigmas
 bm &amp;ldquo;brownie&amp;rdquo; (alpha = 0, indep sigmas)
 a2 independent alpha, theta, global sigma
 s1 indep sigma, global alpha, theta
 s2 indep sigma, theta, global alpha
  Basic Nelder Mead Simulated annealing associated parameter estimates
This approach is really not finding a very robust solution.
Plotting with stats_summary() Using stats_summary instead of melt and cast computations and line and ribbon geometries for adding statistical layers to plots.</description>
    </item>
    
    <item>
      <title>Getting the right distributions</title>
      <link>/2011/11/23/getting-the-right-distributions/</link>
      <pubDate>Wed, 23 Nov 2011 15:43:27 +0000</pubDate>
      
      <guid>/2011/11/23/getting-the-right-distributions/</guid>
      <description>Determining the stochastic transition matrix is the essential computational step of SDP solution. If stochasticity enters only in the growth process:
$$x_{t+1} = z_t f(x_t) $$
where $zt$ is a draw from a log-normal density distribution function $ \log \mathcal{N} (x; \mu, \sigma) $, then the probability that $x{t+1}$ falls within a bin $ [x_i-\Delta,x_i+\Delta] $ given that at it is currently at $x_t = y$ is
$$ P([x_i-\Delta,xi+\Delta] |y) = \int{x-\Delta}^{x+\Delta} \log \mathcal{N}(x; \log(f(y)) + \mu, \sigma) dx$$</description>
    </item>
    
    <item>
      <title>some configuration notes: RStudio setup, syntax highlighting in sweave</title>
      <link>/2011/11/22/some-configuration-notes-rstudio-setup-syntax-highlighting-in-sweave/</link>
      <pubDate>Tue, 22 Nov 2011 18:51:19 +0000</pubDate>
      
      <guid>/2011/11/22/some-configuration-notes-rstudio-setup-syntax-highlighting-in-sweave/</guid>
      <description>Installing R-Studio on my dreamhost VPS server. Dreamhost runs debian lenny, which is a bit dated, making it necessary to install from source. (Would be easy on a modern ubuntu server). Here we go.
First, we probably want to install R from source to begin with (Lenny comes with cutting-edge R 2.7.1&amp;hellip;). This needs to be done with shared libs enabled. Also I needed to run it without recommended-packages to get the initial install working</description>
    </item>
    
    <item>
      <title>Friday</title>
      <link>/2011/11/18/friday-7/</link>
      <pubDate>Fri, 18 Nov 2011 17:32:00 +0000</pubDate>
      
      <guid>/2011/11/18/friday-7/</guid>
      <description>Connecting weather fluctuations to trends in climate: should really consider replicating (Min et. al. 2011) and (Pall et. al. 2011).
Ooh.. David&amp;rsquo;s Nature Climate paper (McCollum et. al. 2011). (Does UC Davis really not have access to this journal?)
Sebastian mentioned his advisor&amp;rsquo;s work oninverting the sphere without creating a fold, including a proof through a series of physical models made with chickenwire. Math is crazy.
Reviewing Sebastian&amp;rsquo;s manuscript on stochastic sinks at lab meeting.</description>
    </item>
    
    <item>
      <title>Steve Pacala - Storer lecture</title>
      <link>/2011/11/17/steve-pacala-storer-lecture/</link>
      <pubDate>Thu, 17 Nov 2011 23:16:30 +0000</pubDate>
      
      <guid>/2011/11/17/steve-pacala-storer-lecture/</guid>
      <description>Excellent visit from a former advisor, Steve Pacala, at Davis for a Storer lecture.
Seminar  atmospheric CO2 is roughly half CO2 production, rest is being mitigated by the natural carbon sink
 Carbon sink is half ocean, half terrestrial
  A grim future:
 450ppm not feasible
 500ppm best case
 550ppm is likely even if we are largely successful
  Even worse if the terrestrial sink collapses.</description>
    </item>
    
    <item>
      <title>wrightscape and sensitivity to initial conditions</title>
      <link>/2011/11/17/wrightscape-and-sensitivity-to-initial-conditions/</link>
      <pubDate>Thu, 17 Nov 2011 23:08:14 +0000</pubDate>
      
      <guid>/2011/11/17/wrightscape-and-sensitivity-to-initial-conditions/</guid>
      <description>Seems ouma performs poorly, though the sign of the effect seems correct. Starting conditions cause this.
Even starting conditions: improves the fit and flips the sign of the result.
More parameters: addendum Longer runs using simulated annealing can still get stuck.</description>
    </item>
    
    <item>
      <title>Tues: Sources of stochastic variation in optimal control</title>
      <link>/2011/11/15/tuesday-10/</link>
      <pubDate>Tue, 15 Nov 2011 23:28:14 +0000</pubDate>
      
      <guid>/2011/11/15/tuesday-10/</guid>
      <description>Adding stochasticity seems to have a small history.
Reed 1979 Reed, 1979 Uncertainty in next year&amp;rsquo;s stock, &amp;ldquo;growth uncertainty&amp;rdquo; at the time of determining harvest. Constant escapement policy, no chance of extinction.
Clark &amp;amp; Kirkwood 1986 Clark &amp;amp; Kirkwood, 1986 Uncertainty in this year&amp;rsquo;s stock, &amp;ldquo;measurement uncertainty&amp;rdquo; when determining harvest.
Roughgarden &amp;amp; Smith (1996) consider both, and add uncertainty in harvest. Sethi et al. 2005 (Sethi et. al. 2005) consider the economist&amp;rsquo;s optimization of this.</description>
    </item>
    
    <item>
      <title>non-optimal outcomes of optimal solutions</title>
      <link>/2011/11/13/non-optimal-outcomes-of-optimal-solutions/</link>
      <pubDate>Sun, 13 Nov 2011 00:54:39 +0000</pubDate>
      
      <guid>/2011/11/13/non-optimal-outcomes-of-optimal-solutions/</guid>
      <description>I consider the optimal stochastic-dynamic programming solution for the model specified with known stochasticity in population dynamics, but now vary the actual simulated dynamics to include further uncertainty or error not included in the optimal solution in different ways. In some way this is an &amp;ldquo;unfair&amp;rdquo; analysis, as I really should be solving for the optimal solution in light of the fully uncertain space, but in practice this at least serves as a sensitivity analysis to the assumptions that certain quantities are perfectly known.</description>
    </item>
    
    <item>
      <title>Wainwright Retreat to Hastings Reserve</title>
      <link>/2011/11/12/of-labrids-and-dubious-convergence/</link>
      <pubDate>Sat, 12 Nov 2011 21:36:51 +0000</pubDate>
      
      <guid>/2011/11/12/of-labrids-and-dubious-convergence/</guid>
      <description>Two-day mini conference with Wainwright lab, Mike Alfaro lab, Rita Mehta lab, Tim Higham lab at the Hastings reserve, with everyone (about 30 of us) presenting, and discussions on convergence and on modularity.
more labrid trait evolution alpha &amp;amp; sigma models on two shifts, not converged runs. should really consider the mcmc or at least simulated annealing.
Peter proposes looking at model adequacy by deviance of a observed traits from what is expected under the model (by replicate simulations).</description>
    </item>
    
    <item>
      <title>Thursday</title>
      <link>/2011/11/10/thursday-12/</link>
      <pubDate>Thu, 10 Nov 2011 17:36:48 +0000</pubDate>
      
      <guid>/2011/11/10/thursday-12/</guid>
      <description>Forage Fish dynamics
 Forage fish consumption: who consumes, how important is it. e.g. Africa imports more quantity of fish, but of low value. net exports based on value.
 food security / undernourished regions
 forage fish substitutable? Study in Asia: Pretty inelastic.
 income elasticity vs wealth elasticity (not a real difference. but patterns of consumption of a rich person aren&amp;rsquo;t same as poor person with a windfall, e.</description>
    </item>
    
    <item>
      <title>Auteur plots for reef fish jaws and monkey brains -- needs tweaking</title>
      <link>/2011/11/10/auteur-plots-for-reef-fish-jaws-and-monkey-brains-needs-tweaking/</link>
      <pubDate>Thu, 10 Nov 2011 17:22:17 +0000</pubDate>
      
      <guid>/2011/11/10/auteur-plots-for-reef-fish-jaws-and-monkey-brains-needs-tweaking/</guid>
      <description>Looking at the diversification patterns from Auteur. Longer rjmcmc runs aren&amp;rsquo;t showing a significant difference, but more attention needed in parameters such as initial merge-split probability perhaps? Seems to overestimate the change points.
Remains true for the primate brains example:
Set up to run on carver cluster, copy over the saved rda file and all files matching the random string already saved as outputs. Full labrid example on 20 cores still exceeds the allocation capacity for an R vector.</description>
    </item>
    
    <item>
      <title>Parallel hpc on clusters in R, MPI</title>
      <link>/2011/11/10/parallel-computing-on-clusters-in-r-mpi/</link>
      <pubDate>Thu, 10 Nov 2011 16:49:17 +0000</pubDate>
      
      <guid>/2011/11/10/parallel-computing-on-clusters-in-r-mpi/</guid>
      <description>Some notes for reference on parallel computing strategies on R with dedicated high performance clusters.
parallelization in R For cluster computing in R, I&amp;rsquo;ve found the &amp;ldquo;snow&amp;rdquo; package with MPI to be the most flexible and robust solution. snowfall is a useful package to use multiple cores on a single processor, but requesting all 16 threads on a node is a much more difficult demand for the queue to fill than 16 threads on all nodes.</description>
    </item>
    
    <item>
      <title>Crashing stocks and optimal harvesting effort on Allee effects</title>
      <link>/2011/11/09/crashing-stocks-and-optimal-harvesting-effort-on-allee-effects/</link>
      <pubDate>Wed, 09 Nov 2011 23:34:48 +0000</pubDate>
      
      <guid>/2011/11/09/crashing-stocks-and-optimal-harvesting-effort-on-allee-effects/</guid>
      <description>Modeling choices Allee effect model: Myers Beverton-Holt with harvesting-effort mortality:
$$ x_{t+1} = f(x) = \frac{a x_t^{\alpha}}{1+ x_t^{\alpha}/b} - e x $$ For $ \alpha = 2 $, equilibrium points are $ x = 0 $ and
$$ x = \frac{ab}{2(1+e)} \pm \frac{1}{2} \sqrt{ \left(\frac{ab}{1+e}\right)^2-4b } $$
As written this differs from our earlier solutions a couple respects &amp;ndash; the growth function applies to the unharvested population, which then experiences harvesting mortality, and the control variable is fishing effort, not harvest.</description>
    </item>
    
    <item>
      <title>SDP solution for allee model</title>
      <link>/2011/11/08/sdp-solution-for-allee-model/</link>
      <pubDate>Tue, 08 Nov 2011 12:40:31 +0000</pubDate>
      
      <guid>/2011/11/08/sdp-solution-for-allee-model/</guid>
      <description>Summarizing efforts from last few days setting up and running some stochastic dynamic programming optimization problems. As we are focusing on discrete time at the moment, these problems are solved by Bellman&amp;rsquo;s equation (don&amp;rsquo;t need Hamilton-Jacobi-Bellman formulation).
Problem Statement Choose the harvest level to optimize the profit $$ \maxh \sum{t=0}^T \beta^t \pi(x,h,t) $$
Subject to the boundary conditions $X(0) = X_0, X(T) = X_T$ and the state equation: $$ X(t+1) = Z(t) f(X(t)) $$</description>
    </item>
    
    <item>
      <title>Sunday</title>
      <link>/2011/11/06/sunday-5/</link>
      <pubDate>Sun, 06 Nov 2011 14:38:18 +0000</pubDate>
      
      <guid>/2011/11/06/sunday-5/</guid>
      <description>Computing notes A few configuration related things from migrating to the new laptop.
Clipboard and Vim vim clipboard - install vim-gnome &amp;ldquo;+y and &amp;ldquo;+p interact between vim and global clipboard, and y, shift+insert work within terminal.
make a repository bare so it can be pushed to (as opposed to moving to it&amp;rsquo;s working directory and running a pull). From stackoverflow:
mv repo/.git repo.git; rm -rf repo cd repo.git git config --bool core.</description>
    </item>
    
    <item>
      <title>Sparkleshare configuration</title>
      <link>/2011/11/04/sparkleshare-configuration/</link>
      <pubDate>Fri, 04 Nov 2011 22:35:11 +0000</pubDate>
      
      <guid>/2011/11/04/sparkleshare-configuration/</guid>
      <description>Configured sparkleshare across my linux server &amp;amp; laptops, and android phone. Provides a dropbox-style syncing and version history for all files using git. I can sync as much space as I have hardisk capacity, with as many users and machines as I like, at no cost. Wonderful.
Basic setup Get sparkleshare working on a server is dead simple, Can also use a github server, gitorious server, etc. Setup is clearly documented, which is really just doing a bunch of standard stuff if you have a server or github already set up.</description>
    </item>
    
    <item>
      <title>Friday&#39;s reading</title>
      <link>/2011/11/04/fridays-reading/</link>
      <pubDate>Fri, 04 Nov 2011 13:14:24 +0000</pubDate>
      
      <guid>/2011/11/04/fridays-reading/</guid>
      <description>Reading Catching up on journal table-of-contents/rss readings.
News Australia Researchers unhappy (unknown, 2011)
Climate change and Open Science Nature debate on the Berkeley climate team&amp;rsquo;s (BEST) press release in advance of publication. (unknown, 2011) Editor critiques the stunt:
 Richard Muller, the physicist in charge, even told the BBC: &amp;ldquo;That is the way I practised science for decades; it was the way everyone practised it until some magazines — particularly Science and Nature — forbade it.</description>
    </item>
    
    <item>
      <title>Warning signals - noise response</title>
      <link>/2011/11/03/warning-signals-noise-response/</link>
      <pubDate>Thu, 03 Nov 2011 11:27:40 +0000</pubDate>
      
      <guid>/2011/11/03/warning-signals-noise-response/</guid>
      <description>Dakos (Dakos et. al. 2012) considers $ \tfrac{dx}{dt} = f(x,p) $ and perturbs the parameter randomly to introduce variation. Evaluating around an equilibrium where $ f(x^, p^) = 0 $, they expand to first order (citing (Ripa &amp;amp; Heino, 1999)):
$$ \frac{dx}{dt} = \partial_x f(x^,p^)(x-x^) + \partial_p f(x^,p^) (p - p^) $$
and taking $ \xi = x- x^* $, with some slight of hand argue this can be rewritten as an Ito process,</description>
    </item>
    
    <item>
      <title>Stochastic Optimal Control</title>
      <link>/2011/11/02/stochastic-optimal-control/</link>
      <pubDate>Wed, 02 Nov 2011 22:57:57 +0000</pubDate>
      
      <guid>/2011/11/02/stochastic-optimal-control/</guid>
      <description>Starting with Reed 1979 Reed, 1979. Consider the stochastic population growth model
$$ X_{t+1} = Z_n f(X_n) $$
$ f(x) $ is concave and non-decreasing (compensating, not over-compensating). A natural choice is the Beverton-Holt model,
$$ f(x) = \frac{A x}{1+B x} $$
Cost of harvest is Schaefer production function $ c(x) = k/q x $, (i.e. doubling fish density halves the cost, assume $q $ constant), or Cobbs-Douglas form $ c(x) = k/x^{\theta} $ where $ \theta = 1+\beta \leq 1$.</description>
    </item>
    
    <item>
      <title>server file management from bowser: ajaxplorer, mollify</title>
      <link>/2011/11/01/server-file-management-from-bowser-ajaxplorer-mollify/</link>
      <pubDate>Tue, 01 Nov 2011 20:18:38 +0000</pubDate>
      
      <guid>/2011/11/01/server-file-management-from-bowser-ajaxplorer-mollify/</guid>
      <description>A few notes on trying out some server-based file sharing solutions.
ajaXplorer Kind of amazingly good and easy to install, with configuration-free functionality like previews of images and playing mp3s. More secure file sharing (at least, public link not generated until asked for, can have password assigned to it). Sharing is the only step not activated by default. Create a folder called &amp;ldquo;public&amp;rdquo; in the ajaxplorer directory, and this feature will appear.</description>
    </item>
    
    <item>
      <title>pdg-control Conference Call</title>
      <link>/2011/11/01/pdg-control-conference-call/</link>
      <pubDate>Tue, 01 Nov 2011 16:53:46 +0000</pubDate>
      
      <guid>/2011/11/01/pdg-control-conference-call/</guid>
      <description>Call includes everyone except Frank &amp;amp; Claire.
Logistics  Meeting 2: 13-15 March
 Review code/files on wiggio.
 Want a group review of material / webX tutorial? Email Paul after the call.
  Training Problem 1b: penalty to policy-change rate. Group is: Paul, Jake, Dan, Carl T, Jim, Frank, &amp;hellip;
 Dan: L2 done. Code coming (in Python, matlab coming). L1 is hard.
 Control variable becomes $ dh/dt $, and $ h $ becomes a control variable.</description>
    </item>
    
    <item>
      <title>Training Problem 2 update</title>
      <link>/2011/11/01/training-problem-2-update/</link>
      <pubDate>Tue, 01 Nov 2011 14:20:08 +0000</pubDate>
      
      <guid>/2011/11/01/training-problem-2-update/</guid>
      <description>Problem Statement We consider the stochastic optimal control problem of fisheries harvests under the scenarios involving alternate stable states, with uncertainty about the parameters of harvest. We consider a series of introductory problems to prepare us for the full problem. We begin with classical optimal control approaches (Pontraygin&amp;rsquo;s principle to transform into an ordinary differential equation boundary-value problem) for continuous time state equations (fish population dynamics) as a reference point.</description>
    </item>
    
    <item>
      <title>Labrids &amp; Parrotfish, method1</title>
      <link>/2011/11/01/labrids-parrotfish-method1/</link>
      <pubDate>Tue, 01 Nov 2011 08:57:15 +0000</pubDate>
      
      <guid>/2011/11/01/labrids-parrotfish-method1/</guid>
      <description>Parrotfish only: Shift at intramandibular joint in BM rate only. Shift in constraint, $ \alpha $ at intramandibular innovation. Labrids: Wrasses vs parrotfish Shift in BM rate Shift in constraint, $ \alpha $ Compare to: method2</description>
    </item>
    
    <item>
      <title>Monday: openfisheries &amp; ggplot</title>
      <link>/2011/10/31/monday-openfisheries-ggplot/</link>
      <pubDate>Mon, 31 Oct 2011 11:54:19 +0000</pubDate>
      
      <guid>/2011/10/31/monday-openfisheries-ggplot/</guid>
      <description>Andrew has put together the preliminary API for the openfisheries.org project. I&amp;rsquo;ve begun an R package, rfisheries, to interface to the openfisheries project. It would be great to incorporate data from the RAM Legacy database and the seaaroundus.org project, which may be done at the level of the R package or (perhaps more flexibly) directly through the developing openfisheries API.
Here&amp;rsquo;s a quick proof-of-principle example for Andrew&amp;rsquo;s API:
(Code linked from image as usual).</description>
    </item>
    
    <item>
      <title>Optimal Control examples continued: Bellman,  Dynamic Programming</title>
      <link>/2011/10/28/optimal-control-examples-continued-bellman-dynamic-programming/</link>
      <pubDate>Fri, 28 Oct 2011 23:23:12 +0000</pubDate>
      
      <guid>/2011/10/28/optimal-control-examples-continued-bellman-dynamic-programming/</guid>
      <description>Discrete-time state equation Discrete-time solution appears to be all about dynamic programming
and a chance for me to remember that I&amp;rsquo;m out of practice writing recursive functions. It&amp;rsquo;s just that in thinking about the problem, you start from the end, with the trivial subcase, and keep adding the layers. But the recursive function kinda starts at the beginning, and that trivial case is the exit condition. R doesn&amp;rsquo;t seem very efficient with these recursive functions, so this might become a C sub-routine eventually.</description>
    </item>
    
    <item>
      <title>Optimal control sample problems (Mostly continuous time by Pontryagin principle)</title>
      <link>/2011/10/27/optimal-control-next-steps/</link>
      <pubDate>Thu, 27 Oct 2011 13:53:50 +0000</pubDate>
      
      <guid>/2011/10/27/optimal-control-next-steps/</guid>
      <description>Optimal Control by Pontryagin principle Problem statement  State equation: $\dot x = x \exp \left( \alpha \left(1-\frac{x}{K}\right) \left( \frac{x-C}{K} \right) \right) - x h$
 Utility function $\pi(h, x, t) = \frac{h^{1+\gamma}}{1+\gamma}$
 Boundary constraints: $x(0) = X_0 \qquad x(T) = X_T$
  See problem statement and analytic BVP formulation details in this post. Additionally we scale the variables appropriately. Then we can begin with some basic parameter exploration in the original model formulation.</description>
    </item>
    
    <item>
      <title>Labrid submodels</title>
      <link>/2011/10/26/labrid-submodels/</link>
      <pubDate>Wed, 26 Oct 2011 15:49:27 +0000</pubDate>
      
      <guid>/2011/10/26/labrid-submodels/</guid>
      <description>Updates to labrids results:
 Results from Parrotfish tree &amp;amp; 2-partition Labrid tree on full model.  Full model, Labrids Pharyngeal Shift 
Alphas Sigmas Full Model, Intramandibular Shift .
Labrid tree, multi-sigma model, both shifts Surprising less powerful at identifying the differences.
Note that this still estimates OU models, and hence has a global alpha, and unique thetas:
LABRID TREE, MULTI-alpha, BOTH SHIFTS Parrotfish tree, multi-sigma model: Parrotfish tree, multi-alpha model: Labrid pharyngeal only, multi-sigma model: Labrid pharyngeal, multi-alpha Labrid intramandibular only, multi-sigma model: Labrid intramandibular, multi-alpha Full model plots with: method2_plots.</description>
    </item>
    
    <item>
      <title>Monday, misc notes</title>
      <link>/2011/10/26/monday-misc-notes/</link>
      <pubDate>Wed, 26 Oct 2011 09:47:13 +0000</pubDate>
      
      <guid>/2011/10/26/monday-misc-notes/</guid>
      <description>R packages relevant to the optimal control problems
 BB: solving system of nonlinear equations bvpSolve: boundary value problems  lunch with Alan &amp;amp; visiting professor from Ottowa, Frithjof Lutscher.
ADG (algorithm discussion group)  Reviewed github, basic git commands. Added roxygen function documentation Created basic package, toyHMM Some git notes: The quick git-undo for a destroyed file:  git checkout filename  This will checkout the file from HEAD, overwriting your change.</description>
    </item>
    
    <item>
      <title>Tuesday notes: package work mostly.</title>
      <link>/2011/10/25/tuesday-notes-package-work-mostly/</link>
      <pubDate>Tue, 25 Oct 2011 19:18:09 +0000</pubDate>
      
      <guid>/2011/10/25/tuesday-notes-package-work-mostly/</guid>
      <description>Treebase release  write updated tutorial.
 cran needs mac and windows binaries.
  Trying devtools win_builder(); emailing Kurt. Nevermind, just got the email saying the binary has been built.
 write email announcement  rfishbase data formatting My problem turned out not to be about &amp;ldquo;\&amp;rdquo; at all, these were octal encodings of symbols used in the XML data, eg: Cape Bojador (26°N)
which xmlValue() would read in using the octal encoding &amp;rdquo;Cape Bojador (26\302\260N)&amp;rdquo;</description>
    </item>
    
    <item>
      <title></title>
      <link>/2011/10/25/treebase-package-on-cran/</link>
      <pubDate>Tue, 25 Oct 2011 19:06:38 +0000</pubDate>
      
      <guid>/2011/10/25/treebase-package-on-cran/</guid>
      <description>My treebase package is now up on the CRAN repository. (Source code is up, the binaries should appear soon). Here&amp;rsquo;s a few introductory examples to illustrate some of the functionality of the package. Thanks in part to new data deposition requirements at journals such as Evolution, Am Nat, and Sys Bio, and data management plan requirements from NSF, I hope the package will become increasingly useful for teaching by replicating results and for meta-analyses that can be automatically updated as the repository grows.</description>
    </item>
    
    <item>
      <title>Training problem 2: the economist&#39;s problem statement</title>
      <link>/2011/10/24/optimal-control-training-problem-2-problem-statement/</link>
      <pubDate>Mon, 24 Oct 2011 17:46:26 +0000</pubDate>
      
      <guid>/2011/10/24/optimal-control-training-problem-2-problem-statement/</guid>
      <description>pdg-control Problem statement: Maximize profits subject to $$\max_{h(t)} \int_0^T e^{-\rho t} \pi(x, h, t) dt $$ Subject to the state equations (biology):
$$ \dot x = x \exp \left( \alpha \left(1-\frac{x}{K}\right) \left( \frac{x-C}{K} \right) \right) - x h $$
Note that we consider the control variable to be effort, $h$ instead of harvest, $\mathcal{H}$, where $\mathcal{H} = h x$.
and the constraints: $$ x(0) = X_0 \qquad x(T) = X_T $$ We have fixed boundary conditions (equalities) and equalities in the state equations, so we have a nice straight-forward problem.</description>
    </item>
    
    <item>
      <title>Friday: Optimal Control</title>
      <link>/2011/10/21/friday-optimal-control/</link>
      <pubDate>Fri, 21 Oct 2011 23:15:08 +0000</pubDate>
      
      <guid>/2011/10/21/friday-optimal-control/</guid>
      <description>Optimal control Imagine we&amp;rsquo;re trying to minimize $J = \theta( y(t_F), t_F)$
subject to both the state equations: $\dot y = f(y(t), u(t))$, Note these are continuous, applying at all times $t$.
and boundary conditions: $\psi(y(t_F), u(t_F), t_F) = 0$. These are discrete, applying only at fixed time $t_F $. We have to put the continuous constraint in as an integral:
$$ \hat J = \left[\phi + \mathbf{\nu}^T \psi \right]_{tF} - \int{t_I}^{t_F} \mathbf{\lambda}^T \left(\dot{\mathbf{y}} - f(\mathbf{y}(t),\mathbf{u}(t)) \right) dt $$</description>
    </item>
    
    <item>
      <title>Thursday - some parrotfish &amp; labrid runs on method2</title>
      <link>/2011/10/20/thursday-some-parrotfish-runs-on-method2/</link>
      <pubDate>Thu, 20 Oct 2011 16:20:14 +0000</pubDate>
      
      <guid>/2011/10/20/thursday-some-parrotfish-runs-on-method2/</guid>
      <description>Running:
 farm cluster, c0-17 method2_parrotfish.R &amp;ndash; Done. Below.
 farm cluster, c0-27 method2_labrids.R (with three partitions)
 farm cluster, c0-13 method2_labrids_phar.R (two partitions)
 farm cluster, c0-19 method2_labrids_intra.R (two partitions)
  Parrotfish Phylogeny The .y indicates the trait has been size-corrected. Parameters reported from estimations in the full model. All sets converged except open lever ratio. Error bars indicate 1 standard deviation estimated from the likelihood curvature. Lighter color indicates the presence of an intramandibular joint, as coded in the phylogeny above.</description>
    </item>
    
    <item>
      <title>Optimal Control Exploration</title>
      <link>/2011/10/19/optimal-control-exploration/</link>
      <pubDate>Wed, 19 Oct 2011 23:01:10 +0000</pubDate>
      
      <guid>/2011/10/19/optimal-control-exploration/</guid>
      <description>Translating Jim&amp;rsquo;s Matlab code.
Adapted for Octave.
R version.
Document review:
 Chapter 04_Sanchirico_Final.pdf
 SanchiricoOptimalSpace_JEEM.pdf (Sanchirico &amp;amp; Wilen, 2005)
 Optimal_Rebuilding_AJAE2010.pdf, Optimal_Rebuilding_Supp_Material.pdf (Sanchirico et. al. 2010)
 Sanchirico_editsembedded.pdf: Book Chapter 1: Economically Optimal Management of a Metapopulation
  Reviewing Bett&amp;rsquo;s Practical Methods for Optimal Control using Nonlinear Programming. (( Practical Methods for Optimal Control and Estimation Using Nonlinear Programming, Second Edition (Advances in Design and Control) John T.</description>
    </item>
    
    <item>
      <title>Mathematical Elements of Attack Risk Analysis for Mountain Pine tribolium</title>
      <link>/2011/10/18/mathematical-elements-of-attack-risk-analysis-for-mountain-pine-beetles/</link>
      <pubDate>Tue, 18 Oct 2011 08:00:46 +0000</pubDate>
      
      <guid>/2011/10/18/mathematical-elements-of-attack-risk-analysis-for-mountain-pine-beetles/</guid>
      <description>(POWELL et. al. 2000)
Regimes endemic - attack the weakling trees. epidemic
Tree has defenses. Aggregation of beetles can exhaust these, but then must disperse to other trees to avoid larval competition.
Mathematical Elements The cast, (after some non-dimensionalization)
 $ \dot Q(x,y,t) = R P - Q R$ Nesting beetles
 $ \dot H(x,y,t) = R P - H R $ Holes: measures attack success
 $ \dot R(x,y,t) = \left( 1 - R \right) R - R H $ Resin: tree defense success</description>
    </item>
    
    <item>
      <title>Algorithms Group: Literate programming</title>
      <link>/2011/10/17/algorithms-group-literate-programming/</link>
      <pubDate>Mon, 17 Oct 2011 18:41:42 +0000</pubDate>
      
      <guid>/2011/10/17/algorithms-group-literate-programming/</guid>
      <description>Algorithms group today took a brake from discussing algorithms for an aside on coding practices. Today we focused primarily on literate programming tools for making better documented, more readable code. We covered:
 Sweave
 Google style guide, also see R core-team developer Hadley Wickam&amp;rsquo;sstyle guide (modified from Google)
 R coding practices grab-bag: using functionalized code, {&amp;hellip;}, S3 vs S4 classes.
 roxygen, roxygen2
  Next time: Github, then we&amp;rsquo;ll spend 30 minutes collaboratively adding roxygen documentation to our existing codes and committing changes over git.</description>
    </item>
    
    <item>
      <title>Rewrites</title>
      <link>/2011/10/17/pnas-rewrites/</link>
      <pubDate>Mon, 17 Oct 2011 17:37:19 +0000</pubDate>
      
      <guid>/2011/10/17/pnas-rewrites/</guid>
      <description>Add more data set examples Remove skew, Remove the broken CaCO3 analysis Show distributions for increased sampling effort. Does time interval make a difference for convergence of deuterium2 run? Nope. Fails in parallel, running in series.  Code:  get away from explicit parallelization and deeply nested functions. really master optimizers, and avoid errors &amp;amp; failed convergence. store finished data for plotting as data objects. CaCO3 example -&amp;gt; MLE estimate of unstable model doesn&amp;rsquo;t converge, shouldn&amp;rsquo;t be used to simulate then!</description>
    </item>
    
    <item>
      <title>Friday, more runs</title>
      <link>/2011/10/17/friday-more-runs/</link>
      <pubDate>Mon, 17 Oct 2011 13:39:08 +0000</pubDate>
      
      <guid>/2011/10/17/friday-more-runs/</guid>
      <description>A couple more runs:
G10:
G8: G7: G6: K9: K8: Stable model: IBM critical on first half of data:  Estimate the nonlinear model, show this method does worse than the linear estimation Apply to systems with alternate dynamics. Parameter distributions writing &amp;amp; formatting continue&amp;hellip;  </description>
    </item>
    
    <item>
      <title>Thursday, Fisheries course</title>
      <link>/2011/10/13/thursday-fisheries-course/</link>
      <pubDate>Thu, 13 Oct 2011 13:28:49 +0000</pubDate>
      
      <guid>/2011/10/13/thursday-fisheries-course/</guid>
      <description>Fisheries impact on forage fish. Forage fish impact on the primary fisheries.
 Huxley, 1882: &amp;ldquo;Great Sea Fisheries cannot be exhausted&amp;rdquo; (full address) Worm et al., 2006: All fish will collapse by 2050 (Worm et. al. 2006)  Benguela Current upwelling (Anchovy collapse)
Discussion of: Prey switching impact?
Wasp-waist ecosystems
Ecopath/ecosim vs Atlantis
Questions:
Can we identify the nature of control?
Importance of wasp-waist control.
regime switching
Negative impact of forage fish on ground fish.</description>
    </item>
    
    <item>
      <title>Wednesday</title>
      <link>/2011/10/12/wednesday-10/</link>
      <pubDate>Wed, 12 Oct 2011 22:01:56 +0000</pubDate>
      
      <guid>/2011/10/12/wednesday-10/</guid>
      <description>8:30 gist - flush swap. Catalyst grant review. 9-9:30 SCHA stuff 9:30 - query roc curve thresholds 10 - 10:30 post rfishbase update 10:30 http://openfisheries.org/ 11:15 back to roc curves. noon. curves threshold reading done. lunch.  PNAS writing, examples.
Adding more Drake-data examples: on farm, running G10 and G6.
 1pm-2pm domes 2pm back to writing  Launch additional data runs: deut2, trying in series.</description>
    </item>
    
    <item>
      <title>rfishbase Tutorial - updated &amp; extended</title>
      <link>/2011/10/12/rfishbase-tutorial-updated-extended/</link>
      <pubDate>Wed, 12 Oct 2011 11:59:49 +0000</pubDate>
      
      <guid>/2011/10/12/rfishbase-tutorial-updated-extended/</guid>
      <description>Updated rfishbase package. Include querying for a list of scientific names and the addition of more quantitative traits, though the selection is still somewhat limited. Demo includes how to grab some data to match a phylogenetic tree, and some regular expression (grep) searches for feeding behavior.
Source code
Windows binary also available.
# demo.R rm(list=ls()) require(rfishbase) ###### Grabbing, Loading &amp;amp; Caching Fishbase Data ###### ## Download and parse data for first 40 ids (36 fish) #fish.</description>
    </item>
    
    <item>
      <title>Loo Botsford, CPB seminar</title>
      <link>/2011/10/11/lou-botsford-cpb-seminar/</link>
      <pubDate>Tue, 11 Oct 2011 17:04:57 +0000</pubDate>
      
      <guid>/2011/10/11/lou-botsford-cpb-seminar/</guid>
      <description>&amp;ldquo;Effects of Fishing on the Sensitivity of Fisheries to Climate Variability&amp;rdquo; Truncation of age structure.
juvenation (younger population), maternal effects (first-year breeders are poor), genetic selection, ability to track environment (vs smoothing &amp;ndash; averaging over longer times).
Outline:
Empirical evidence for increased variability, model explanations  Story begins with Hsieh, et al 2006. Long time series, increasing fluctuations. (Hsieh et. al. 2006)
 Anderson et al no age structure model (Anderson et.</description>
    </item>
    
    <item>
      <title>Algorithms Group, HMM meets EM</title>
      <link>/2011/10/10/algorithms-group-hmm-meets-em/</link>
      <pubDate>Mon, 10 Oct 2011 18:42:03 +0000</pubDate>
      
      <guid>/2011/10/10/algorithms-group-hmm-meets-em/</guid>
      <description>Alisa reviews HMM, EM, and shows us how to combine them.
The EM version treats the transition probabilities (exchanging coins) and emission probabilities (chance of heads/tails under each coin) as unknowns. Make a guess, calculate the blue line from before. This can be used to calculate a new guess that will hill climb to the locally optimum solution (EM).
New guess for the transition probability is:
$$ A_{lk} = \frac{f_i bi a{lk} ek(x{i+1}) }{P(x)} $$</description>
    </item>
    
    <item>
      <title>Matt Helmus visit</title>
      <link>/2011/10/07/matt-helmus-visit/</link>
      <pubDate>Fri, 07 Oct 2011 14:36:33 +0000</pubDate>
      
      <guid>/2011/10/07/matt-helmus-visit/</guid>
      <description>Notes from presentation 1. Species-area curve:  Species sorting by environment. species clustering due to limited dispersal Random displacement (faster saturation) In-situ speciation looks like clustering Compare to colonization Phylogenetic species variability metric: compare phylogenetic covariance matrix to a star-phylogeny, not expected to increase with area.  $$ \frac{n \textrm{tr}C - \sum C }{n(n-1)}$$
2. Simulations:  species sort along an environmental gradient. BM trait determining position. : closely related species clustered.</description>
    </item>
    
    <item>
      <title>Wednesday - forage fish &amp; cascades</title>
      <link>/2011/10/05/wednesday-forage-fish-cascades/</link>
      <pubDate>Wed, 05 Oct 2011 23:38:52 +0000</pubDate>
      
      <guid>/2011/10/05/wednesday-forage-fish-cascades/</guid>
      <description>Forage fish presentation Some simulations exploring top-down &amp;amp; bottom up control concepts in simple models.
$$ \frac{dN}{dt} = r N\left( 1 - \frac{N}{K} \right) - \alpha N P $$ $$ \frac{dP}{dt} = \beta \alpha N P - \mu P $$ Note that at equilibrium, N depends only on predator dynamics, P on K and r. $$\hat N = \frac{\mu}{\alpha\beta} $$ $$ \hat P = \frac{r}{\alpha}\left( 1 - \frac{N}{K} \right) $$</description>
    </item>
    
    <item>
      <title>Tuesday</title>
      <link>/2011/10/04/tuesday-9/</link>
      <pubDate>Tue, 04 Oct 2011 22:29:29 +0000</pubDate>
      
      <guid>/2011/10/04/tuesday-9/</guid>
      <description>Hastings seminar: Forest Pest Outbreaks Schedule
Prof Dave Rizzo  Reviews major pest outbreaks (Major Forest Insect &amp;amp; Disease Conditions in the United States 2009 Update)  Mentions weekend&amp;rsquo;s NY Times piece, (and see author&amp;rsquo;s commentary), reviews major pest outrbreak trends.   David Kling Allee effects &amp;amp; Management (Gypsy moth). * Review review (Taylor &amp;amp; Hastings, 2005). * Simulation exploration: pmid: 19831081, * Also discuss (Tobin et. al. 2011).</description>
    </item>
    
    <item>
      <title>Friday, wordpress backups, pmc edits</title>
      <link>/2011/09/30/friday-wordpress-backups-pmc-edits/</link>
      <pubDate>Fri, 30 Sep 2011 17:51:31 +0000</pubDate>
      
      <guid>/2011/09/30/friday-wordpress-backups-pmc-edits/</guid>
      <description>Wordpress local copy  configured mysqldump backup, following dreamhost wiki (added cron job manually instead of in panel).  edit local wp-config.php to use localhost. Get the database name, user name and password from the lines above it, which are used later.
define(&#39;DB_HOST&#39;, &#39;localhost&#39;); // ...and the server MySQL is running on  create user: log in as root
mysql -u root -p  and create user
mysql&amp;gt; create database database_name mysql&amp;gt; create user &#39;username&#39;@&#39;localhost&#39; identified by &#39;password&#39;; mysql&amp;gt; create database database_name mysql&amp;gt; grant usage on *.</description>
    </item>
    
    <item>
      <title>Thursday</title>
      <link>/2011/09/29/thursday-10/</link>
      <pubDate>Thu, 29 Sep 2011 16:46:03 +0000</pubDate>
      
      <guid>/2011/09/29/thursday-10/</guid>
      <description>9-9:20 Updating research statement (home page). 9:20 -9:40 Updating notebook: Review, Tuesday &amp;amp; Wednesday meetings coffee 9:50 Application. 10-11:30:  Forage fish dynamics, Sanchirico and Essington Jim gives the broad overview, central question: What are the benefits/costs of a % reduction in the catch C of forage fish N:
$$ \Delta C \downarrow \to \Delta N \to \Delta F, \Delta M \Delta S$$
F predator commercial fisheries, M marine mammals, S seabirds.</description>
    </item>
    
    <item>
      <title>Phylogenetics - Research Proposal</title>
      <link>/2011/09/29/phylogenetics-research-proposal/</link>
      <pubDate>Thu, 29 Sep 2011 15:20:10 +0000</pubDate>
      
      <guid>/2011/09/29/phylogenetics-research-proposal/</guid>
      <description>Evolution has shaped all ecological communities. It has tested their resilience in experiments we could never perform. Now can it help us identify what characteristics make a community resilient or vulnerable to external forces?
Anthropogenic influences such as invasive species, climate change, and urbanization pressure ecosystems everywhere on the planet. Some collapse suddenly, others appear remarkably resilient. What makes some systems more vulnerable, and how could we identify them? Ecologists have long sought to understand the factors most influencing this stability, but the scale is immense and the problem complex &amp;ndash; making controlled experimentation difficult and limited.</description>
    </item>
    
    <item>
      <title>Wednesday - Berkeley visits</title>
      <link>/2011/09/28/wednesday-berkeley-visits/</link>
      <pubDate>Wed, 28 Sep 2011 09:25:56 +0000</pubDate>
      
      <guid>/2011/09/28/wednesday-berkeley-visits/</guid>
      <description>Consultation call with Rebecca Lawrence, F1000. F1000 is exploring offering a data publishing platform, and we discussed some of the potential challenges (submission incentives, data review/reproducible review, meta-data standards).   anyone who might be interested in working with us to get this project off the ground, with a scientific PhD background, a reasonable understanding of data sharing/mining issues and some knowledge of technical issues (not necessarily a coder but I guess it might help) then do let me know.</description>
    </item>
    
    <item>
      <title>Tuesday - Berkeley visits</title>
      <link>/2011/09/27/tuesday-berkeley-visits/</link>
      <pubDate>Tue, 27 Sep 2011 23:19:08 +0000</pubDate>
      
      <guid>/2011/09/27/tuesday-berkeley-visits/</guid>
      <description>In Berkeley for a few meetings with faculty and students.
 7:15 Train Davis to Berkeley 9:30 -11 Coffee with George Oster. 11- 1 Meeting with de Valpine lab 1p Presentation from Viorel Popescu, (post-doc in lab, mostly working remotely from Vancover) on BACI (before-after, control-impact) occupancy models. 2p meeting with Perry 3p Meeting with Karthik 4:24-6 train to Davis  </description>
    </item>
    
    <item>
      <title>Monday</title>
      <link>/2011/09/26/monday-10/</link>
      <pubDate>Mon, 26 Sep 2011 15:31:07 +0000</pubDate>
      
      <guid>/2011/09/26/monday-10/</guid>
      <description>Phylogenetics paper  Grayscale the figures  Moore &amp;amp; Coop PBG 270: Phylo methods for exploring correlations between character traits and lineage rates.
 Models ((Are the generalized birth-death models (e.g. Kendall 1948) good limit to interesting process? somtimes. ))    detecting variation in rates
 locating shifts along branches
 locating shifts in time
 correlates of differential rates (_e.g. _traits; our subject for today/course).
 Parameter estimation</description>
    </item>
    
    <item>
      <title>Saturday</title>
      <link>/2011/09/24/saturday-2/</link>
      <pubDate>Sat, 24 Sep 2011 18:03:02 +0000</pubDate>
      
      <guid>/2011/09/24/saturday-2/</guid>
      <description>NIMBioS Working group follow-up:  Install pdf plugin (pdf24, Kalin&amp;rsquo;s pdf, epub all don&amp;rsquo;t display equations) &amp;hellip; Posted issue to wordpress-for-scientists list. Solution: simply print to file (pdf) from google-chrome. (Doesn&amp;rsquo;t work when printing from firefox 6.0) Reply to Paul, add pdf of notes on wiggio.  Fellowship stuff  Email Alan, David, George, John, Perry  Reviews  Answer request to review for Ecology Answer request to review for Evolution _**Working on reviews (see private notes) **_3-6pm  Misc  Testing Droideley.</description>
    </item>
    
    <item>
      <title>Friday: ropensci, manuscript edits</title>
      <link>/2011/09/23/friday-ropensci-manuscript-edits/</link>
      <pubDate>Fri, 23 Sep 2011 11:03:43 +0000</pubDate>
      
      <guid>/2011/09/23/friday-ropensci-manuscript-edits/</guid>
      <description>rOpenSci Conference Call Catalyst grant  Reviewed budget. Karthik will merge current proposals, Carl will review. Goal: send out next week. Ask Mark Hahnel to look it over  Blog posts  Carley planning to make guest blog post within the next week.  Mendeley/Plos Binary battle  Carl will file entry form. Karthik push edits to rplos Scott will add rplos tutorial to ropensci.org Carl will add rmendeley tutorial to ropensci.</description>
    </item>
    
    <item>
      <title>Thursday</title>
      <link>/2011/09/22/thursday-9/</link>
      <pubDate>Thu, 22 Sep 2011 17:51:06 +0000</pubDate>
      
      <guid>/2011/09/22/thursday-9/</guid>
      <description>Sent off review. finally.
Sanchirico seminar with Tim Essington (U Washington). Goal: Prepare for a review on forage fisheries.
Outline  background background Fishery interactions marine mammal/seabird interactions Climate &amp;amp; forage fish Fishmeal (Demand side) direct consumption (Demand side) Vitamin supp / health benefits (Demand side) Non-market value marine mammals Synthesis  Forage-fish: &amp;ldquo;foundation species&amp;rdquo; in marine ecosystems, get energy from zooplankton/upwelling to high-level predators (high-market target fisheries). Sardines/pilchards, anchovies, sandeels, krill, herrings, capelin, menhaden.</description>
    </item>
    
    <item>
      <title>Wednesday</title>
      <link>/2011/09/21/wednesday-9/</link>
      <pubDate>Wed, 21 Sep 2011 22:34:13 +0000</pubDate>
      
      <guid>/2011/09/21/wednesday-9/</guid>
      <description>Alan meeting  Sanchirico course, Hastings course Berkeley visits NIMBioS working group Lab website, lab group meeting.  To Do  Finish THEE review Evolution edits Miller Application Berkeley visits emails. File ESA reimbursements. File NIMBioS reimbursements.  Next steps  Paper for treebase/rfishbase packages? wrightscape paper. Training problem II. Economics warning signals. Costs of errors. Updating (multiple decision points). Mitigation strategy.  Inferring the uncertainty in model, adaptive management.</description>
    </item>
    
    <item>
      <title>Colored noise: some classic results in ecology</title>
      <link>/2011/09/21/colored-noise-some-classic-results-in-ecology/</link>
      <pubDate>Wed, 21 Sep 2011 13:20:52 +0000</pubDate>
      
      <guid>/2011/09/21/colored-noise-some-classic-results-in-ecology/</guid>
      <description>Some of my early notes &amp;amp; derivations on the impact of red environmental noise on population dynamics as pdf:
 Roughgarden&amp;rsquo;s paper Fieberg &amp;amp; Ellner, (2000) &amp;ldquo;When is it Meaningful to Estimate an Extinction Probability?&amp;rdquo; Ecology, 81. doi. Lawton, J. H. (1988). More time means more variation. Nature, 334, 563. Petchey, O. L., Gonzalez, A., &amp;amp; Wilson, H. B. (1997). Effects on population persistence: the interaction between environmental noise colour, intraspecific competition and space.</description>
    </item>
    
    <item>
      <title>Van Kampen Expansion and Stochastic population dynamics</title>
      <link>/2011/09/21/van-kampen-expansion-and-stochastic-population-dynamics/</link>
      <pubDate>Wed, 21 Sep 2011 13:02:30 +0000</pubDate>
      
      <guid>/2011/09/21/van-kampen-expansion-and-stochastic-population-dynamics/</guid>
      <description>Embedding a file from some of my earlier work illustrating the use of the linear noise approximation describing demographic noise processes and highlighting some of the more interesting results therein.</description>
    </item>
    
    <item>
      <title>Tuesday: Visit to Berkeley</title>
      <link>/2011/09/21/tuesday-visit-to-berkeley/</link>
      <pubDate>Wed, 21 Sep 2011 10:04:37 +0000</pubDate>
      
      <guid>/2011/09/21/tuesday-visit-to-berkeley/</guid>
      <description>Train to Berkeley 7:15-8:32 (6:35a)  9-10:30 Harte lab meeting: Chloe presented her work on mima mounds and pocket gofers 10:30 - noon Justin (coffee, tour campus). Discussed grant opportunities: Lab has a recent NSF and likely will get a Moore grant to extend maximum entropy work. (Not to be confused with species distribution modeling maxent). noon-1p Erica (lunch). 1p-2:15 John. 2:15-3:30 Andy. Great discussions about phylogenetic methods and hierarchical models, regime shifts, open science.</description>
    </item>
    
    <item>
      <title>Monday</title>
      <link>/2011/09/19/monday-9/</link>
      <pubDate>Mon, 19 Sep 2011 23:55:33 +0000</pubDate>
      
      <guid>/2011/09/19/monday-9/</guid>
      <description> Catching up on ToCs, reading.
 Working on THEE review.
 Manuscript edits.
 Algorithms group meeting - planning for quarter.
 Interview on KDVS In which I discuss mathematical ecology with my advisor and our local radio station.
   </description>
    </item>
    
    <item>
      <title>pdg-control pdg-control: Thursday</title>
      <link>/2011/09/15/nimbios-pdg-control-thursday/</link>
      <pubDate>Thu, 15 Sep 2011 14:54:05 +0000</pubDate>
      
      <guid>/2011/09/15/nimbios-pdg-control-thursday/</guid>
      <description>Thursday, August 15 8:00 Coffee &amp;amp; Breakfast at NIMBioS 8:45 Training Problem Groups TASK: Prepare progress report/action strategy for full group 9:30 Regroup: Reports from each Training Problem Group 10:30 Planning for Meeting 2 12:00 Lunch at NIMBioS &amp;amp; Departure</description>
    </item>
    
    <item>
      <title>pdg-control PDG group, Tasks</title>
      <link>/2011/09/15/nimbios-pdg-group-tasks/</link>
      <pubDate>Thu, 15 Sep 2011 08:59:36 +0000</pubDate>
      
      <guid>/2011/09/15/nimbios-pdg-group-tasks/</guid>
      <description>Tools  Sharing: Dropbox (Team account? 350 gigs/12 users $1670/yr)
 Common language for training development: Matlab
 Remote collaboration: GoToMeeting? Evo?
 Code collaboration GitHub?
  Training problem I 1a) State vars &amp;gt; Control vars: Can give solutions with chattering (periodic, possibly jumping between boundaries.)
Short-term priorities:
1) shared numerics. Jim looks at collocation problem: how do they perform on periodic controls on the infinite time? (If they can&amp;rsquo;t work, we go to finite time.</description>
    </item>
    
    <item>
      <title>Training Problem II</title>
      <link>/2011/09/14/training-problem-ii/</link>
      <pubDate>Wed, 14 Sep 2011 22:47:29 +0000</pubDate>
      
      <guid>/2011/09/14/training-problem-ii/</guid>
      <description>Consider a harvested fish population with discrete-time population dynamics under an allee effect:
$$ N_{t+1} = N_t \exp \left( \gamma \left[ 1-\frac{N_t}{K} \right] \left[ \frac{N_t - C}{K} \right] \right) - \beta E_h N_t$$
Note that C is the unfished allee threshold, K the carrying capacity, $E_h$ the fish harvesting effort.
Consider that the initial population is unknown, but described by a density function whose variance can be decreased by sampling. Just to get started, let&amp;rsquo;s assume log-normal (avoiding the chance of negative population sizes), with log-standard deviation inversely proportional to the sampling effort $E_s $.</description>
    </item>
    
    <item>
      <title>pdg-control pdg-control: Wednesday</title>
      <link>/2011/09/14/nimbios-pdg-control-wednesday/</link>
      <pubDate>Wed, 14 Sep 2011 14:54:29 +0000</pubDate>
      
      <guid>/2011/09/14/nimbios-pdg-control-wednesday/</guid>
      <description>Wednesday, August 14 8:00 Coffee &amp;amp; Breakfast at NIMBioS 8:45 Introduction to Day 3 (Donahue/Armsworth) 9:00 Training Problem Groups
Marie-Jose reflects on the sampling problem:  Optimization between effort and data.
 Spatial autocorrelation challenges
 periodic sampling challenges.
 Fortin et al 1989
 Carl asked: Nyquist frequency?
 Spatial sampling the correct scale by maximum variance in wavelet scaling.
  Frank reflects on our activities from a control engineer&amp;rsquo;s perspective  MPC for fishery management - few long-sampling engineering examples.</description>
    </item>
    
    <item>
      <title>pdg-control pdg-control, Tuesday</title>
      <link>/2011/09/13/2588/</link>
      <pubDate>Tue, 13 Sep 2011 09:00:38 +0000</pubDate>
      
      <guid>/2011/09/13/2588/</guid>
      <description>Tuesday, August 13 8:00 Coffee &amp;amp; Breakfast at NIMBioS 8:45 Outline for Day 2 (Donahue/Armsworth)
Adaptive Control, Jake Introduced by he two-armed bandit problem, Rothchild i = 1,2. $ T_i $ is the number of trials, $ N_i $ are numbers of successes.
Define $$ \rho_i = \frac{1}{1+T_i}, \mu_i = \frac{N_i}{1+T_i} $$
If i is played $ p_i $ becomes
$$ \frac{p_i}{1+p_i} = \frac{1}{T+2} $$
If i is played and successful $ \mu_i $ becomes</description>
    </item>
    
    <item>
      <title>Pretty Darn Good Control Working Group</title>
      <link>/2011/09/12/pretty-darn-good-control-working-group/</link>
      <pubDate>Mon, 12 Sep 2011 12:49:39 +0000</pubDate>
      
      <guid>/2011/09/12/pretty-darn-good-control-working-group/</guid>
      <description>Monday, August 12 8:00 Coffee &amp;amp; Breakfast at NIMBioS 8:45 Welcome to NIMBioS (Lou Gross, Director of NIMBioS) 9:00 Intro to the pdg-control Working Group (Paul Armsworth) 9:30 Introductions by each Working Group Participant 5-minute self-introduction to the group, including your background, expertise, and current work 10:30 Break 11:00 Introduction to Training Problem 1 &amp;amp; Discussion (Jim Sanchirico)
Training problem 0: Optimal Control Jim
maximize present discounted value:
$$\max_{h_t} \int_0^T e^{-rt} \Pi(h_t) dt $$</description>
    </item>
    
    <item>
      <title>Likelihood expressions for branching processes</title>
      <link>/2011/09/10/likelihood-expressions-for-branching-processes/</link>
      <pubDate>Sat, 10 Sep 2011 14:29:09 +0000</pubDate>
      
      <guid>/2011/09/10/likelihood-expressions-for-branching-processes/</guid>
      <description>Lineage-through-time approach Nee, then Paradis (Paradis, 2003) introduces unresolved tips
Distribution of branch-lengths approach Note that in any Markov branching process, only node depth, not topology, influence the likelihood.
See also:  Notes on bootstrapping in laser
 Earlier Notes on distribution derivation from Kendall 1948
 My derivation of the analytic probability of N individuals in pure birth (from van Kampen approximation)
  (manual list)
Refs Kendall, D.</description>
    </item>
    
    <item>
      <title>How google views me: by search terms or citation counts?</title>
      <link>/2011/09/09/how-google-views-me-by-search-terms-or-citation-counts/</link>
      <pubDate>Fri, 09 Sep 2011 09:55:39 +0000</pubDate>
      
      <guid>/2011/09/09/how-google-views-me-by-search-terms-or-citation-counts/</guid>
      <description>How Google search views me: here&amp;rsquo;s a word cloud of search terms reaching my site in August. Word cloud produced with R: click-through for link to source-code. Uses the rather convenient tm package for text-mining functions in R. Note that this shows the frequency of individual words used in searches, rather than the whole search term.
Code:
require(tm) require(wordcloud) require(RColorBrewer) carl &amp;lt;- read.csv(&amp;quot;searchterms.csv&amp;quot;, colClasses=c(&amp;quot;character&amp;quot;, &amp;quot;numeric&amp;quot;)) words &amp;lt;- character(sum(carl[[2]])) m &amp;lt;- 1 for(i in 1:length(carl[[1]])){ n &amp;lt;- carl[[2]][i] x &amp;lt;- carl[[1]][i] words[m:(m+(n-1))] &amp;lt;- rep(x, n) m &amp;lt;- m+n } carl &amp;lt;- Corpus(DataframeSource(carl)) carl &amp;lt;- tm_map(carl, removePunctuation) carl &amp;lt;- tm_map(carl, tolower) carl.</description>
    </item>
    
    <item>
      <title>discriminating early bursts</title>
      <link>/2011/09/08/discriminating-early-bursts/</link>
      <pubDate>Thu, 08 Sep 2011 23:08:33 +0000</pubDate>
      
      <guid>/2011/09/08/discriminating-early-bursts/</guid>
      <description>Looking at cases when early burst can be discriminated from OU, a la Harmon et al 2010 (Harmon et. al. 2010). Fixed models can be told apart. Rather trivially, none of these models can be told apart if initially estimated from Brownian data. Rather encouraging: models estimated from common data can be told apart. 600 taxa tree
Still works on 60 taxa, identifying OU correctly when sim under OU (left), and EB for EB data (right):</description>
    </item>
    
    <item>
      <title>memory management, cron</title>
      <link>/2011/09/07/memory-management-cron/</link>
      <pubDate>Wed, 07 Sep 2011 21:28:03 +0000</pubDate>
      
      <guid>/2011/09/07/memory-management-cron/</guid>
      <description>Create the memcheck.sh script that will write a mem.log file with the data, and agnuplot script that will plot it.
[gist id=1201994]
Then set up a cron job. First, set the editor to something functional:
export EDITOR=vi  then, crontab -e to edit the cron table. Add this line to run the command every 2 minutes (see wikipedia entry for quick intro), and plot it every 15 minutes:
*/2 * * * * /home/cboettig/.</description>
    </item>
    
    <item>
      <title>Wednesday</title>
      <link>/2011/09/07/wednesday-8/</link>
      <pubDate>Wed, 07 Sep 2011 12:30:39 +0000</pubDate>
      
      <guid>/2011/09/07/wednesday-8/</guid>
      <description>Alan Meeting Next steps directions
 economics of uncertainty in early warning
 simulated data approach - insect pest dynamics.
 cod data set. fisheries depensation
  Send Alan: Slides, CV (for post doc apps)
Discussed some relevant literature, mostly for the warning signals in fisheries questions: (Colchero &amp;amp; Clark, 2012), (Hutchings, 2000), HUTCHINGS &amp;amp; REYNOLDS, 2004, (Minckley et. al. 2012), (Myers et. al. 1995), (Schröder et. al. 2012)</description>
    </item>
    
    <item>
      <title>rfishbase demo: Are there more Goby or Labrid species on reefs?</title>
      <link>/2011/09/02/rfishbase-demo/</link>
      <pubDate>Fri, 02 Sep 2011 12:59:35 +0000</pubDate>
      
      <guid>/2011/09/02/rfishbase-demo/</guid>
      <description>I have updated the package to 0.0-3 alpha, having all the target functionality now. Improved error handling, downloading of data, processing. Get the source or windows binary here. I now download the full database and cache it locally for faster querying. Just about any kind of manipulation is then possible and fast.
For instance, here&amp;rsquo;s a quick demo based on a question from Peter Wainwright: &amp;ldquo;are there more gobys or labrids on reefs?</description>
    </item>
    
    <item>
      <title>Thursday Reading</title>
      <link>/2011/09/01/thursday-reading/</link>
      <pubDate>Thu, 01 Sep 2011 23:58:40 +0000</pubDate>
      
      <guid>/2011/09/01/thursday-reading/</guid>
      <description>Very interesting article on tipping points that seems to answer a question I put to Vasilis back in 2009 at IIASA: whether critical transitions due to bifurcations could be distinguished from stochastic transitions due to rare events Ditlevsen &amp;amp; Johnsen, 2010. Argues that some of the well-known climate transitions may have been stochastic transitions instead. Will need a closer read to better assess how they are distinguishing between such transitions in the data.</description>
    </item>
    
    <item>
      <title>Wednesday</title>
      <link>/2011/08/31/wednesday-7/</link>
      <pubDate>Wed, 31 Aug 2011 12:09:29 +0000</pubDate>
      
      <guid>/2011/08/31/wednesday-7/</guid>
      <description>Reading Wait, the storage effect is often evolutionarily unstable? Yikes. (Snyder &amp;amp; Adler, 2011). Will have to read this more closely.
 Vasseur &amp;amp; Fox nice AD paper in PNAS Am Nat (Vasseur &amp;amp; Fox, 2011), ((One day Am Nat will finish registering the doi for these papers?))   Contrary to previous verbal arguments that suggest that character convergence leads to neutral stability, coadaptation of competing consumers always leads to stable coexistence.</description>
    </item>
    
    <item>
      <title>Tuesday</title>
      <link>/2011/08/30/tuesday-8/</link>
      <pubDate>Tue, 30 Aug 2011 22:11:23 +0000</pubDate>
      
      <guid>/2011/08/30/tuesday-8/</guid>
      <description> Completed review for Methods.
 First read-through of review/resubmission for THEE.
 Working on Evolution manuscript
 Wrightscape: root should have the option of being fixed at phylogenetic mean for all models. Do root estimates occur far from this currently?
 Check graph color schemes, seem inconsistent.
   </description>
    </item>
    
    <item>
      <title>Algorithms group: Hidden Markov Models</title>
      <link>/2011/08/29/algorithms-group-hidden-markov-models/</link>
      <pubDate>Mon, 29 Aug 2011 21:43:42 +0000</pubDate>
      
      <guid>/2011/08/29/algorithms-group-hidden-markov-models/</guid>
      <description>Great group discussion on Hidden Markov Models tag-teamed by Yaniv and Alisa. Walked through the coin flip example, creating the forward algorithm, and the posterior decoding. In this case it is assumed model and parameters are known: two coins, known ratios, known rate of swapping; goal is to guess which coin is being used in a given interval. Algorithm does quite well, as shown in Yaniv&amp;rsquo;s awesome graph.
As usual in the notebook, click on the graph to get link-through to the code.</description>
    </item>
    
    <item>
      <title>Monday: scaling wrightscape examples</title>
      <link>/2011/08/29/monday-scaling-wrightscape-examples/</link>
      <pubDate>Mon, 29 Aug 2011 18:27:20 +0000</pubDate>
      
      <guid>/2011/08/29/monday-scaling-wrightscape-examples/</guid>
      <description>syntaxHighligher isn&amp;rsquo;t working. no idea why, posted to forums.
 Still no luck compiling gsl on carver. Can&amp;rsquo;t install gsl R package or compile wrightscape C code. posted C issue to NERSC, R issue to statscicomp.
   Commits to taxize pushed to Scott.
wrightscape parrotfish example Convergence test: with simple (common) initial values (alpha=.1, sigma=1), the different methods behave mostly appropriately: outer nested models out-perform inner ones, and likelihoods roughly agree between ouch package methods and wrightscape equivalents:</description>
    </item>
    
    <item>
      <title>Sunday: scaling, runs</title>
      <link>/2011/08/28/sunday-scaling-runs/</link>
      <pubDate>Sun, 28 Aug 2011 22:33:59 +0000</pubDate>
      
      <guid>/2011/08/28/sunday-scaling-runs/</guid>
      <description>laptop: ubuntu upgrades: 10.04 LTS -&amp;gt; 10.10 -&amp;gt; 11.04, geesh.
Set up for running primates.R in likelihood mode with abstracted parallelization:
Carver trouble getting wrightscape installed: even after module load gsl, cannot find gsl library. Testing on zero in mpi mode, 16. Testing on farm, mpi mode with snow, 16 cores.
hmm, high (9%) memory usage on primates.R on zero&amp;hellip; monitoring situation closely&amp;hellip; Only .3% on farm so far, which has 24G instead of zero&amp;rsquo;s 32Gig RAM.</description>
    </item>
    
    <item>
      <title>Saturday: working on computational scaling, ion, etc</title>
      <link>/2011/08/27/saturday-working-on-computational-scaling-abstraction-etc/</link>
      <pubDate>Sat, 27 Aug 2011 23:44:09 +0000</pubDate>
      
      <guid>/2011/08/27/saturday-working-on-computational-scaling-abstraction-etc/</guid>
      <description>Can I get a generic montecarlotest function working for both warningsignals and pmc?
Needs to be able to handle S4 classes as well as S3 classes, or need to define the methods update, simulate, loglik and getParameters for any object that would use the method. i.e. these need to be defined in warningsignals for its functions and in wrightscape/pmc for its creatures. then the generic can be used. Implementing now&amp;hellip; Completed.</description>
    </item>
    
    <item>
      <title>rropensci and some taxonomy in R with taxize</title>
      <link>/2011/08/26/rfishbase-and-some-taxonomy-in-r-with-taxize/</link>
      <pubDate>Fri, 26 Aug 2011 23:16:22 +0000</pubDate>
      
      <guid>/2011/08/26/rfishbase-and-some-taxonomy-in-r-with-taxize/</guid>
      <description>rfishbase Went through demo of rfishbase with Tomomi. Improved error handling, added a few data types and a few use cases.
I always forget that I have to drop nulls by indexing, not my return values of sapply.
x[!sapply(x, is.null)]  Very annoyed with fishbase id numbers (being discontinuous listings and unable to query xml by anything more intelligent). Querying all fishbase ids 1:30000, I get only 999 fish. hmm.</description>
    </item>
    
    <item>
      <title>FishBASE from R: some XML parsing</title>
      <link>/2011/08/26/fishbase-from-r-some-xml-parsing/</link>
      <pubDate>Fri, 26 Aug 2011 10:51:29 +0000</pubDate>
      
      <guid>/2011/08/26/fishbase-from-r-some-xml-parsing/</guid>
      <description>cross-posted from Wainwright Lab blog, archiving in the notebook here. This early tutorial includes some background on XML parsing from R using XPath. See the later rfishbase tutorial for more functionality.
In lab known for its quality data collection, high-speed video style, writing the weekly blog post can be a bit of a challenge for the local code monkey. That&amp;rsquo;s right, no videos today. But lucky for me, even this group can still make good use of publicly available data.</description>
    </item>
    
    <item>
      <title>DataCite Day 2</title>
      <link>/2011/08/25/datacite-day-2/</link>
      <pubDate>Thu, 25 Aug 2011 08:14:58 +0000</pubDate>
      
      <guid>/2011/08/25/datacite-day-2/</guid>
      <description>9:00am-10:30am Session 4: Data and the Scholarly Output  MacKenzie Smith, Research Director, MIT Libraries. Orcid: the Open Researcher and Contributor ID Registry. (slides)
 Greg Janee, Digital Library Research Specialist, Earth Research Institute, University of California, Santa Barbara. Earth Science Data:Second-Class Citizen in the Scholarly Record.
  see great example of the ACRID database
 Dr. Micah Altman, Archival Director, Henry A. Murray Research Archive, Senior Research Scientist, Harvard University.</description>
    </item>
    
    <item>
      <title>DataCite Day 1</title>
      <link>/2011/08/24/datacite-day-1/</link>
      <pubDate>Wed, 24 Aug 2011 08:10:51 +0000</pubDate>
      
      <guid>/2011/08/24/datacite-day-1/</guid>
      <description>12:00pm-1:00pm Lunch
 1:15pm-2:00pm Keynote Address: John Wilbanks, Vice President for Science, Creative Commons. Citation in the Commons. (Slides)    Find -&amp;gt; access -&amp;gt; understand -&amp;gt; be influenced -&amp;gt; cite.
Lesson of the Library of Babel, Early Web (Greenspun, 1995) Simple and weak is best &amp;ndash; scalable. (Rule of least power).
 2:00pm-3:30pm Session 1: Exposing Dataset DOIs and Citations
 Heather Piwowar, DataONE Postdoctoral Researcher, NESCent and Dryad.</description>
    </item>
    
    <item>
      <title>Tuesday: rropensci, Rmpi, manuscripts, ...</title>
      <link>/2011/08/23/tuesday-rfishbase-rmpi-manuscripts/</link>
      <pubDate>Tue, 23 Aug 2011 15:10:24 +0000</pubDate>
      
      <guid>/2011/08/23/tuesday-rfishbase-rmpi-manuscripts/</guid>
      <description>rfishbase In answer to Tomomi&amp;rsquo;s question from last week, have basic functionality as an R package on github, rfishbase. Learned some slightly richer XML parsing in the process.
XML Notes Had to identify blocks by a child node that specifies the identity, and then find the sibling node that contains the content I needed. Goes something like this:
&amp;lt;dataObject&amp;gt; &amp;lt;dc:identifier&amp;gt;FB-Size-2&amp;lt;/dc:identifier&amp;gt; &amp;lt;dc:description&amp;gt; Text I need &amp;lt;/dc:description&amp;gt; &amp;lt;/dataObject&amp;gt;  Which I parsed in R as:</description>
    </item>
    
    <item>
      <title>Academic Year 2011 Summary</title>
      <link>/2011/08/21/academic-year-2011-summary/</link>
      <pubDate>Sun, 21 Aug 2011 23:46:13 +0000</pubDate>
      
      <guid>/2011/08/21/academic-year-2011-summary/</guid>
      <description>Brief summary of events for this past academic year, as submitted to my dissertation committee.
TALKS  Model Choice for Phylogenetic Comparative Methods, Evolution 2010 Computational Methods for comparative inference (poster), DoE CSGF Meeting, 2010. My experiment with open notebook science, iEvoBio 2010 Power in Phylogenetic Comparative Methods, SICB 2011 Open Notebook Science - Connections to databases. Science Online, 2011 General model of evolution for continuous traits on phylogenies, Evolution 2011 Automated meta-analyses via an R - TreeBASE package, iEvoBio 2011 Early Warning Signals, ESA 2011.</description>
    </item>
    
    <item>
      <title>Thursday: reviewing edits, ropensci, computers.</title>
      <link>/2011/08/18/thursday-reviewing-edits-fishbase-computers/</link>
      <pubDate>Thu, 18 Aug 2011 15:03:16 +0000</pubDate>
      
      <guid>/2011/08/18/thursday-reviewing-edits-fishbase-computers/</guid>
      <description>Graham &amp;amp; Peter meeting Going over review and figuring out how to address issues. Plan: Will write our line-by-line responses under the reviewer comments in the Google Doc. Peter and I will implement remaining changes on the .tex file, then we&amp;rsquo;ll compose the reply letter from the notes under the comments and include the latex-diff.
Brief topic notes from today&amp;rsquo;s meeting:
 set up different take on layout: lambda, AIC, power</description>
    </item>
    
    <item>
      <title>Wednesday: migrating codes into MPI</title>
      <link>/2011/08/17/wednesday-migrating-codes-into-mpi/</link>
      <pubDate>Wed, 17 Aug 2011 22:53:33 +0000</pubDate>
      
      <guid>/2011/08/17/wednesday-migrating-codes-into-mpi/</guid>
      <description>Parellelization/Scaling of code MPI on farm cluster
Got my MPI codes running.
Much better way to get jobs into the queue, asking for 16 threads that don&amp;rsquo;t have to be on the same node is much faster. Can also ask for 161 threads, but will wait longer in the queue.
The trick to getting this to run was mostly getting the library set correctly. Setting the library path at the top of the script did the trick:</description>
    </item>
    
    <item>
      <title>Wrightscape: a brief tutorial</title>
      <link>/2011/08/17/wrightscape-a-brief-tutorial/</link>
      <pubDate>Wed, 17 Aug 2011 14:15:59 +0000</pubDate>
      
      <guid>/2011/08/17/wrightscape-a-brief-tutorial/</guid>
      <description>While the wrightscape package is still in active development, I realize the code base doesn&amp;rsquo;t contain any introductory examples. So as a first tutorial, here&amp;rsquo;s a short walk-through of the package. We begin by loading the package and a few useful additional packages:
require(wrightscape} # My package for this analysis require(auteur) # for the data only require(maticce) # to create paintings  We&amp;rsquo;ll load a data set of 233 taxa of primates with their body sizes(REDDING et.</description>
    </item>
    
    <item>
      <title>Tuesday:</title>
      <link>/2011/08/16/tuesday-7/</link>
      <pubDate>Tue, 16 Aug 2011 19:04:22 +0000</pubDate>
      
      <guid>/2011/08/16/tuesday-7/</guid>
      <description> Finished first round of edits and sent off to Graham and Peter.
 Exploring wrightscape runs on additional data sets
 Exploring migrating code into MPI
   </description>
    </item>
    
    <item>
      <title>Monday: Evolution manuscript revisions; early burst models, etc</title>
      <link>/2011/08/16/monday-evolution-manuscript-revisions-early-burst-models-etc/</link>
      <pubDate>Tue, 16 Aug 2011 12:13:46 +0000</pubDate>
      
      <guid>/2011/08/16/monday-evolution-manuscript-revisions-early-burst-models-etc/</guid>
      <description>Evolution Manuscript Edits Received the reviews of our evolution manuscript back with relatively straight-forward edits. (Yay!)
Need better citations of the early history in phylogenetic comparative methods, which is quite rich. Reviewer pointed me to an early book chapter by AW Edwards and LL Cavalli-Sforza introducing Brownian motion model in 1964, of which Joe Felsenstein has a nice description (of this and other work) in his 1988 review(Felsenstein, 1988).</description>
    </item>
    
    <item>
      <title>ESA personal notes: people, goals</title>
      <link>/2011/08/13/esa-personal-notes-people-goals/</link>
      <pubDate>Sat, 13 Aug 2011 19:22:27 +0000</pubDate>
      
      <guid>/2011/08/13/esa-personal-notes-people-goals/</guid>
      <description>Meetings  John Drake Suzanne O&amp;rsquo;Regan (Post-doc with John, strong dynamical systems) Justin Kinze &amp;ndash; great post-doc at Berkeley with John Harte, should visit. Paul Armsworth &amp;ndash; with Alan, have asked me to join NIMBioS working group on Pretty Darn Good Control (Tuesday evening). Hal Caswell &amp;ndash; interested in some of the data management / provenance for theoretical work. (Mon) Jeremy Fox &amp;ndash; Interesting lunch discussion, clonal interference as ecological insight?</description>
    </item>
    
    <item>
      <title>Saturday: Post ESA, NSF Intersections post-doc?</title>
      <link>/2011/08/13/saturday/</link>
      <pubDate>Sat, 13 Aug 2011 15:46:13 +0000</pubDate>
      
      <guid>/2011/08/13/saturday/</guid>
      <description>run system backup
 reading TOCs
 Catch up from ESA
 Working on review for THEE
 New phylogenetic methods in _Evolution _(Paradis, 2012), (Revell et. al. 2012)
 Next steps for fellowship applications.
   Post ESA  Theoretical Ecology Review
 Revisions on Evolution manuscript
 TreeBASE paper. See Kemp et. al. 2012
 outline next steps on warning signals
 wrightscape manuscript, finalize examples</description>
    </item>
    
    <item>
      <title>ESA Friday</title>
      <link>/2011/08/12/esa-friday/</link>
      <pubDate>Fri, 12 Aug 2011 18:34:47 +0000</pubDate>
      
      <guid>/2011/08/12/esa-friday/</guid>
      <description>Great last day of the conference, despite noticeably decreased attendance. Once again just pulling in my tweets, since I haven&amp;rsquo;t had a chance to transcribe proper notes. Meanwhile, some of the bloggers have done a rather nice day-to-day coverage; no idea how they all manage to keep up. Links below, with a nice mix of those targeting more theory oriented, more application oriented and more outreach oriented sessions.
Twitter-log    cboettig ESA should have science cafes!</description>
    </item>
    
    <item>
      <title>ESA Thursday</title>
      <link>/2011/08/11/esa-thursday/</link>
      <pubDate>Thu, 11 Aug 2011 18:43:02 +0000</pubDate>
      
      <guid>/2011/08/11/esa-thursday/</guid>
      <description>Just automatically generating a log form twitter since I cannot find the time to write proper notes. Perhaps those will amended eventually&amp;hellip;
Twitter-log    cboettig Predicting rare; predicting ubiquitous/noxious weed species by machine learning vs GLMs #esa11
   cboettig Beautiful thing when you know just how talk methods will proceed after 2 min of intro to problem.. but stay tuned for surprises #esa11
   cboettig Deitterich: how to reconstruct life history patterns from abundance fluctuations #esa11 inferring what we want from what we have w models</description>
    </item>
    
    <item>
      <title>ESA Wednesday</title>
      <link>/2011/08/10/esa-wednesday/</link>
      <pubDate>Wed, 10 Aug 2011 18:46:00 +0000</pubDate>
      
      <guid>/2011/08/10/esa-wednesday/</guid>
      <description>My talk today, as well as several others from our Theory group at Davis. Journal review requirements mean posting my slides is gonna be delayed somewhat, but appreciated some excellent questions and those who laughed at my jokes in between slides. Meanwhile, automatically generating a log form twitter since I cannot find the time to write proper notes. Perhaps those will amended eventually&amp;hellip;
Twitter-log    cboettig @carlystrasser Here&amp;rsquo;s the paper I mentioned for introducing ontologies/linked data into spreadsheetshttp://t.</description>
    </item>
    
    <item>
      <title>ESA Tuesday</title>
      <link>/2011/08/09/esa-tuesday/</link>
      <pubDate>Tue, 09 Aug 2011 18:48:44 +0000</pubDate>
      
      <guid>/2011/08/09/esa-tuesday/</guid>
      <description>Just automatically generating a log form twitter since I cannot find the time to write proper notes. Perhaps those will amended eventually&amp;hellip;
twitter-log    cboettig Great Eco Let mixer. Kudos to Marcel &amp;amp; crew for increasing citation rates w/o decreasing acceptance. Now how bout data sharing reqs? #esa11
   cboettig RT @IceAgeEcologist: #ESA11 Marten Scheffer gets Honorary Member Award (max 20 living awardees); Don Strong ge… (cont) http://deck.</description>
    </item>
    
    <item>
      <title>Monday: ESA Conference</title>
      <link>/2011/08/08/monday-esa-conference/</link>
      <pubDate>Mon, 08 Aug 2011 13:09:27 +0000</pubDate>
      
      <guid>/2011/08/08/monday-esa-conference/</guid>
      <description>Hope to process the day&amp;rsquo;s happenings later, meanwhile just a snapshot of my twitter-stream notes. My own highlights certainly include Steve Pacala&amp;rsquo;s fantastic plenary session in receiving the MacArthur award, and Mark Urban&amp;rsquo;s crystal clear presentation on &amp;ldquo;climate collisions.&amp;rdquo; I thought I was less tolerant of data-free models with arbitrary assumptions these days, but somehow Mark just swept those concerns away. In pointing out really fundamental concepts, such details just aren&amp;rsquo;t so important.</description>
    </item>
    
    <item>
      <title>Fisheries stock assessments for early warning</title>
      <link>/2011/08/02/fisheries-stock-assessments-for-early-warning/</link>
      <pubDate>Tue, 02 Aug 2011 16:59:14 +0000</pubDate>
      
      <guid>/2011/08/02/fisheries-stock-assessments-for-early-warning/</guid>
      <description>What you want to look for are stock assessments. For example, for the species closest to home, under the Pacific Fisheries Management Council:
http://www.pcouncil.org/groundfish/stock-assessments/archived-stock-assessments/
Three rockfish species that might be good to look into for your purposes are widow, yelloweye, and bocaccio, but these will have shorter-term data than any of the cod data. Also, NOAA NMFS Technical Reports on individual stocks often have long appendices with lots of data.</description>
    </item>
    
    <item>
      <title>Monday</title>
      <link>/2011/08/02/monday-8/</link>
      <pubDate>Tue, 02 Aug 2011 16:41:03 +0000</pubDate>
      
      <guid>/2011/08/02/monday-8/</guid>
      <description>Peter advice  Figure out your focus. Have all the stuff from your PhD published (at least submitted), make sure your post-doc moves forward. (#1 mistake). Publish with data folks to show you have much to offer the non-theorist community Speak to potential advisers, get them excited about the work. Berkeley over Michigan over NESCent/NIMBioS. Visit Berkeley. Ackerley on sabbatical?  Review for Theoretical Ecology Working on another review. Not a bad paper, but presenting many classical results as novel.</description>
    </item>
    
    <item>
      <title>Saturday: Fisheries Data Survey, Warning Signals</title>
      <link>/2011/07/30/saturday-fisheries-data-survey-warning-signals/</link>
      <pubDate>Sat, 30 Jul 2011 17:26:54 +0000</pubDate>
      
      <guid>/2011/07/30/saturday-fisheries-data-survey-warning-signals/</guid>
      <description>Marissa mentioned looking into some of the fisheries data for early warning signals: particularly the Canadian Cod collapse.
Apparently several of the data sets are problematic. All deal with catch instead of abundance and measurement error is highly significant, though it seems that some may suffer from more troublesome systematic errors. Taking a quick look over what is available. Lots of data, but despite what appears to be some rather sophisticated tools available on the sites, I&amp;rsquo;m having a bit of difficulty finding just what I&amp;rsquo;m looking for.</description>
    </item>
    
    <item>
      <title>Friday: ESA Practice Talk</title>
      <link>/2011/07/29/2268/</link>
      <pubDate>Fri, 29 Jul 2011 17:26:44 +0000</pubDate>
      
      <guid>/2011/07/29/2268/</guid>
      <description>Practice talk in Teary today; Jamie, Marissa and myself. Lots of discussion and feedback. Some good general discussion about presentations as well &amp;ndash; Marissa mentioned the Oceanographic Institute&amp;rsquo;s tips for speakers and other resources on her website. Brief notes on changes to make in my talk based on some excellent discussion:
 Julie and others point out I should at least reference Type I &amp;amp; Type II Error &amp;ndash; statement contrasting scientific hypothesis testing vs managing for collapse.</description>
    </item>
    
    <item>
      <title>Weds: Manuscript</title>
      <link>/2011/07/27/weds-manuscript/</link>
      <pubDate>Wed, 27 Jul 2011 22:38:55 +0000</pubDate>
      
      <guid>/2011/07/27/weds-manuscript/</guid>
      <description>I&amp;rsquo;ve removed the model choice/model adequacy section of the appendix. This is the section that Reviewer 2 said needed further development, which would be beyond the scope of this paper:
 Here the authors claim that by using particular structural models based on assumptions about underlying dynamics their method makes it easy to identify cases that do not conform to the assumptions. It would be interesting to evaluate this claim but it would require a substantial amount of analysis that may be beyond the scope of a short paper.</description>
    </item>
    
    <item>
      <title>Wednesday: ESA presentation, manuscript/appendix edits </title>
      <link>/2011/07/27/wednesday-esa-presentation-manuscriptappendix-edits/</link>
      <pubDate>Wed, 27 Jul 2011 16:22:02 +0000</pubDate>
      
      <guid>/2011/07/27/wednesday-esa-presentation-manuscriptappendix-edits/</guid>
      <description>Misc morning  Site trouble, again. requested migrating servers. Done. hope we&amp;rsquo;re more stable now. Checking in with Peter about migrating site domain. Sent request to Matt. Looking over NERSC PI application, see first allocation instructions. Emailed Mary Ann w/ questions on forms. SMB 2012 is at NIMBioS! Nick to join ropensci. Coordinating launch, advisers, etc. Karthik and Scott have done a great job editing my intro post and sprucing up the site.</description>
    </item>
    
    <item>
      <title>Tues: ESA presentation</title>
      <link>/2011/07/26/tues-esa-presentation/</link>
      <pubDate>Tue, 26 Jul 2011 13:24:34 +0000</pubDate>
      
      <guid>/2011/07/26/tues-esa-presentation/</guid>
      <description>Working on ESA presentation. See slides and code for details.
 Adding movie a time series which gets longer (and closer to collapse) each frame, with corresponding warning signals for the interval thus far shown below (for CV and autocorrelation). Include sparsely sampled (100) and densely sampled (1000) examples. Compare always using a sliding window-size equal to half the length of the available data (works well on longer time series) to a fixed-width sliding window (doesn&amp;rsquo;t work well ever).</description>
    </item>
    
    <item>
      <title>Monday: ESA, appendix, etc</title>
      <link>/2011/07/25/monday-esa/</link>
      <pubDate>Mon, 25 Jul 2011 23:22:37 +0000</pubDate>
      
      <guid>/2011/07/25/monday-esa/</guid>
      <description>Reading Gene expression as a continuous phenotypic trait &amp;ndash; establishing signal for selection over drift. (Bedford &amp;amp; Hartl, 2009) OU vs BM (or just estimation of selection in the OU model relative to tree length) would have been an obvious way to do this, but the paper tries to make the argument that scaling the data and then comparing
$$\frac{\sigma^2}{2\alpha} $$
is some indication.
Model choice section on warning signals Trying to figure out whether or not to remove this section (previously Appendix H: Model Choice and Model Adequacy).</description>
    </item>
    
    <item>
      <title>Monday: Algorithms Discussion Group, EM finished</title>
      <link>/2011/07/25/monday-algorithms-discussion-group-em-finished/</link>
      <pubDate>Mon, 25 Jul 2011 17:58:55 +0000</pubDate>
      
      <guid>/2011/07/25/monday-algorithms-discussion-group-em-finished/</guid>
      <description>Finished up the EM algorithm today. Key was getting the right function to maximize. Turns out wikipedia has a very nice write up of this very example, but in our notation:
$$ E_p \log(p f_1) + (1-E_p) \log( (1-p) f_2 )$$
Where $E_p$ comes from the expectation step.
Jamie has joined us and has set up a github repository for the discussion group. Find the successful abstract algorithm there.</description>
    </item>
    
    <item>
      <title>Sunday: Appendix edits</title>
      <link>/2011/07/24/sunday-appendix-edits/</link>
      <pubDate>Sun, 24 Jul 2011 16:47:15 +0000</pubDate>
      
      <guid>/2011/07/24/sunday-appendix-edits/</guid>
      <description>Appendix A. Method Summary &amp;ndash; Basically the &amp;ldquo;methods&amp;rdquo; section as we had it in the Nature version, a bit updated.
 These sections are as before, with minor updates from the reviewers, etc. They&amp;rsquo;re also probably the most important part:
 Appendix B. The data sets Appendix C. Model Derivations Appendix D. Likelihood calculations Appendix E. The likelihood statistic  Appendix F. The distributions for the ROC curves &amp;ndash; these are the former figure 1b/c distributions used to make the ROC curve.</description>
    </item>
    
    <item>
      <title>CSGF Conference Notes</title>
      <link>/2011/07/24/csgf-conference-notes/</link>
      <pubDate>Sun, 24 Jul 2011 14:30:43 +0000</pubDate>
      
      <guid>/2011/07/24/csgf-conference-notes/</guid>
      <description>Just returned from 5 days in Washington, DC for the annual computational science graduate fellowship conference. No live notes/tweets, so just attempting to synthesize some of the major ideas before I get back to paper writing. Most of the conference material, including workshop slides, are archived online.
The high performance computing workshop made two things clear to me &amp;ndash; a lot of parallel computing can be done without lots of communication between nodes (i.</description>
    </item>
    
    <item>
      <title>CSGF 2010 Computing Practices Survey Summary</title>
      <link>/2011/07/24/csgf-2010-computing-practices-survey-summary/</link>
      <pubDate>Sun, 24 Jul 2011 14:11:07 +0000</pubDate>
      
      <guid>/2011/07/24/csgf-2010-computing-practices-survey-summary/</guid>
      <description>Thanks to everyone who participated in the CSGF 2010 Survey.With too many things going on this year, I didn&amp;rsquo;t conduct a survey at the 2011 Conference. But as people were asking about the survey, I thought I could at least make last year&amp;rsquo;s summary a bit more accessible. The following comes from the pdf report I submitted to Krell and a few example figures from data.This year&amp;rsquo;s survey was longer and broader, recieving over 90 responses from fellows and alumni.</description>
    </item>
    
    <item>
      <title>Showcasing the latest phylogenetic methods: AUTEUR</title>
      <link>/2011/07/20/showcasing-the-latest-phylogenetic-methods-auteur/</link>
      <pubDate>Wed, 20 Jul 2011 15:07:14 +0000</pubDate>
      
      <guid>/2011/07/20/showcasing-the-latest-phylogenetic-methods-auteur/</guid>
      <description>While high-speed fish feeding videos may be the signature of the lab, dig a bit deeper and you&amp;rsquo;ll find a wealth of comparative phylogenetic methods sneaking in. It&amp;rsquo;s a natural union &amp;ndash; expert functional morphology is the key to good comparative methods, just as phylogenies hold the key to untangling the evolutionary origins of that morphology. The lab&amp;rsquo;s own former graduate, Brian O&amp;rsquo;Meara, made a revolutionary step forward in the land of phylogenetic methods when he unveiled Brownie in 2006, allowing researchers to identify major shifts in trait diversification rates across the tree.</description>
    </item>
    
    <item>
      <title>Sunday: Warning Signals</title>
      <link>/2011/07/17/sunday-warning-signals/</link>
      <pubDate>Sun, 17 Jul 2011 23:38:23 +0000</pubDate>
      
      <guid>/2011/07/17/sunday-warning-signals/</guid>
      <description>Continuing work on warning signals manuscript. Most entries for this work are delayed-release. Some final stages of editing today:
Data sets for appendix  deut1
 caco3
 Other datasets? other drake? other deut?
 launched drakeI9 on farm c0-2 by ssh.
 launched ibm_stable on farm c0-1.
 launched deut2_analysis on farm c0-3, failed. needs better initial conditions to run
  Main paper fix plots: Figure 4 needs axis labels &amp;ndash; done.</description>
    </item>
    
    <item>
      <title>Saturday - back to Warning Signals MS</title>
      <link>/2011/07/17/saturday-back-to-warning-signals-ms/</link>
      <pubDate>Sun, 17 Jul 2011 10:59:43 +0000</pubDate>
      
      <guid>/2011/07/17/saturday-back-to-warning-signals-ms/</guid>
      <description>New outline   &amp;rdquo;An increasing recognition&amp;rdquo;  &amp;ldquo;proof-of-principle&amp;rdquo; - reliability is unknown  &amp;ldquo;Cries wolf&amp;rdquo;  ROC, Fig 1  tau  method  data, Fig 2  analysis, Fig 3  enough data Fig 4  disclaimer  conclusion  Former Outline  Early Warning matter, no-one does statistics We need quantify uncertainty stats ROC curve shows this trade-off ROC also compares different methods &amp;amp; data sizes (i.</description>
    </item>
    
    <item>
      <title>The Case for Better Data Citation Practices?</title>
      <link>/2011/07/14/the-case-for-better-data-citation-practices/</link>
      <pubDate>Thu, 14 Jul 2011 09:34:31 +0000</pubDate>
      
      <guid>/2011/07/14/the-case-for-better-data-citation-practices/</guid>
      <description>An excellent question came up on ecoinformatics list today on data citation from Kyle Kwaiser at the Michigan Biological Station
 I am working with graduate students this summer to archive their work at our field station. I want to tell them to cite their datasets on their CV&amp;rsquo;s but I know this is not yet the norm.
 Any general thoughts on how close we are to including datasets on CV&amp;rsquo;s?</description>
    </item>
    
    <item>
      <title>UC Davis Student Assembled Panel on Data Management Issues</title>
      <link>/2011/07/13/uc-davis-student-assembled-panel-on-data-management-issues/</link>
      <pubDate>Wed, 13 Jul 2011 17:47:41 +0000</pubDate>
      
      <guid>/2011/07/13/uc-davis-student-assembled-panel-on-data-management-issues/</guid>
      <description>Panel Members (listed left to right)
 Paul Gepts: UC Davis Professor of Plant Science: evolution of plants on domestication.
 Mario Biagioli: Professor of Law in Science and Technology, Director of Science and Innovation, formerly Professor of History of Science at Harvard; written extensively on the role of secrecy in science.
 John Kunze: Preservation Technologist and Ass. Director of California Digital Library.
 Phoebe Ayers: UC Davis Librarian, Wikimedia Foundation Board of Trustees.</description>
    </item>
    
    <item>
      <title>141 scientists can&#39;t be wrong?</title>
      <link>/2011/07/08/141-scientists-cant-be-wrong/</link>
      <pubDate>Fri, 08 Jul 2011 13:18:10 +0000</pubDate>
      
      <guid>/2011/07/08/141-scientists-cant-be-wrong/</guid>
      <description>Turning the author-list into a petition is becoming an almost familiar ruse in the table of contents of journals such as Nature (Simberloff, 2011), (Abbot et. al. 2011). This as prompted some rather provocative commentary on whether we have begun conducting scientific debates as popularity contests rather than arguments of evidence and logic (see David Sloan Wilson on inclusive fitness theory 137 scientists can&amp;rsquo;t be wrong, or Chris on invasive species on ecolog.</description>
    </item>
    
    <item>
      <title>Friday: writing post-doc applications</title>
      <link>/2011/07/08/friday-writing-post-doc-applications/</link>
      <pubDate>Fri, 08 Jul 2011 11:17:06 +0000</pubDate>
      
      <guid>/2011/07/08/friday-writing-post-doc-applications/</guid>
      <description>Today looks like mostly writing post-doc applications, research statements etc. Planning to finish in a year, amazing how many of these are due quite soon. Somehow this reflective process prompted me to take a look at how Google sees me; through the lens of search terms landing on my website. Here they are from the past month, in wordle form:</description>
    </item>
    
    <item>
      <title>Thursday: sending off paper draft, starting applications</title>
      <link>/2011/07/07/thursday-8/</link>
      <pubDate>Thu, 07 Jul 2011 19:48:32 +0000</pubDate>
      
      <guid>/2011/07/07/thursday-8/</guid>
      <description>Add re-sampling blurb to appendix. Done
 Read over manuscript &amp;amp; send to Marissa and Marcel. Done
 Now to spend today working on fellowship applications: research statement and proposal&amp;hellip;
   Appendix edits  Add distributions to the appendix.
 Show where where the data actually fall in the distribution, as would be used in traditional hypothesis testing framework.
 Add extra examples to the appendix.</description>
    </item>
    
    <item>
      <title>Segue: Easy cloud hpc in R, now with custom packages</title>
      <link>/2011/07/07/segue-easy-cloud-computing-in-r-now-with-custom-packages/</link>
      <pubDate>Thu, 07 Jul 2011 16:45:05 +0000</pubDate>
      
      <guid>/2011/07/07/segue-easy-cloud-computing-in-r-now-with-custom-packages/</guid>
      <description>After a few helpful emails from package creator JD Long, I have the segue package running with custom R packages. The package is available on Google code. With two lines of code I can start submitting jobs to very large clusters of computers on the Amazon cloud. For a basic introduction to the package see Jeff Breen&amp;rsquo;s post.
Quick notes on updating using mercurial: Since I&amp;rsquo;ve already pulled the code using</description>
    </item>
    
    <item>
      <title>Early warning signals presentation notes</title>
      <link>/2011/07/07/early-warning-signals-presentation-notes/</link>
      <pubDate>Thu, 07 Jul 2011 16:40:06 +0000</pubDate>
      
      <guid>/2011/07/07/early-warning-signals-presentation-notes/</guid>
      <description> motivate story of fisheries management.
 Step advance a time series of fluctuations. Shows a gradual decline and eventually sudden crash. Predict when we crash? Introduce indicators. Advance a different time series, this time displaying summary statistics as we go. Have audience make prediction whether next step will be collapse. Present summary statistics with uncertainty included. (color code confidence?)  </description>
    </item>
    
    <item>
      <title>Exact Simulation by the Gillespie Algorithm</title>
      <link>/2011/07/06/exact-simulation-by-the-gillespie-algorithm/</link>
      <pubDate>Wed, 06 Jul 2011 18:00:58 +0000</pubDate>
      
      <guid>/2011/07/06/exact-simulation-by-the-gillespie-algorithm/</guid>
      <description>The Gillespie algorithm has two parts: (1) determine what event happens, (2) determine when it happens. Consider the system of equations $$ \dot X_i = f_i(\vec X) $$
where the $f_i$ give the rates of creation and annihilation (negative and postive parts of $f_i(\vec X)$ must be listed seperately) for all species $x_i$. We assume this gives the mean rate at which each event occurs, drawn from on exponential distribution. We could simply draw the associated random exponential time for each reaction, and pick the minimum for which event occurs.</description>
    </item>
    
    <item>
      <title>Wednesday: Data wrangling into graphs</title>
      <link>/2011/07/06/wednesday-6/</link>
      <pubDate>Wed, 06 Jul 2011 14:34:37 +0000</pubDate>
      
      <guid>/2011/07/06/wednesday-6/</guid>
      <description>Really high sampling runs (20000 pts) still don&amp;rsquo;t seem to show any improvement in deut3 dataset summary statistics, perhaps it is the window size. testing by launching deut_replot.R, n5 on zero, 500, 1000, 2000 on a fixed windowsize of 60, see how it compares to the half window. probably because is such a weak signal.
running drake tau sampling with corrected (1&amp;frasl;2 length) windowsizes. &amp;ndash; destroys any improvement in indicators:</description>
    </item>
    
    <item>
      <title>Tuesday: Warning Signals Data Wrangling</title>
      <link>/2011/07/05/tuesday-6/</link>
      <pubDate>Tue, 05 Jul 2011 17:45:53 +0000</pubDate>
      
      <guid>/2011/07/05/tuesday-6/</guid>
      <description>Revise abstract. 10a-11a. done.  Misc data handling 11-1pm
 wrote a file to fix flickr data file names that are occasionally mangled by parallel loop printing. wrote a file to plot $m T$ values on each dataset to get a sense of which have the most dramatic warning signals. running on one.   locale troubles on install lead to errors in data read  Error in make.</description>
    </item>
    
    <item>
      <title>Open F1000 reviews?</title>
      <link>/2011/07/04/open-f1000-reviews/</link>
      <pubDate>Mon, 04 Jul 2011 22:53:43 +0000</pubDate>
      
      <guid>/2011/07/04/open-f1000-reviews/</guid>
      <description>Sebastian has started posting article reviews on his website, and invites us (Teary - our theoretical ecology tea mailing list) to do likewise. He uses a rather nifty Jabref converter to display the reviews created as bibtex entries, using the format indicated below.
These reviews are cross-posted from the reviews he (and associates) submit to Faculty of 1000, a commercial, subscription-based service. While this gives F1000 some publicity directly from his own site, it also means individuals can access these reviews freely.</description>
    </item>
    
    <item>
      <title>Warning Signals writing, organization, appendices</title>
      <link>/2011/07/04/warning-signals-writing-organization-appendices/</link>
      <pubDate>Mon, 04 Jul 2011 19:03:32 +0000</pubDate>
      
      <guid>/2011/07/04/warning-signals-writing-organization-appendices/</guid>
      <description>main text Summary Sentence. Abstract
Paragraphs  Early Warning matter, no-one does statistics We need quantify uncertainty stats ROC curve shows this trade-off ROC also compares different methods &amp;amp; data sizes (i.e. Fig 4) Quantifying &amp;ldquo;increasing variance&amp;rdquo; etc &amp;ndash; we&amp;rsquo;ll use tau We&amp;rsquo;ll also do a likelihood-based method Introduce the datasets ROC curves on the data, Fig 3 Quantifying data necessary, Fig 4 Disclaimers: Not completely general Conclusion  Supporting Online Material Original Appendix had:</description>
    </item>
    
    <item>
      <title>Friday, warning signals writing, etc</title>
      <link>/2011/07/01/friday-warning-signals-writing-etc/</link>
      <pubDate>Fri, 01 Jul 2011 17:57:59 +0000</pubDate>
      
      <guid>/2011/07/01/friday-warning-signals-writing-etc/</guid>
      <description>9-10a email, etc 10 am check simulations: Daphnia examples (Drake data) runs done. A few examples, see neighboring plots in image database for the corresponding distributions and further examples. Runtime of this code (click images for script) about 10 hours on 16 cores on zero.
   launched ibm_analysis.R on zero, n10.
 Writing writing&amp;hellip; first full text draft done.
  Trying to get started on the centos cluster, some trouble submitting job to queue, see email discussion with Bill.</description>
    </item>
    
    <item>
      <title>Thursday: Warning Signals writing, figures, segue</title>
      <link>/2011/06/30/thursday-7/</link>
      <pubDate>Thu, 30 Jun 2011 10:13:52 +0000</pubDate>
      
      <guid>/2011/06/30/thursday-7/</guid>
      <description>Alan meeting Figure 1: Introducing the ROC Curve Figure 2: Standard approach Figure 3: ROC curves corresponding to standard approach Do we show the distributions? &amp;ndash; Create for each, but log in appendix
ROC curves corresponding to increased sampling &amp;ndash; our method, other stats? organize how?
Computational Runs Running at constant sample points rather than sample effort.
 On eleven: n5ibm_stable.R 6pm On zero, n10 drake_analysis.R 6pm On zero, n19 deut_analysis.</description>
    </item>
    
    <item>
      <title>Warning signals: summary statistic performance at varying sampling effort</title>
      <link>/2011/06/29/warning-signals-summary-statistic-performance-at-varying-sampling-effort/</link>
      <pubDate>Wed, 29 Jun 2011 22:08:01 +0000</pubDate>
      
      <guid>/2011/06/29/warning-signals-summary-statistic-performance-at-varying-sampling-effort/</guid>
      <description>oikos post launch case of increased sampling on sim data for autocorrelation (is our approach more robust to model differences?)  IBM data Example Using data from the individual-based model simulation of a system approaching a saddle-node.
Variance While the initial example with variance shows almost no signal, increasing the sampling effort substantially improves the performance. This can be seen in the ROC curves and as a tightening and spreading out of the null and test distributions as the sampling effort is increased.</description>
    </item>
    
    <item>
      <title>Warning Signals writing</title>
      <link>/2011/06/29/warning-signals-writing/</link>
      <pubDate>Wed, 29 Jun 2011 18:35:18 +0000</pubDate>
      
      <guid>/2011/06/29/warning-signals-writing/</guid>
      <description> Alan Meeting: Discussed yesterday&amp;rsquo;s possible representations, post-doc considerations.
Misc &amp;amp; Reading  Catching up on ToCs, now 13 papers to review Installing pilot mx database for comparative methods data accessible semantic web introduction Dean&amp;rsquo;s Lab statement of mutual expectations: nice guide for things that are too rarely spelled out.  </description>
    </item>
    
    <item>
      <title>Monday: Warning Signals Manuscript</title>
      <link>/2011/06/27/monday-warning-signals-manuscript/</link>
      <pubDate>Mon, 27 Jun 2011 12:33:21 +0000</pubDate>
      
      <guid>/2011/06/27/monday-warning-signals-manuscript/</guid>
      <description>Looking at ways to visually explain receiver-operator characteristic (ROC) curves. Should probably be done in a way that maps the curves to the points along the curve. May make a nice graphic but perhaps unnecessary.
Perhaps simpler to present as single panel Integrating the test distribution to the left instead of the right gives the error rate (Type I/Type II errors, False Alarms/Missed Events):
Analyses  Maximization algorithm failing at initial conditions on deut2</description>
    </item>
    
    <item>
      <title>#ievobio Day 2</title>
      <link>/2011/06/22/ievobio-day-2/</link>
      <pubDate>Wed, 22 Jun 2011 23:44:58 +0000</pubDate>
      
      <guid>/2011/06/22/ievobio-day-2/</guid>
      <description>Day 2 is every bit as packed as day 1, and then some do to the higher concentration of lightning talks. Other coverage of #ievobio is starting to find it&amp;rsquo;s way to the web:
 Nico Cellinese
 Scott Chamberlain
 Rob Guralnick
  Meanwhile, my scratchpad of notes from day 2, tweet-style.
My Lightning Talk Gave my lightning talk in this session, slides:
R interface to TreeBASE</description>
    </item>
    
    <item>
      <title>Evolution Day 4 / #ievobio Day 1</title>
      <link>/2011/06/21/evolution-day-4-ievobio-day-1/</link>
      <pubDate>Tue, 21 Jun 2011 23:44:26 +0000</pubDate>
      
      <guid>/2011/06/21/evolution-day-4-ievobio-day-1/</guid>
      <description>Start of the ievobio conference, simultaneously the forth day of evolution. ievobio conference was very busy, luckily given the nature of the conference it is also largely well documented online. My notes are again archived primarily in tweet form below. My personal highlights of the day included the Keynote by Cladio Silva on Provenance &amp;ndash; essentially supporting reproducible research workflows &amp;ndash; and examples through his vistrails software, and Mark Yoder&amp;rsquo;s demonstration of mx at the software bazaar.</description>
    </item>
    
    <item>
      <title>Evolution Day 3</title>
      <link>/2011/06/20/evolution-day-3/</link>
      <pubDate>Mon, 20 Jun 2011 23:44:25 +0000</pubDate>
      
      <guid>/2011/06/20/evolution-day-3/</guid>
      <description>Talks  David Babst: Patterns of diversification on large species level supertree of extinct graptolites &amp;ndash; Actually, more on methods for making such a supertree for extinct taxa than on diversification analysis, but excellent talk.
 Gene Hunt: _Using fossils to test the link between speciation and phenotypic evolution &amp;ndash; _another highlight of the talks, really looking at cladeogeneic vs anaogenic models of evolutionary change, modifying the approach of Folmer Bokma</description>
    </item>
    
    <item>
      <title>Slides from my talk at Evolution 2011</title>
      <link>/2011/06/20/slides-from-my-talk-at-evolution-2011/</link>
      <pubDate>Mon, 20 Jun 2011 20:59:59 +0000</pubDate>
      
      <guid>/2011/06/20/slides-from-my-talk-at-evolution-2011/</guid>
      <description>A general model of continuous character evolution [iframe http://www.slideshare.net/slideshow/embed_code/8371419 425 355]
View more presentations from Carl Boettiger
As highlighted in the last slide (following acknowledgments), clicking on the results graphs will take you to the image repository, which records when the result was generated in my workstream, and provides a link to the script, software package and data to replicate. Code is parallel, examples shown took between 2 and 12 hours on a 16-core cpu.</description>
    </item>
    
    <item>
      <title>Evolution Day 2</title>
      <link>/2011/06/19/evolution-day-2/</link>
      <pubDate>Sun, 19 Jun 2011 23:44:20 +0000</pubDate>
      
      <guid>/2011/06/19/evolution-day-2/</guid>
      <description>Second day of the conference. Many of the talks I most want to see are coming up Monday and Tuesday, and I have a bit more to do to prepare my own talk, so I take it a bit light on sessions. Highlight of the day was definitely the discussion with Mark McPeek and the other journal editors during and following the &amp;ldquo;Happy hour with the editors&amp;rdquo; session, which was perhaps the best event of the conference, despite a rather unimpressive attendance.</description>
    </item>
    
    <item>
      <title>Evolution Conference Day 1</title>
      <link>/2011/06/18/evolution-conference-day-1/</link>
      <pubDate>Sat, 18 Jun 2011 21:34:01 +0000</pubDate>
      
      <guid>/2011/06/18/evolution-conference-day-1/</guid>
      <description>Morning Sessions SSB Symposium 8:30 - noon: Unified Approaches for Understanding Patterns of Character Evolution and Diversification  Stacey Smith (U. of Nebraska-Lincoln) and Boris Igic (U.of Illinois-Chicago) - &amp;ldquo;Introduction to models of character state-dependent diversification&amp;rdquo;  Introduces the BiSSE model.
 Richard Fitzjohn (U. of British Columbia) - &amp;ldquo;Stochastic mapping incorporating differential diversification&amp;rdquo;  BiSSE comparison to traditional discrete-trait transition rate which ignores the correlation.
 Folmer Bokma (Umeå University) - &amp;ldquo;Estimating speciation and extinction with incomplete phylogenies&amp;rdquo;   Emma Goldberg (University of Illinois-Chicago) - &amp;ldquo;Modes of speciation and character change from phylogenetic trees&amp;rdquo;</description>
    </item>
    
    <item>
      <title>Friday: more labrid &amp; parrotfish wrightscape examples</title>
      <link>/2011/06/17/friday-more-labrid-parrotfish-wrightscape-examples/</link>
      <pubDate>Fri, 17 Jun 2011 15:16:32 +0000</pubDate>
      
      <guid>/2011/06/17/friday-more-labrid-parrotfish-wrightscape-examples/</guid>
      <description>Runs from yesterday: MLE comparison of full labrid pharyngeal innovation (all parrotfish), alpha-v-sigma: Unfortunately, the all-variable mcmc over labrid tree was unsuccessful.
Pure-brownie vs pure diversification ends up with the surprisingly opposite conclusion from the sigmas-alphas on parrotfish close ratio:
Clearly a convergence problem but with which model? (see parameter distributions adjacent; following in photostream archive).
Luckily this is not the case in the full labrid (size-corrected, protrusion, pharyngeal innovation) model set:</description>
    </item>
    
    <item>
      <title>Wrightscape labrid/parrotfish results; Evolution pres</title>
      <link>/2011/06/16/wrightscape-labridparrotfish-results-evolution-pres/</link>
      <pubDate>Thu, 16 Jun 2011 22:14:58 +0000</pubDate>
      
      <guid>/2011/06/16/wrightscape-labridparrotfish-results-evolution-pres/</guid>
      <description>Analysis Summarizing recently completed runs:  Reviewing last night&amp;rsquo;s runs. Some mcmcs complete:  Labrid prot.y alpha  and some crashed mcmc&amp;rsquo;s on Zero launched Tuesday night. (gape.y, close, open don&amp;rsquo;t seem to want to run)
 the sigma-theta Vs alpha-theta on parrotfish (size-corrected) protrusion (over intramandibular innovation), which looks indistinguishable:
  sigma-theta vs alpha-theta, parrotfish prot.y alpha v sigma also indistinguishable on this data, see yesterday.
Closing, alpha vs sigma, parrotfish (intramandibular, 200 reps) Alpha Sigma Comparison Would like nicer with more replicates, but clearly distinguishable, as were yesterday&amp;rsquo;s when theta could also vary.</description>
    </item>
    
    <item>
      <title>Wednesday MCMC and MLEs for wrightscape</title>
      <link>/2011/06/15/wednesday-mcmc-and-mles-for-wrightscape/</link>
      <pubDate>Wed, 15 Jun 2011 22:36:07 +0000</pubDate>
      
      <guid>/2011/06/15/wednesday-mcmc-and-mles-for-wrightscape/</guid>
      <description>Wrote plotting function for wrightscape MCMC analysis
 added support to write MCMC to a file.
 exploring divergent MCMCs. more checks on NaNs
 trying MLE initiated MCMC
 Revising talk for evolution
 tweaks to socialR reporting &amp;ndash; include error message, exit with status=1, fewer time sigfigs; see gitlog.
   Max likelihoods &amp;amp; bootstraps Parrotfish protrusion (size corrected, 400 reps) If thetas are different and not allowed to vary, the alpha model will obviously do worse than the sigma model, even if it is correct.</description>
    </item>
    
    <item>
      <title>Tuesday - Evolution/wrightscape talk &amp; sundry</title>
      <link>/2011/06/14/tuesday-evolutionwrightscape-talk-sundry/</link>
      <pubDate>Tue, 14 Jun 2011 23:29:48 +0000</pubDate>
      
      <guid>/2011/06/14/tuesday-evolutionwrightscape-talk-sundry/</guid>
      <description>Computing For today&amp;rsquo;s analyses run history (with result/code links): see tweeting_cpu account or its search history (from Topsy)
Analysis/Summary MCMC over parrotfish tree on protrusion doesn&amp;rsquo;t converge when alpha and sigma are both free to vary.
MLE approach, (size-corrected) protrusion (12hr run)
Vary both theta and sigma:
Vary alpha and theta:
alpha-theta wins over theta-sigma:
git ids/urls git codes must be obtained at start of run, together with commit, or link will point to the wrong code!</description>
    </item>
    
    <item>
      <title>EM Algorithm</title>
      <link>/2011/06/13/em-algorithm-2/</link>
      <pubDate>Mon, 13 Jun 2011 22:39:32 +0000</pubDate>
      
      <guid>/2011/06/13/em-algorithm-2/</guid>
      <description>Yaniv ran us through our second session on EM algorithms. We implemented a simple case described in this tutorial.
[gist id=1028113]
Code doesn&amp;rsquo;t reflect the abstraction of the algorithm into a proper Expectation step and Maximization step. We attempted this generalization:
[gist id=1028122]
Missed something in framing this correctly, since the maximization step includes a function that doesn&amp;rsquo;t depend on s[1]. Any ideas?</description>
    </item>
    
    <item>
      <title>Monday -</title>
      <link>/2011/06/13/monday-7/</link>
      <pubDate>Mon, 13 Jun 2011 13:06:51 +0000</pubDate>
      
      <guid>/2011/06/13/monday-7/</guid>
      <description> Algorithms group meeting Evolution presentation warningsignals runs complete and troubleshooting finalizing power in phylogenies manuscript cover letter, supplement, final check through, etc.  </description>
    </item>
    
    <item>
      <title>Sunday</title>
      <link>/2011/06/12/sunday-3/</link>
      <pubDate>Sun, 12 Jun 2011 23:03:33 +0000</pubDate>
      
      <guid>/2011/06/12/sunday-3/</guid>
      <description> SocialR updates: print runtime, handle NULL mentions, and truncate messages to avoid over-length errors.
 Rmendeley repackage in response to user issue. Updated issues list.
 _warningsignals: _Separate demo scripts for each data set, running analysis now
 reversed nboot and cpu values, way to create very annoying error. Back up and running all demo scripts now.
   </description>
    </item>
    
    <item>
      <title>Friday</title>
      <link>/2011/06/10/friday-6/</link>
      <pubDate>Fri, 10 Jun 2011 17:21:03 +0000</pubDate>
      
      <guid>/2011/06/10/friday-6/</guid>
      <description>Finish updates to socialR and wrote post.
 reply to Richard on DataONE workflow internship
 really should meet Bertram, re: workflow, dataONE, open science, etc.
 wrote an avereps fn to replace limma dependency. hmmf.
 setup analysis.R to run complete analysis sets. still testing.
   To Do  consider returning myCall information on most standard functions
 Review model implementations
 model convergence error handling.</description>
    </item>
    
    <item>
      <title>Workflows that Work: making it &#34;easy enough&#34;</title>
      <link>/2011/06/10/workflows-that-work-making-it-easy-enough/</link>
      <pubDate>Fri, 10 Jun 2011 13:31:07 +0000</pubDate>
      
      <guid>/2011/06/10/workflows-that-work-making-it-easy-enough/</guid>
      <description>I thought I had already fixed this problem. I thought I already had a way to recover the code and parameter values of figures saved in my image log. Grab the SHA hash from the comment, go to the relevant repository on github, search the commit history for the commit, find the version of that file that was current at that time of commit (which could be in an earlier version if nothing had changed&amp;hellip;) and so forth&amp;hellip; Instead, I would catch myself re-running the code with parameters I knew (I&amp;rsquo;d scribble somewhere), just so I could be sure.</description>
    </item>
    
    <item>
      <title>mcmc and bootstrapped likelihood runs on parrotfish tree</title>
      <link>/2011/06/09/mcmc-and-bootstrapped-likelihood-runs-on-parrotfish-tree/</link>
      <pubDate>Thu, 09 Jun 2011 16:48:42 +0000</pubDate>
      
      <guid>/2011/06/09/mcmc-and-bootstrapped-likelihood-runs-on-parrotfish-tree/</guid>
      <description>Thursday Overview  Alan Meeting
 Still running scripts, see below
 pmc vignette
  To Do  Got Duncan&amp;rsquo;s ROAuth utilities for RMendeley, still need to test.
 Testing Scott&amp;rsquo;s rplos functions
 Send Alan the paragraph for edits.
  Computation Running on one  n 15: sim_general_mcmc.R MCMC of general model with 8 x 1e6 reps. alpha diverged. DEAD
 n14 Retry above with 8 x 1e6 and with less general model: sigma, theta indep only.</description>
    </item>
    
    <item>
      <title>Wednesday: Simulated model fit analysis on wrightscape, parrotfish tree</title>
      <link>/2011/06/08/wednesday-simulated-model-fit-analysis-on-wrightscape-parrotfish-tree/</link>
      <pubDate>Wed, 08 Jun 2011 13:03:15 +0000</pubDate>
      
      <guid>/2011/06/08/wednesday-simulated-model-fit-analysis-on-wrightscape-parrotfish-tree/</guid>
      <description>Reviewed last night&amp;rsquo;s simulations, see yesterday&amp;rsquo;s post.  Simulated data testing: Fitting the general model well on the parrotfish tree even with clear simulated data seems hard. Simulating with alpha(intramandibulars) = .01, and others = 20, and fitting general model and the alpha-only independent model (release of constraint model). The release model MLE recovers reasonable values: alpha(intra) = 1.7, alpha(others) = 21.8, while the general model fit is clearly struggling even with SANN.</description>
    </item>
    
    <item>
      <title>Tuesday: Parrotfish/wrightscape runs and code modification</title>
      <link>/2011/06/07/tuesday-parrotfishwrightscape-runs-and-code-modification/</link>
      <pubDate>Tue, 07 Jun 2011 23:47:09 +0000</pubDate>
      
      <guid>/2011/06/07/tuesday-parrotfishwrightscape-runs-and-code-modification/</guid>
      <description>Runs: Mon midnight: parrotfish.R with updated SANN parameters and corrected output parameter labeling (always {Xo, alpha, sigma, theta} ordering), implemented on zero, nice 19. General model (&amp;ldquo;wright&amp;rdquo;) still not outperforming others, so still un-converged.
[flickr]5808279169/[/flickr]
 MCMC runs of gape.y and close on one, at nice 19 and 18 1e5 reps. (Alex running matlab nice 10). protrusion.y at nice 11, 1e6 reps.
 open at nice 18 on zero, 1e6 reps.</description>
    </item>
    
    <item>
      <title>Parrotfish in wrightscape</title>
      <link>/2011/06/06/parrotfish-in-wrightscape/</link>
      <pubDate>Mon, 06 Jun 2011 17:54:23 +0000</pubDate>
      
      <guid>/2011/06/06/parrotfish-in-wrightscape/</guid>
      <description>Bootstrapping option Needs a method to pass the optional optim arguments to the update function, such that update uses the same algorithm as the initial fit. Required being a little clever:
[gist id=&amp;ldquo;1010999&amp;rdquo;]
Done. but perhaps we won&amp;rsquo;t always want to bootstrap under this? I suppose it is good practice but slow! Shoot, now I need a lot of really large computers really soon.
Excellent suggestion for better ways to do this from statscicomp list.</description>
    </item>
    
    <item>
      <title>Sunday -- warning signals manuscript (mostly)</title>
      <link>/2011/06/05/sunday-warning-signals-manuscript-mostly/</link>
      <pubDate>Sun, 05 Jun 2011 16:20:26 +0000</pubDate>
      
      <guid>/2011/06/05/sunday-warning-signals-manuscript-mostly/</guid>
      <description>Updates to Scott&amp;rsquo;s rspringer package
 Grabbed remaining datasets from Dakos et al., added to package
 Reading (Biggs et. al. 2009) a bit more closely
 Writing and revisions on warning signals manuscript.
   References  Biggs R, Carpenter S and Brock W (2009). &amp;ldquo;Turning Back From The Brink: Detecting an Impending Regime Shift in Time to Avert it.&amp;rdquo; Proceedings of The National Academy of Sciences, 106.</description>
    </item>
    
    <item>
      <title>Saturday: git with latexdiff, TreeBASE and PMC package updates, bounds on lambda</title>
      <link>/2011/06/04/saturday-git-with-latexdiff-treebase-and-pmc-package-updates-bounds-on-lambda/</link>
      <pubDate>Sat, 04 Jun 2011 21:27:30 +0000</pubDate>
      
      <guid>/2011/06/04/saturday-git-with-latexdiff-treebase-and-pmc-package-updates-bounds-on-lambda/</guid>
      <description>bounds on lambda: Updated the pmc wrappers for fit_continuous to pass bounds on lambda to the bootstrapping Monte Carlo functions. Settled on passing all options explicitly after quite a bit of effort. Looking for way to pass a function all of it&amp;rsquo;s arguments as a named arguments in a list; statscicomp list suggested do.call() function; quite brilliant.
Considering user workflow for wrappers. Conceptually, makes sense for user to run the standard package fit routines first, and then pass the results to pmc.</description>
    </item>
    
    <item>
      <title>Friday</title>
      <link>/2011/06/03/friday-5/</link>
      <pubDate>Fri, 03 Jun 2011 17:52:31 +0000</pubDate>
      
      <guid>/2011/06/03/friday-5/</guid>
      <description>A day&amp;rsquo;s agenda  Scott&amp;rsquo;s got us going on aR package forPLoS API, released Tuesday. Checked over the package and did some basic reorganization to put it in R package form. lots of feedback on my FF question on pw vs private for delayed-disclosure entries. warning signals manuscript package, figures, writing 9-11a Going through Peter&amp;rsquo;s revisions 11-1p Meeting with Peter &amp;amp; Graham 1-2p Meeting with Mikaela, Betta for GTC 2-4 PDG on Brian&amp;rsquo;s Autoparts paper 4-5:30  Colored git diff&amp;rsquo;s etc (from progit.</description>
    </item>
    
    <item>
      <title>Thursday: Warning Signals</title>
      <link>/2011/06/02/thursday-warning-signals/</link>
      <pubDate>Thu, 02 Jun 2011 21:31:39 +0000</pubDate>
      
      <guid>/2011/06/02/thursday-warning-signals/</guid>
      <description>Alan Meeting Reviewing my edits.
 Writing writing writing
 updating graphs and package
  Reading  Yet another volley in the kin-selection group-selection debate (debacle?)(Marshall, 2011)
 This looks excellent, will have to find time for a closer read: (Davies et. al. 2011)
 Jonah&amp;rsquo;s Science paper, the subject of his Merton-Love seminar, (Piovia-Scott et. al. 2011)
  References  Marshall J (2011). &amp;ldquo;Group Selection And Kin Selection: Formally Equivalent Approaches.</description>
    </item>
    
    <item>
      <title>Warning Signals Literature: when stats are and aren&#39;t attempted</title>
      <link>/2011/06/01/warning-signals-literature-when-stats-are-and-arent-attempted/</link>
      <pubDate>Wed, 01 Jun 2011 15:10:56 +0000</pubDate>
      
      <guid>/2011/06/01/warning-signals-literature-when-stats-are-and-arent-attempted/</guid>
      <description>In preparing manuscript on warning signals, reviewing the literature on when statistical validation of the warning signal is included, and if so, what kind are done. There&amp;rsquo;s certainly no consensus in the approach, with the majority of papers not even attempting a method (and those that do not finding significance). Scheffer&amp;rsquo;s key review (Scheffer et. al. 2009) calls for the need to measure statistical significance of warning signals,
 Therefore, it would be useful to build a set of reliable statistical procedures to test whether an increase in autocorrelation, for example, is significant.</description>
    </item>
    
    <item>
      <title>Tuesday: PMC, confidence intervals; screen code-tricks</title>
      <link>/2011/05/31/tuesday-5/</link>
      <pubDate>Tue, 31 May 2011 14:38:59 +0000</pubDate>
      
      <guid>/2011/05/31/tuesday-5/</guid>
      <description>PMC  Final read through of manuscript from me and Peter.
 Looking at confidence intervals in fitContinuous? Package used to use the hessian from optim, but it was later removed due to errors. I added this back manually and attempt a few estimates. Given the Hessian (likelihood surface curvature) this is approximated by
sqrt(diag(solve(out$hessian)))
 See conf_interval_ex.R. i.e for Geospiza tree is:
[1] SE sigma: +/ 0.6763731 SE lambda: +/- 1.</description>
    </item>
    
    <item>
      <title>Monday</title>
      <link>/2011/05/30/monday-6/</link>
      <pubDate>Mon, 30 May 2011 23:44:54 +0000</pubDate>
      
      <guid>/2011/05/30/monday-6/</guid>
      <description>Power in Phylogenies Paper (PMC)  Working through / incorporated Graham&amp;rsquo;s edits Added confidence intervals discussion tweaks to associated pmc package Exploring confidence intervals (and lack thereof) in literature on comparative methods. Pagel (1999) (Pagel, 1999) includes them, but few other papers do. He does not include any discussion about how these are calculated. Seems Sweave makes sense for the recreate-figures code from the cached data-files, but perhaps not for the entire analysis code-base (in demos/).</description>
    </item>
    
    <item>
      <title>Sunday</title>
      <link>/2011/05/29/sunday-2/</link>
      <pubDate>Sun, 29 May 2011 23:24:59 +0000</pubDate>
      
      <guid>/2011/05/29/sunday-2/</guid>
      <description>Completed phylogenetic power manuscript updates based on Peter&amp;rsquo;s comments. Graham will read Monday. Took a whack at updating the treebase package with a method for grabbing nexus character matrices. Seegithub issues log, querying Emmanuel on this one. Local directory management / cleanup  Prepare annual progress report for committee  Phylogenetics Power manuscript. Nearly there. (SICB presentation) Warning signals manuscript resubmission. (Presenting at ESA) Generalized comparative method/release of constraint &amp;ndash; method done, time to write.</description>
    </item>
    
    <item>
      <title>Site configuration: file sharing notes</title>
      <link>/2011/05/28/site-configuration-file-sharing-notes/</link>
      <pubDate>Sat, 28 May 2011 23:22:02 +0000</pubDate>
      
      <guid>/2011/05/28/site-configuration-file-sharing-notes/</guid>
      <description>Easiest way to share files is ssh onto the carlboettiger.info server, change into the directory carlboettiger.info/ and create a new directory there &amp;ndash; i.e. share/. This behaves as a regular static webpage directory that will list the files provided.
Secure access can be created by going to the goodies &amp;ndash;&amp;gt;htaccess/WebDav page and selecting the option to make a directory or subdirectory secure, and then specifying the passwords, etc. Have created the subdirectory http://carlboettiger.</description>
    </item>
    
    <item>
      <title>Matt Potts: Conserving Diversity in Tropical Landscapes</title>
      <link>/2011/05/27/matt-potts-conserving-diversity-in-tropical-landscapes/</link>
      <pubDate>Fri, 27 May 2011 21:27:20 +0000</pubDate>
      
      <guid>/2011/05/27/matt-potts-conserving-diversity-in-tropical-landscapes/</guid>
      <description>My notes from Matt&amp;rsquo;s seminar: Theory and field work addressing getting beyond binary decision making. Malaysia. Tropical forest becoming oil palm, rice, rubber, tea.
Reserve Selection vs Landscape Reserve Design Optimality of Specialized vs Uniform Forest Management Uniform (sustainable forest management) vs very protected areas, ignore what&amp;rsquo;s done outside. More intensive disturbance.
An important ecological nonlinearity: What&amp;rsquo;s the most ubiquitous spatial pattern? Aggregated, random, uniform? (50 hectares is .5 km by km, or 120 English acres, tag every tree taller than 1.</description>
    </item>
    
    <item>
      <title>Thursday Meetings: Duncan; Alan</title>
      <link>/2011/05/26/thursday-6/</link>
      <pubDate>Thu, 26 May 2011 23:53:05 +0000</pubDate>
      
      <guid>/2011/05/26/thursday-6/</guid>
      <description>Duncan Meeting  ROAuth/RCurl question. Mendeley is OAuth 1, github is OAuth 2 (simpler). Both are implemented in pure R in another package, may be good. OAuth 1 constructs complicated http urls with secret, and token, and random key, need to escape chars, etc. OAuth 2 is https, just uses token. Authentication options: Jeff&amp;rsquo;s ROAuth/Duncan&amp;rsquo;s mod, other OAuth package. RMendeley&amp;ndash; windows binary, competition? socialR &amp;ndash; discussed strategy to get a figure with matching code and data.</description>
    </item>
    
    <item>
      <title>Wednesday</title>
      <link>/2011/05/25/wednesday-5/</link>
      <pubDate>Wed, 25 May 2011 17:25:06 +0000</pubDate>
      
      <guid>/2011/05/25/wednesday-5/</guid>
      <description>R packages  Trying to build Windows binaries for R packages using win-builder service.
 First have to get R CMD check working. Check runs in &amp;ndash;vanilla mode so have to tell it where libraries are. Created the file ~/.R/check.Renviron containing the line: R_LIBS=&amp;ldquo;/home/cboettig/R/packages&amp;rdquo; seems to do the trick.
 Successfully built windows binaries for RMendeley package (pre-release, still in development). Download the binaries from github.
 Matt successfully installed CUDA on zero (2.</description>
    </item>
    
    <item>
      <title>Tuesday</title>
      <link>/2011/05/24/tuesday-4/</link>
      <pubDate>Tue, 24 May 2011 23:09:15 +0000</pubDate>
      
      <guid>/2011/05/24/tuesday-4/</guid>
      <description>Warning signals package  Reviewing Numerical challenges for faster analysis on warningsignals
 created a quick mcmcTools package so different packages can use my custom routines. Will have to explore some of the standard packages eventually, though most seem somewhat specialized (the Bayesian task-view is epic). bayesm looks promising, and LearnBayes package that accompanies Jim Albert&amp;rsquo;s book (Albert, unknown) might be worth a closer look.
 Wrote mcmc script for warningsignals, much more debugging to handle out-of-bounds conditions then expected.</description>
    </item>
    
    <item>
      <title>Monday: some code-tricks, Algorithms group planning</title>
      <link>/2011/05/23/monday-5/</link>
      <pubDate>Mon, 23 May 2011 23:00:18 +0000</pubDate>
      
      <guid>/2011/05/23/monday-5/</guid>
      <description>Teary Some discussion on combining Greek letters with variables in R. Previously have solved this with substitute() command,
x = 4.5 plot(1:10, main = substitute(paste(&amp;quot;Kendall &amp;quot;, tau == val), list(val = x[1])))  but Peter has a more elegant solution that can be vectorized:
sapply(interaction(&amp;quot;sigma&amp;quot;,1:5, sep=&amp;quot; == &amp;quot;),function(x)parse(text=x)) #for instance plot(0) legend(&amp;quot;topright&amp;quot;,legend=sapply(interaction(&amp;quot;sigma&amp;quot;,1:5, sep=&amp;quot; == &amp;quot;),function(x)parse(text=x)),lty=2)  Better yet, bquote has a mechanism to evaluate an argument vs express the argument as a symbol, see gist id=1108159.</description>
    </item>
    
    <item>
      <title>Sunday</title>
      <link>/2011/05/22/sunday/</link>
      <pubDate>Sun, 22 May 2011 21:33:41 +0000</pubDate>
      
      <guid>/2011/05/22/sunday/</guid>
      <description>Reading  International Symposium on Biomathematics and Ecology: Education and Research &amp;ndash; This looks excellent, wonder if I can make it. Besides, it&amp;rsquo;s in Portland and the acronym is promising. Pacific Ecoinformatics and Computational Ecology Lab - Based in Berkeley, looks rather intriguing, hard to tell how active this is as a group. Ecoinformatics? So it does exist? Paraphrasing Jeremy Fox, has it done anything? A rather nice review in ARES: (Jones et.</description>
    </item>
    
    <item>
      <title>End of NCEAS &amp; the legacy of synthetic data</title>
      <link>/2011/05/22/end-of-nceas-the-legacy-of-synthetic-data/</link>
      <pubDate>Sun, 22 May 2011 15:40:43 +0000</pubDate>
      
      <guid>/2011/05/22/end-of-nceas-the-legacy-of-synthetic-data/</guid>
      <description>The upcoming termination of NSF funding for NCEAS has recently been receiving a bit of attention, including this nice piece in Science (Stokstad, 2011). I was particularly intrigued by Oikos&amp;rsquo;s treatment of this, in which Oikos editor Jeremy Fox writes,
 that&amp;rsquo;s probably NCEAS&amp;rsquo; biggest legacy-the sense that the answers to all, or at least many, of our questions are already out there, in existing data that just needs to be pulled together&amp;rdquo;</description>
    </item>
    
    <item>
      <title>Algorithms group: MCMCMC</title>
      <link>/2011/05/19/algorithms-group-mcmcmc/</link>
      <pubDate>Thu, 19 May 2011 12:52:34 +0000</pubDate>
      
      <guid>/2011/05/19/algorithms-group-mcmcmc/</guid>
      <description>Discussed $\text{MC}^3$, the Metropolis coupled Markov Chain Monte Carlo, in Monday&amp;rsquo;s algorithms group meeting, just getting around to posting code. The MrBayes paper is a good reference for this (Altekar et. al. 2004). Ourpractice example needed some debugging. I re-wrote a general purpose mcmcmc function in R to illustrate the algorithm, below. Recall that it modifies our original MCMC in two ways. The normal proposal step gets weighted by temperature, allowing heated chains to step downhill more often.</description>
    </item>
    
    <item>
      <title>Thursday</title>
      <link>/2011/05/19/thursday-5/</link>
      <pubDate>Thu, 19 May 2011 10:52:22 +0000</pubDate>
      
      <guid>/2011/05/19/thursday-5/</guid>
      <description>Finish and post core notes from yesterday. Debugging locale problem in phylo packages = success. Emmanuel has already patched drop.fossils() in the ape package, will see if Gieger and TreeSim try to handle locale issue directly too. Problem in comparisons:  &amp;gt; Sys.setlocale(locale = &amp;quot;&amp;quot;) # default locale using UTF8 # message deleted &amp;gt; &amp;quot;-1&amp;quot; &amp;gt; 0 [1] TRUE &amp;gt; Sys.setlocale(locale = &amp;quot;C&amp;quot;) # message deleted &amp;gt; &amp;quot;-1&amp;quot; &amp;gt; 0 [1] FALSE   Posted MCMCMC notes from algorithms.</description>
    </item>
    
    <item>
      <title>Birth-death Tutorial for PBG Core</title>
      <link>/2011/05/18/birth-death-tutorial-for-pbg-core/</link>
      <pubDate>Wed, 18 May 2011 23:55:05 +0000</pubDate>
      
      <guid>/2011/05/18/birth-death-tutorial-for-pbg-core/</guid>
      <description>Ran a introductory tutorial on birth-death models for phylogenetic trees in R today for Peter Wainwright&amp;rsquo;s section of the Pop Bio Core sequence. Notes below, in a manner that may suggest I was better organized than reality might attest. Luckily the firsties are brilliant&amp;hellip;
Getting Started Code is shown section by section with results in the following examples. If you prefer, you can download my full code file here, but you will have to comment out my flickr plotting utilities before it will run.</description>
    </item>
    
    <item>
      <title>Tuesday: Parrotfish results, MCMCMC testing, APIs</title>
      <link>/2011/05/17/tuesday-3/</link>
      <pubDate>Tue, 17 May 2011 22:55:59 +0000</pubDate>
      
      <guid>/2011/05/17/tuesday-3/</guid>
      <description>Finished review for TE
 Shared post on TreeBASE API
 Reviewed Scott&amp;rsquo;s updates to dryad R API, adjusted formatting.
 Looking at documentation for the OAI-MPH queries, don&amp;rsquo;t seem to be as rich as Phylo-ws queries. This is why treeBASE metadata searches tend to download the full metadata set into R and query that. Looks like we&amp;rsquo;ll need to take a similar approach to Dryad, as it doesn&amp;rsquo;t seem like there&amp;rsquo;s a way to query the API by author name at all?</description>
    </item>
    
    <item>
      <title>TreeBASE in R: a first tutorial</title>
      <link>/2011/05/16/treebase-in-r-a-first-tutorial/</link>
      <pubDate>Mon, 16 May 2011 19:46:54 +0000</pubDate>
      
      <guid>/2011/05/16/treebase-in-r-a-first-tutorial/</guid>
      <description>My TreeBASE R package is essentially functional now. Here&amp;rsquo;s a quick tutorial on the kinds of things it can do. Grab the treebase package here, install and load the library into R.
TreeBASE provides two APIs to query the database, one which searches by the metadata associated with different publications (called OAI-PMH), and another which queries the phylogenies directly (called Phylo-ws). They have somewhat redundant functions, but for our purposes the second one returns the actual data, while the first returns metadata.</description>
    </item>
    
    <item>
      <title>MathJax the smart way: Child Themes</title>
      <link>/2011/05/16/mathjax-the-smart-way-child-themes/</link>
      <pubDate>Mon, 16 May 2011 12:54:05 +0000</pubDate>
      
      <guid>/2011/05/16/mathjax-the-smart-way-child-themes/</guid>
      <description>Adding mathjax by modifying the header.php file in my wordpress theme, as recommended by MathJax website, isn&amp;rsquo;t stable to upgrades of the theme, which simply replace the header.php file with a fresh version. The &amp;ldquo;correct&amp;rdquo; way to do this is using child themes, which are pretty simple, even though this got me writing my first php functions.
 Create a directory in wp-content/themes with the desired name of the new theme.</description>
    </item>
    
    <item>
      <title>Thursday: Fun with databases continued</title>
      <link>/2011/05/12/thursday-fun-with-databases-continued/</link>
      <pubDate>Thu, 12 May 2011 20:32:26 +0000</pubDate>
      
      <guid>/2011/05/12/thursday-fun-with-databases-continued/</guid>
      <description>Dryad Hilmar pointed out the documentation for machine access to Dryad fileson the wiki, much nicer than guessing from the XML. (Good thing too, since it&amp;rsquo;s a bit more complicated than I thought). Wiki describes four steps:
 Get the dryad short-identifier for the datafile
 look up the METS reference using that identifier
 parse the XML returned by METS to find the bitstream url
 Query the bitstream url and presto!</description>
    </item>
    
    <item>
      <title>Wednesday: Treebase</title>
      <link>/2011/05/11/wednesday-treebase/</link>
      <pubDate>Wed, 11 May 2011 15:12:14 +0000</pubDate>
      
      <guid>/2011/05/11/wednesday-treebase/</guid>
      <description>TREEBASE PACKAGE:
 Modified treebase package to return the treebase id in the phylo class as phy$id, so that I can use the id to query the appropriate meta data.
 Modified the package with the option to return only max number of trees,
try(xpathApply(search_returns, paste(&amp;quot;//rdf:li[position()&amp;lt; &amp;quot;, max_trees, &amp;quot;]&amp;quot;, sep=&amp;quot;&amp;quot;), function(x){  &amp;hellip;
 Modified to check for branch lengths and remove trees without branch lengths from the returned set.</description>
    </item>
    
    <item>
      <title>Interfaces for databases: TreeBASE, Dryad, DataONE</title>
      <link>/2011/05/10/interfaces-for-databases-treebase-dryad-dataone/</link>
      <pubDate>Tue, 10 May 2011 09:55:57 +0000</pubDate>
      
      <guid>/2011/05/10/interfaces-for-databases-treebase-dryad-dataone/</guid>
      <description>Next Steps Treebase  (See Sunday&amp;rsquo;s post) - Phylo-ws implemented, but a few extra functions would strengthen the interface a bit: limit the number of trees returned, querying trees for branch lengths,
 RaXML pipeline for returning rough branch lengths conditioned on the given topology, user documentation, more test examples.
 Implement OAI-PMH test cases for treebase: For instance, query all records after a given date (or all possible other queries), i.</description>
    </item>
    
    <item>
      <title>Monday: meetings, notebook</title>
      <link>/2011/05/09/monday-4/</link>
      <pubDate>Mon, 09 May 2011 23:56:35 +0000</pubDate>
      
      <guid>/2011/05/09/monday-4/</guid>
      <description>Coop &amp;amp; Moore 270: Species Trees Discussing Bucky paper (Ane et. al. 2006)
Approach of BEST and *BEAST (last time): Prior probability on gene trees P(G|S), given species trees. Goal: Posterior of species trees,
$$ P(S|X) = \intG \Pi{\ell} \left[ P(X{\ell}|G{\ell}) P(G_{\ell}|S) \right] P(S) dG $$
$$ P(G{\ell}|S) = \Pi{b \in S} P(Hb(G{\ell})|S_b) $$
Uses a Dirchlet process model for clustering genes by topologies. All genes in a cluster agree to share a common topology.</description>
    </item>
    
    <item>
      <title>Sunday: a few Treebase R package updates</title>
      <link>/2011/05/08/sunday-a-few-treebase-r-package-updates/</link>
      <pubDate>Sun, 08 May 2011 23:16:24 +0000</pubDate>
      
      <guid>/2011/05/08/sunday-a-few-treebase-r-package-updates/</guid>
      <description>Working on a few updates to the TreeBASE package. This flushes out the basic functionality provided by the phylo-ws API now. Needs a bit more testing of the possible queries and some bells and whistles options. Meanwhile, going to start looking at the metadata side with the OAI-PMH API. With this I should be able to grab metadata associated with a tree or the tree associated with the metadata. Should also be able to extend the queries over to other databases such as Dryad.</description>
    </item>
    
    <item>
      <title>Building a semantic notebook</title>
      <link>/2011/05/08/building-a-semantic-notebook/</link>
      <pubDate>Sun, 08 May 2011 18:39:49 +0000</pubDate>
      
      <guid>/2011/05/08/building-a-semantic-notebook/</guid>
      <description>What would a semantic lab notebook look like? What would be possible with such a structure, ideally? What is already possible now? There&amp;rsquo;s a lot that can be done with an electronic notebook that adds value over a paper notebook: browsing by categories and tags, embedding links, time-stamping entries, searching the full text, and having automated trackbacks or pingbacks when a post is mentioned in another post or appears elsewhere on the web.</description>
    </item>
    
    <item>
      <title>Reproducible Research, Large data sets, and SI2 </title>
      <link>/2011/05/06/reproducible-research-large-data-sets-and-si2/</link>
      <pubDate>Fri, 06 May 2011 19:24:03 +0000</pubDate>
      
      <guid>/2011/05/06/reproducible-research-large-data-sets-and-si2/</guid>
      <description>What follows are my notes from May 6th, 2011 expressing the ideas that would ultimately coalesce into the rOpenSci project. Much of this was turned into an email to Duncan and Todd, whose feedback was invaluable in working through this, and several others. (The reference to SI2 refers to an NSF call from about that time, which also stimulated my thinking on this matter.) Since then I&amp;rsquo;ve learned quite a bit about these tools, with which I now feel quite comfortable.</description>
    </item>
    
    <item>
      <title>Mendeley API in R</title>
      <link>/2011/05/06/mendeley-api-in-r/</link>
      <pubDate>Fri, 06 May 2011 11:21:10 +0000</pubDate>
      
      <guid>/2011/05/06/mendeley-api-in-r/</guid>
      <description>Started to implement the Mendeley API in R, with much help and guidance from Prof. Duncan Temple-Lang in the Stats dept. R is a widely used statistical software environment, and this should facilitate real-time statistical analysis of the rich amount of publication data available in Mendeley.
My motivation is primarily pedagogical at the moment- Mendeley seems to have a nice modern API with both public and authentication-required elements (using OAuth). Writing out the API gives me some good practice making GET requests in RCURL and handling JSON returns, and experiencing the bumps that go with this kind of work.</description>
    </item>
    
    <item>
      <title>Thursday: parrotfish analysis</title>
      <link>/2011/05/05/thursday-parrotfish-analysis/</link>
      <pubDate>Thu, 05 May 2011 16:57:28 +0000</pubDate>
      
      <guid>/2011/05/05/thursday-parrotfish-analysis/</guid>
      <description>Summarizing parrotfish data under the single shift at the intramandibular joint. See version stable code for data loading/transforms (parrotfish_data.R), and for plots (parrotfish.R) as shown, and for analysis functions (loop_models_traits_regimes.R). Models are named by the parameter which is regime-dependent. Results are shown sorted by likelihood, so the best model is on top, and likelihood values are scaled by the weakest model.
Tree: alpha is favored in all the ratio traits, sometimes substantially.</description>
    </item>
    
    <item>
      <title>Weds: Parrotfish data set analysis</title>
      <link>/2011/05/04/weds-parrotfish-data-set-analysis/</link>
      <pubDate>Wed, 04 May 2011 23:16:29 +0000</pubDate>
      
      <guid>/2011/05/04/weds-parrotfish-data-set-analysis/</guid>
      <description>Parrotfish  Need better convergence error handling.
 Need to remedy: &amp;ldquo;Function cannot be evaluated at initial parameters&amp;rdquo; errors &amp;ndash; Occur when attempting very large values of alpha, resulting in NaN output (trouble with exponentials of alpha in calculations).
 Changed summaries to group by painting, so compare models and traits. Less natural than comparing across painting for a single trait since that allows comparisons both across models and across paintings, but makes sense when comparing only a single partition.</description>
    </item>
    
    <item>
      <title>Algorithms Discussion Group: MCMC</title>
      <link>/2011/05/04/algorithms-discussion-group-mcmc/</link>
      <pubDate>Wed, 04 May 2011 17:32:42 +0000</pubDate>
      
      <guid>/2011/05/04/algorithms-discussion-group-mcmc/</guid>
      <description>Implemented a basic MCMC routine in our little algorithms discussion group today, works quite nicely once you remember to use differences of log probabilities instead of ratios. Code and results below.
[gist id=956311]</description>
    </item>
    
    <item>
      <title>Tuesday: phylogenetics- wrightscape coding</title>
      <link>/2011/05/03/tuesday-phylogenetics-wrightscape-coding/</link>
      <pubDate>Tue, 03 May 2011 23:31:25 +0000</pubDate>
      
      <guid>/2011/05/03/tuesday-phylogenetics-wrightscape-coding/</guid>
      <description>Writing methods to loop wrightscape models over lists of different traits, regimes, and model specifications. Easy to end up with large-dimensional output, challenge for visualization. Experimenting with different groupings.
[flickr-gallery mode=&amp;ldquo;search&amp;rdquo; tags=&amp;ldquo;phylogenetics&amp;rdquo; min_upload_date=&amp;ldquo;2011-05-03 00:00:00&amp;rdquo; max_upload_date=&amp;ldquo;2011-05-03 23:59:59&amp;rdquo;]
See code: loop_models_traits_regimes.R
Routine attempts hansen fit for initial estimates of alpha and sigma. Could be greatly improved. Should extend attempts to guess initial conditions for optimization. Should add better convergence testing, simulated annealing option.</description>
    </item>
    
    <item>
      <title>treeBASE R interface: proposal for #iEvoBio</title>
      <link>/2011/05/03/treebase-an-r-interface-proposal-for-ievobio/</link>
      <pubDate>Tue, 03 May 2011 21:07:36 +0000</pubDate>
      
      <guid>/2011/05/03/treebase-an-r-interface-proposal-for-ievobio/</guid>
      <description>Lightning Talk Proposal  I will present the R package treeBASE, which provides an R implementation of the treeBASE phylows API. This package makes it possible to search and import data from this database of published phylogenetic trees easily from within an R script. Recent data archiving requirements at major evolutionary journals such as The American Naturalist (Whitlock et. al. 2010) and Evolution (Fairbairn, 2011) to deposit data used in the study on the Dryad digital repository (and deposit accompanying trees in TreeBASE), along with new requirements for data management from funderssuch as NSF are rapidly changing the landscape of data availability.</description>
    </item>
    
    <item>
      <title>Monday</title>
      <link>/2011/05/03/monday-3/</link>
      <pubDate>Tue, 03 May 2011 11:09:43 +0000</pubDate>
      
      <guid>/2011/05/03/monday-3/</guid>
      <description>Today:
 Application for CPB travel funds. DONE
 Faxed receipts from Felsenstein&amp;rsquo;s visit. DONE
  Seminar on Species trees Coop/Moore Seminar on *BEAST (Heled &amp;amp; Drummond, 2009) and BEST (Liu et. al. 2008).
Essential differences: BEST uses Mr. Bayes to compute probabilities over gene trees (over uniform prior). Then estimates the species tree by importance sampling from this distribution to reflect constraints under a convergence model. Integrates over effective population sizes rather than estimating (highly uncertain anyway), requires rooting, and a rather fast/loose implementation of ultra-metricizing trees.</description>
    </item>
    
    <item>
      <title>Friday: Notes on Labrids, notes on Transforms and size-corrections</title>
      <link>/2011/04/29/friday-notes-on-labrids-notes-on-transforms-and-size-corrections/</link>
      <pubDate>Fri, 29 Apr 2011 22:19:43 +0000</pubDate>
      
      <guid>/2011/04/29/friday-notes-on-labrids-notes-on-transforms-and-size-corrections/</guid>
      <description>The specific traits were:
Oral Jaw traits
 mouth-closing lever ratio (Close),
 mouth-opening lever ratio (Open), kinematic
 transmission coefficient of the oral jaws four-bar linkage (Jaw KT),
 adductor mandibulae (AM) muscle mass,
 premaxillary protrusion distance (Prot),
 gape width (Gape),
  Exterior to the Oral Jaws, not expected to become unconstrained:
 levator posterior (LP) muscle mass: (Pharyngeal jaw muscle)
 sterno-hyoideus (SH) muscle mass, (Primarily buccual cavity)</description>
    </item>
    
    <item>
      <title>Reading Notes, presentation prep treebase error handling</title>
      <link>/2011/04/28/thursday-reading-notes/</link>
      <pubDate>Thu, 28 Apr 2011 13:59:43 +0000</pubDate>
      
      <guid>/2011/04/28/thursday-reading-notes/</guid>
      <description>Reading  Oikos journal recently started a rather nice blog. A journal long responsible for some of the best examples of developing and confronting ecological theory with empirical results, with an commendable emphasis on general principles and synthesis, it&amp;rsquo;s nice to see them enter the Web2.0 ecosystem. Editor Jeremy Fox has a nice introduction to the goals of the blog &amp;ndash; check out the &amp;ldquo;new ideas&amp;rdquo; categories for worthwhile reading.</description>
    </item>
    
    <item>
      <title>Wednesday</title>
      <link>/2011/04/27/wednesday-4/</link>
      <pubDate>Wed, 27 Apr 2011 21:58:09 +0000</pubDate>
      
      <guid>/2011/04/27/wednesday-4/</guid>
      <description>7:30-9:30 Review for Theoretical Ecology
 Profiling wrightscape   Compile with profiling (-g -pg flags, in make profile). Run
valgrind --leak-check-full ./wrightscape.exe  to remove memory links. Run
valgrind --tool=callgrind kcachegrind callgrind.out.&amp;lt;###&amp;gt;  For profiling information
Troubleshooting implementation of restricted-domain functions. Cannot be wright_tree since they have to know their likelihood method. Will need an indicator to their type. Some troubleshooting of the simulation method too: my pmc&amp;rsquo;s montecarlotest() is set up so that simulate() can return the data set directly that is passed to update() or return a list object with the dataset in $rep.</description>
    </item>
    
    <item>
      <title>Accessing phylognenies in TreeBASE from R</title>
      <link>/2011/04/26/accessing-phylognenies-in-treebase-from-r/</link>
      <pubDate>Tue, 26 Apr 2011 14:10:22 +0000</pubDate>
      
      <guid>/2011/04/26/accessing-phylognenies-in-treebase-from-r/</guid>
      <description>I&amp;rsquo;ve recently ((25 April, 8 April)) begun a project to see if I can search for and load phylogenies from TreeBASE directly into R. Thanks to the rather brilliant API in place (documented on the treeBASE wiki) for TreeBASE, some advice from Rutger Vos (TreeBASE developer), and some xpaths R code from Gabe Becker (stats grad student, UC Davis), I have a (mostly) working demonstration. As I get a chance, I&amp;rsquo;ll be adding the rest of the queries available in the API, improve the error handling and give some more thought to a user interface.</description>
    </item>
    
    <item>
      <title>TreeBASE interface continued...</title>
      <link>/2011/04/25/treebase-interface-continued/</link>
      <pubDate>Mon, 25 Apr 2011 10:11:31 +0000</pubDate>
      
      <guid>/2011/04/25/treebase-interface-continued/</guid>
      <description>Returning to exploration of treeBASE interface and my attempt to implement an R interface the API (earlier entry)
Rutger Vos has gotten me started, pointing out that the handling of the metadata interface is done separately from the handling of the content (phylogenies and matrices).
Meta data Meta-data interface uses the Open Archives Initiative Protocol for Metadata Harvesting (OAI-PMH) which has a beginners tutorial. The tutorial provides broad background about the initiative and the basic xml schema, but I didn&amp;rsquo;t find it particularly accessible or get a clear idea of how interacting with the protocol works.</description>
    </item>
    
    <item>
      <title>wrightscape profiling</title>
      <link>/2011/04/24/wrightscape-profiling/</link>
      <pubDate>Sun, 24 Apr 2011 18:50:11 +0000</pubDate>
      
      <guid>/2011/04/24/wrightscape-profiling/</guid>
      <description>Optimization at the R level is substantially slower than at the C level:
system.time(wright_test = wright(data,tree,regimes, alpha=ou2@sqrt.alpha^2, sigma=ou2@sigma)) user system elapsed 82.157 0.068 82.346 system.time(ws2 = wrightscape(trait, labrid$tree, regime=labrid$regimes, (ou2@sqrt.alpha)^2, ou2@sigma, theta=ou2@theta[[1]])) iter: 229, llik = 34.750, size = 0.000, par values = 0.000069 2.456353 0.000026 0.225234 0.973002 0.488713 user system elapsed 4.964 0.000 4.971  This is possibly due to repeating the lca matrix calculation. As it&amp;rsquo;s not done in a separate R function yet, the profiler cannot tell us this.</description>
    </item>
    
    <item>
      <title>Release of constraint in labrids?</title>
      <link>/2011/04/22/release-of-constraint-in-labrids/</link>
      <pubDate>Fri, 22 Apr 2011 18:45:05 +0000</pubDate>
      
      <guid>/2011/04/22/release-of-constraint-in-labrids/</guid>
      <description>Started writing outline, assembling references
 Reviewed brownie-lite as an alternative model to compare the release-of-constraint, but looks like it will be easier just to modify wrightscape code to keep parameters fixed or global.
 Writing a wrapper to move the likelihood function for wrightscape to up to the R level.
 Figure out which function to pass up: easiest is to build off of fit_model, but just evaluate, don&amp;rsquo;t optimize the likelihood.</description>
    </item>
    
    <item>
      <title>Wednesday</title>
      <link>/2011/04/20/wednesday-3/</link>
      <pubDate>Wed, 20 Apr 2011 22:24:25 +0000</pubDate>
      
      <guid>/2011/04/20/wednesday-3/</guid>
      <description>Reading  GrrlScientist disagrees with M. Nielsen (and I add my 2c: Open Science might not give you the credit you need to get a job in today&amp;rsquo;s science culture, but hey, in all probability, neither will the traditional strategy, so have fun). Nature says: Too many PhDs Some useful tools for data visualization: particularly want to try:Fusion Tables, Gephi, DataViz Mendeley groups don&amp;rsquo;t display (or share) stars. Can only sort A-Z or by most recent.</description>
    </item>
    
    <item>
      <title>Tuesday: Reading and thoughts</title>
      <link>/2011/04/19/tuesday-reading-and-thoughts/</link>
      <pubDate>Tue, 19 Apr 2011 12:32:53 +0000</pubDate>
      
      <guid>/2011/04/19/tuesday-reading-and-thoughts/</guid>
      <description>Reading Taking twenty minutes to take down some notes and reactions to this morning&amp;rsquo;s reading.
Interdisciplinary Science Meeting Great post by the AAAS on theScience on FIRE meeting. Think the focus on young faculty and undergraduate education is dead on. However , the lack of emphasis (or even inclusion) of ecology and evolution material in &amp;ldquo;exemplar programs&amp;rdquo; such as CIMB (not be confused with UC Davis&amp;rsquo;s CLIMB, which does this balance very well) is tragic, given that (a) these fields have a richer and longer quantitative history than mol bio, (b) undergraduate ed in these areas shares the same general lack of emphasis in computation and mathematics skills as it&amp;rsquo;s molecular brethren classes &amp;copy; world challenges in these areas are at least on par with challenges in medicine, and deserve attention (despite the differences in funding).</description>
    </item>
    
    <item>
      <title>Early Warning Signals in Coral Dynamics -- Economic analysis of risk</title>
      <link>/2011/04/19/early-warning-signals-in-coral-dynamics-economic-analysis-of-risk/</link>
      <pubDate>Tue, 19 Apr 2011 11:53:23 +0000</pubDate>
      
      <guid>/2011/04/19/early-warning-signals-in-coral-dynamics-economic-analysis-of-risk/</guid>
      <description>Alan and I have been considering analyzing a particular system for early warning signals where we could highlight risk management from an economics stand-point, probably with the help of Jim Sanchirico. Our current work focuses on quantifying the relative risk of false alarms and missed detections. While statisticians typically accept a 5% &amp;ldquo;false alarm&amp;rdquo; rate, we argue this given limited data this is always a trade-off against the missed detection rate and hence the location of this threshold should properly a decision of management, not of convention.</description>
    </item>
    
    <item>
      <title>Thursday: submitting warning signals manuscript</title>
      <link>/2011/04/18/thursday-submitting-warning-signals-manuscript/</link>
      <pubDate>Mon, 18 Apr 2011 23:47:56 +0000</pubDate>
      
      <guid>/2011/04/18/thursday-submitting-warning-signals-manuscript/</guid>
      <description>Crazy day today submitting the warning signals manuscript.
 Github hosting Precedings hosting?  </description>
    </item>
    
    <item>
      <title>Algorithms Discussion Group: algorithms Continued</title>
      <link>/2011/04/18/algorithms-discussion-group-abc-continued/</link>
      <pubDate>Mon, 18 Apr 2011 14:11:24 +0000</pubDate>
      
      <guid>/2011/04/18/algorithms-discussion-group-abc-continued/</guid>
      <description>Our little informal ABC group met again today to continue our discussion of ABC methods from last week. The updated code is included in the gist below. ((Nick asked about gists &amp;ndash; they are code boxes provided by Github that are easy to embed into blogs, etc. They provide automatic syntax highlighting and version management. For instance, I just opened last week&amp;rsquo;s gist and started editing during today&amp;rsquo;s session &amp;ndash; when I save it I get a new version ID, so last week&amp;rsquo;s post still points to last week&amp;rsquo;s code, but it doesn&amp;rsquo;t create a second copy, so you can tell if you have the right version.</description>
    </item>
    
    <item>
      <title>TreePar: changing rates of evolution</title>
      <link>/2011/04/17/treepar-changing-rates-of-evolution/</link>
      <pubDate>Sun, 17 Apr 2011 18:11:46 +0000</pubDate>
      
      <guid>/2011/04/17/treepar-changing-rates-of-evolution/</guid>
      <description>Review &amp;amp; Comments on Article T. Stadler&amp;rsquo;s article Mammalian phylogeny reveals recent diversification rate shifts (Stadler, 2011) describes her new TreePar package, evaluating shifts in the mammalian phylogeny (from and analyzed by (Bininda-Emonds et. al. 2007)) as an example.
The heart of the article is the calculation of the likelihood for a branching process model with rate shifts at specified times. This approach is dramatically more powerful and less susceptible to spurious conclusions than the earlier approach of looking for a shift in slope in the lineage-through-time (LTT) plot.</description>
    </item>
    
    <item>
      <title>Friday</title>
      <link>/2011/04/16/friday-4/</link>
      <pubDate>Sat, 16 Apr 2011 20:00:49 +0000</pubDate>
      
      <guid>/2011/04/16/friday-4/</guid>
      <description>Reading  Arxiv has several articles on the EM-algorithm from J. Statistical Science unknown, unknown. What makes this distinct from applying any traditional optimization routine (Nelder-Mead, simulated annealing, etc) to the likelihood function? Just in that it determines the probability distribution as well as maximum?
 UPDATE ON EM: brief discussion with Graham, Peter, Yaniv on this, now my impression is: Not necessarily get the distribution, but doesn&amp;rsquo;t just generically take a function and minimize it, but may not calculate the likelihood at each step.</description>
    </item>
    
    <item>
      <title>Weds: Final round edits</title>
      <link>/2011/04/13/weds-final-round-edits/</link>
      <pubDate>Wed, 13 Apr 2011 16:21:30 +0000</pubDate>
      
      <guid>/2011/04/13/weds-final-round-edits/</guid>
      <description> Low-power (40 data-point) IBM simulation example   Consider examples of false negative (Deteriorating example), and negative correlations in constant and deteriorating environments (? - nope) Implement LTC updated models! Working over Alex revisions  </description>
    </item>
    
    <item>
      <title>Tuesday: manuscript and appendix edits</title>
      <link>/2011/04/12/tuesday-manuscript-and-appendix-edits/</link>
      <pubDate>Tue, 12 Apr 2011 23:40:28 +0000</pubDate>
      
      <guid>/2011/04/12/tuesday-manuscript-and-appendix-edits/</guid>
      <description>Today&amp;rsquo;s log  Edited cover letter summary for public.
 Soliciting feedback on examples in manuscript vs appendix, see Monday&amp;rsquo;s entry. (Entry posted, images added to flickr database)
 Jeff fixed the double-post bug in twitteR, tested update.
 Improved initialization estimates for LSN model in fit_models (code), as identified &amp;amp; discussed in Sunday&amp;rsquo;s entry. Needs testing on a unit case, trying on ibm_analysis.R now&amp;hellip; seems to work fine.</description>
    </item>
    
    <item>
      <title>A bit of work on my socialR package for reproducible research</title>
      <link>/2011/04/12/a-bit-of-work-on-my-socialr-package-for-reproducible-research/</link>
      <pubDate>Tue, 12 Apr 2011 09:55:42 +0000</pubDate>
      
      <guid>/2011/04/12/a-bit-of-work-on-my-socialr-package-for-reproducible-research/</guid>
      <description>A few small updates on my socialR package, (continued from my earlier entries) which should hopefully help it evolve from a personal tool to a portable package one day. Starting by incorporating support for native R packages to handle the API interface to flickr, twitter, and github, rather than just calling command-line scripts. Jeff Gentry has just released an ROAuth package for authentication, which can be used by his twitteR package.</description>
    </item>
    
    <item>
      <title>Monday: Warning Signals - Updated graphs</title>
      <link>/2011/04/11/monday-warning-signals-updated-graphs/</link>
      <pubDate>Mon, 11 Apr 2011 22:47:04 +0000</pubDate>
      
      <guid>/2011/04/11/monday-warning-signals-updated-graphs/</guid>
      <description>Trying a different set-up for the graphs. Added two additional datasets, trying layout of making all three figures into a panels in a single figure.
Concerns:
 Better than only one empirical example, but not sure that the three Glaciation data sets add that much since they are all quite similar. Five panels wide might be too much. Don&amp;rsquo;t have an example where a transition is about to occur but the data doesn&amp;rsquo;t have adequate power even for our Likelihood method, third panel.</description>
    </item>
    
    <item>
      <title>Monday: algorithms Meeting</title>
      <link>/2011/04/11/monday-abc-meeting-2/</link>
      <pubDate>Mon, 11 Apr 2011 16:21:09 +0000</pubDate>
      
      <guid>/2011/04/11/monday-abc-meeting-2/</guid>
      <description>Yaniv has started an algorithms discussion group. We just met with a few students to discuss implementing Approximate Bayesian Computing methods from scratch. Most of us had read (Beaumont, 2010) and (Csilléry et. al. 2010) but also followed [cite source=&amp;ldquo;pubmed&amp;rdquo;]12524368[/cite] most helpful during the session.
[gist id=914487]
This gets us as far as the regression step, Figure 1 of (Csilléry et. al. 2010). This in part distinguishes the approach from simple rejection sampling.</description>
    </item>
    
    <item>
      <title>Sunday: Warning signals edits continue</title>
      <link>/2011/04/11/sunday-warning-signals-edits-continue/</link>
      <pubDate>Mon, 11 Apr 2011 08:13:05 +0000</pubDate>
      
      <guid>/2011/04/11/sunday-warning-signals-edits-continue/</guid>
      <description>Marissa edits &amp;ndash; Nearly done
 Single-figure layout &amp;ndash; DONE
 equations in appendix &amp;ndash; DONE
 convergence / likelihood agreement between constOU and constLSN (Done, see below; consider using for a better initial-condition guessing routine for better convergence)
 Reformulate transcritical bifurcation?
 Rewrite cover letter
   load(&amp;quot;5598226674.Rdat&amp;quot;) require(warningsignals) OU &amp;lt;- deterior_mc$null LSN &amp;lt;- deterior_mc$test LSN_OU &amp;lt;- updateGauss(const_LSN, OU$pars, OU$X) c(OU$loglik, LSN$loglik, LSN_OU$loglik) [1] -1038.510 -1142.539 -1162.</description>
    </item>
    
    <item>
      <title>Warning signals</title>
      <link>/2011/04/08/warning-signals-3/</link>
      <pubDate>Fri, 08 Apr 2011 17:08:48 +0000</pubDate>
      
      <guid>/2011/04/08/warning-signals-3/</guid>
      <description> ibm simulation fit convergence on constOU vs constLSN &amp;ndash; are likelihood scores off from including out-of-bound parameter estimates? Consider transcritical in levins model setup Consider re-arranging figures: one panel, full-width, variance and autocorrelation only, three empirical examples. Trying smaller numbers of replicates in simulated data to get low-power examples.  flickr-gallery mode=&amp;ldquo;search&amp;rdquo; tags=&amp;ldquo;stochpop&amp;rdquo; min_upload_date=&amp;ldquo;2011-04-06 00:00:00&amp;rdquo; max_upload_date=&amp;ldquo;2011-04-11 23:59:59&amp;rdquo;
 move ibm simulation code into warningsignals package Working through Marissa&amp;rsquo;s edits.  </description>
    </item>
    
    <item>
      <title>TreeBase: exploratory exercises in database-driven phylogenetics</title>
      <link>/2011/04/08/treebase-exploratory-exercises-in-database-driven-phylogenetics/</link>
      <pubDate>Fri, 08 Apr 2011 15:18:02 +0000</pubDate>
      
      <guid>/2011/04/08/treebase-exploratory-exercises-in-database-driven-phylogenetics/</guid>
      <description>Taking a look at the TreeBase database for potential project with Gabe &amp;amp; Duncan&amp;rsquo;s Large Data seminar. It would be interesting to get a working knowledge of the database and the API, making large-scale meta-analyses easy. Many studies seem to select taxa based on what they have in their own lab rather than re-use existing phylogenies, not because it is better suited to answering the questions but because it is more familiar.</description>
    </item>
    
    <item>
      <title>Some reproducible research practices in journals</title>
      <link>/2011/04/08/reproducible-research/</link>
      <pubDate>Fri, 08 Apr 2011 12:48:44 +0000</pubDate>
      
      <guid>/2011/04/08/reproducible-research/</guid>
      <description>Interesting discussion on the Reproducible Research Group about rates at which the various reproducible research standards are used in the Journal of Biostatistics:
from unknown, 2010, which provides a great basis for recommendations to authors, publishers, and funders to ensure reproducible research. Victoria Stodden describes two journals with Open Review and two with Associate Editors of Reproducible Research.
Some of the articles from Biostatistics discussing this practice: (Baker et. al.</description>
    </item>
    
    <item>
      <title>Steve Ellner&#39;s seminar</title>
      <link>/2011/04/07/steve-ellners-seminar/</link>
      <pubDate>Thu, 07 Apr 2011 17:09:29 +0000</pubDate>
      
      <guid>/2011/04/07/steve-ellners-seminar/</guid>
      <description>What started as three men and a chemostat&amp;hellip;
This is Part III of the talk &amp;ndash; some of you were in elementary school for the first two, so here&amp;rsquo;s a reminder:
Consumer-resource interactions are prone to cycle: due to delayed negative feedbacks. (note prey peaks are 1&amp;frasl;4-cycle shifted). Simulations, Larch Budmoth and parasitoids, (Kendall et. al. 1998)
Chaos should be common But it isn&amp;rsquo;t. we observe Stable : cycles : chaos 2 : 1 : $ \epsilon $ Zimmer 1999 (Zimmer, 1999)</description>
    </item>
    
    <item>
      <title>Warning Signals - Manuscript touch-ups</title>
      <link>/2011/04/06/warning-signals-manuscript-touch-ups/</link>
      <pubDate>Wed, 06 Apr 2011 17:27:42 +0000</pubDate>
      
      <guid>/2011/04/06/warning-signals-manuscript-touch-ups/</guid>
      <description>[toc]
Refining examples  Updating finished runs to full formats
 Condensing/organizing code examples under the demos to follow the structure of the paper.
 Currently plotting code for manuscript loads a menagerie of different run results from different files. Would be better to consolidate by dataset.
  Proposed figure changes  Consider multiple empirical examples in main text
 Consider removing skew/kurtosis examples to the supplement?
 Consider other empirical examples</description>
    </item>
    
    <item>
      <title>Comparative methods paper status/to-do</title>
      <link>/2011/04/06/comparative-methods-paper-statusto-do/</link>
      <pubDate>Wed, 06 Apr 2011 11:56:20 +0000</pubDate>
      
      <guid>/2011/04/06/comparative-methods-paper-statusto-do/</guid>
      <description>Finished revisions yesterday after rewriting introduction considerably. Following Graham&amp;rsquo;s comment, taking a closer look at aic error along power curves:
&amp;gt; load(&amp;quot;../../pmc/demos/5594495254.Rdat&amp;quot;) &amp;gt; require(pmc) &amp;gt; aic &amp;lt;- 2 &amp;gt; aic_errors_size &amp;lt;- sapply(1:(length(n)), function(i) sum(size[[i]]$null_dist &amp;gt; aic)/size[[i]]$nboot ) &amp;gt; aic_errors_shape &amp;lt;- sapply(1:length(lambda), function(i) sum(shape[[i]]$null_dist &amp;gt; aic)/shape[[i]]$nboot ) &amp;gt; data.frame(n, aic_errors_size) n aic_errors_size 1 10 0.1945 2 20 0.2405 3 40 0.1800 4 60 0.1590 5 80 0.0750 6 100 0.1015 7 150 0.</description>
    </item>
    
    <item>
      <title>Updates to socialR package</title>
      <link>/2011/04/05/updates-to-socialr-package/</link>
      <pubDate>Tue, 05 Apr 2011 12:27:16 +0000</pubDate>
      
      <guid>/2011/04/05/updates-to-socialr-package/</guid>
      <description>Talking with Nick a bit about the socialR package, hope to find a chance to streamline the package a bit, move away from all system calls and interface directly with the APIs for Flickr, twitter, etc from R. This should avoid the command-line program dependencies and configurations I need to use currently.
Building my own API interfaces looks like it will require a good bit of work, meanwhile significant hope the community might develop reasonable packages to pull this off &amp;ndash; basic packages already exist for twitter and flickr.</description>
    </item>
    
    <item>
      <title>evolution manuscript revisions</title>
      <link>/2011/04/04/phylogenetics-manuscript-revisions/</link>
      <pubDate>Mon, 04 Apr 2011 22:48:21 +0000</pubDate>
      
      <guid>/2011/04/04/phylogenetics-manuscript-revisions/</guid>
      <description>Heard back from Graham Friday on manuscript revisions. Notes on reviewing edits:
 Reconsider title? (Currently: &amp;ldquo;is your phylogeny informative? estimating power in phylogenetic trees&amp;rdquo;). Suggestions from Graham/Brian?
 1000 taxa, 500 taxa seem to break the ouch package inferences.
 Add table for AIC comparisons etc
 Does AIC work better/worse on the lambda = 0 trees?
n[1:3] [1] 10 50 100 aic_errors_size &amp;lt;- sapply(1:(length(n)-2), function(i) sum(size[[i]]$null_dist &amp;gt; aic)/size[[i]]$nboot ) aic_errors_size [1] 0.</description>
    </item>
    
    <item>
      <title>Thursday finishing up appendices(?)</title>
      <link>/2011/04/01/thursday-finishing-up-appendices/</link>
      <pubDate>Fri, 01 Apr 2011 15:50:05 +0000</pubDate>
      
      <guid>/2011/04/01/thursday-finishing-up-appendices/</guid>
      <description>Fresh off the cpus: single replicate examples on the Drake data
What&amp;rsquo;s still running:  likelihood for IBM data with 2000 replicates, nice 19 on zero (ibm_likelihood.R) likelihood for Glaciation I-III with 2000 replicates, nice 18 on zero (deut_likelihood.R) likelihood for Glaciation I-III with 2000 replicates, (nice 19 on one)? (deut_likelihood.R) likelihood on sim data, Glaciation III and CaCO3: 80 replicates on one, nice 1 on one (figure3.R) and with 2000 replicates, nice 19 on one (figure3.</description>
    </item>
    
    <item>
      <title>A few large data problems in Ecology &amp; Evolution</title>
      <link>/2011/03/31/a-few-large-data-problems-in-ecology-evolution/</link>
      <pubDate>Thu, 31 Mar 2011 11:18:38 +0000</pubDate>
      
      <guid>/2011/03/31/a-few-large-data-problems-in-ecology-evolution/</guid>
      <description>I&amp;rsquo;ve joined a student-led seminar with Gabriel Becker in the Statistics department on dealing with large data, primarily in R. Offered to say a few words about large data problems in my field for a few minutes, so making some notes.
Large dataBases  Genebank: $ &amp;gt; 10^8$ sequences. Phylogenetic inference
 Morphological databases: Specialized databases with semantic tools (Dahdul et. al. 2010)
 NEON observatories data Keller et. al.</description>
    </item>
    
    <item>
      <title>Brian O&#39;Meara discusses new algorithms approaches on Phylo</title>
      <link>/2011/03/30/brian-omeara-discusses-new-abc-approaches-on-phyloseminar/</link>
      <pubDate>Wed, 30 Mar 2011 20:52:04 +0000</pubDate>
      
      <guid>/2011/03/30/brian-omeara-discusses-new-abc-approaches-on-phyloseminar/</guid>
      <description>Brian gave an excellent overview of Approximate Bayesian Computing (ABC) and described the TreEvo software he is developing with post-doc Barb Banbury. My notes from the seminar, with my own comments italics and a few added references
Intro / Motivation  Rates of model innovation is rather slow
 Can be impossible to specify in closed form (can&amp;rsquo;t specify median of binomial in closed form)
 Perhaps it would be faster if we didn&amp;rsquo;t have to wait for someone to come up with all the likelihood functions</description>
    </item>
    
    <item>
      <title>Wednesday: appendices; parameter distributions</title>
      <link>/2011/03/30/wednesday-appendices-parameter-distributions/</link>
      <pubDate>Wed, 30 Mar 2011 17:59:20 +0000</pubDate>
      
      <guid>/2011/03/30/wednesday-appendices-parameter-distributions/</guid>
      <description>Fixed bug causing montecarlotest() calls not to complete: in likelihood_bifurcation_models, LTC error checking uses any() to see if any Vx are negative, returns NA if none are negative but has NAs. rm.na=TRUE fixed this. GetParNames works, probably worth an appendix section to discuss parameter bootstraps as well, particularly in the cases of low power. Updated codes to turn this flag back on and am re-running. Figure3 plot has been using the 160 bootstrap replicates, updated to the 2000 replicates.</description>
    </item>
    
    <item>
      <title>Tuesday, simulations &amp; appendix</title>
      <link>/2011/03/29/tuesday-simulations-appendix/</link>
      <pubDate>Tue, 29 Mar 2011 22:45:28 +0000</pubDate>
      
      <guid>/2011/03/29/tuesday-simulations-appendix/</guid>
      <description>Today mostly working over code sets for examples in appendix, and increasing replicates. Somehow more trouble than it should be, see commit history for today.
ibm_sim.R &amp;ndash; simulate from individual-based dynamics containing a saddle-node bifurcation (fully hysteresis model).
ibm_analysis.R &amp;ndash; run figure1, 2, 3 analysis (correlation test, bootstrap of test, likelihood test) on each data.
ibm_likelihood.R &amp;ndash; shouldn&amp;rsquo;t be needed, all code is in deut_examples.R. Running now due to earlier parallel instance errors during montecarlotest.</description>
    </item>
    
    <item>
      <title>Monday, appendices continue...</title>
      <link>/2011/03/29/monday-appendices-continue/</link>
      <pubDate>Tue, 29 Mar 2011 01:09:43 +0000</pubDate>
      
      <guid>/2011/03/29/monday-appendices-continue/</guid>
      <description>Finished writing up section on correlations (time averages vs ensembles) and the following section on error types. (yay, that writing went much better than yesterday). Appendices nearly done, a few more bits:
 Must figure out what data examples are going into the supplement. Most should be reasonably straight-forward to set up, may take a while to run.
 Have to figure out what to say about likelihood-based statistical method beyond definition of Cox&amp;rsquo;s delta,</description>
    </item>
    
    <item>
      <title>Sunday -- edits and appendices</title>
      <link>/2011/03/27/sunday-edits-and-appendices/</link>
      <pubDate>Sun, 27 Mar 2011 21:34:39 +0000</pubDate>
      
      <guid>/2011/03/27/sunday-edits-and-appendices/</guid>
      <description>Read over Scheffer&amp;rsquo;s rather nice introduction(Scheffer, 2010) to the Drake paper(Drake &amp;amp; Griffen, 2010). Last paragraph is particularly pertinenant:
 Clearly, we have just scratched the surface in exploring the possibilities and limitations of this emerging field. However, the prospect of identifying generic indicators is exciting, as the approach may provide an independent way to assess the risk of critical transitions. Expansion of our toolbox for prediction is especially welcome given the almost insurmountable problem of modelling complex systems in a quantitatively accurate way.</description>
    </item>
    
    <item>
      <title>Saturday-- Appendices</title>
      <link>/2011/03/26/saturday-appendices/</link>
      <pubDate>Sat, 26 Mar 2011 23:28:00 +0000</pubDate>
      
      <guid>/2011/03/26/saturday-appendices/</guid>
      <description>Appendices Working on Appendices
Ergodicity Null of Kendall&amp;rsquo;s tau/rank correlations &amp;ndash; independence of X and Y, not satisfied even over replicates. Adjusted codes to use Pearson&amp;rsquo;s (default option, need to pass option up to higher-level functions). Repeated Figure 2 plots with Pearson&amp;rsquo;s, results not much different, funny multimodal though:
Actually verifying independence is rather more challenging, though convenient in this case that a test such as Pearson&amp;rsquo;s is not designed to do this, see http://en.</description>
    </item>
    
    <item>
      <title>Friday</title>
      <link>/2011/03/25/friday-3/</link>
      <pubDate>Fri, 25 Mar 2011 17:25:02 +0000</pubDate>
      
      <guid>/2011/03/25/friday-3/</guid>
      <description>Reading Some nice theoretical ecology papers out from our group recently, looking over today:
 Paul&amp;rsquo;s paper (Williams &amp;amp; Hastings, 2011) deals with some interesting work on persistence in complex models, (stochastic systems of mixture models), curious how it compares to the conclusions of (Schreiber, 2010).
 Sebastian&amp;rsquo;s paper (Schreiber et. al. 2011) with Dan Bolnick and Burger, another example of the importance of individual heterogeneity, this time in a nice phenotype/genotype specific way by combining quantitative genetics approaches with predator dynamics.</description>
    </item>
    
    <item>
      <title>Thursday</title>
      <link>/2011/03/24/thursday-3/</link>
      <pubDate>Thu, 24 Mar 2011 23:19:19 +0000</pubDate>
      
      <guid>/2011/03/24/thursday-3/</guid>
      <description>Assembled plots for figures 1,2,3 see paper_plots.R. Considerable adjustment of axes/layout. Sent figures out for comments.
 Considered removing skew/kurtosis from Figure 1 &amp;amp;/or Figure 2, currently leaving in (particularly in Figure 2 to make point clear that no indicator works well?) Easy to remove using paper_plots.R script.   To Do list:  Figure 3 layout should mimic Figure 2 as much as possible (font sizes, margins, etc).</description>
    </item>
    
    <item>
      <title>Data Management Workshop at UC Davis Center for Population Biology: Video archive</title>
      <link>/2011/03/24/data-management-workshop-at-uc-davis-center-for-population-biology-video-archive/</link>
      <pubDate>Thu, 24 Mar 2011 16:30:24 +0000</pubDate>
      
      <guid>/2011/03/24/data-management-workshop-at-uc-davis-center-for-population-biology-video-archive/</guid>
      <description>Videos are now up from our workshop, The Future of Data, held at the UC Davis Center for Population Biology March 2nd-4th.
Panel  Don Strong, Editor-in-Chief of Ecology
 Marcel Holyoak, Editor-in-Chief, **Ecology Letters **
 Jonathan Eisen, Editor-in-Chief, PLoS Biology
 Alan Hastings, founding Editor-in-Chief, Theoretical Ecology
 Robert Hijmans, Asst Professor of Environmental Science &amp;amp; Policy
 Trisha Cruse (Director), with Associate Directors Stephen Abrams &amp;amp; John Kunze from UC Curation Center.</description>
    </item>
    
    <item>
      <title>Wednesday</title>
      <link>/2011/03/23/wednesday-2/</link>
      <pubDate>Wed, 23 Mar 2011 18:39:08 +0000</pubDate>
      
      <guid>/2011/03/23/wednesday-2/</guid>
      <description>Still to do on figures:
 Plots with and without skew/kurtosis &amp;ndash; DONE, enabled for Figure 1 &amp;amp; 2
 Combine plots into full panels &amp;ndash; DONE for Figure 1 &amp;amp; Figure 2
 separate plotting codes from analysis codes (at least whenever takes any computational effort/time to produce). &amp;ndash; DONE
 bootstrap_indicators should have option of which indicators are included &amp;ndash; DONE
 all_indicators should have option of which indicators are included &amp;ndash; DONE</description>
    </item>
    
    <item>
      <title>Tuesday: Figures, figures, figures</title>
      <link>/2011/03/23/tuesday-figures-figures-figures/</link>
      <pubDate>Wed, 23 Mar 2011 10:37:35 +0000</pubDate>
      
      <guid>/2011/03/23/tuesday-figures-figures-figures/</guid>
      <description>Today working mostly on selecting examples of data sets to include in the figure patterns. Working with the idea of three figures &amp;ndash; data, bootstraps of Tau, bootstraps of likelihood &amp;ndash; in panels for several examples: some real data sets and some simulated data sets with and without warning. In addition to this, I still have some more work to do with references, and refining the writing of a few of the appendices.</description>
    </item>
    
    <item>
      <title>Monday -- Edits and organization</title>
      <link>/2011/03/22/monday-edits-and-organization/</link>
      <pubDate>Tue, 22 Mar 2011 09:07:36 +0000</pubDate>
      
      <guid>/2011/03/22/monday-edits-and-organization/</guid>
      <description>Skype with Alan: 9-9:4
 Figures as panels
 Write Appendix
 Finish References
 Move into Word
   Sims  LSN m = -0.049, N =50, T=100
 LSN m = -0.049, N =100, T=100
 LTC m = -0.049, N =100, T=100
 LTC m = -0.049, N =100, T=50
 LTC m = -0.049, N =100, T=200
  Autocorrelation [flickr-gallery mode=&amp;ldquo;search&amp;rdquo; tags=&amp;ldquo;stochpop, acor&amp;rdquo; tag_mode=&amp;ldquo;all&amp;rdquo; min_upload_date=&amp;ldquo;2011-03-21 10:00:00&amp;rdquo; max_upload_date=&amp;ldquo;2011-03-22 10:00:00&amp;rdquo;]</description>
    </item>
    
    <item>
      <title>Sunday - manuscript and simulations</title>
      <link>/2011/03/21/sunday-manuscript-and-simulations/</link>
      <pubDate>Mon, 21 Mar 2011 11:19:59 +0000</pubDate>
      
      <guid>/2011/03/21/sunday-manuscript-and-simulations/</guid>
      <description>Working on manuscript. lot of writing / editing.
Edited package and example to include skew and kurtosis bootstrap estimates of tau. Currently testing.
 m = -0.04, N = 50, nboot = 160, (with all moments)
 m = -0.04, N = 50, nboot = 800, (with all moments)
 m = -0.05, N = 50, nboot = 800, (with all moments)
 m = -0.02, N = 500, nboot = 800 (without skew/kurtosis yet)</description>
    </item>
    
    <item>
      <title>Challenges with Collaboration in Open Science </title>
      <link>/2011/03/21/challenges-with-collaboration-in-open-science/</link>
      <pubDate>Mon, 21 Mar 2011 10:43:45 +0000</pubDate>
      
      <guid>/2011/03/21/challenges-with-collaboration-in-open-science/</guid>
      <description>On Thursday I silently switched my ONS claim from all-content, instant (aci) to all-content, delayed (acd). This wasn&amp;rsquo;t just an admission that I&amp;rsquo;m sometimes a day behind in posting my entries. That day&amp;rsquo;s post was tagged private in wordpress, and didn&amp;rsquo;t appear in the RSS feed. I updated my socialR package to include a toggle to make uploaded images from public to private, and opened a private github repository. No, nothing tragic has happened and this doesn&amp;rsquo;t mean that everything I do will now be locked down until publication.</description>
    </item>
    
    <item>
      <title>Writing: Warning Signals Mansucript</title>
      <link>/2011/03/20/writing-warning-signals-mansucript/</link>
      <pubDate>Sun, 20 Mar 2011 14:39:13 +0000</pubDate>
      
      <guid>/2011/03/20/writing-warning-signals-mansucript/</guid>
      <description>Summary Paragraph
 Critical transitions exist (Holling, 1973), (May, 1977),(Scheffer et. al. 2001) Warning signals exist (Scheffer et. al. 2009), (Drake &amp;amp; Griffen, 2010) Warning signals are summary statistics, critical slowing down (Wissel, 1984). Statement of general problem: double-edged sword &amp;ndash; no quantification of the chance detection scheme will fail. We provide a way to do this We find existing methods lack sufficient power and have high false-alarm potential We provide a model-based solution using machinery of modern likelihood statistics  Background  Define CSD, standard detection scheme.</description>
    </item>
    
    <item>
      <title>Warning Signals examples and tracking graphs</title>
      <link>/2011/03/19/warning-signals-examples-and-tracking-graphs/</link>
      <pubDate>Sat, 19 Mar 2011 20:52:26 +0000</pubDate>
      
      <guid>/2011/03/19/warning-signals-examples-and-tracking-graphs/</guid>
      <description>Working on more examples for the notebook. Currently exploring a collection of simulated examples. In particular, would be useful to have simulated examples that look as realistic in data-density as possible (i.e. fewer sample points, also shorter sampling interval relative to timescale, so doesn&amp;rsquo;t look like a fuzzy caterpillar. Second, would be good to include examples on data simulated from non-linearized systems made to represent some richer bifurcation examples. Finally it would be good to include as many real-data examples as reasonable.</description>
    </item>
    
    <item>
      <title>Approximate Bayesian Computing (algorithms) methods</title>
      <link>/2011/03/19/approximate-bayesian-computing-abc-methods/</link>
      <pubDate>Sat, 19 Mar 2011 11:07:50 +0000</pubDate>
      
      <guid>/2011/03/19/approximate-bayesian-computing-abc-methods/</guid>
      <description>Erick Matsen  asked me about the question at the end of Luke Harmon&amp;rsquo;s phyloseminar critiquing Approximate Bayesian Computing ABC methods. The question wasn&amp;rsquo;t any more specific, though Luke recognized the paper. Searching the literature didn&amp;rsquo;t turn anything up, asking Leo through the MCMC group on Mendeley I think this is the paper:
﻿Robert, C.P. et al. Lack of confidence in ABC model choice. PNAS I, 8(2011). (arXiv)
Seems a more pointed critique to ABC then Templeton&amp;rsquo;s discussion (Templeton, 2010) particularly as the lead author is a critic of Templeton (Berger et.</description>
    </item>
    
    <item>
      <title>Sam&#39;s Practice talk</title>
      <link>/2011/03/18/friday-2/</link>
      <pubDate>Fri, 18 Mar 2011 16:37:40 +0000</pubDate>
      
      <guid>/2011/03/18/friday-2/</guid>
      <description>Notes from: Sam Price&amp;rsquo;s Practice Job Talk for Hull, UK, next week, in Wainwright lab:
 Diversification of mammals predated KT event(Bininda-Emonds et. al. 2007) (also considerably later, but not right after) Ecological shift in wrasses to parrotfishes(Price et. al. 2010). No evidence of elevate rates of evolution. But, scraping parrotfishes do show difference (starting from base of Hipposcarus-Scarus common ancestor). Multiple transitions to/from reef living. 2x faster on coral reefs!</description>
    </item>
    
    <item>
      <title>Warning Signals in Ecological Systems: Revisions and Drake &amp; Griffen Data</title>
      <link>/2011/03/17/warning-signals-in-ecological-systems-drake-griffen-data/</link>
      <pubDate>Thu, 17 Mar 2011 09:59:18 +0000</pubDate>
      
      <guid>/2011/03/17/warning-signals-in-ecological-systems-drake-griffen-data/</guid>
      <description>Manuscript revisions  Heard back from Alan this morning on manuscript, need to cut wordcount in half, from 3000 to 1500 words. Should emphasize the countless and utterly arbitrary choices made in every one of these analyses. Should emphasize our approach can be applied without replicates. (also without interpolating/having evenly sampled data) Should do coefficient of variation on non-detrended data(?) should discuss?  Chemostat data This morning Alan sent me the data used by Drake &amp;amp; Griffen (Drake &amp;amp; Griffen, 2010).</description>
    </item>
    
    <item>
      <title>Wednesday</title>
      <link>/2011/03/16/wednesday/</link>
      <pubDate>Wed, 16 Mar 2011 23:49:35 +0000</pubDate>
      
      <guid>/2011/03/16/wednesday/</guid>
      <description>Updated dependencies of warningsignals package. Removed old dependencies, migrated montecarlotest into package, removing the pmc dependency.
 Updated my webpage teaching statement (lunch break)
 montecarlotest wasn&amp;rsquo;t getting sfLibrary(warningsignals) called in yesterday&amp;rsquo;s runs, so redoing this.
 Writing &amp;ndash; conclusion, finalized organization, sent off to Alan.
   To Do:  Panel for models. Appendix for model derivations.
 Panel for approach/algorithm. Appendix for algorithm implementation.
 Figure review</description>
    </item>
    
    <item>
      <title>Tuesday</title>
      <link>/2011/03/15/tuesday-2/</link>
      <pubDate>Tue, 15 Mar 2011 22:38:08 +0000</pubDate>
      
      <guid>/2011/03/15/tuesday-2/</guid>
      <description>Variance and warning signals Sebastian has several examples of dynamical systems that decrease in variance as they approach a bifurcation. In some sense this is not surprising, both are through the collapse of periodic attractors. Figure 2d in TPB paperSchreiber, 2003 has an example in a discrete system, and Figure 5a in the Ecology Letters paper (Schreiber &amp;amp; Rudolf, 2008) has a continuous-time example. Consider for instance the supercritical Hopf bifurcation, in which a stable limit cycle vanishes into an unstable node, as in a van der Pol oscillator,</description>
    </item>
    
    <item>
      <title>Model identifiability in phylogenetic inference GTR&#43;I&#43;G</title>
      <link>/2011/03/15/models-in-phylogenetic-inference/</link>
      <pubDate>Tue, 15 Mar 2011 13:07:13 +0000</pubDate>
      
      <guid>/2011/03/15/models-in-phylogenetic-inference/</guid>
      <description>Another phylogenetics paper (Perelman et. al. 2011) using GTR+I+G inspired me to look back over the discussion and objections with this model. This model is the basis of 100s of publications, 40 alone in Sys Bio in 2006(Allman et. al. 2008). There&amp;rsquo;s a decent discussion on Dechronization about the issue. There&amp;rsquo;s some treatment of identifiability on this issue, such as 2001 Sys Bio (Rogers, 2001) which suggests this is possible and a nice paper in Adv.</description>
    </item>
    
    <item>
      <title>Peter&#39;s talk </title>
      <link>/2011/03/14/peters-talk/</link>
      <pubDate>Mon, 14 Mar 2011 22:29:55 +0000</pubDate>
      
      <guid>/2011/03/14/peters-talk/</guid>
      <description>Peter spoke in Sebastian&amp;rsquo;s lab meeting about a spatially explicit Moran model, for which he derives Fisher&amp;rsquo;s wave equation and an ancestry process. Here&amp;rsquo;s what he says,
 the general plan is to describe a simple spatial model of adaptation (or, could be of invasion&amp;hellip;); and use it to derive (Fisher&amp;rsquo;s) traveling wave; the corrections that arise if you don&amp;rsquo;t assume the population is infinitely large; and describe how to follow lineages back through the expanding wave.</description>
    </item>
    
    <item>
      <title>Warning Signals, Monday</title>
      <link>/2011/03/14/warning-signals-monday/</link>
      <pubDate>Mon, 14 Mar 2011 11:18:59 +0000</pubDate>
      
      <guid>/2011/03/14/warning-signals-monday/</guid>
      <description>Set up a few long runs of simulated data to better illustrate the effects of sampling time and density, and better resolve the distributions.
 Longer baseline run, nice 19, indicator_vs_likelihood.R 1600 reps, m=-0.015, N=500, T=100
 Longer sampling, same interval: nice 18, stronger_signal.R 160 reps m=-0.015, N = 2500, T=500
  Fails to compute, looks like poor estimates of model fits.
 Denser sampling, nice 17: indicator_vs_likelihood.R 160 reps, m=-0.</description>
    </item>
    
    <item>
      <title>Warning signals: summary stats vs likelihood on real and simulated data</title>
      <link>/2011/03/11/warning-signals-summary-stats-vs-likelihood-on-real-and-simulated-data/</link>
      <pubDate>Fri, 11 Mar 2011 14:35:05 +0000</pubDate>
      
      <guid>/2011/03/11/warning-signals-summary-stats-vs-likelihood-on-real-and-simulated-data/</guid>
      <description>Added bar of observed tau on real data to the tau distributions. Fixed the tau-distribution method, running new data and real examples now.
Simulated data: can tell tau apart for instance, for autocorrelation (see photostream for variance, code hash for parameters, etc). While can&amp;rsquo;t really tell anything based on the tau on the autocorrelation for the Deuterium data for Glaciation III (which has just about the clearest signal of the deuterium set): Waiting to see how the likelihood statistics compare on these examples.</description>
    </item>
    
    <item>
      <title>Numerical challenges in likelihood estimation of time-dep OU models</title>
      <link>/2011/03/10/numerical-challenges-in-likelihood-estimation-of-time-dep-ou-models/</link>
      <pubDate>Thu, 10 Mar 2011 23:46:46 +0000</pubDate>
      
      <guid>/2011/03/10/numerical-challenges-in-likelihood-estimation-of-time-dep-ou-models/</guid>
      <description>Worried about accurate maximum likelihood estimates of parameters, as the optimization could still converge on values not far from the starting conditions (not as surprising as the starting parameters are estimated intelligently first from the summary statistics) but could also vary depending on initial conditions.
Second, while it requires some re-parameterization, the stationary model for both linearized transcritical (LTC) bifurcation model and the linearized saddle-node (LSN) model are identically Ornstein-Uhlenbeck models.</description>
    </item>
    
    <item>
      <title>Warning Signals data examples</title>
      <link>/2011/03/09/warning-signals-data-examples/</link>
      <pubDate>Wed, 09 Mar 2011 16:31:56 +0000</pubDate>
      
      <guid>/2011/03/09/warning-signals-data-examples/</guid>
      <description>Working on a little data exploration while writing up manuscript. I have been puzzled why it appears that most estimates of tau on the CaCO3 data infer negative correlation, as in
Despite the fact that there seems to be a loss of stability in the model:
require(warningsignals) load(&amp;quot;CaCO3.Rdat&amp;quot;) timedep$pars Ro m theta sigma 8.36841588 -0.03347119 -2.86194248 282.03234042  So m is negative, so that the system is loosing stability, but only very gradually.</description>
    </item>
    
    <item>
      <title>Bodega evolution Tutorial: behind the scenes difficulties in R packages</title>
      <link>/2011/03/07/bodega-phylogenetics-tutorial-behind-the-scenes-difficulties-in-r-packages/</link>
      <pubDate>Mon, 07 Mar 2011 21:22:42 +0000</pubDate>
      
      <guid>/2011/03/07/bodega-phylogenetics-tutorial-behind-the-scenes-difficulties-in-r-packages/</guid>
      <description>Just finished my tutorial for comparative methods on continuous traits in R, which I&amp;rsquo;ll be presenting on Wednesday with Justen Whittall. The tutorial is up on the Bodega Phylogenetics Wiki, together with the necessary data files.
Errors that shouldn&amp;rsquo;t happen: a few package bugs in simulation functions Assembling the tutorial exposed a few more frustrations in the R packages. Consider simulating OU with rTraitCont:
## Load the libraries, simulate a tree require(geiger) require(TreeSim) tree &amp;lt;- sim.</description>
    </item>
    
    <item>
      <title>Warning Signals: Comparing Methods on Climate Data</title>
      <link>/2011/03/01/warning-signals-comparing-methods-on-climate-data/</link>
      <pubDate>Tue, 01 Mar 2011 16:51:54 +0000</pubDate>
      
      <guid>/2011/03/01/warning-signals-comparing-methods-on-climate-data/</guid>
      <description>Continuing my exploration in applying these techniques to real climate data. Applying the Kendall&amp;rsquo;s Tau based approach on real data.
Greenhouse Earth, CaCO3 data:
Glaciation I-IV (deuterium data)
These use the unadjusted timeseries, and hence don&amp;rsquo;t reproduce the values of Kendall&amp;rsquo;s tau statistic reported in (Dakos et. al. 2008). In fact they don&amp;rsquo;t even agree on the sign &amp;ndash; visually many of the datasets are certainly decreasing in variance. I ran the Monte-Carlo distributions for tau on models estimated from these data-sets with and without warning, for variance (left) and autocorrelation (right), in the CaCO3 data:</description>
    </item>
    
    <item>
      <title>Warning Signals on Real data continued</title>
      <link>/2011/02/28/warning-signals-on-real-data-continued/</link>
      <pubDate>Mon, 28 Feb 2011 12:08:03 +0000</pubDate>
      
      <guid>/2011/02/28/warning-signals-on-real-data-continued/</guid>
      <description>Continuing my tweaks to code to apply warning signals to the climate data used in (Dakos et. al. 2008). After adjusting my code to deal with variably spaced sampling intervals, I reread the supplement &amp;ndash; I had forgotten that they don&amp;rsquo;t actually consider data with variable time-scales, but instead interpolate the curves to have equally spaced sampling intervals.
Obviously this is not ideal. It is true that the autocorrelation would be impacted by non-equally spaced data, while there is no reason to do so for the variance indicator.</description>
    </item>
    
    <item>
      <title>Warning Signals on Real Data?</title>
      <link>/2011/02/27/warning-signals-on-real-data/</link>
      <pubDate>Sun, 27 Feb 2011 16:24:03 +0000</pubDate>
      
      <guid>/2011/02/27/warning-signals-on-real-data/</guid>
      <description>Grabbed the data used in (Dakos et. al. 2008), which is includes climate data from the Deuterium levels in the Vostok ice core (Petit et. al. 1999), showing transitions into the last several ice ages, and calcium carbonate from Eocene &amp;ldquo;greenhouse&amp;rdquo; climate (Tripati et. al. 2005), and carbon-14 data from the Younger Dryas (Hughen, 2000). Data is all freely provided through NOAA.
 CaCO3 data file (Tripati et. al. 2005), NOAA entry.</description>
    </item>
    
    <item>
      <title>Is BM nested in OU?  Understanding likelihoods of ouch</title>
      <link>/2011/02/25/is-bm-nested-in-ou-understanding-likelihoods-of-ouch/</link>
      <pubDate>Fri, 25 Feb 2011 20:16:37 +0000</pubDate>
      
      <guid>/2011/02/25/is-bm-nested-in-ou-understanding-likelihoods-of-ouch/</guid>
      <description>A quick run of the example ouch code given by
 ?bimac  will produce something of a surprise for most users:
require(ouch) data(bimac) tree &amp;lt;- with(bimac,ouchtree(node,ancestor,time/max(time),species)) h1 &amp;lt;- brown(log(bimac[&#39;size&#39;]),tree) h2 &amp;lt;- hansen(log(bimac[&#39;size&#39;]),tree,bimac[&#39;OU.1&#39;],sqrt.alpha=1,sigma=1) c(&amp;quot;BM LogLik&amp;quot;=h1@loglik, &amp;quot;OU LogLik&amp;quot;=h2@loglik) BM LogLik OU LogLik 17.33129 15.69682  These models are supposed to be nested, right? Set OU&amp;rsquo;s $ \alpha $ parameter to zero and you get BM, so how does it manage to do worse in log likelihood?</description>
    </item>
    
    <item>
      <title>Phylo: Luke Harmon</title>
      <link>/2011/02/25/phyloseminar-luke-harmon/</link>
      <pubDate>Fri, 25 Feb 2011 14:36:16 +0000</pubDate>
      
      <guid>/2011/02/25/phyloseminar-luke-harmon/</guid>
      <description>My notes on Luke Harmon&amp;rsquo;s excellent talk on Phyloseminar this morning. See the recording of Luke&amp;rsquo;s actual talk to know what he said, below are my thoughts and notes to myself having watched the talk.
Luke summarizes his goal rather nicely as:
 Analyzing the data that people actually have to answer the questions they actually want to know
 For him, this focuses on incomplete trees and non-Brownian models.</description>
    </item>
    
    <item>
      <title>ESA 2011 Abstract: Limits to Detection of Early Warning Signals</title>
      <link>/2011/02/23/esa-2011-abstract/</link>
      <pubDate>Wed, 23 Feb 2011 17:58:45 +0000</pubDate>
      
      <guid>/2011/02/23/esa-2011-abstract/</guid>
      <description>Just submitted my abstract to for an oral presentation at the Ecological Society of America 2011 meeting in Austin, based on my recent work on early warning signals. Here it is:
Limits to Detection of Early Warning Signals of Population Collapse Background/Question/Methods The recognition that ecosystems can undergo sudden shifts to alternate, less desirable stable states has led to the desire to identify early warning signs of these impending collapses.</description>
    </item>
    
    <item>
      <title>Monday: Writing, Mendeley groups, Notebook plugin tweaks</title>
      <link>/2011/02/21/monday-2/</link>
      <pubDate>Mon, 21 Feb 2011 23:45:37 +0000</pubDate>
      
      <guid>/2011/02/21/monday-2/</guid>
      <description>A day of Writing  Reviewed Chris&amp;rsquo;s manuscript.
 Completed my revisions to phylogenetics mansucript, meeting with Peter tomorrow to discuss. Still need to work through the discussions of model adequacy Goldman, 1993, Cox&amp;rsquo;s delta (1961&amp;frasl;62), and going beyond (simulations by under both null and test distributions).
 Meanwhile, a few thoughts:
  Reproducible Research Mentioned in Thursday&amp;rsquo;s entry coming across Victoria Stodden&amp;rsquo;s post on Reproducible research standards such as practiced by Journal of Biostatistics.</description>
    </item>
    
    <item>
      <title>Bodega evolution Workshop: Continuous Characters R session planning</title>
      <link>/2011/02/19/bodega-phylogenetics-workshop-continuous-characters-r-session-planning/</link>
      <pubDate>Sat, 19 Feb 2011 03:45:09 +0000</pubDate>
      
      <guid>/2011/02/19/bodega-phylogenetics-workshop-continuous-characters-r-session-planning/</guid>
      <description>Preparing for the Bodega Phylogenetics workshop. I&amp;rsquo;ll be covering the R tutorial followingJusten Whittall&amp;rsquo;s introduction to continuous characters:
 In my intro lecture i will discuss Felsenstein 1985 (including a little phylo signal), then follow with some alternatives (including the OU model). I can also discuss the tree transformations ala Pagel&amp;rsquo;s kappa, delta, etc. and mention multivariate approaches to detecting correlated characters in a phylogenetic context.
 I&amp;rsquo;m toying with the idea of a brief (~1hr) phylogenetic signal / model inference exercise:</description>
    </item>
    
    <item>
      <title>Friday</title>
      <link>/2011/02/18/friday/</link>
      <pubDate>Fri, 18 Feb 2011 15:21:41 +0000</pubDate>
      
      <guid>/2011/02/18/friday/</guid>
      <description>Spoke with Prof. Jim Carey about getting Data Mangement Workshop videocast with Cametasia (and possibly Adobe Connect for live streaming). Jim has worked with Entomology seminar series, and UCTV on videocasting seminars, see his recent PLoS Biology paper Carey et. al. 2010.  Spoke with Marissa about some of the resources at NCEAS. Learned a bit about data standards from FGDC and NBII. Working on manuscript revisions (phylogenetics) Writing (warning signals) Revised Weds post, reviewing context for Goldman 1993 Goldman, 1993 relative to original simulation-based parametric bootstrap of Cox&amp;rsquo;s statistic as illustrated in (McLachlan, 1987) in mixture models.</description>
    </item>
    
    <item>
      <title>Thursday</title>
      <link>/2011/02/17/thursday-4/</link>
      <pubDate>Thu, 17 Feb 2011 23:55:56 +0000</pubDate>
      
      <guid>/2011/02/17/thursday-4/</guid>
      <description>Mostly working on manuscript revisions throughout this week. Haven&amp;rsquo;t really learned to integrate this workflow into the notebook. In some ways it makes more sense not to, as it interrupts the flow of the research description. But then it looks like I&amp;rsquo;m not doing anything when I have nothing meaningful in the entry. Perhaps I should just put a heading saying &amp;ldquo;Writing.&amp;rdquo;
Morning&amp;rsquo;s reading: Reproducible Research  Victoria Stodden highlights the Journal of Biostatistics approach to Reproducible Research.</description>
    </item>
    
    <item>
      <title>Weds &amp; Framing warning signals manuscript</title>
      <link>/2011/02/16/weds-framing-warning-signals-manuscript/</link>
      <pubDate>Wed, 16 Feb 2011 23:56:41 +0000</pubDate>
      
      <guid>/2011/02/16/weds-framing-warning-signals-manuscript/</guid>
      <description>Alan Meeting, 10a Good meeting discussing warning signals manuscript details and organization. Particularly on the best way to present some of the major conceptual and semantic elements: there are many ways to describe the same thing, each of which carries a lot of semantic baggage.
Do we choose to present this as:
As Hypothesis Testing Null = isn&amp;rsquo;t a loss of stability (distribution produced by the MLE model of no stability loss), hypothesis = there is (distribution produced by, MLE model with stability loss) determine p value for falsely rejecting the null and the power of the statistical test.</description>
    </item>
    
    <item>
      <title>Citation tools &amp; Future of Publishing</title>
      <link>/2011/02/16/citation-tools-future-of-publishing/</link>
      <pubDate>Wed, 16 Feb 2011 23:04:50 +0000</pubDate>
      
      <guid>/2011/02/16/citation-tools-future-of-publishing/</guid>
      <description>There has been a lot of rapid development in scientific tools based on a Wordpress platform recently, perhaps spurred in part by the recent Beyond-the-PDF and sessions in Science Online conferences. A new discussion group has emerged around these tools, as described by Martin Fenner.
I have been exploring better tools for citation management within my lab notebook. Recently I have been using the papercite plugin to add citations from my BibTeX files, which are generated from Mendeley, as I described earlier.</description>
    </item>
    
    <item>
      <title>Data Mangement on UC3 Merritt Repository</title>
      <link>/2011/02/16/data-mangement-on-uc3-merritt-repository/</link>
      <pubDate>Wed, 16 Feb 2011 19:06:11 +0000</pubDate>
      
      <guid>/2011/02/16/data-mangement-on-uc3-merritt-repository/</guid>
      <description>I&amp;rsquo;ve been trying to learn a little more about the potential for data management solutions through the UC3 Merritt repository, and decide how this compares to commercial alternatives such as Amazon S3, Picasa/Flickr (obviously for images only), and field-specific and publication specific repositories such as Dryad. Merritt email support have been very helpful in answering my questions and concerns.
 Persistence: of the data itself, of the URLs &amp;amp; object identifiers, of access to the data?</description>
    </item>
    
    <item>
      <title>Tuesday</title>
      <link>/2011/02/15/tuesday/</link>
      <pubDate>Tue, 15 Feb 2011 23:20:18 +0000</pubDate>
      
      <guid>/2011/02/15/tuesday/</guid>
      <description>In at 8:30. 10a and still getting through Google Reader journals, emails.
 Finished up yesterday&amp;rsquo;s entry and posted. Exploring some of the new developments in Wordpress for scientists. Some trouble with the link2link code interfacing with kcite. No luck yet on mathjax: renders the shortcode instead of the equations, i.e $dx = \sigma d B_t$ NIMBioS workshop inquiry: Offering a workshop on HPC in R, I was curious about the scope and depth of the workshop.</description>
    </item>
    
    <item>
      <title>Monday</title>
      <link>/2011/02/14/monday/</link>
      <pubDate>Mon, 14 Feb 2011 23:37:00 +0000</pubDate>
      
      <guid>/2011/02/14/monday/</guid>
      <description>Excellent CPB visiting weekend with perspective students Thurs evening - Sunday morning. Hosting students, etc doesn&amp;rsquo;t make for much of a research entry Friday. Catching up with many things today.
 ESA registration. Topics, Abstract
 Checking in with Alan
 Data workshop: create &amp;amp; post advertisement, map out subject areas
 Reading: Syst Bio issue
 Updated pubmed author alerts
 Checking in with Peter &amp;amp; Graham on revisions</description>
    </item>
    
    <item>
      <title>Thursday</title>
      <link>/2011/02/10/thursday-2/</link>
      <pubDate>Thu, 10 Feb 2011 17:00:44 +0000</pubDate>
      
      <guid>/2011/02/10/thursday-2/</guid>
      <description>Organizing for Future of Data workshop. Confirming time/room booking, etc. Science makes open access a special issue on Dealing with Data  Hosting visiting prospective CPB student, scheduling events. Going over edits questions with Peter R. on phylogenetics manuscript. Editing/pruning plugins &amp;ndash; starting to choke my Wordpress hosting. Folks at DreamHost have been very helpful, hopefully no key plugins are off. Apparently deactivating doesn&amp;rsquo;t necessarily prevent plugin from contributing to the memory load.</description>
    </item>
    
    <item>
      <title>Phylogenetic Monte Carlo for the Laser package</title>
      <link>/2011/02/09/phylogenetic-monte-carlo-for-the-laser-package/</link>
      <pubDate>Wed, 09 Feb 2011 18:17:54 +0000</pubDate>
      
      <guid>/2011/02/09/phylogenetic-monte-carlo-for-the-laser-package/</guid>
      <description>Laser simulations: First ensuring example has expected behaviour, can in general get the expected likelihood differences between fits of Yule and birth-death models.
Estimated models had been appearing identical in the runs (on left), seems to have been a bug. Distributions appear roughly the same across different tree sizes and values of death rate. General pattern of likelihood tests is reminiscent of the lambda models: high variability in likelihood ratios under bd simulations relative to the pure-birth simulations.</description>
    </item>
    
    <item>
      <title>Why ONS? From a discussion with friends</title>
      <link>/2011/02/08/why-ons-from-a-discussion-with-friends/</link>
      <pubDate>Tue, 08 Feb 2011 14:36:19 +0000</pubDate>
      
      <guid>/2011/02/08/why-ons-from-a-discussion-with-friends/</guid>
      <description>I agree that the key is open data, and it really only helps if that data is discoverable, and better if it&amp;rsquo;s in a central repository. The open notebook community is pretty focused on figuring out ways to automate and link the data from the notebook. For instance, many solubilities recorded for chemicals given in wikipedia automatically link to the open notebook entries describing the experiment wherein the data was collected, check out http://en.</description>
    </item>
    
    <item>
      <title>Notes during revisions on phylogenetics manuscript</title>
      <link>/2011/02/08/notes-during-revisions-on-phylogenetics-manuscript/</link>
      <pubDate>Tue, 08 Feb 2011 13:47:10 +0000</pubDate>
      
      <guid>/2011/02/08/notes-during-revisions-on-phylogenetics-manuscript/</guid>
      <description>I have made the revisions to attempt to address Graham&amp;rsquo;s annotations and Peter&amp;rsquo;s comments. (revisions are also up on the git repo.) I have added a brief section introducing the models immediately after the introduction. I also rewrote more of the PMC method to include definitions of p and power in the context of comparing model likelihood ratios. I moved the AIC section up before I talk about the other comparisons.</description>
    </item>
    
    <item>
      <title>Warning signals &amp; hpc</title>
      <link>/2011/02/04/warning-signals-computing/</link>
      <pubDate>Fri, 04 Feb 2011 18:30:12 +0000</pubDate>
      
      <guid>/2011/02/04/warning-signals-computing/</guid>
      <description>Morning has been rather difficult trying to get simulations up and running. Parallel library isn&amp;rsquo;t running on zero or one, variety of errors that seemed to be machine dependent and reminiscent of the ~./sfCluster problem, 3 hrs of debugging revealed this was indeed just a bug in my updated code. (In changing to my object-oriented simulate.gauss and update.gauss functions rather than calling the specific functions directly I hadn&amp;rsquo;t updated all the function calls).</description>
    </item>
    
    <item>
      <title>Progress on warning signals</title>
      <link>/2011/02/03/progress-on-warning-signals/</link>
      <pubDate>Thu, 03 Feb 2011 18:30:15 +0000</pubDate>
      
      <guid>/2011/02/03/progress-on-warning-signals/</guid>
      <description>Going several directions at once in tweaking the warning signals code to make sure I have clear comparisons that are not resulting from any limitations in the numerical algorithms. Performing a variety of error checks, etc:
 Comparing fixed models vs comparing models estimated from the data
 Ensure that const model doesn&amp;rsquo;t attempt to estimate m (doesn&amp;rsquo;t impact likelihood anyway
 Ensure only positive values of sigma are returned (trying use trigger in setLTC and setLSN to return infinite variance if sigma is negative)</description>
    </item>
    
    <item>
      <title>To podcast or not to podcast university lectures</title>
      <link>/2011/02/01/to-podcast-or-not-to-podcast-university-lectures/</link>
      <pubDate>Tue, 01 Feb 2011 13:27:53 +0000</pubDate>
      
      <guid>/2011/02/01/to-podcast-or-not-to-podcast-university-lectures/</guid>
      <description>Today in graduate teaching community we&amp;rsquo;re discussing the value of podcasts which rapidly becoming the standard expectation of in university lectures. There weren&amp;rsquo;t podcasts when I was a student, at least never in the classes I&amp;rsquo;d taken -though I&amp;rsquo;ve often wished I had access to complete recordings of my university lectures. Most wouldn&amp;rsquo;t be valuable, but some I would still wish to go back to long after the fact, not so much to recall content but to remember the styles and stories my notes fail to capture.</description>
    </item>
    
    <item>
      <title>The Future of Data: Plans for a UC Davis workshop</title>
      <link>/2011/02/01/the-future-of-data-preparing-researchers-to-face-new-funding-and-publishing-policies/</link>
      <pubDate>Tue, 01 Feb 2011 09:40:59 +0000</pubDate>
      
      <guid>/2011/02/01/the-future-of-data-preparing-researchers-to-face-new-funding-and-publishing-policies/</guid>
      <description>I have been working with several of the faculty of UC Davis to prepare a workshop for our department to (1) help make our researchers aware of the new requirements for NSF proposals and journal submissions with regard to data archiving, (2) To explore what new opportunities this creates and what tools exist that will help our researchers take maximum advantage of it, and (3) to engage our research community in the discussion of future standards for sharing, standardizing, rewarding and funding the archiving of data.</description>
    </item>
    
    <item>
      <title>Warning signals: Indicators vs Likelihood continued</title>
      <link>/2011/01/31/warning-signals-indicators-vs-likelihood-continued/</link>
      <pubDate>Mon, 31 Jan 2011 16:49:22 +0000</pubDate>
      
      <guid>/2011/01/31/warning-signals-indicators-vs-likelihood-continued/</guid>
      <description>Continuing to explore examples
Some difficulty in the &amp;ldquo;snowfall&amp;rdquo; parallel computation engine, removing the ~/.sfCluster directory seems to reset the error &amp;ldquo;unable to unserialize nodes&amp;hellip;&amp;ldquo; Also don&amp;rsquo;t have good handling of variable names for tracking the boostrapping of parameters. For the moment have just added a toggle to suppress these to avoid dim mismatch in rownames command. Strange that this happens to the indicator_vs_likelihood code but not to the nearly-identical call to montecarlotest() in lin_bifur_models.</description>
    </item>
    
    <item>
      <title>more Phylogenetic signal metrics &amp; Brownie comparison</title>
      <link>/2011/01/31/more-phylogenetic-signal-metrics-brownie-comparison/</link>
      <pubDate>Mon, 31 Jan 2011 16:31:42 +0000</pubDate>
      
      <guid>/2011/01/31/more-phylogenetic-signal-metrics-brownie-comparison/</guid>
      <description>Blomberg&amp;rsquo;s K estimates on trees of different sizes. Estimates differ across the distribution of possible data generated by BM model and generated from white noise. In principle, the K statistic should be able to distinguish between data simulated between these two. Of course, the ability to do this depends on the size and structure of the phylogenetic tree &amp;ndash; Blomberg&amp;rsquo;s K is not an estimate of whether the phylogeny is sufficiently structured as to be informative.</description>
    </item>
    
    <item>
      <title>Notes on Bokma 2010: evolution in drifts and jumps</title>
      <link>/2011/01/31/notes-on-bokma-2010-evolution-in-drifts-and-jumps/</link>
      <pubDate>Mon, 31 Jan 2011 12:15:45 +0000</pubDate>
      
      <guid>/2011/01/31/notes-on-bokma-2010-evolution-in-drifts-and-jumps/</guid>
      <description>Bokma 2010 asks if there is an analytic expression for the likelihood in the evolutionary model he describes.
The trait value of the process is determined by two things &amp;ndash; a Brownian motion random walk (diffusion) with rate parameter $ s_a^2$ and speciation events. Under a speciation event, the trait jumps to a new value that differs from it&amp;rsquo;s parent&amp;rsquo;s by some amount chosen from zero-mean normal distribution with variance $ s_c^2$.</description>
    </item>
    
    <item>
      <title>Warning signals of differing stregths by likelihood and by indicator</title>
      <link>/2011/01/28/warning-signals-of-differing-stregths-by-likelihood-and-by-indicator/</link>
      <pubDate>Fri, 28 Jan 2011 17:59:25 +0000</pubDate>
      
      <guid>/2011/01/28/warning-signals-of-differing-stregths-by-likelihood-and-by-indicator/</guid>
      <description>Strong indicator example: m=-0.049, T=100, Ro=5 And likelihood ratio monte carlo model choice (nonparametric bootstrap) has no trouble: Less strong stability loss, m=-0.02 How statistics perform: </description>
    </item>
    
    <item>
      <title>Phylogenetic Signal metrics</title>
      <link>/2011/01/28/phylogenetic-signal-metrics/</link>
      <pubDate>Fri, 28 Jan 2011 17:52:39 +0000</pubDate>
      
      <guid>/2011/01/28/phylogenetic-signal-metrics/</guid>
      <description>Blomberg&amp;rsquo;s K distribution under data simulated from BM on the geospiza tree (red) compared to simulating independent random draws from the Normal distribution.
Would be good to compare with differing size trees.</description>
    </item>
    
    <item>
      <title>Warning signals vs model choice</title>
      <link>/2011/01/27/warning-signals-vs-model-choice/</link>
      <pubDate>Thu, 27 Jan 2011 17:11:14 +0000</pubDate>
      
      <guid>/2011/01/27/warning-signals-vs-model-choice/</guid>
      <description>Continuing writing and experimentation for examples in the warning signals manuscript, figuring out how to explain the need for the likelihood-based model comparison approach rather than the standard method of summary statistics.
The traditional approach computes a particular &amp;ldquo;leading indicator&amp;rdquo;, such as variance or autocorrelation, in a sliding window along the time series. If the system is loosing stability approaching a bifurcation, it&amp;rsquo;s leading eigenvalue must go through zero and hence shows critical slowing down, with the associated pattern of increasing autocorrelation an increasing variance.</description>
    </item>
    
    <item>
      <title>McElreath: A Bayesian approach to hierarchical modeling, using R to build our own estimator from scratch</title>
      <link>/2011/01/26/mcelreath-a-bayesian-approach-to-hierarchical-modeling-using-r-to-build-our-own-estimator-from-scratch/</link>
      <pubDate>Wed, 26 Jan 2011 17:12:18 +0000</pubDate>
      
      <guid>/2011/01/26/mcelreath-a-bayesian-approach-to-hierarchical-modeling-using-r-to-build-our-own-estimator-from-scratch/</guid>
      <description>CPB workshop continues, introduction to Bayesian inference.
McElreath discusses (slides):
 Bayes Theorem  $$ P(\theta | D) = \frac{Pr(D|\theta) Pr(\theta )}{Pr(D)} $$
 Philosophy of Priors, Uninformative Priors
 Confidence intervals / credible intervals for free
 Computing the posterior: Directly or by MCMC
  Nice visual example of updating prior as we add data:
[gist id=&amp;ldquo;797795&amp;rdquo;]
 King Markov and the chain islands.
 Evaluating: Burn in , autocorrelation.</description>
    </item>
    
    <item>
      <title>Intro Ecology Lecture at University of the Pacific</title>
      <link>/2011/01/25/intro-ecology-lecture-at-university-of-the-pacific/</link>
      <pubDate>Tue, 25 Jan 2011 10:12:06 +0000</pubDate>
      
      <guid>/2011/01/25/intro-ecology-lecture-at-university-of-the-pacific/</guid>
      <description>I was invited to give a guest lecture on introductory ecology for an introductory environmental science course at University of the Pacific in Stockton today. This provided both a nice outreach opportunity and a chance to speak to a full introductory class for 1:45hr, which I haven&amp;rsquo;t done before.
I ran the class something as an experiment for myself as much as an instruction. Having spent considerable time thinking more-or-less abstractly about effective teaching strategies with carefully planned lectures, activities, objectives, and assessments, I found myself suddenly at the other end of the spectrum: faced with giving a long lecture covering pretty much my entire field with little time to prepare and only the fuzziest objectives.</description>
    </item>
    
    <item>
      <title>McElreath Hierarchical Models</title>
      <link>/2011/01/24/mcelreath-hierarchical-models/</link>
      <pubDate>Mon, 24 Jan 2011 16:03:31 +0000</pubDate>
      
      <guid>/2011/01/24/mcelreath-hierarchical-models/</guid>
      <description>CPB workshop on hierarchal modeling starts off today with Richard McElreath&amp;rsquo;s introduction.[ref]These are my own notes as taken during the seminar and may not accurately reflect everything. I merely confirm with the speaker that my notes are publicly visible. My own commentary/thoughts indicated in square brackets. As these notes are taken directly during seminar (on my droid phone &amp;ndash; saves me transcribing, later) , please forgive typos and shorthand.[/ref] &amp;ldquo;This is a workshop, not a job talk, meaning I&amp;rsquo;m going to give away the tricks and you have to learn something.</description>
    </item>
    
    <item>
      <title>Felsenstein (web) seminar</title>
      <link>/2011/01/24/felsenstein-web-seminar/</link>
      <pubDate>Mon, 24 Jan 2011 11:13:08 +0000</pubDate>
      
      <guid>/2011/01/24/felsenstein-web-seminar/</guid>
      <description>Joe Felsenstein on phyloseminar (watch here). This morning. [ref]These are my own notes as taken during the seminar and may not accurately reflect everything. I merely confirm with the speaker that my notes are publicly visible. My own commentary/thoughts indicated in square brackets.[/ref] Discusses bridging population genetics &amp;amp; comparative methods: where does covariation in traits across a phylogeny come from?
Morphometrics Using morphometrics (digitized landmarks [though now we can do spherical harmonics, CT scans, etc]) to evolve on a phylogeny under BM rather than use that data to infer phylogeny.</description>
    </item>
    
    <item>
      <title>Shape as well as size influence power of phylogeny</title>
      <link>/2011/01/21/shape-as-well-as-size-influence-power-of-phylogeny/</link>
      <pubDate>Fri, 21 Jan 2011 17:34:57 +0000</pubDate>
      
      <guid>/2011/01/21/shape-as-well-as-size-influence-power-of-phylogeny/</guid>
      <description>Finished the runs comparing the power to detect different strengths of selection using different size phylogenetic trees all generated under pure-birth process simulation, and then under trees of the same size but gradually lengthening the tips, (or rather shortening everything but the tips) using the lambda transformation, which puts the informative differences deep in the past where they are less reflected in the stationary state. Bure-birth (also the constant rate birth-death) trees on the other hand are particularly twiggy and quite informative.</description>
    </item>
    
    <item>
      <title>Estimating phylogenetic signal (lambda) on large trees</title>
      <link>/2011/01/20/estimating-phylogenetic-signal-lambda-on-large-trees/</link>
      <pubDate>Thu, 20 Jan 2011 19:21:23 +0000</pubDate>
      
      <guid>/2011/01/20/estimating-phylogenetic-signal-lambda-on-large-trees/</guid>
      <description>Used a simulated tree of 600 taxa to show that lambda distribution continues to improve with larger taxa. Recall the results with 13 taxa and with 23 taxa:
[flickr size=&amp;ldquo;small&amp;rdquo; float=&amp;ldquo;left&amp;rdquo;]5370016511 [/flickr]
[flickr size=&amp;ldquo;small&amp;rdquo; float=&amp;ldquo;right&amp;rdquo;]5370635360 [/flickr]
compare to 281 taxa and then 600 taxa:
[flickr size=&amp;ldquo;small&amp;rdquo; float=&amp;ldquo;left&amp;rdquo;]5310150538 [/flickr]
By 281 taxa the distribution is at least centered on the true value. The width of that distribution gets somewhat tighter with more taxa, though the increase is marginal.</description>
    </item>
    
    <item>
      <title>Robert Hijmans on Models to predict sp response to climate change</title>
      <link>/2011/01/19/robert-hijmans-on-models-to-predict-sp-response-to-climate-change/</link>
      <pubDate>Wed, 19 Jan 2011 12:53:34 +0000</pubDate>
      
      <guid>/2011/01/19/robert-hijmans-on-models-to-predict-sp-response-to-climate-change/</guid>
      <description>Notes from seminar.[ref]These are my own notes as taken during the seminar and may not accurately reflect everything. I merely confirm with the speaker that my notes are publicly visible. My own commentary/thoughts indicated in square brackets. [/ref] Robert speaks to an utterly packed room. Predicting future range of species: 4 topics. 1 cross-validation, 2 niches, 3 unit (sp?), 4 mechanism. Presence-absence predictions from machine learning, maxent.
Opening: AUC for measure of fit- lousy stat!</description>
    </item>
    
    <item>
      <title>Reflections from #scio11: Saturday&#39;s Open Science Track</title>
      <link>/2011/01/15/reflections-from-scio11-saturdays-open-science-track/</link>
      <pubDate>Sat, 15 Jan 2011 23:12:45 +0000</pubDate>
      
      <guid>/2011/01/15/reflections-from-scio11-saturdays-open-science-track/</guid>
      <description>Have just returned from the amazing and energetic science online 2011 conference, where I will now, like the rest of the attendees, turn to catching up on sleep, following new online acquaintances, struggling not to append #scio11 to everything I write, and composing that nearly obligatory post-event blog entry we all use like a glass of water after a party; with the hope in may help me metabolize the experience.</description>
    </item>
    
    <item>
      <title>evolution- wrightscape</title>
      <link>/2011/01/11/phylogenetics-wrightscape/</link>
      <pubDate>Tue, 11 Jan 2011 15:38:41 +0000</pubDate>
      
      <guid>/2011/01/11/phylogenetics-wrightscape/</guid>
      <description>Interesting meeting with Peter to discuss a variety of issues in comparative phylogenetics. Short notes:
 Transforming data, log data
 Trends in directions in convergent traits
 multivariate inference
 Manuscript
  Wrightscape First have to test PMC to make sure it works with OUCH classes. Also adding PMC-required wrappers for wrightscape. Ended up modifying PMC to handle the case of simulate functions that return replicates, like these packages do.</description>
    </item>
    
    <item>
      <title>Warning Signals, Power and Sufficient Statistics</title>
      <link>/2011/01/10/warning-signals-power-and-sufficient-statistics/</link>
      <pubDate>Mon, 10 Jan 2011 15:57:57 +0000</pubDate>
      
      <guid>/2011/01/10/warning-signals-power-and-sufficient-statistics/</guid>
      <description>Working on warning signals manuscript. Looking at overall powercurves as a function of sample size and rate of stability loss in both models. Planning to repeat that analysis with summary statistics approach to illustrate the relative loss in power of the &amp;ldquo;leading indicator&amp;rdquo; approach. (simulations just set up to run now, figures should appear below as they complete. Click on figures for links to code).
 Power curve based on transcritical bifurcation as a function of rate of stability loss:  [flickr-gallery mode=&amp;ldquo;search&amp;rdquo; tags=&amp;ldquo;warningsignals, LTC, stability&amp;rdquo; tag_mode=&amp;ldquo;all&amp;rdquo; min_upload_date=&amp;ldquo;2011-01-10 00:00:00&amp;rdquo; max_upload_date=&amp;ldquo;2011-01-12 23:59:59&amp;rdquo;]</description>
    </item>
    
    <item>
      <title>Phylo Monte Carlo for diversification rates</title>
      <link>/2011/01/09/phylo-monte-carlo-for-diversification-rates/</link>
      <pubDate>Sun, 09 Jan 2011 13:28:55 +0000</pubDate>
      
      <guid>/2011/01/09/phylo-monte-carlo-for-diversification-rates/</guid>
      <description>Writing function wrappers for geiger functions to perform Phylogenetic Monte Carlo. Any object that has methods defined for update.objecttype (object, data) and simulate.objecttype(data), and loglik.object(object) should be able to use the montecarlotest() function. OUCH almost does this but not quite, since the datatype returned by &amp;lsquo;simulate&amp;rsquo; doesn&amp;rsquo;t match that needed by &amp;lsquo;update&amp;rsquo;. OUCH also uses S4 class styles.
Wrote wrappers for ouch functions such that the ouch models will work with the same montecarlotest() code.</description>
    </item>
    
    <item>
      <title>Two routes to adaptive branching</title>
      <link>/2011/01/06/two-routes-to-adaptive-branching/</link>
      <pubDate>Thu, 06 Jan 2011 10:56:11 +0000</pubDate>
      
      <guid>/2011/01/06/two-routes-to-adaptive-branching/</guid>
      <description>Simulations completed, help accentuate the different paths for branching. When the most failures occur while waiting for the first mutation to enter first established dimorphism, mutation rate seems limiting (left):
(right) With a higher mutation rate, most collapses back to monomorphism occur after a mutation successfully invades in the dimorphic population. Unfortunately these runs result in large fraction of the ensemble never reaching the final branching, those that do, do so fast:</description>
    </item>
    
    <item>
      <title>Finishing up my #SICB Presentation</title>
      <link>/2011/01/02/finishing-up-my-sicb-presentation/</link>
      <pubDate>Sun, 02 Jan 2011 21:00:03 +0000</pubDate>
      
      <guid>/2011/01/02/finishing-up-my-sicb-presentation/</guid>
      <description>Finished up my SICB presentation tweaks, slides now up on slideshare, flying off to the conference tomorrow. Created this in OpenOffice, started adding animations and then decided it would be more reliable to just duplicate slides to have parts appear (really just for the explanation of the likelihood ratio distributions under each model). Next time think I&amp;rsquo;ll stick with my usual inkscape slides tied together with latex beamer, the lack of vector images in this one is not ideal.</description>
    </item>
    
    <item>
      <title>Comparative evolution: Is the data informative?</title>
      <link>/2010/12/31/comparative-phylogenetics-is-the-data-informative/</link>
      <pubDate>Fri, 31 Dec 2010 21:22:07 +0000</pubDate>
      
      <guid>/2010/12/31/comparative-phylogenetics-is-the-data-informative/</guid>
      <description>Working on my SICB talk, going a little further into the example of fitting the lambda model on the Anoles data to illustrate the ways in which we may lack sufficient data for the question.
 The dataset may not contain adequate signal of the parameter / phenomenon in question
 The dataset may not be adequately large
  Anoles data set (23 taxa):
This first image shows the distribution of lambda values estimated from many datasets all simulated under a lambda = 0.</description>
    </item>
    
    <item>
      <title>Stochastic limits to evolutionary branching</title>
      <link>/2010/12/30/stochastic-limits-to-evolutionary-branching/</link>
      <pubDate>Thu, 30 Dec 2010 22:12:47 +0000</pubDate>
      
      <guid>/2010/12/30/stochastic-limits-to-evolutionary-branching/</guid>
      <description>My last post was a bit pessimistic, sometimes I can still miss the forest for the trees. Hidden in those figures, the main point has been staring me in the face. So let&amp;rsquo;s try this again.
Stochastic limits to evolutionary branching is the story of two dueling timescales. The first timescale is that of the evolutionary process: the frequency of steps (mutation rate, $ \mu$) and the size of the steps (mutation kernel standard deviation $ \sigma_{\mu}$), on top of which we add the selection gradient, created by the ecology.</description>
    </item>
    
    <item>
      <title>Open Notebook Science Abstract</title>
      <link>/2010/12/30/open-notebook-science-abstract/</link>
      <pubDate>Thu, 30 Dec 2010 17:54:37 +0000</pubDate>
      
      <guid>/2010/12/30/open-notebook-science-abstract/</guid>
      <description>In addition to my primary research categories, I make some entries in my lab notebook to document and reflect on my experiment in open notebook science. This includes my notes on tools I try out for open and collaborative science, including uses of social media, cloud computing, and scientific databases and repositories.
This serves as a cover-page for the open science entries in my notebook, displaying the most recent entries, articles, figures and code through rss feeds.</description>
    </item>
    
    <item>
      <title>Parameter exploration in adaptive dynamics branching</title>
      <link>/2010/12/30/parameter-exploration-in-adaptive-dynamics-branching/</link>
      <pubDate>Thu, 30 Dec 2010 16:52:09 +0000</pubDate>
      
      <guid>/2010/12/30/parameter-exploration-in-adaptive-dynamics-branching/</guid>
      <description>Ran a series of simulations overnight to explore aspects of time-to-branching at different phases of the branching process. Still using only 16 replicates per data point, though increased maximum time for a run another order of magnitude to avoid timing out runs influencing the dataset for the slow-rate parameters. Still seems to suggest a regime beyond which branching becomes completely improbable. Not clear that the transition is a sharp as the Arrhenius approximation might suggest.</description>
    </item>
    
    <item>
      <title>adaptive-dynamics Simulations</title>
      <link>/2010/12/29/adaptive-dynamics-simulations/</link>
      <pubDate>Wed, 29 Dec 2010 16:29:25 +0000</pubDate>
      
      <guid>/2010/12/29/adaptive-dynamics-simulations/</guid>
      <description>Setting up some adaptive dynamics simulations to complete the parameter-space search. Currently the demo library contains two files, providing the coexistence-only tests and the full evolutionary simulation. This picks up from Aug 30/Sept 1 on coexistence times and Aug 12&amp;frasl;13 entries on waiting times until branching (while still on OWW).
coexistence times coexist_times.R creates contour plots of the coexistence time under demographic noise expected at a particular position of the pairwise invasibility plot (PIP).</description>
    </item>
    
    <item>
      <title>DoE renewal and a year in review</title>
      <link>/2010/12/24/doe-renewal-and-a-year-in-review/</link>
      <pubDate>Fri, 24 Dec 2010 03:24:40 +0000</pubDate>
      
      <guid>/2010/12/24/doe-renewal-and-a-year-in-review/</guid>
      <description>This time of year I have to file my renewal for my DOE Fellowship, including a statement of accomplishments and a summary of the computational aspects of my work. Seemed like a good idea to jot these down in my notebook as well:
synopsis of accomplishments over the year: In January I passed my qualifying exam, advancing to candidacy where my dissertation remains my only requirement. In March I attended the phylogenetics workshop in Bodega Bay, an internationally known week-long training program.</description>
    </item>
    
    <item>
      <title>Writing, Cloud Computing, and #scio11</title>
      <link>/2010/12/23/writing-cloud-computing-and-scio11/</link>
      <pubDate>Thu, 23 Dec 2010 19:08:58 +0000</pubDate>
      
      <guid>/2010/12/23/writing-cloud-computing-and-scio11/</guid>
      <description>Working on a few things in today&amp;rsquo;s lab notebook entry. Some more notes on exploring cloud computing tools, sketching out some ideas for my #scio11 science online panel discussion on open notebook science, and otherwise working on my phylogenetics mansucript.
Cloud Computing An interesting package was announced over the r-sig-hpc list today, creating an arbitrarily large Hadoop cluster out of Amazon EC2 instances directly from the R command line. JD Long has been very responsive to my naive questions on setting it up, so I was able to quickly activate an Elastic Map Reduce account via Amazon Web Services and run the example code.</description>
    </item>
    
    <item>
      <title>Sun: Visualizing my coding over the past year</title>
      <link>/2010/12/20/sun-visualizing-my-coding-over-the-past-year/</link>
      <pubDate>Mon, 20 Dec 2010 00:05:10 +0000</pubDate>
      
      <guid>/2010/12/20/sun-visualizing-my-coding-over-the-past-year/</guid>
      <description>Not really working today, as holidays approach, but came across the Gource toolkit for creating video visualization from git development (inspired by the Mendeley&amp;rsquo;s example). So in the spirit of year-in-review reflections, here&amp;rsquo;s my development from the past year (just for the phylogenetic statistics work).
Quality is a little too poor to read file names, more entertaining than practical. Other user icons appear in December corresponding with my move to running the code from Amazon cloud.</description>
    </item>
    
    <item>
      <title>Thurs: writing section on comparing to AIC</title>
      <link>/2010/12/16/thurs-writing-section-on-comparing-to-aic/</link>
      <pubDate>Thu, 16 Dec 2010 22:50:53 +0000</pubDate>
      
      <guid>/2010/12/16/thurs-writing-section-on-comparing-to-aic/</guid>
      <description>Phylogenetics writing still continues.
AIC Error rates
Choosing by having &amp;lt; 5% probability of rejecting the simpler model when it is true.
Choosing the equal-likelihood division:</description>
    </item>
    
    <item>
      <title>Weds: Example sets &amp; more EC2</title>
      <link>/2010/12/15/weds-example-sets-more-ec2/</link>
      <pubDate>Wed, 15 Dec 2010 16:24:46 +0000</pubDate>
      
      <guid>/2010/12/15/weds-example-sets-more-ec2/</guid>
      <description>A bit delayed from having to rerun analyses on EC2 (still learning&amp;hellip;) More to run today (lambda trials for Anoles &amp;ndash; should really recode this in C!).
Trying to decide if its best to start off with the power curves and work backwards or build up from the basics. Probably doesn&amp;rsquo;t matter too much which. Also figuring out which examples to present first:
Where the painted trees are the following:</description>
    </item>
    
    <item>
      <title>Tues: evolution thoughts while writing...</title>
      <link>/2010/12/14/tues-phylogenetics-thoughts-while-writing/</link>
      <pubDate>Tue, 14 Dec 2010 17:06:57 +0000</pubDate>
      
      <guid>/2010/12/14/tues-phylogenetics-thoughts-while-writing/</guid>
      <description>Again spending most of the day writing. (Maybe) processing some ideas in writing by writing in my notebook as I make my edits.
Ideas I&amp;rsquo;m trying to get across in today&amp;rsquo;s edits Parameter estimation is more demanding of the data than model choice. Knowing if a value is different from zero is easier than knowing what it is.
Code updates to-do  Need to add S3 wrapper functions for ouch so both can call montecarlotest() in the pmc package.</description>
    </item>
    
    <item>
      <title>Back to Writing</title>
      <link>/2010/12/13/back-to-writing/</link>
      <pubDate>Mon, 13 Dec 2010 10:56:09 +0000</pubDate>
      
      <guid>/2010/12/13/back-to-writing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Citations</title>
      <link>/2010/12/11/citations/</link>
      <pubDate>Sat, 11 Dec 2010 07:06:22 +0000</pubDate>
      
      <guid>/2010/12/11/citations/</guid>
      <description>This evening I&amp;rsquo;m testing extensions to find a better way to include citations in my entries. Thus far I&amp;rsquo;ve use Mendeley&amp;rsquo;s convenient copy-paste citation tool to paste the whole citation in, which I suppose could work reasonably smoothly with the nice footnotes plugin I recently adopted. However, this still requires a couple more steps than I need to cite in my LaTeX text editor or in OpenOffice.
Using the papercite plugin, I can add citations to posts in much the same way that I add them to my latex documents, using the citation key created Mendeley when it makes my bibtex file.</description>
    </item>
    
    <item>
      <title>socialR: Reproducible Research &amp; Notebook integration with R</title>
      <link>/2010/12/11/socialr-an-r-package-to-track-the-status-of-computations-with-social-network-tools/</link>
      <pubDate>Sat, 11 Dec 2010 03:44:54 +0000</pubDate>
      
      <guid>/2010/12/11/socialr-an-r-package-to-track-the-status-of-computations-with-social-network-tools/</guid>
      <description>I&amp;rsquo;ve created an R package that uses social media tools for reproducible research. The goal of the package is this: whenever I run a code, output figures are automatically added to my figure repository (Flickr), linked to the timestamped version of the code that produced them in the code repository. Figures should be tagged by project and be embedded selectively or automatically into this lab notebook. The basic workflow of the notebook looks like this:[ref]Diagram of my notebook as presented at Science Online, 2011, see other slides in my entry on this.</description>
    </item>
    
    <item>
      <title>Warning signals manuscript</title>
      <link>/2010/12/10/warning-signals-manuscript/</link>
      <pubDate>Fri, 10 Dec 2010 21:10:38 +0000</pubDate>
      
      <guid>/2010/12/10/warning-signals-manuscript/</guid>
      <description>Meeting with Alan today to discuss outline. Came up with basic break-down of paragraphs:
 Intro/Abstract
 Scope: Previous work, scope simple example existence of warning signal/CSD is clear. Identifiability/Power not clear. Mention the issue of Replicates
 Nonlinearity not observed with infinite data
 reasons detection fails: Identifiability issue &amp;amp; Power issue. Example signal that exists but inadequate power to detect?
 Eigenvalue story
 Probability of data vs Probability of a statistic</description>
    </item>
    
    <item>
      <title>Exploring Power in Warning Signals</title>
      <link>/2010/12/09/exploring-power-in-warning-signals/</link>
      <pubDate>Thu, 09 Dec 2010 23:03:40 +0000</pubDate>
      
      <guid>/2010/12/09/exploring-power-in-warning-signals/</guid>
      <description>Started trying to get the power curves for sample-size and rate of change. Currently focusing on the transcritical bifurcation model. This first pass uses just 100 replicates, which appears to be not nearly enough. Need some troubleshooting on handling to get power curves out. Scroll through, the set has 65 different images:
[flickr-gallery mode=&amp;ldquo;tag&amp;rdquo; tags=&amp;ldquo;stochpowercurvesslides&amp;rdquo;]
(code ids in image discription, compare to structured-popultions git log. )
Includes plots of the timeseries, giving a visual clue of how dramatic the warning signal is under each case.</description>
    </item>
    
    <item>
      <title>Practice SICB Presentation</title>
      <link>/2010/12/08/practice-sicb-presentation/</link>
      <pubDate>Wed, 08 Dec 2010 22:21:34 +0000</pubDate>
      
      <guid>/2010/12/08/practice-sicb-presentation/</guid>
      <description>Gave my practice talk for Society for Integrative and Comparative Biology in Wainwright lab this afternoon, after (not quite) finishing the presentation. Trying to figure out the best way to introduce these ideas to a broad audience (same challenge as with the manuscript).
Talk storyboard:
Looking at other talks in my session: Macroevolution I - Methods and Character Evolution, looks like a reasonably sophisticated group.
Good feedback from the Wainwright Lab:  Emphasize: Currently we worry that we don&amp;rsquo;t have the right models.</description>
    </item>
    
    <item>
      <title>Mapping out SICB Presentation: Is your phylogeny informative?</title>
      <link>/2010/12/07/mapping-out-sicb-presentation-is-your-phylogeny-informative/</link>
      <pubDate>Tue, 07 Dec 2010 22:42:08 +0000</pubDate>
      
      <guid>/2010/12/07/mapping-out-sicb-presentation-is-your-phylogeny-informative/</guid>
      <description>Assembling material/outline for my SICB presentation in January, will be giving a practice talk in the Wainwright lab on Wednesday. 15 minute presentation with 5 minutes for questions.
 Designing presentation in &amp;ldquo;storyboard&amp;rdquo; format in Inkscape. Will figure out if I convert to slides or not.
 Simulations under the Anoles dataset to show posterior distributions of lambda. Exploring the connection between the likelihood of a parameter under each model to that of the distributions of the likelihood ratio.</description>
    </item>
    
    <item>
      <title>follow up from Fri discussions: Revisiting post-predictive evaluation</title>
      <link>/2010/12/06/follow-up-from-fri-discussions-revisiting-post-predictive-evaluation/</link>
      <pubDate>Mon, 06 Dec 2010 21:24:00 +0000</pubDate>
      
      <guid>/2010/12/06/follow-up-from-fri-discussions-revisiting-post-predictive-evaluation/</guid>
      <description>A few weeks ago, a seminar prompted me to take a closer look at a particular post-predictive evaluation technique applied reasonably often in our recent literature,see earlier entry. I think by phrasing the approach more concisely and precisely it will be clear what the difficulty is.
As usual, we consider some data $ \vec X$ and a set of $ N$ models specified by parameters, $ \lbrace \vec \theta_1, \vec \theta_2, \vec \ldots \theta_N\rbrace $, then we can express the likelihood of the model as the probability of the data under the given model and parameter values:</description>
    </item>
    
    <item>
      <title>Identifying Warning Signals</title>
      <link>/2010/12/04/identifying-warning-signals/</link>
      <pubDate>Sat, 04 Dec 2010 22:41:08 +0000</pubDate>
      
      <guid>/2010/12/04/identifying-warning-signals/</guid>
      <description>Updated methods for the Monte Carlo estimate of the distributions of likelihood ratios completed on Wednesday this week, modulo some troubleshooting of code. Now exploring the parameter range in which warning signals can be identified with accurate power. Individual power tests provide a good start, but remains to generate power curves for each bifurcation type by magnitude of the loss of stability, length/duration of the timeseries and the sampling frequency.</description>
    </item>
    
    <item>
      <title>Thoughts on the New Policies for Data Archiving at NSF and in Common Journals</title>
      <link>/2010/12/03/nsf-and-journal-data-archiving/</link>
      <pubDate>Fri, 03 Dec 2010 19:08:53 +0000</pubDate>
      
      <guid>/2010/12/03/nsf-and-journal-data-archiving/</guid>
      <description>This post is a work in progress, a scratch pad for me to start assembling what I&amp;rsquo;ve been learning about and resources pertaining to the new policies emerging from NSF and journals relevant to ecology and evolution. Hoping to highlight not only the policies, but the issues, opportunities, and concerns around them.
I am hoping to help organize a workshop to discuss these issues in my department this Winter. The Davis Open Science group, is planning a series of these workshops, hoping to work with departments, the libraries and the UC Davis Office of Research and its Responsible Conduct of Research  program (in compliance with NIH/NSF ethics requirements), as well as resident faculty and editors.</description>
    </item>
    
    <item>
      <title>CPB : David Collar</title>
      <link>/2010/12/01/cpb-seminar-david-collar/</link>
      <pubDate>Wed, 01 Dec 2010 00:58:28 +0000</pubDate>
      
      <guid>/2010/12/01/cpb-seminar-david-collar/</guid>
      <description>Identifying ecological constraint on morph and function using phylogenies. 2007 CPB grad, losos post doc, now postdoc w Rita.
Indep origin of &amp;lsquo;bass&amp;rsquo; cranial morph. Also unique patterns- stonefish. Phylo comparative methods to address why and how. Three types of factors on morphology: ecological, time!, intrinsic (genetic, behavior) constraints. Outline:
I. determinants of morph diversification.
II. Complex traits.
I. Diversification rate vary by habitat? (Dragon lizards- diverse morph, diverse habitat). Reconstruct history of habitat use (4 types), (assign discrete traits) then stoch character maps to reconstruct (paint) tree.</description>
    </item>
    
    <item>
      <title>Tues: Fitting the limiting OU models to each bifurcation</title>
      <link>/2010/11/30/tues-fitting-the-limiting-ou-models-to-each-bifurcation/</link>
      <pubDate>Tue, 30 Nov 2010 22:56:03 +0000</pubDate>
      
      <guid>/2010/11/30/tues-fitting-the-limiting-ou-models-to-each-bifurcation/</guid>
      <description>Yesterday I derived the linearized SDEs for the saddle node bifurcation :
$$ dX = 2\sqrt{r(t)} (\sqrt{r(t)} + \theta -X) dt + \sigma \sqrt{\sqrt{r(t)}+\theta} dB_t $$
and the transcritical bifurcation
$$ dX = r(t) (K - X) dt + \sqrt{K} dB_t $$
Now to implement them for fitting by likelihood using generic $ r(t) $. I go back to the warning() model implemented in sde_likelihood.R code. We can just solve the odes directly:</description>
    </item>
    
    <item>
      <title>Further treatment of the limiting models</title>
      <link>/2010/11/29/further-treatment-of-the-limiting-models/</link>
      <pubDate>Mon, 29 Nov 2010 19:01:29 +0000</pubDate>
      
      <guid>/2010/11/29/further-treatment-of-the-limiting-models/</guid>
      <description>Have spent the last three days building and testing the infrastructure to fit the canonical form of a saddle-node (fold) bifurcation by likelihood. Actually I don&amp;rsquo;t use the canonical form straight up: $ dx/dt = x^2 +r$ cannot be fit directly in this manner, since it needs a couple scale transformations on the variables to get the units right (a multiple for the unit scale and an additive factor for the zero point), and more importantly, isn&amp;rsquo;t a stochastic model so cannot assign probabilities to the outcomes.</description>
    </item>
    
    <item>
      <title>Challenges in estimating phylogenetic signal</title>
      <link>/2010/11/29/challenges-in-estimating-phylogenetic-signal/</link>
      <pubDate>Mon, 29 Nov 2010 07:21:00 +0000</pubDate>
      
      <guid>/2010/11/29/challenges-in-estimating-phylogenetic-signal/</guid>
      <description>Uncertainty in estimate of lambda illustrated by simulating 1000 data sets on the Geopsiza tree under a model with lambda = 0.62. Shows the high uncertainty in estimating lambda at all, despite the power in the estimate at this value.
(Code)
Will fill this out further later. Will be interesting to compare at different base values of lambda used for the simulation.
Have updated the codbase to provide bootstraps of parameters as part of the monte carlo output.</description>
    </item>
    
    <item>
      <title>Likelihoods for quadratic models cont</title>
      <link>/2010/11/28/likelihoods-for-quadratic-models-cont/</link>
      <pubDate>Sun, 28 Nov 2010 21:14:09 +0000</pubDate>
      
      <guid>/2010/11/28/likelihoods-for-quadratic-models-cont/</guid>
      <description>Considering the fits of the quadratic models from yesterday.
[flickr-gallery mode=&amp;ldquo;tag&amp;rdquo; tags=&amp;ldquo;quadraticfitslides&amp;rdquo; tag_mode=&amp;ldquo;all&amp;rdquo;]
Analysis of fits Of course these fits rely entirely on mapping the location of the stable point and the slope through that point, something they still cannot do all that well. In this parameterization the the stable intercept is $$ \hat x = \sqrt{r}+\theta $$ and slope at intercept is $$ \frac{\partial f(\hat x)}{\partial x} = -2\sqrt{r} $$ This creates a numerical optimization problem, since there is high importance on getting the mean right, and less on the variance, the routine tends to fix the combination of r and theta to get the mean right, and then cannot change r to get the slope correct without getting penalized for the loss of likelihood in changing the mean.</description>
    </item>
    
    <item>
      <title>Implementing Likelihoods for quadratic models</title>
      <link>/2010/11/27/implementing-likelihoods-for-quadratic-models/</link>
      <pubDate>Sat, 27 Nov 2010 11:09:06 +0000</pubDate>
      
      <guid>/2010/11/27/implementing-likelihoods-for-quadratic-models/</guid>
      <description>Working from the quadratic model for the saddle node bifurcation rather than the linear (OU) model. Recall that the dynamics are:
$$dX = \left( r - (x-\theta)^2\right)dt + \beta \sqrt{X} dB_t $$
and the linear noise approximation gives a linear Fokker Planck equation such that the probability distribution is Gaussian with moments ((corrected from yesterday to scale noise, basically as pure-birth Poisson process))
$$\frac{d \hat{x}}{dt} &amp;amp;= r - (\hat{x}-\theta)^2 $$ $$ \frac{d \sigma^2}{dt} &amp;amp;= -2 (\hat x - \theta )\sigma^2 + \beta \left(r - (\hat{x}-\theta)^2 \right) $$</description>
    </item>
    
    <item>
      <title>Tweets from an Ecology Field class </title>
      <link>/2010/11/25/tweets-from-an-ecology-field-class/</link>
      <pubDate>Thu, 25 Nov 2010 02:06:15 +0000</pubDate>
      
      <guid>/2010/11/25/tweets-from-an-ecology-field-class/</guid>
      <description>I just spoke with Professor Mau Stanton, a leading researcher in our field and an award-winning teacher, about the potential for using twitter in her field ecology course. Though never having used any social media before, Mau has both clear and clever idea of how she wants to apply it in this 15-student field class.
The challenge: Students don&amp;rsquo;t seem to read email as much any more, and are often not at a computer.</description>
    </item>
    
    <item>
      <title>Warning signals: Likelihoods Straight-up</title>
      <link>/2010/11/24/warning-signals-likelihoods-straight-up/</link>
      <pubDate>Wed, 24 Nov 2010 21:44:57 +0000</pubDate>
      
      <guid>/2010/11/24/warning-signals-likelihoods-straight-up/</guid>
      <description>Meeting with Alan this morning. I haven&amp;rsquo;t solved likelihood of power spectra (previous couple entries in Stoch. Pop / warning signals), though after meeting with Sebastian (11&amp;frasl;9) probably the best method works from the correlation function. Define a new stochastic process Y $$ Y_1 = X_1 X_2 + X_2 X_3 + X_3 X_4 + \ldots $$ $$ Y_2 = X_1 X_3 + X_2 X_4 + \ldots $$ $$ Y_3 = \ldots $$</description>
    </item>
    
    <item>
      <title>Power in simple tests</title>
      <link>/2010/11/22/power-in-simple-tests/</link>
      <pubDate>Mon, 22 Nov 2010 08:00:33 +0000</pubDate>
      
      <guid>/2010/11/22/power-in-simple-tests/</guid>
      <description>Exploring power in simple tree models. With the smaller tree from the _geospiza _dataset, (14 tips, left) is less than yesterday&amp;rsquo;s in the bimaculus Anoles (with 23 tips, right)
(code)
Also wrote the OUCH-based wrapper function to fit tree transformation parameters. Unfortunately it currently transforms from ape to ouch format repeatedly (in order to use ape&amp;rsquo;s tree transforms, need to write native ouch-format transforms), so it may not be any faster.</description>
    </item>
    
    <item>
      <title>Two questions</title>
      <link>/2010/11/21/two-questions/</link>
      <pubDate>Sun, 21 Nov 2010 21:53:44 +0000</pubDate>
      
      <guid>/2010/11/21/two-questions/</guid>
      <description>I&amp;rsquo;ve been thinking about a few elements of the Monte Carlo approach that seem to be particularly subtle in interpretation. Thought I&amp;rsquo;d write them out here as a separate examples to help think through them. Thoughts?
Question 1 Should the Monte Carlo simulations use the maximum likelihood test and null model estimated from the data (as in McLachlan 1987, Goldman 1993, Huelsenbeck 1996) or draw from the distribution of model parameters for each simulation?</description>
    </item>
    
    <item>
      <title>Making R twitter?</title>
      <link>/2010/11/21/following-my-computer-simulations-on-twitter/</link>
      <pubDate>Sun, 21 Nov 2010 21:28:20 +0000</pubDate>
      
      <guid>/2010/11/21/following-my-computer-simulations-on-twitter/</guid>
      <description>I&amp;rsquo;m running quite a few of my analyses on my remote server, a 16 core, 32 GB ram, Ubuntu server with Tesla GPU, named &amp;ldquo;zero&amp;rdquo; (we&amp;rsquo;re creative folks). It&amp;rsquo;s easy to start lots of simulations (from ssh), harder to track when they are finished and verify results. No longer &amp;ndash; &amp;ldquo;zero&amp;rdquo; now uses social media to share what she&amp;rsquo;s up to. Find her on twitter: @tweeting_cpu
Social Computation  Provides automated updating of simulation status and error messages</description>
    </item>
    
    <item>
      <title>Sat: evolution -- porting tree transformations to OUCH?</title>
      <link>/2010/11/20/sat-phylogenetics-porting-tree-transformations-to-ouch/</link>
      <pubDate>Sat, 20 Nov 2010 23:36:09 +0000</pubDate>
      
      <guid>/2010/11/20/sat-phylogenetics-porting-tree-transformations-to-ouch/</guid>
      <description>The overnight runs yesterday using the geiger models bm and lambda on the (transformed) Anoles dataset don&amp;rsquo;t seem to converge, spooling jobs that continue running even when R exits &amp;ndash; probably that same problem in ape somewhere that was fixed by writing the tree out to Nexus and re-reading it, a very strange and subtle bug. Will try this and restart the runs. 
Ordered as: bm_v_lambda_origdata.png, delta_v_lambda.png, bm_v_lambda.png (data simulated under OU), each with 100 replicates.</description>
    </item>
    
    <item>
      <title>Fri: extending Geiger to Monte Carlo method</title>
      <link>/2010/11/19/fri-extending-geiger-to-monte-carlo-method/</link>
      <pubDate>Fri, 19 Nov 2010 19:51:34 +0000</pubDate>
      
      <guid>/2010/11/19/fri-extending-geiger-to-monte-carlo-method/</guid>
      <description>Completing my extension of geiger into object oriented design whereby I can easily apply the Monte Carlo approach to test fits using function calls to model fits such as update() and simulate(). A quick convenient example: AIC would prefer (though not by munch) the delta transform model over the Brownian motion model; a conclusion not supported by the Monte Carlo test, which suggests there is not enough power to choose between these models:</description>
    </item>
    
    <item>
      <title>Thurs: evolution likelihood</title>
      <link>/2010/11/18/thurs-phylogenetics-likelihood/</link>
      <pubDate>Thu, 18 Nov 2010 20:05:16 +0000</pubDate>
      
      <guid>/2010/11/18/thurs-phylogenetics-likelihood/</guid>
      <description>Back to writing for today. Working on discussion of non-nested models. Looking at the reverse comparison, can get the reverse p value. The case of OU.3 vs the OU.4 model doesn&amp;rsquo;t show either test to be significant at the 95\% confidence level,but the case of OU.3 vs OU.15 (lets every species in the top two clades be unique) does:
The reverse p value easily rejects this silly OU.15 model, though AIC vastly prefers it.</description>
    </item>
    
    <item>
      <title>Weds</title>
      <link>/2010/11/18/weds/</link>
      <pubDate>Thu, 18 Nov 2010 08:06:45 +0000</pubDate>
      
      <guid>/2010/11/18/weds/</guid>
      <description>Great discussion in Monte Carlo Seminar with Rannala on the two rate estimation papers. See in-text notes, but focus on mechanisms of speciation and extinction as intrinsic (lineage specific) or extrinsic (perhaps spatially specific or global).
Calculation of the likelihood function for the rates seems straight forward. Start by imaging the pure-birth model, simply allow branch lengths as draws from the exponential distribution of parameter lambda. Allowing extinction: probability a lineage speciates (as before) and then survives to present day.</description>
    </item>
    
    <item>
      <title>Tues seminar</title>
      <link>/2010/11/16/tues-seminar/</link>
      <pubDate>Tue, 16 Nov 2010 17:47:39 +0000</pubDate>
      
      <guid>/2010/11/16/tues-seminar/</guid>
      <description>Sarah Dalrymple seminar. Rick Karban&amp;rsquo;s excellent intro: &amp;ldquo;unlike the rest of these seminars, Sarah will tell us something new.&amp;rdquo; &amp;ldquo;Sarah&amp;rsquo;s really out there.&amp;ldquo; Also mentions TAC and art teaching.
Ants, Jeff pine &amp;amp; fire Fire suppression dramatic impacts. Prescribed under story burns work! ie Angora fire in Tahoe, 2007. Discover rings of unburned soil around base of tree, reducing damage&amp;hellip; undescribed!
More common in recently burned ( 30 yrs. What makes the rings?</description>
    </item>
    
    <item>
      <title>evolution today:  Discussion groups, writing, etc</title>
      <link>/2010/11/15/phylogenetics-today-discussion-groups-writing-etc/</link>
      <pubDate>Mon, 15 Nov 2010 22:37:52 +0000</pubDate>
      
      <guid>/2010/11/15/phylogenetics-today-discussion-groups-writing-etc/</guid>
      <description>Interesting discussion of a Lenski paper in Wainwright&amp;rsquo;s 270.
Barrick, J.E. et al. Genome evolution and adaptation in a long-term experiment with Escherichia coli. Nature 461, 1243-7(2009).
Seems to focus on surprise of continuing linear rate of increase in beneficial mutations, though statistics don&amp;rsquo;t seem to confirm. Curious about uncertainty in assay of fitness estimates (seem to go down at times, but surely not fixing deleterious mutations). General difficulties in setup of exponential growth with applications of classic constant population size, but maybe we&amp;rsquo;re all missing something.</description>
    </item>
    
    <item>
      <title>Thursday: Post-predictive verification exploration; writing and figures</title>
      <link>/2010/11/11/thursday-post-predictive-verification-exploration-writing-and-figures/</link>
      <pubDate>Thu, 11 Nov 2010 20:47:51 +0000</pubDate>
      
      <guid>/2010/11/11/thursday-post-predictive-verification-exploration-writing-and-figures/</guid>
      <description>On Post-predictive Verification Considering the kind of post-predictive verification I was discussing with Dan on Tuesday. Let&amp;rsquo;s start with the simple birth-death branching process. Starting from the master equation, the linearity gives us an accurate model as a Gaussian process where the systematic van Kampen expansion gives us the Fokker Planck equation whose solution is completely specified by its first two moments:
[latex] \frac{dN}{dt} = (\lambda - \mu) N \</description>
    </item>
    
    <item>
      <title>evolution statistics </title>
      <link>/2010/11/11/phylogenetics-statistics/</link>
      <pubDate>Thu, 11 Nov 2010 08:13:49 +0000</pubDate>
      
      <guid>/2010/11/11/phylogenetics-statistics/</guid>
      <description>Exploring the best way for representing the Monte Carlo Likelihood approach visually, including comparison power and comparison to AIC.
Blue line is AIC, dotted red line is real data. Red line to the right of blue line indicates test model is rejecting the null model by AIC score. Solid distribution are likelihood ratios simulated under null, dotted are simulated under test.
The p-value is the integral of the null distribution lying right of the observed likelihood ratio in the real data:</description>
    </item>
    
    <item>
      <title>Tuesday - SDEs then back to phylogenetics</title>
      <link>/2010/11/10/tuesday-sdes-then-back-to-phylogenetics/</link>
      <pubDate>Wed, 10 Nov 2010 19:17:00 +0000</pubDate>
      
      <guid>/2010/11/10/tuesday-sdes-then-back-to-phylogenetics/</guid>
      <description>Nice meeting with Sebastian this morning, reviewed my spectral approach problem (see anything in Stochastic Population Dynamics / warning signals in the past week) and the multivariate SDE problem Peter posed Oct 30th. No solutions yet but some ideas to get started.
With regards the SDE problem, note that it reduces to:
$$ dX_1 = B_2 d B_1 $$
and note also that if this were $$ dX_1 = B_1 d B_1 $$ this would be a classic exercise in intro SDEs we can look up in Oksendal,</description>
    </item>
    
    <item>
      <title>Monday and some phylogenetics</title>
      <link>/2010/11/08/monday-and-some-phylogenetics/</link>
      <pubDate>Mon, 08 Nov 2010 22:33:42 +0000</pubDate>
      
      <guid>/2010/11/08/monday-and-some-phylogenetics/</guid>
      <description>Working on paper revisions. Added a separate demo file just for generating the figures and analysis used in the manuscript, called likelihood_manuscript.R Need to clean and reorganize the package files and demos.
Added full species names and islands to the tip labels of the tree. Adjusting which example paintings/regimes to include, currently focusing on the original OU.LP model (now calling it OU.3 following Brian&amp;rsquo;s recommendation for simplicity), OU.4, (originally OU.</description>
    </item>
    
    <item>
      <title>Welcome to my Lab Notebook</title>
      <link>/2010/11/08/welcome-to-my-lab-notebook/</link>
      <pubDate>Mon, 08 Nov 2010 02:50:02 +0000</pubDate>
      
      <guid>/2010/11/08/welcome-to-my-lab-notebook/</guid>
      <description>Disclaimer: Not a Blog Welcome to my open lab notebook. This is the active, permanent record of all my scientific research, standing in place of the traditional bound lab notebook. It is a record of ideas, and intuitions; results and mistakes. Please bear in mind that the notebook is primarily a tool for me to do science, not communicate it. I write my entries with the hope that they are intelligible to my future self; and maybe intelligible to my collaborators and experts in my field.</description>
    </item>
    
    <item>
      <title>Friday: Evolution reading, writing</title>
      <link>/2010/11/05/friday-evolution-reading-writing/</link>
      <pubDate>Fri, 05 Nov 2010 18:21:35 +0000</pubDate>
      
      <guid>/2010/11/05/friday-evolution-reading-writing/</guid>
      <description>Read through the article for Monday&amp;rsquo;s PBG270, a 2009 Nature paper from the Plotkin lab on mutational robustness and the rate of evolution. They consider an interesting little setup. Start with a Moran model (individual born, may mutate, choses who to replace at random), but allow the following mutational structure (landscape). Of P possible genotypes, each can only move to one of K neighbors by a single mutation. Call the genotype(s) of optimal fitness C.</description>
    </item>
    
    <item>
      <title>Thursday</title>
      <link>/2010/11/05/thursday/</link>
      <pubDate>Fri, 05 Nov 2010 18:08:32 +0000</pubDate>
      
      <guid>/2010/11/05/thursday/</guid>
      <description>Wrote yesterday&amp;rsquo;s entry on power spectral analysis difficulties from yesterday. Why don&amp;rsquo;t I remember my physics training better? Bialek&amp;rsquo;s Phy562 notes still very helpful. No one else seems to write about this stuff clearly enough for me. Including me. 8a-11a
Catching up on reading. Good news and discussion items in Nature on publishing code and review materials, excellent piece on climate change scientists engaging media, climate high performance computing in Brazil; etc see headlines and links in my twitter feed archive for today.</description>
    </item>
    
    <item>
      <title>Getting the details right on the Fourier Transform approach to likelihood</title>
      <link>/2010/11/03/getting-the-details-right-on-the-fourier-transform-approach-to-likelihood/</link>
      <pubDate>Wed, 03 Nov 2010 16:28:39 +0000</pubDate>
      
      <guid>/2010/11/03/getting-the-details-right-on-the-fourier-transform-approach-to-likelihood/</guid>
      <description>Recall that we consider the power spectrum of some measurable fluctuating quantity x(t), defined as
$$ y(\omega) = \int0^T dt e^{i\omega t} x(t) $$ $$ S(\omega) = \lim{T \to \infty} \frac{1}{2\pi T} \left| y(\omega)\right|^2 $$
A little work can show is equal to the Fourier transform of the autocorrelation function, $ \langle x(t) x(t&amp;rsquo;) \rangle = C(t-t&amp;rsquo;) $.
We evaluate the correlation function of their Fourier transform (note $ x (\omega) $ is really $ \tilde x(\omega)$, the new transformed variable, I&amp;rsquo;ve dropped the tilde only out of laziness):</description>
    </item>
    
    <item>
      <title>Reviews, organization, rewrites</title>
      <link>/2010/11/03/reviews-organization-rewrites/</link>
      <pubDate>Wed, 03 Nov 2010 05:20:18 +0000</pubDate>
      
      <guid>/2010/11/03/reviews-organization-rewrites/</guid>
      <description>Today&amp;rsquo;s a mixed bag of activities. Finished a journal review, comments confidential, recorded in my reviewed papers archive. I then organized documents library (more below) and then back to paper revisions.
The reference manager software Mendeley recently upgraded the way it handles groups and sharing, and I&amp;rsquo;ve been waiting to revise how it impacts my workflow around articles. Articles can be organized into folders (collections) or kept unsorted within the library, and can be part of as multiple collections.</description>
    </item>
    
    <item>
      <title>Short note: Trait diversification rates controlled by other traits</title>
      <link>/2010/10/30/short-note-trait-diversification-rates-controlled-by-other-traits/</link>
      <pubDate>Sat, 30 Oct 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/10/30/short-note-trait-diversification-rates-controlled-by-other-traits/</guid>
      <description>Peter posed an interesting question to me this afternoon: can we infer a model in which the rate of evolution in one trait (say, its Brownian diversification rate parameter) depends on the value of another trait (say, linearly and assume the other trait depends on Brownian motion). Without all those assumptions we write this generally as:
$$ dX_t = f_x(X_t, Y_t) dt + \sigma_x(X_t, Y_t) d W_t $$ $$ dY_t = f_y(Y_t) dt + \sigma_y(Y_t) d W_t $$ (subscripts do not imply derivatives in my notation)</description>
    </item>
    
    <item>
      <title>A new twist on the approach</title>
      <link>/2010/10/28/a-new-twist-on-the-approach/</link>
      <pubDate>Thu, 28 Oct 2010 16:08:25 +0000</pubDate>
      
      <guid>/2010/10/28/a-new-twist-on-the-approach/</guid>
      <description>Matching the warning signal to different SDE models couldn&amp;rsquo;t retain the simplicity and generality needed, so I intend to work on the transformed data instead. Taking the power spectrum of the data, we have a new curve fitting problem:
(Code). This can be turned into a linear curve fitting problem by taking the log of the inverse Fourrier transform, then the slope is our stability parameter. Can we do this estimation by likelihood instead of least-squares?</description>
    </item>
    
    <item>
      <title>Red Noise (aside exercise)</title>
      <link>/2010/10/28/red-noise-aside-exercise/</link>
      <pubDate>Thu, 28 Oct 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/10/28/red-noise-aside-exercise/</guid>
      <description>Consider the first-order autoregressive process: $$ X_{t+1} = \rho X_t + \sqrt{1-\rho^2}Z_t $$
Why the funny term at the end? This comes from normalizing the variance,
$$ \begin{multline} E( (\rho X_t + \sqrt{1-\rho^2} Z_t)^2 ) = E (\rho^2 X_t^2) + E(2 \rho X_t \sqrt{1-\rho^2}) Z_t ) + E( X_t^2 Z_t^2 (1-\rho^2) ) \end{multline}$$
by independence:
$$ = \rho^2 E(X_t^2) + 2 \rho \sqrt{1-\rho^2} E( X_t ) E( Z_t ) + E( X_t^2) E(Z_t^2) (1-\rho^2) $$</description>
    </item>
    
    <item>
      <title>Warning Signals -- Where are we now?</title>
      <link>/2010/10/27/warning-signals-where-are-we-now/</link>
      <pubDate>Wed, 27 Oct 2010 16:00:48 +0000</pubDate>
      
      <guid>/2010/10/27/warning-signals-where-are-we-now/</guid>
      <description>The last few days have involved an investigation into the ability to capture the essential features of the dynamics leading up to a saddle node bifurcation as a linear stochastic differential equation. The warning signals question then becomes a model-choice problem between constant and time-dependent coefficients:
$$ dX_t = \alpha \left(\theta_t - X_t\right) dt + \sigma_t dW_t $$
and
$$ dX_t = \alpha_t (\theta_t - X_t) dt + \sigma_t dW_t $$</description>
    </item>
    
    <item>
      <title>Correcting for the mean dynamics</title>
      <link>/2010/10/26/correcting-for-the-mean-dynamics/</link>
      <pubDate>Tue, 26 Oct 2010 16:46:24 +0000</pubDate>
      
      <guid>/2010/10/26/correcting-for-the-mean-dynamics/</guid>
      <description>Yesterday I began to address concerns of different models that have different mean dynamics, and how this influences the warning signals. This poses several kinds of issues.
 First, if the mean is changing, the model fitting must be appropriate to this &amp;ndash; either by fitting this rate of change or correcting for it.
 Second, the variance is expected to scale with the mean, and scale differently under different noise models (particularly environmental vs.</description>
    </item>
    
    <item>
      <title>Wrong picture, wrong model: why warning signals don&#39;t look like rare events</title>
      <link>/2010/10/25/wrong-picture-wrong-model-why-warning-signals-dont-look-like-rare-events/</link>
      <pubDate>Mon, 25 Oct 2010 23:24:45 +0000</pubDate>
      
      <guid>/2010/10/25/wrong-picture-wrong-model-why-warning-signals-dont-look-like-rare-events/</guid>
      <description>Detecting a warning signal of collapse isn&amp;rsquo;t about detecting that a system is non-stationary, but more specifically, that the system is about to do something sudden. The classic saddle-node bifurcation example results in a picture like this:
A visible steady decrease interrupted by a sudden jump. The goal is to distinguish this from the case of a steady decrease that involves no loss of stability &amp;ndash; such as would be created by continually lowering the carrying capacity of logistic-model system at a linear rate.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/10/21/warning-signals-2/</link>
      <pubDate>Thu, 21 Oct 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/10/21/warning-signals-2/</guid>
      <description>Trying to select clear examples of sufficient and sufficient power in detecting warning signals. Addressing a couple side issues today as well:
 Proper handling of trends
 Best model for eigenvalue change
  Computed an example with steeper nonlinearity to compare rate of change in lambda. Here&amp;rsquo;s an example with Hill coefficient of 5 (see code for details). Note that the plot simply shows whichever root the numerical algorithm converges to at the time, should modify to express all roots.</description>
    </item>
    
    <item>
      <title>Spatial Warning Signals, power, etc</title>
      <link>/2010/10/21/spatial-warning-signals-power-etc/</link>
      <pubDate>Thu, 21 Oct 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/10/21/spatial-warning-signals-power-etc/</guid>
      <description>Noam gave an interesting presentation in our lab today, prompted me to do a little experimentation. Weakening stability across a set of coupled patches should result in increased autocorrelation. Decided to test this with a little visualization with help of a quick R script. Time progresses across the x-axis, 1-D space (on S1) across the y-axis. Each patch suffers a slow loss of stability, resulting in a clearly visible increase in autocorrelation.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/10/20/adaptive-dynamics-abstract/</link>
      <pubDate>Wed, 20 Oct 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/10/20/adaptive-dynamics-abstract/</guid>
      <description>Adaptive dynamics is a set of recently developed techniques for understanding phenotypic evolution, using a dynamical systems approach to concepts from evolutionary game theory. In contrast to population genetics, this approach tends to explore richer ecological interactions and simpler genetic assumptions, with significant controversy. My own work has focused on a particular element of the theory known as the canonical equation, a macroscopic equation describing the deterministic rate of evolution.</description>
    </item>
    
    <item>
      <title>ecology Abstract</title>
      <link>/2010/10/20/stochastic-population-dynamics-abstract/</link>
      <pubDate>Wed, 20 Oct 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/10/20/stochastic-population-dynamics-abstract/</guid>
      <description>Ecological population sizes fluctuate not only in response to environmental fluctuations but because of the stochastic nature of natural births and deaths. While in very large populations these fluctuations have negligible impact, ecology rarely obliges us by satisfying this limit. Age and stage structure in populations serve to amplify the effect, where the fate of the population is determined by a smaller subset of, say, the fecund adults alone. Demographic noise is probably responsible for the ultimate extinction of many populations once reduced to a small size.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/10/19/warning-signals/</link>
      <pubDate>Tue, 19 Oct 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/10/19/warning-signals/</guid>
      <description> Working examples  kendall.R example of kendall&amp;rsquo;s correlation test on standard warning signal indicator being misleading.  </description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/10/18/teaching/</link>
      <pubDate>Mon, 18 Oct 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/10/18/teaching/</guid>
      <description>Graduate Teaching Community &amp;ndash; reflections on teaching Haven&amp;rsquo;t made a lot of entries in this notebook as I&amp;rsquo;m not teaching regularly at the moment, though am still attending meetings of the Graduate Teaching Community, a record of which can be found on our GTC blog. But today in GTC we are thinking about reflections on teaching, and starting with a little bit of journaling, so this seemed like a good place to do it.</description>
    </item>
    
    <item>
      <title>Status update</title>
      <link>/2010/10/15/status-update/</link>
      <pubDate>Fri, 15 Oct 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/10/15/status-update/</guid>
      <description>Actually out of town this day, but draft off to co-authors, will review Friday. meanwhile time to get back to some warning signals work, will be in other notebook for rest of the week.</description>
    </item>
    
    <item>
      <title>Writing continues</title>
      <link>/2010/10/14/writing-continues/</link>
      <pubDate>Thu, 14 Oct 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/10/14/writing-continues/</guid>
      <description>Deleting large sections is a great way to spur better writing. Revised organization substantially, discussion somewhat loose still. But basic framework all in place. draft off to Peter and Graham!</description>
    </item>
    
    <item>
      <title>Wednesday</title>
      <link>/2010/10/13/wednesday/</link>
      <pubDate>Wed, 13 Oct 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/10/13/wednesday/</guid>
      <description>Monte Carlo  Reading Sanderson&amp;rsquo;s nonparametric rate smoothing and semi-parametric r8s papers in Monte Carlo with Rannala. Comments on articles in text, but great discussion today, particularly Bruce&amp;rsquo;s take on this style of approach.   Sanderson, M.J. Estimating absolute rates of molecular evolution and divergence times: a penalized likelihood approach. Molecular biology and evolution 19, 101-9(2002). Sanderson, M.J. A Nonparametric Approach of Rate Constancy to Estimating Divergence Times in the Absence.</description>
    </item>
    
    <item>
      <title>a day of writing</title>
      <link>/2010/10/12/a-day-of-writing/</link>
      <pubDate>Tue, 12 Oct 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/10/12/a-day-of-writing/</guid>
      <description>Figuring out the best way to present the critique of AIC, introduction to the method, introduction to the power test. Seeking inspiration from Huelsenbeck 1996 and digging farther back into the literature:

 Cox, D.R. Further results on tests of separate families of hypotheses. Journal of the Royal Stastical Society 24, 406-424(1962). Cox, D.R. Tests of Seperate Families of Hypotheses. Proceedings of the 4th Berkeley Symposium, University of California Press 105 - 123(1961).</description>
    </item>
    
    <item>
      <title>Still writing</title>
      <link>/2010/10/11/still-writing/</link>
      <pubDate>Mon, 11 Oct 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/10/11/still-writing/</guid>
      <description>Ah, back after being in bed almost a week with flu. Back to writing manuscript, reworking the presentation of the actual method. Much of the day caught up in Watson&amp;rsquo;s practice orals (applying computational mechanics to inhibitory neuron circuits), checking in with Yun on his orals and then GTC. too many delays, hope I feel fully better soon.</description>
    </item>
    
    <item>
      <title>LR Manuscript</title>
      <link>/2010/10/05/lr-manuscript/</link>
      <pubDate>Tue, 05 Oct 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/10/05/lr-manuscript/</guid>
      <description>Still writing. Working on the comparisons to AIC section. Things to think about adding: Explicitly show p values on bootstrap What are we calling this thing anyway? After Hulsenbeck &amp;amp; Bull, 1996: ``likelihood heterogeneity test All-different seems to have some stability/convergence problems, perhaps a less aggressive example would be better? &amp;ndash;Carl Boettiger 19:46, 5 October 2010 (EDT) Stability issues resulted from different fitting methods in initial fit vs. bootstraps.</description>
    </item>
    
    <item>
      <title>Monday</title>
      <link>/2010/10/04/monday/</link>
      <pubDate>Mon, 04 Oct 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/10/04/monday/</guid>
      <description>7:30 &amp;ndash; 8:30 Read ﻿article for Wainwright&amp;rsquo;s 270:  Streisfeld, M.a. &amp;amp; Rausher, M.D. Population Genetics, Pleiotropy, and the Preferential Fixation of Mutations During Adaptive Evolution. Evolution no-no(2010).doi:10.1111/j.1558-5646.2010.01128.x
Interesting approach, methods description a little light and both prediction and interpretation of pattern of mutations in coding, cis-reg, and transcription factor sites seems a little loose. Detailed notes on article in Mendeley. More comments after the discussion section at 1pm today.</description>
    </item>
    
    <item>
      <title>Likelihood Ratio Paper</title>
      <link>/2010/10/03/likelihood-ratio-paper/</link>
      <pubDate>Sun, 03 Oct 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/10/03/likelihood-ratio-paper/</guid>
      <description>Higher resolution power plot for Anoles tree Figure (below right) shows power for increasing alpha in the Anoles tree. The vertical line shows the estimated value of alpha for the body-size data &amp;ndash; unlikely that a tree of this size can detect selection that is this weak even if it were present. Consequently, this fit should not be taken as evidence that BM is a better fit than the OU, but rather that the data is insufficient to inform this analysis.</description>
    </item>
    
    <item>
      <title>Adaptive Dynamics Updates</title>
      <link>/2010/09/30/adaptive-dynamics-updates/</link>
      <pubDate>Thu, 30 Sep 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/09/30/adaptive-dynamics-updates/</guid>
      <description>The numerical coexistence time simulations are still running, (Server rest brought down these runs two weeks ago, and they take a few weeks to do all the replicates) meanwhile here are the rest of the analytic set (and one simulation that finished). See code for parameters etc. (Below in frame)


EVE Seminar: Brad Shaffer A rather good talk on the California Tiger salamander, emphasizing intersection of ecological and evolutionary investigation in a conservation, management-oriented context.</description>
    </item>
    
    <item>
      <title>Thursday</title>
      <link>/2010/09/30/thursday/</link>
      <pubDate>Thu, 30 Sep 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/09/30/thursday/</guid>
      <description>Alan will write introduction to manuscript. Schedule meeting for next week. Scheduling the Hastings lab meeting doodle Coordinate with Baskett lab  Resources for ABC / Bayesian inference in ecological and spatial context workshop  Sisson Sa, Fan Y, Tanaka MM. Sequential Monte Carlo without likelihoods. Proceedings of the National Academy of Sciences of the United States of America. 2007;104(6):1760-5. Available at: http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1794282&amp;amp;tool=pmcentrez&amp;amp;rendertype=abstract. de Valpine P, Hastings A. Fitting Population Models Incorporating Process Noise and Observation Error.</description>
    </item>
    
    <item>
      <title>Writing</title>
      <link>/2010/09/15/writing/</link>
      <pubDate>Wed, 15 Sep 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/09/15/writing/</guid>
      <description>Working on likelihood ratio/phylogenetic signal manuscript.

scrap notes from more literature combing  Cheverud 1985 autocorellational model, extended by Gittlman &amp;amp; Kot 1990 Grafen 89, Pagen &amp;amp; Harvey 89 extending PIC to polytomies Harvey &amp;amp; Mace 82, Harvey &amp;amp; Clutton Brock 85 taxonomic rather than phylogenetic  From Blomberg et al: &amp;ldquo;The three best-justified phylogenetically based statistical methods can all be applied with a star phylogeny, in which case they yield results that are exactly the same as a conventional analysis (phylogenetically independent contrasts: Felsenstein 1985; generalized least squares: Grafen 1989; Martins and Hansen 1997; Garland and Ives 2000; Rohlf 2001; Monte Carlo simulations: Martins and Garland 1991; Garland et al.</description>
    </item>
    
    <item>
      <title>Power plots</title>
      <link>/2010/09/14/power-plots/</link>
      <pubDate>Tue, 14 Sep 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/09/14/power-plots/</guid>
      <description>Testing power code. currently null and test distributions of likelihood scores are distinguishable even for small beta on the long time scale. See code for run.
 running on shorter timescale. Note that parameters match but small code differences in repository code on the last commit since I committed the version on the local machine (my laptop, for development) but ran a slightly tweaked code (typo in reps vs nboot, .</description>
    </item>
    
    <item>
      <title>Writing</title>
      <link>/2010/09/14/writing/</link>
      <pubDate>Tue, 14 Sep 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/09/14/writing/</guid>
      <description>Working on likelihood ratio/phylogenetic signal manuscript</description>
    </item>
    
    <item>
      <title>Peter meeting</title>
      <link>/2010/09/13/peter-meeting/</link>
      <pubDate>Mon, 13 Sep 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/09/13/peter-meeting/</guid>
      <description>SICB conference  Abstract &amp;ndash; sent   Phylogenetic comparative methods have become all but ubiquitous in only a few decades, forcing us to reconsider if information from a phylogenetic tree can justify the results. Existing approaches to this question have been inadequate and do not scale with tree size or the ability to resolve branches. For instance, selection between phylogenetic models typically based on information criteria fails to adequately reflect this uncertainty, and can lead to preference for arbitrarily complicated models.</description>
    </item>
    
    <item>
      <title>Meeting with Alan</title>
      <link>/2010/09/10/meeting-with-alan/</link>
      <pubDate>Fri, 10 Sep 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/09/10/meeting-with-alan/</guid>
      <description>Some discussion of references  ﻿ Ovaskainen O, Meerson B. Stochastic models of population extinction. Trends in Ecology &amp;amp; Evolution. 2010;(Box 3):1-10. Available at: http://dx.doi.org/10.1016/j.tree.2010.07.009.  ﻿* Goel NS, Richter-Dyn N. Stochastic Models in Biology. The Blackburn Press; 2004:269. Available at: http://www.amazon.com/Stochastic-Models-Biology-Narendra-Goel/dp/193066592X.
 Bjørnstad O, Finkenstädt B, BT. Dynamics of measles epidemics: estimating scaling of transmission rates using a time series SIR model. Ecological Monographs. 2002;72(2):169-184. Available at: http://www.esajournals.org/doi/pdf/10.1890&amp;frasl;0012-9615(2002)072%5B0169%3ADOMEES%5D2.0.CO%3B2072%5B0169%3ADOMEES%5D2.0.CO%3B2&amp;rdquo;). Grenfell BT, Bjørnstad ON, Finkenstädt BF.</description>
    </item>
    
    <item>
      <title>Lab Notebooks</title>
      <link>/2010/09/07/lab-notebooks/</link>
      <pubDate>Tue, 07 Sep 2010 08:23:45 +0000</pubDate>
      
      <guid>/2010/09/07/lab-notebooks/</guid>
      <description>I strive for a transparent and reproducible research process. My lab notebooks are kept on an open wiki (via OpenWetWare). I curate the literature I read into several public lists (Mendeley), maintain my research source code and simulations on a collective database for open source development (Github), and am active on academic forums and mailing lists. These web-based tools make a largely automated, interlinked archive of my work I can search, update and share easily.</description>
    </item>
    
    <item>
      <title>Meeting with Sam</title>
      <link>/2010/09/07/meeting-with-sam/</link>
      <pubDate>Tue, 07 Sep 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/09/07/meeting-with-sam/</guid>
      <description>Discussing elements of likelihood ratio manuscript and review results from release of constraint data. Figure out what to include in one manuscript, what order to present elements in, and what examples are necessary.
 Phylogenetic Signal introduction. Need for examples? A good example where phylogenetically independent contrasts is misleading, but lambda/K definition of phylogenetic signal is also misleading. Power in phylogenetic tree:  Likelihood ratio and model choice: Monte Carlo LR approach, support in the literature http://openwetware.</description>
    </item>
    
    <item>
      <title>evolution Research Abstract</title>
      <link>/2010/09/04/hello-world-2/</link>
      <pubDate>Sat, 04 Sep 2010 16:51:53 +0000</pubDate>
      
      <guid>/2010/09/04/hello-world-2/</guid>
      <description>Comparative methods in evolutionary biology use phylogenetic trees to explore the origins and maintenance of biodiversity. I develop methods to extend the kinds of questions we can ask and also to test the statistical limits of our ability to make evolutionary inferences through such a periscope into the past. I am particularly interested in detecting evolutionary regime shifts &amp;ndash; locations in evolutionary history where the governing rules or parameters shift suddenly &amp;ndash; as well as more general questions of model choice, informativeness &amp;amp; identifiability in phylogenetic inference.</description>
    </item>
    
    <item>
      <title>Updating examples of stochastic structured population dynamics</title>
      <link>/2010/09/02/updating-examples-of-stochastic-structured-population-dynamics/</link>
      <pubDate>Thu, 02 Sep 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/09/02/updating-examples-of-stochastic-structured-population-dynamics/</guid>
      <description>Demonstrating the differences in accounting for the two-step transitions explicitly.
 Dotted lines show the one_step process, solid show the two_step process. code. Code embedded below (experimental, wonder if this is easier than following the link).
  

Summer Research Summary  Finished and sent off the summer research summary for my afternoon meeting with Adam and Micha.</description>
    </item>
    
    <item>
      <title>Entry title</title>
      <link>/2010/09/01/entry-title/</link>
      <pubDate>Wed, 01 Sep 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/09/01/entry-title/</guid>
      <description>Automated scripts for image uploads. Tag-based generation of a slideshow:


Running the script:
 ./flickr_slideshow *.png  Creates the html code that can be embedded into the notebook for a slideshow those images. Images only get the date-time tag as a unique id.


This one uses the mediawiki plugin. More formatting options could be incorporated of course. (Creates the thumbnail images down the right-hand side).</description>
    </item>
    
    <item>
      <title>Tuesday</title>
      <link>/2010/08/31/tuesday/</link>
      <pubDate>Tue, 31 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/31/tuesday/</guid>
      <description>Much of today&amp;rsquo;s activity included in yesterday&amp;rsquo;s.
Recording Reading Still looking for a good way to capture time snapshots of what I&amp;rsquo;ve read. Perhaps the Mendeley API will have a good solution. Here I try twapper-keeper to create an rss of my tweets on a given day, and the google api, but not very ideal solutions. Checked a variety of ways to filter rss feeds by date so that it would just show the current ones, none seem to manage this though.</description>
    </item>
    
    <item>
      <title>Adaptive Dynamics</title>
      <link>/2010/08/30/adaptive-dynamics/</link>
      <pubDate>Mon, 30 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/30/adaptive-dynamics/</guid>
      <description>Simulation Results (code)  Analytics (Analytics code)
Notebooks and files Looking at a better way to get figures into my online notebook. I often run simulations that generate figures which I look at, make some adjustments to the code based on the figure, and then delete or overwrite the figure without uploading it to my notebook, because it isn&amp;rsquo;t &amp;ldquo;right&amp;rdquo; or &amp;ldquo;finished&amp;rdquo; and uploading takes a lot of clicks, particularly when the code generates 36 figures in a run.</description>
    </item>
    
    <item>
      <title>Summer Review</title>
      <link>/2010/08/30/summer-review/</link>
      <pubDate>Mon, 30 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/30/summer-review/</guid>
      <description>Stochastic Population Dynamics in Beetles    Early Warning from Fluctuations in Populations</description>
    </item>
    
    <item>
      <title>Likelihood ratio ToDo</title>
      <link>/2010/08/27/likelihood-ratio-todo/</link>
      <pubDate>Fri, 27 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/27/likelihood-ratio-todo/</guid>
      <description>Inclusion of power figure, discussion of power. (include comparison to smaller trees?)  Code ToDo  Fix parallelization &amp;ndash; lower-level parallelization in LR_boot function seems to have high memory and processing overhead. Parallelize over alpha only. Funny that sfSapply at lower level conflicts when inside an upper-level sfSapply call? Can the lower level be put into sequential mode? Requires more experimenting, probably with simple test functions.
 Create package around power analysis, including ability to test bootstraps</description>
    </item>
    
    <item>
      <title>Likelihood Ratio Paper- Power in Trees</title>
      <link>/2010/08/26/likelihood-ratio-paper--power-in-trees/</link>
      <pubDate>Thu, 26 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/26/likelihood-ratio-paper--power-in-trees/</guid>
      <description>Power in Trees tests (Results from single OU simulation per alpha, run yesterday) 2000 replicates gives a cleaner picture of the critical alpha, though with low alpha values the estimates of p are quite variable. Also more variable on the smaller trees. Even arbitrarily large alpha aren&amp;rsquo;t significant on the 5-taxa primate tree. On the small geospiza tree (13 taxa) from the geiger package we find:
0.5735 0.29 0.</description>
    </item>
    
    <item>
      <title>Likelihood Ratio Manuscript</title>
      <link>/2010/08/25/likelihood-ratio-manuscript/</link>
      <pubDate>Wed, 25 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/25/likelihood-ratio-manuscript/</guid>
      <description>Graham &amp;amp; Peter Meeting Some comments on Neyman Pearson and approaches &amp;gt; In the phylogenetics world, Huelsenbeck has a paper doing this: &amp;ldquo; A Likelihood Ratio Test to Detect Conflicting Phylogenetic Signal&amp;rdquo; and there&amp;rsquo;s a good introduction to the paper.
This is great, nice to know there&amp;rsquo;s a basis for it.
&amp;gt; I see that in the paper John references, &amp;ldquo; Statistical tests of models of DNA substitution &amp;ldquo;, they call what you&amp;rsquo;re doing &amp;ldquo;Monte Carlo&amp;rdquo;, and refers to some sort of resampling-the-data equivalent as the bootstrap.</description>
    </item>
    
    <item>
      <title>Entry title</title>
      <link>/2010/08/19/entry-title/</link>
      <pubDate>Thu, 19 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/19/entry-title/</guid>
      <description>OWW was down, notebook embedded from springnote:</description>
    </item>
    
    <item>
      <title>Writing</title>
      <link>/2010/08/19/writing/</link>
      <pubDate>Thu, 19 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/19/writing/</guid>
      <description>revising likelihood ratio manuscript &amp;ndash; added a section of conceptual examples to link the model choice and phylogenetic signal sections.</description>
    </item>
    
    <item>
      <title>Warning Signals -- still in code development</title>
      <link>/2010/08/18/warning-signals----still-in-code-development/</link>
      <pubDate>Wed, 18 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/18/warning-signals----still-in-code-development/</guid>
      <description>OWW was down, notebook embedded from springnote:</description>
    </item>
    
    <item>
      <title>Warning Signals</title>
      <link>/2010/08/17/warning-signals/</link>
      <pubDate>Tue, 17 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/17/warning-signals/</guid>
      <description>Bootstrapping for likelihood ratios! Updated class behavior &amp;ndash; all simulation and fitting routines now return timeseries objects as data with correct range and timestep. updated plotting routines. Likelihood ratio plotting function. Bootstraps of parameters can be plotted using the output from the likelihood ratio fit simulation, avoiding redundancy, just specify which model is desired. Bootstrap likelihood ratio plots includes the original ratio and calculates plot range using this information.</description>
    </item>
    
    <item>
      <title>Warning Signals</title>
      <link>/2010/08/16/warning-signals/</link>
      <pubDate>Mon, 16 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/16/warning-signals/</guid>
      <description>bootstrapping models implemented improved handling of model classes &amp;ndash; included T, t0, N, and X0 in object def implemented plotting for model bootstrap difficulties with changePt model fit remain. fixed one source of trouble &amp;ndash; no longer passes zero-length data to OU.lik() when t_shift is outside the time interval.  Still giving errors on coercing lists into doubles for the saddle_node bifurcation simulated data set. &amp;ndash;fixed, was getting t_shift as a vector from time(X).</description>
    </item>
    
    <item>
      <title>Warning Signals</title>
      <link>/2010/08/15/warning-signals/</link>
      <pubDate>Sun, 15 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/15/warning-signals/</guid>
      <description>Exploring convergence in maximum likelihood model fits each on data produced by their own simulation method:
 fit1, basic OU method, converges just fine. (using L-BFGS-B method with appropriate bounding box to avoid negatives). fit2 , the linear change rate model, converges fine using Nelder-Meade (using 1e12 ~ inf likelihood return when attempting negative alpha or sigma), but throws hard errors for L-BFGS-B:   Error in optim(pars, warning.likfn, method = method, lower = lower) : non-finite finite-difference value [3]   fit3 runs on &amp;ldquo;L-BFGS-B&amp;rdquo; and returns reasonable values, though not meeting convergence standards.</description>
    </item>
    
    <item>
      <title>Adaptive Dynamics</title>
      <link>/2010/08/13/adaptive-dynamics/</link>
      <pubDate>Fri, 13 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/13/adaptive-dynamics/</guid>
      <description>Wrote the code for a better interface to simulate coexistence times and creating contour plots from the results.  see code</description>
    </item>
    
    <item>
      <title>Adaptive Dynamics</title>
      <link>/2010/08/12/adaptive-dynamics/</link>
      <pubDate>Thu, 12 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/12/adaptive-dynamics/</guid>
      <description>Created plotting functions for:   waiting time distribution by phase, (cumulative and difference), distribution of number of failures before invasion of dimophism can occur and after it has occurred (indicating if mutational rate is more limiting or mutational step size (selection gradient). Adding to the pairwise invasibility plot the locations where dimorphism collapses, color coded by the time of collapse.  Exploring branching time distributions in different regimes by phase.</description>
    </item>
    
    <item>
      <title>Warning Signals</title>
      <link>/2010/08/12/warning-signals/</link>
      <pubDate>Thu, 12 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/12/warning-signals/</guid>
      <description>Reworking code to allow standard format for:   evaluating likelihood, &amp;ndash; Done fitting by maximum-likelihood, &amp;ndash; Done simulating, &amp;ndash; Done bootstrapping plotting models and bootstrap results.  changePt.sim, changePt.lik implemented.

Function Behavior notes  R&amp;rsquo;s mle function wants a named list.
 Updated parameter handling of OU.lik to allow parameters in alpha,theta,sigma format or theta1, theta2, theta3 format, as either lists or numerics, named or unnamed. Type handling in each function isn&amp;rsquo;t helping the speed, but optimization will have to wait.</description>
    </item>
    
    <item>
      <title>Adaptive Dynamics</title>
      <link>/2010/08/11/adaptive-dynamics/</link>
      <pubDate>Wed, 11 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/11/adaptive-dynamics/</guid>
      <description>Adding demos directory for the simulations to create the figures in User:Carl Boettiger/Notebook/Comparative Phylogenetics/2010/05/03 and User:Carl Boettiger/Notebook/Comparative Phylogenetics/2010/05/04 Updating the contour plot figure as per suggestions by Rupert and Ulf:  Branching times, original figure
 use more points for the simulation, and don&amp;rsquo;t put them on a regular grid, but maybe draw them from a uniform distribution, so as not to create spurious impressions of symmetry. You could then maybe also use the tripack package to draw colored Voronoi cells instead of same-sized symbols.</description>
    </item>
    
    <item>
      <title>Likelihood ratio update</title>
      <link>/2010/08/10/likelihood-ratio-update/</link>
      <pubDate>Tue, 10 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/10/likelihood-ratio-update/</guid>
      <description>Sent drafts of Likelihood ratio paper to Peter Wainwright (Sunday 08/08) and Graham Coop (Monday 08/09)  Wrightscape  Sent Peter more information on the release of constraint results in the Labrid system. Starting wrightscape manuscript.  Changes to wrightscape.R  added a tree plotting function to the wrighttree class. labels on parameter bootstrap distributions for labrids in last week&amp;rsquo;s entry reversed wrasses and parrotfish. I&amp;rsquo;ve updated the software so that the plotting function takes care of the labeling automatically (when these were made it had to be added manually, while the automation of the data conversions and the painting by clade reversed the label assignments).</description>
    </item>
    
    <item>
      <title>Warning Signals</title>
      <link>/2010/08/10/warning-signals/</link>
      <pubDate>Tue, 10 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/10/warning-signals/</guid>
      <description>Alternate models  Writing down the change-point model correctly now, starting with the simulation. Done. Implemented in sde_likelihood.R
 Implementing Neyman-Pearson comparisons for all three models.
  Linearizing directly from the saddle node model Dynamics:
Slope (alpha) at equilibrium comes from the derivative:
is the slope evaluated at n equal to equilbrium (which is the root of some messy cubic).</description>
    </item>
    
    <item>
      <title>Warning Signals by model choice</title>
      <link>/2010/08/09/warning-signals-by-model-choice/</link>
      <pubDate>Mon, 09 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/09/warning-signals-by-model-choice/</guid>
      <description>Finished implementation of simulation from saddle-node example Implemented simulation from transition density for all three models  Whoops  The change point model can&amp;rsquo;t be summarized by the transition density, as this depends only on the time interval and not the absolute time. The nice description of being able to solve for the transition density when the transition occurs during the time interval specified is neither necessary nor applicable in this context!</description>
    </item>
    
    <item>
      <title>Warning Signals</title>
      <link>/2010/08/08/warning-signals/</link>
      <pubDate>Sun, 08 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/08/warning-signals/</guid>
      <description>Working on implementation of the the TwoRates model looking for changepoint: See for most of code implementation sde_likelihood.R and for the model choice example see warning_example.R  General Code cleanup  Added a saddle-node bifurcation simulation in the format of the metapop/hastings/crowley/beetles models already in the stochastic population dynamics library. Allows for C-based parallelized ensemble simulation using my Gillespie library. R call to all of these models can be found in ind_based_models.</description>
    </item>
    
    <item>
      <title>Reading</title>
      <link>/2010/08/07/reading/</link>
      <pubDate>Sat, 07 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/07/reading/</guid>
      <description>Trying to make this show reading of the day, the script below shows only current reading:
Friendfeed discussion on solving this:
Warning Signals  Implementing likelihood-based methods for early warning signals. Trying three models:  
 Model 3 is intended to be a changepoint analysis, where α(t) is piecewise constant. I solved analytically the transition probability density in Model 2 on User:Carl Boettiger/Notebook/Stochastic Population Dynamics/2010/05/06, see this and the following entry.</description>
    </item>
    
    <item>
      <title>Batch Data</title>
      <link>/2010/08/05/batch-data/</link>
      <pubDate>Thu, 05 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/05/batch-data/</guid>
      <description>Some of the nexus files don&amp;rsquo;t seem to read into R. Opening and saving the file in figtree solves this.  Data Sets Labrid traits &amp;ndash;Carl Boettiger 00:52, 11 August 2010 (EDT) Note: labels on parameter bootstrap distributions have reversed wrasses and parrotfish. I&amp;rsquo;ve updated the software so that the plotting function takes care of the labeling automatically (when these were made it had to be added manually, while the automation of the data conversions and the painting by clade reversed the label assignments).</description>
    </item>
    
    <item>
      <title>Data Format functions</title>
      <link>/2010/08/04/data-format-functions/</link>
      <pubDate>Wed, 04 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/04/data-format-functions/</guid>
      <description>Spent much of the day trying to code an intelligent data-preprocessing function. Seems to mostly be working now, see github for details. Testing on a variety of datasets.
 Currently the function assumes paintings can be specified by common ancestors of a set of tips, assumes non-overlapping clades. Doesn&amp;rsquo;t error-check for this either.
 should also have more output processing functions, particularly to return a &amp;ldquo;phylo&amp;rdquo; object together with paintings (see earlier existing code in my Comparative-Phylogenetics repository).</description>
    </item>
    
    <item>
      <title>Writing</title>
      <link>/2010/08/03/writing/</link>
      <pubDate>Tue, 03 Aug 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/08/03/writing/</guid>
      <description>Finished a draft of manuscript on Likelihood ratio, sent to Sam and Peter Ralph.</description>
    </item>
    
    <item>
      <title>Open Science Summit Day 3</title>
      <link>/2010/07/31/open-science-summit-day-3/</link>
      <pubDate>Sat, 31 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/31/open-science-summit-day-3/</guid>
      <description>see previous day for links to more details on summit.</description>
    </item>
    
    <item>
      <title>Open Science Summit day 2</title>
      <link>/2010/07/30/open-science-summit-day-2/</link>
      <pubDate>Fri, 30 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/30/open-science-summit-day-2/</guid>
      <description>Full day (really &amp;ndash; no breaks, lunch served during talks) of talks at the open science summit&amp;hellip;
Amazingly well web-captured conference, in addition to streaming on fora.tv, complete transcripts of talks are available thanks to someone with fast fingers.
Also through the back-channel, particularly the links it shares:</description>
    </item>
    
    <item>
      <title>Open Science Summit</title>
      <link>/2010/07/29/open-science-summit/</link>
      <pubDate>Thu, 29 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/29/open-science-summit/</guid>
      <description>First day of the Open Science Summit, began with excellent panel discussion including Cameron Neylon, Victoria Stodden, Peter Murray-Rust and Jason Hoyt. Followed by great lineup of short talks, but behind schedule and no breaks.
 Conference Schedule Backchannel twitter archive A neat backchannel question proposing site used for the conference.  </description>
    </item>
    
    <item>
      <title>Cetartiodactyle data</title>
      <link>/2010/07/28/cetartiodactyle-data/</link>
      <pubDate>Wed, 28 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/28/cetartiodactyle-data/</guid>
      <description>Exploring the cetartiodactyle data (unreleased) Nelder-Mead fails to converge or improve upon the hansen model. Likelihood scores differ little:  &amp;gt; bm@loglik [1] -362.6228 &amp;gt; ou1@loglik [1] -364.9039 &amp;gt; ws1$loglik [1] -362.7616 &amp;gt; ou2@loglik [1] -361.6976 &amp;gt; ws2$loglik [1] -361.2542  See Cetaceans code.

Fig. 1 The Brownian Motion model is preferred to the OU.1 model (left). Two separate optima are supported over a single optima (right).</description>
    </item>
    
    <item>
      <title>Parameter Estimates for Labrid-Parrotfish model</title>
      <link>/2010/07/27/parameter-estimates-for-labrid-parrotfish-model/</link>
      <pubDate>Tue, 27 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/27/parameter-estimates-for-labrid-parrotfish-model/</guid>
      <description>See fast_boot and plot.wrightscape functions in code. Gape size

See fast_boot and plot.wrightscape functions in code Jaw Protrusion
Figures show strong evidence for the relax of constraint hypothesis, as the strength of selection (alpha parameters) appears to have substantially weakened in both morphological traits in the parrotfish clade relative to the wrasses clade. The wrasses show strong preference for OU model with substantial stabilizing selection, while the Parrotfish estimate almost zero stabilizing selection (Brownian model, clear phylogenetic signal).</description>
    </item>
    
    <item>
      <title>Parrotfish Model choice</title>
      <link>/2010/07/26/parrotfish-model-choice/</link>
      <pubDate>Mon, 26 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/26/parrotfish-model-choice/</guid>
      <description>code, Gape data
code, Protrusion data
For both the gape data and the jaw protrusion data, the model treating parrotfish clade as a separate regime using ouch (differing optima) is not supported (even though it does have better AIC score for the protrusion data). The model using my new method allowing alpha and sigma to differ is strongly supported, providing support for the &amp;ldquo;release of constraint&amp;rdquo; hypothesis.</description>
    </item>
    
    <item>
      <title>Writing</title>
      <link>/2010/07/23/writing/</link>
      <pubDate>Fri, 23 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/23/writing/</guid>
      <description>Working on likelihood ratio manuscript.  Labrid Herbivory data Parrotfish gape shows significant differences for independent OU models (alpha, theta, sigma different) than wrasses. While the two-peak ouch model gets no support, allowing alpha and sigma to very results in a strongly significant model improvement.
code
&amp;gt; ws2$ ws2$alpha ws2$data ws2$loglik ws2$regimes ws2$sigma ws2$theta ws2$tree ws2$Xo &amp;gt; ws2$theta [1] 0.2245493 0.9569619 &amp;gt; ws2$alpha [1] 2.943846e+00 4.995744e-06 &amp;gt; ws2$sigma [1] 0.</description>
    </item>
    
    <item>
      <title>Writing</title>
      <link>/2010/07/22/writing/</link>
      <pubDate>Thu, 22 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/22/writing/</guid>
      <description>Working on likelihood ratio manuscript.</description>
    </item>
    
    <item>
      <title>Writing</title>
      <link>/2010/07/21/writing/</link>
      <pubDate>Wed, 21 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/21/writing/</guid>
      <description>working on likelihood ratio manuscript.</description>
    </item>
    
    <item>
      <title>Writing</title>
      <link>/2010/07/20/writing/</link>
      <pubDate>Tue, 20 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/20/writing/</guid>
      <description>working on Likelihood ratio manuscript. Some more literature review and outlining.</description>
    </item>
    
    <item>
      <title>Wainwright Meeting</title>
      <link>/2010/07/19/wainwright-meeting/</link>
      <pubDate>Mon, 19 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/19/wainwright-meeting/</guid>
      <description>Discussed goals and appropriate approach. Settled on linear order rather than trying to directly implement the full MCMC over paintings solution directly. Breaks into four steps/manuscripts:
 Phylogenetic signal and model choice in Comparative Methods: Likelihood ratio approach Detecting changing constraints in evolution: varying alpha and sigma across the tree Bayesian approach for all existing continuous trait comparative methods MCMC over possible histories to infer number of niches</description>
    </item>
    
    <item>
      <title>Parrotfish-Wrasse example</title>
      <link>/2010/07/15/parrotfish-wrasse-example/</link>
      <pubDate>Thu, 15 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/15/parrotfish-wrasse-example/</guid>
      <description>Painting the tree with parrotfish as a separate regime from wrasses, I find significant support for a model with separate optima with differential strengths of selection and diversification as well with respect to fin angle.  code
The painting for this tree (click for larger and zoom in):</description>
    </item>
    
    <item>
      <title>Organizing analyses, data, codes</title>
      <link>/2010/07/14/organizing-analyses-data-codes/</link>
      <pubDate>Wed, 14 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/14/organizing-analyses-data-codes/</guid>
      <description>Codes  Should have a suite of likelihood tools as a package Suite of data manipulation functions, mostly to and from ape/ouch  
idealized workflow:
 Read in nexus file and csv data. Call model fit for each model to be tested (BM, one peak, multiple peaks, multiple peaks with independent selective forces)  
 A function checks tree and data for matches, discards those without match. This could be done automatically by the model fit.</description>
    </item>
    
    <item>
      <title>Bootstrapping the independent alpha-sigma models</title>
      <link>/2010/07/13/bootstrapping-the-independent-alpha-sigma-models/</link>
      <pubDate>Tue, 13 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/13/bootstrapping-the-independent-alpha-sigma-models/</guid>
      <description>I compare in a robust framework the likelihood that species mean trait values are generated by Brownian motion, a single peak OU model, or a model with different regimes (postulated in the literature) in which the selective strength (alpha) and diversification rate (sigma) are fixed across the entire tree or allowed to vary by selective regime. (Regimes are defined as branches with different values for the selective optimum).
The parametric bootstrap of the likelihood ratio statistic provides a rigorous way to quantify the probability that the model choice is correct: the probability that the data was produced by the test model vs the null model is assured by the Neyman-Pearson lemma.</description>
    </item>
    
    <item>
      <title>Multivariate normal random variables</title>
      <link>/2010/07/12/multivariate-normal-random-variables/</link>
      <pubDate>Mon, 12 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/12/multivariate-normal-random-variables/</guid>
      <description>GSL lacks a multivariate normal random variable option, so have implemented one using the eigenvalue decomposition (default method in the R function rmvnorm). Function should consider doing error handling (i.e. warning if covariance matrix isn&amp;rsquo;t positive definite or if the vectors given don&amp;rsquo;t match dimensions), though these may be mostly unnecessary cost. Also uses a general blas matrix multiplication when one of the matrices is just sqrt(eigenvalues) on the diagonal, so this could possibly be sped up considerably using the correct blas matrix multiply.</description>
    </item>
    
    <item>
      <title>Status - Thoughts</title>
      <link>/2010/07/09/status---thoughts/</link>
      <pubDate>Fri, 09 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/09/status---thoughts/</guid>
      <description>Goal: BM vs OU vs proposed multipeak OU model with and without global alpha/sigma. Anoles dataset, carex dataset, labrids?
 Added ape2ouch_all function based on maticce to convert file formats. Might be worth checking against my current implementation. Meanwhile it&amp;rsquo;s really the converting trees back from ouch to ape that gives the ace function trouble. something about ordering of the nodes, even though that shouldn&amp;rsquo;t matter in the phylo format.</description>
    </item>
    
    <item>
      <title>Evolutionary Regime Shift examples</title>
      <link>/2010/07/08/evolutionary-regime-shift-examples/</link>
      <pubDate>Thu, 08 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/08/evolutionary-regime-shift-examples/</guid>
      <description>Time to get more data and examples to start testing methods, particularly for cases in where regime shifts are hypothesized by painting a tree. Starting a Mendeley public collection for the literature in Web of Science that actually applies either the OUCH or Brownie framework to identify shifts in rates of continuous trait evolution.
Research collected using Mendeley

now I&amp;rsquo;ll have to see how hard it is to obtain both the trees and trait data&amp;hellip;</description>
    </item>
    
    <item>
      <title>Ensemble simulations of beetle dynamics</title>
      <link>/2010/07/07/ensemble-simulations-of-beetle-dynamics/</link>
      <pubDate>Wed, 07 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/07/ensemble-simulations-of-beetle-dynamics/</guid>
      <description>code Fig 1
code Fig 2
code Fig 3
Exploring full ensemble simulations of beetle dynamics. Linear noise approximations (Fig 2) show divergent noise under oscillating conditions (Fig 2 lower panel), though this may be an artifact of the approximation, which applies only for finite time calculations.

Note that mean dynamics agree, and oscillations damp out, Fig 1 simulation means (circles) fall exactly on predicted lines. Variance dynamics do not agree.</description>
    </item>
    
    <item>
      <title>Multitype OU process interfaces</title>
      <link>/2010/07/07/multitype-ou-process-interfaces/</link>
      <pubDate>Wed, 07 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/07/multitype-ou-process-interfaces/</guid>
      <description>Removing old implementations from the R package, so will need to grab them from the version history from now on to access the original linear implementations.
 Nelder-Mead simplex algorithm seems quite sensitive to starting conditions. Seeding it with values fit from the hansen algorithm (global alpha and sigma), it rapidly improves the log likelihood score (going up from 25 to 30, which is just barely significant according to AIC).</description>
    </item>
    
    <item>
      <title>Generalizing the multi-type OU process- continued</title>
      <link>/2010/07/02/generalizing-the-multi-type-ou-process--continued/</link>
      <pubDate>Fri, 02 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/02/generalizing-the-multi-type-ou-process--continued/</guid>
      <description>Efficiency updates:
 As expected, calculating the last common ancestor on the fly was responsible for a significant (&amp;gt;50%) fraction of the computational effort, so it&amp;rsquo;s worth calculating this once for the tree and storing the information. Current profiling table:   % cumulative self self total time seconds seconds calls us/call us/call name 57.14 0.08 0.08 1604986 0.05 0.05 calc_gamma 35.71 0.13 0.05 802493 0.06 0.16 calc_var 7.14 0.14 0.</description>
    </item>
    
    <item>
      <title>Multitype OU Processes with varying alpha and sigma</title>
      <link>/2010/07/01/multitype-ou-processes-with-varying-alpha-and-sigma/</link>
      <pubDate>Thu, 01 Jul 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/07/01/multitype-ou-processes-with-varying-alpha-and-sigma/</guid>
      <description>Been meaning to sit down and work this one out for a while; somehow travel and conferences helped out with that &amp;ndash; now I only have to transcribe some dozen messy hotel notepad sheets to get the calculations into this lab notebook. Meanwhile, 15 hours on a train from Portland was just the right amount of time to code up the approach, which is now implemented at the C level for the Anoles dataset; code in the wrightscape project on github.</description>
    </item>
    
    <item>
      <title>iEvoBio day two</title>
      <link>/2010/06/30/ievobio-day-two/</link>
      <pubDate>Wed, 30 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/30/ievobio-day-two/</guid>
      <description>Program:

My Lightning talk on Open Science:
Ievobio
View more presentations from cboettig.
Also in Nature Proceedings.</description>
    </item>
    
    <item>
      <title>iEvoBio day one</title>
      <link>/2010/06/29/ievobio-day-one/</link>
      <pubDate>Tue, 29 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/29/ievobio-day-one/</guid>
      <description>Program:
conference twitter
 Lunch with O&amp;rsquo;Meara &amp;amp; Price, discussing working group potential
 Dinner with Nescent folks on Dryad project and others</description>
    </item>
    
    <item>
      <title>Evolution 2010 Day 3</title>
      <link>/2010/06/28/evolution-2010-day-3/</link>
      <pubDate>Mon, 28 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/28/evolution-2010-day-3/</guid>
      <description>Chris Martin: Trophic innovation drives exceptional rates of morphological diversification in two adaptive radiations of Cyprinodon pupfishes  Fantastic story of exceptional rates of evolution and trophic novelty in two tropical lakes. (8:45, Adaptation 9, talk 097002)
 David Plachetzki: Deep homology and the evolution of animal senses: insights from Cnidaria  Cnidarians have homologous proteins to opsins and taste receptors!
 Jeremy Yoder: Coevolution and gene flow in obligate pollination mutualism  Two species of joshua tree each with its own pollinator yucca moth.</description>
    </item>
    
    <item>
      <title>Evolution 2010 Day 2</title>
      <link>/2010/06/27/evolution-2010-day-2/</link>
      <pubDate>Sun, 27 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/27/evolution-2010-day-2/</guid>
      <description>Clay Cressler : Can you trust evolutionary parameters estimated by complex phylogenetic comparative methods? A simulation study with OUCH
 Jeet Sukumaran (Mark Holder lab) Performance and robustness of phylogeographic analytical studies
  Tests common macroscopic models of inferring population structure (i.e. via coalescent) an individual based simulation model.
 Graham Slater, Luke Harmon, Liam Revell, Marc Suchard, Mike Alfaro. Estimating rates of phenotypic evolution and speciation from incomplete trees.</description>
    </item>
    
    <item>
      <title>Evolution 2010</title>
      <link>/2010/06/26/evolution-2010/</link>
      <pubDate>Sat, 26 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/26/evolution-2010/</guid>
      <description>Carl Boettiger A new phylogenetic comparative method: detecting niches and transitions with continuous characters  My slides:
A new phylogenetic comparative method: detecting niches and transitions with continuous characters
View more presentations from cboettig.
 Joe Felsenstein A comparative method for discrete and continuous characters using the threshold model
 Lynsey McInnes: Deep-time changes to equilibrium diversity &amp;ndash; a simulation study of th power to detect rule changes from reconstructed phylogenies</description>
    </item>
    
    <item>
      <title>CSGF Conference Thursday</title>
      <link>/2010/06/24/csgf-conference-thursday/</link>
      <pubDate>Thu, 24 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/24/csgf-conference-thursday/</guid>
      <description>Conference Agenda</description>
    </item>
    
    <item>
      <title>CSGF Conference Day 2</title>
      <link>/2010/06/23/doe-csgf-conference-day-2/</link>
      <pubDate>Wed, 23 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/23/doe-csgf-conference-day-2/</guid>
      <description>DoE CSGF Conference, Day 2
Conference Agenda

Fellows Poster Session Photo credit Michelle King, Krell Institute. Others in the photo are: Devin Matthews, University of Texas at Austin, DOE CSGF fellow (dark blue CSGF shirt) and Jeff Lewandowski, Computational Science and Discovery Magazine.


Presented my poster which qualified as a finalist in the competition.</description>
    </item>
    
    <item>
      <title>CSGF Conference- Tuesday</title>
      <link>/2010/06/22/csgf-conference-tuesday/</link>
      <pubDate>Tue, 22 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/22/csgf-conference-tuesday/</guid>
      <description>Conference Agenda

HPC Survey Results Presented the results of my survey of the computational habits and tools of CSGF fellows and alumni. See my Survey summary. Slides, data, etc available on my github repository.</description>
    </item>
    
    <item>
      <title>CSGF Conference- HPC Workshop</title>
      <link>/2010/06/21/csgf-conference-hpc-workshop/</link>
      <pubDate>Mon, 21 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/21/csgf-conference-hpc-workshop/</guid>
      <description>I found the breakout sessions in the afternoon particularly fascinating for their paradigm-breaking look into the future of high performance computing. While FLOPS become free, huge scale and ultra-low-power devices (little voltage difference to identify bits) make error handling a topic of major concern, and the idea of &amp;ldquo;wasting&amp;rdquo; processors to perform redundant calculations to avoid errors becomes quite serious. Other ideas, like moving computation around the memory instead of the reverse, the rise of large data and questioning the role of GPU and other novel architecture was also an important theme.</description>
    </item>
    
    <item>
      <title>Wainwright Lab Meeting</title>
      <link>/2010/06/16/wainwright-lab-meeting/</link>
      <pubDate>Wed, 16 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/16/wainwright-lab-meeting/</guid>
      <description>Presented a revised version of my talk for Evolution 2010, focusing on the inadequacy of information-criteria heuristics for model choice in phylogenetic comparative methods and presenting the likelihood-ratio based approach I&amp;rsquo;ve been working on. Much better received this time. (The last two weeks have been pretty dedicated to preparing for the upcoming conferences, mostly for this presentation, so not much in the way of new research. Will be able to return to new stuff in July, following iEvoBio).</description>
    </item>
    
    <item>
      <title>Questions</title>
      <link>/2010/06/10/questions/</link>
      <pubDate>Thu, 10 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/10/questions/</guid>
      <description>Current population dynamics model macroscopic equations:
Interpreting μ terms as death events, b as birth, and the a terms as transitions between age classes gives a natural form for the master equation.
Divergent Solutions to the linear noise approximation? Breaking the age classes into k subclasses makes waiting time within an age class gamma instead of exponential, which better matches observation. Also allows sustained oscillations. The numerical solution to the linear noise approximation shows divergent variance dynamics.</description>
    </item>
    
    <item>
      <title>Graham &amp; Peter Meeting</title>
      <link>/2010/06/09/graham-and-peter-meeting/</link>
      <pubDate>Wed, 09 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/09/graham-and-peter-meeting/</guid>
      <description>Fantastic meeting with Graham and Peter today, covered a lot of ground.
MNV I briefly sketched the multivariate normal solution for joint probability across the tree under the regimes model. The original regimes approach did not take advantage of the fact that the solution to the joint probability across the tree is multivariate normal given the painting. This allows the calculation to be partitioned as outlined in Saturday&amp;rsquo;s entry:</description>
    </item>
    
    <item>
      <title>Making slides for Evolution meeting</title>
      <link>/2010/06/08/making-slides-for-evolution-meeting/</link>
      <pubDate>Tue, 08 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/08/making-slides-for-evolution-meeting/</guid>
      <description>Anoles LP model vs BM
Anoles LP fits vs OU1
Anoles Neyman-Pearson model selection
Visualization of transition matrix</description>
    </item>
    
    <item>
      <title>Implementing the new approach</title>
      <link>/2010/06/06/implementing-the-new-approach/</link>
      <pubDate>Sun, 06 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/06/implementing-the-new-approach/</guid>
      <description>Spent just about the entire day off and on implementing the approach described in yesterday&amp;rsquo;s entry. Code includes the more direct implementation of the likelihood by generating trees from the process and averaging, as well as by weighting trees by their probability. Methods appear to agree reasonably well. The second approach should generate a wider variety of trees instead of using those produced by the first method. This could be done by varying the parameters of the transition rates to populate the collection.</description>
    </item>
    
    <item>
      <title>Likelihood Calculation</title>
      <link>/2010/06/05/likelihood-calculation/</link>
      <pubDate>Sat, 05 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/05/likelihood-calculation/</guid>
      <description>Direct Calculation of the Joint Probability Fig 1 Sample tree
 This is the approach implemented in the wrightscape project matrix_method.c. Consider an example phylogenetic tree (Fig 1) over which a stochastic process describes the evolution of trait x, defined by the transition probability rate w. Then the joint probability for a set of observed traits under this process can be written:   The transition density from any state to any state can be represented as a matrix over the domain of the integral.</description>
    </item>
    
    <item>
      <title>Comparative Phylogenetics Talk</title>
      <link>/2010/06/04/comparative-phylogenetics-talk/</link>
      <pubDate>Fri, 04 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/04/comparative-phylogenetics-talk/</guid>
      <description>Practice talk in Wainwright lab meeting next Weds. 12 minutes.
 Introduce question: Inferring the number of regimes Context relative to existing methods Statistical challenges &amp;ndash; model-dependent phylogenetic signal problem Labrid example  Frameworks for approaching regimes question  wrightscape phylogenetically corrected clustering
 speed/feasibility concerns, rate limiting steps.
 model realism / representation concerns
 statistical concerns
  Returning to Wrightscape approach Haven&amp;rsquo;t worked on the full problem of inferring multiple peaks directly from comparative data using the joint probability calculation since the beginning of this notebook, so about time to return to the direct problem and compare with the more heuristic approach of &amp;ldquo;phylogenetically corrected clustering&amp;rdquo; and also synthesize the work on uncertainty which has been a dominate theme thus far (add category label for this group!</description>
    </item>
    
    <item>
      <title>Entry title</title>
      <link>/2010/06/03/entry-title/</link>
      <pubDate>Thu, 03 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/03/entry-title/</guid>
      <description>Insert content here&amp;hellip;</description>
    </item>
    
    <item>
      <title>Actually starting at Arkin Lab</title>
      <link>/2010/06/02/actually-starting-at-arkin-lab/</link>
      <pubDate>Wed, 02 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/02/actually-starting-at-arkin-lab/</guid>
      <description>Meeting with M. Samoilov  Kurtz Theorems: two limits, timescale and system size, often taken in the wrong order in practice. Einstein-Smoluchowski debate regarding Langevin correspondence to Ito vs Statonvich representations resolved: [theorem]. (Statonvich is the more natural interpretation of the way in which we measure data to compare to Langevin. Of course Ito and Stratonvich can be mapped back and forth anyway). Of course this difference doesn&amp;rsquo;t exist, and nothing goes wrong / no stochastic surprises if dynamics are linear.</description>
    </item>
    
    <item>
      <title>Gamma Waiting times on individual level</title>
      <link>/2010/06/01/gamma-waiting-times-on-individual-level/</link>
      <pubDate>Tue, 01 Jun 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/06/01/gamma-waiting-times-on-individual-level/</guid>
      <description>Wrote the proper record structure into C code to handle reporting to R, including ensemble data. Wrote the R interface to the dynamics. Needs exploration.  Version-stable code for parameters. Run using defaults, graph as:
png(&amp;quot;ibm_gamma.png&amp;quot;) o &amp;lt;- gamma_beetles_ibm() plot(o$times, o$mv[[1,1]], type=&#39;l&#39;, col=&amp;quot;yellow&amp;quot;) lines(o$times, o$mv[[1,2]], col=&amp;quot;yellowgreen&amp;quot;) lines(o$times, o$mv[[1,3]], col=&amp;quot;lightgreen&amp;quot;) lines(o$times, o$mv[[1,4]], col=&amp;quot;darkgreen&amp;quot;) dev.off() o$parameters b ue ul up ua ae al ap cle cap 5.000 0.000 0.001 0.000 0.010 1.</description>
    </item>
    
    <item>
      <title>CSGF Survey</title>
      <link>/2010/05/31/csgf-survey/</link>
      <pubDate>Mon, 31 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/31/csgf-survey/</guid>
      <description>Wrote survey. Getting feedback and will send out this week.  previous comments
Wiki Tricks Exploring use of mvs to download and upload entries from openwetware. The mediawiki client is easy to install as described in the link. Doesn&amp;rsquo;t seem to have a tool to grab everything in my Notebook namespace, but with a little bash script I can grab all the entries in a particular notebook:</description>
    </item>
    
    <item>
      <title>Individual based simulation with gamma waiting times</title>
      <link>/2010/05/29/individual-based-simulation-with-gamma-waiting-times/</link>
      <pubDate>Sat, 29 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/29/individual-based-simulation-with-gamma-waiting-times/</guid>
      <description>Began implementing the individual-based simulation of gamma waiting times by subdividing the first three age classes into K subclasses. Required rewriting gillespie function so as to intelligently calculate rates rather than writing 3K+1 functions. This leads to an alternative gillespie simulation interface that takes a function to calculate rates, producing cumulative sum (though perhaps that step should be moved into the raw gillespie code) of rates for each event, and an outcome function that will execute the outcome of each of those events.</description>
    </item>
    
    <item>
      <title>Conference call w- Bob and Brett</title>
      <link>/2010/05/28/conference-call-w--bob-and-brett/</link>
      <pubDate>Fri, 28 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/28/conference-call-w--bob-and-brett/</guid>
      <description>So far no large noise in larval class alone, several potential mechanisms we may have missed so far:  Getting large noise in larva  Noise from egg class (due to nonlinear dynamics) Nonlinearity in larval class due to large larva eating smaller ones Unknown effect of more realistic aging/stage transitions. Long transients? &amp;ndash; Experiments start with larva, pupa, adults to speed up transient period.</description>
    </item>
    
    <item>
      <title>Summary of Structured Population noise so far</title>
      <link>/2010/05/27/summary-of-structured-population-noise-so-far/</link>
      <pubDate>Thu, 27 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/27/summary-of-structured-population-noise-so-far/</guid>
      <description>Fig 1 Code b=5, ue= 0, ul = 0.001, up = 0, ua = 0.01, ae = .13*k, al = .01*k, ap = .15*k, cle = .2, cap = .1, cae = 5, V=volume
Fig 2 b=5, ue= 0, ul = 0.001, up = 0, ua = .001, ae = .1*k, al = .01*k, ap = .1*k, cle = 1, cap = .4, cae = 1, V=volume

System Size Expansion  Analytic calculation captures the noise propagation through the age structure correctly.</description>
    </item>
    
    <item>
      <title>Rethinking Beetles Noise</title>
      <link>/2010/05/26/rethinking-beetles-noise/</link>
      <pubDate>Wed, 26 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/26/rethinking-beetles-noise/</guid>
      <description>Noise in the larval class is damped by and grows proportional to its intrinsic variation and the contribution of other classes through their derivatives of f~L~, that is, as well as the sum of its intrinsic rates (essentially whichever is larger). Taking E dynamics to be fast we might reduce to a continous time LPA model:  and the larval fluctuations are essentially:
where β~i~ is the intrinsic noise of the age class.</description>
    </item>
    
    <item>
      <title>Bug fixed!</title>
      <link>/2010/05/25/bug-fixed/</link>
      <pubDate>Tue, 25 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/25/bug-fixed/</guid>
      <description>Wasn&amp;rsquo;t taking the Jacobian of the transition terms. Fixes the unstable behavior and disagreement between simulations and theory. Other note: the &amp;ldquo;hastings.c&amp;rdquo; model can trivially be obtained from the standard crowley-form metapopulation model by taking b_1 = 0.  For the crowley class of models at least, seems that while the two-step vs one-step involved different dynamics, this difference exists only in transients while equilbrium covariances agree.</description>
    </item>
    
    <item>
      <title>Status on Structured Populations</title>
      <link>/2010/05/24/status-on-structured-populations/</link>
      <pubDate>Mon, 24 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/24/status-on-structured-populations/</guid>
      <description>Model roundup  metapop Two populations with one-step transitions. IBM in C code, R interface to IBM and linear noise approximation. crowley One-step transitions version of metapop. R interface to IBM and linear noise. beetles Two-step transitions with exponential waiting times in age classes. R interface completed in ind_based_models.R hastings Simple two-step model. no R interfaces yet. tribolium Non-markov aging process. R interface completed in simulate.R. includes likelihood inference as well.</description>
    </item>
    
    <item>
      <title>Puzzled over the two-step jump process results</title>
      <link>/2010/05/21/puzzled-over-the-two-step-jump-process-results/</link>
      <pubDate>Fri, 21 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/21/puzzled-over-the-two-step-jump-process-results/</guid>
      <description>The variance dynamics are slightly different if the continuous time Markov process allows events to contain two steps (such as a transition of an individual from one age class to another, or one patch to another, etc) as well as one step birth/death) transitions. *V*τ~*i*j~(X / V) to represent the rate of transitions from state i to state j. We change variables for our state space from the discrete count state variable X by dividing by the system size (volume) V, to obtain the continuous, mean-field approximation of the density p = X/V.</description>
    </item>
    
    <item>
      <title>Beetle dynamics exploration &amp; adjustments</title>
      <link>/2010/05/20/beetle-dynamics-exploration-and-adjustments/</link>
      <pubDate>Thu, 20 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/20/beetle-dynamics-exploration-and-adjustments/</guid>
      <description>Adjusted individual based Crowley model to follow same parameterization as the macroscopic model. IBM rules had divided b and c by K in the dynamics while the macroscopic was just using rescaled dynamical rates. Now both use the rescaled rates as parameter values while the equations match.
 Variation in the Crowley model agrees between individual-based simulation and the equations.
  Code troubleshooting  openmp private declarations perform allocs without frees!</description>
    </item>
    
    <item>
      <title>Noisy Beetles</title>
      <link>/2010/05/19/noisy-beetles/</link>
      <pubDate>Wed, 19 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/19/noisy-beetles/</guid>
      <description>Goals  individual-based simulation via my gillespie C library with 2-step transitions.
 Integrate the function definitions from R? Use of R formula language? Conversely, have the R code use the C functions?  Handle population-size scaling correctly
 Methods write-up, read/compare to other examples.
 Exploration/demonstration of the significance of two-step process vs two one-step processes. Highlight which examples will show largest differences, and in which terms (means vs variances/covariances, etc).</description>
    </item>
    
    <item>
      <title>Noisy beetles</title>
      <link>/2010/05/18/noisy-beetles/</link>
      <pubDate>Tue, 18 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/18/noisy-beetles/</guid>
      <description>Fig 1: Noise in lavae dominate
Fig: 2 lower mortality, higher noise
 Success! My first full implementation of the four stage (EPLA) beetle model, so far without any adaptation, and the noise of the larval class dominates (Fig 1). Without the time delays the stationary dynamics are stable nodes, at least in this part of parameter space, with a large adult class clamping tightly down on the other classes.</description>
    </item>
    
    <item>
      <title>Annual Progress Report</title>
      <link>/2010/05/17/annual-progress-report/</link>
      <pubDate>Mon, 17 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/17/annual-progress-report/</guid>
      <description>Tomorrow will be meeting with my dissertation committee: Alan Hastings, Peter Wainwright, and Brian Moore. This provides a good opportunity to summarize the status of my current projects and my principle accomplishments for the year. Will try a tex&amp;rsquo;d document as I&amp;rsquo;ve done in previous years but here&amp;rsquo;s for some preliminary brainstorming.
 Summary: In the past year, I&amp;rsquo;ve published one paper, given 4 talks (CPB, NIMBioS, Berkeley, IIASA), read 144+ articles and wrote 9000+ lines of code.</description>
    </item>
    
    <item>
      <title>General matrix form and correcting equations</title>
      <link>/2010/05/16/general-matrix-form-and-correcting-equations/</link>
      <pubDate>Sun, 16 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/16/general-matrix-form-and-correcting-equations/</guid>
      <description>Pursuing a matrix form, seems I had missed some terms in the covariance equations Friday, which are suggested by the nice symmetry of this representation: (sometimes chalk and a camera are faster than tex).
This suggests the general form looks like
*dM* = *JM* + (*J*M)^T^ + g
Where M is the covariance matrix and J the Jacobian of f as before. dM is the matrix of derivative terms, though clearly not a rigorous notation.</description>
    </item>
    
    <item>
      <title>Large Intrinsic Noise</title>
      <link>/2010/05/15/large-intrinsic-noise/</link>
      <pubDate>Sat, 15 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/15/large-intrinsic-noise/</guid>
      <description>Modified Crowley model Realizing Arbitrarily large demographic noise systems??
Consider the Crowley model from last week which I&amp;rsquo;d implemented as an individual birth-death model: (x is the better competitor, y the better colonist)
I&amp;rsquo;ve implemented the linear noise approximation for this model as a system of coupled ODEs:
And solved numerically (R code, links directly to this version and can run stand-alone from the package) using parameter values matching the individual based simulation (C code from warning_signals package).</description>
    </item>
    
    <item>
      <title>Structured Population Dynamics</title>
      <link>/2010/05/14/structured-population-dynamics/</link>
      <pubDate>Fri, 14 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/14/structured-population-dynamics/</guid>
      <description>Beetle Model Macroscopic equations:
Has the corresponding variance-covariance dynamics
Where g_i is the second jump moment, which is a function of the state (E, L, P, A) just as f_i is. (In this case it will correspond to the sum of all birth and death terms).
General Form &amp;amp; Algorithm Consider the dynamics are given by
and define variance-covariance matrix M and the Jacobian matrix of f as J. Then the dynamics of the diagonal elements (variance terms) are written as</description>
    </item>
    
    <item>
      <title>Adaptive Dynamics</title>
      <link>/2010/05/13/adaptive-dynamics/</link>
      <pubDate>Thu, 13 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/13/adaptive-dynamics/</guid>
      <description>Public code hosting  Project code now available through Github. Advantages to public hosting: Replication of adaptive dynamics simulations can be difficult, particularly in matching various nuisance parameters. While there is certainly much pedagogical value in individual researchers implementing their own simulations, verification and reproducibility of scientific results would be greatly facilitated by adapting an accepted open source code base and adding branches, etc. Researchers could much more immediately benefit from the work of their colleagues and spend more time implementing novel research and less reproducing it.</description>
    </item>
    
    <item>
      <title>Beetles workshop Day 2</title>
      <link>/2010/05/13/beetles-workshop-day-2/</link>
      <pubDate>Thu, 13 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/13/beetles-workshop-day-2/</guid>
      <description>Goals  van Kampen expansion of LPA model, maximize noise in L while keeping A robust?   Indiv. heterogeneity issue: dividing larval class into a smaller, highly-cannibal and remainder of more weakly cannibalistic. Pulse dynamics &amp;ndash; interspike interval, magnitude?  Potential Data  1995 Dennis et al. &amp;ndash; 5 replicate populations (2-cycle dataset), 5 age-cycles. eight-year chaotic time series Strawbridge daily samples (single replicate), occasional disease in lines though.</description>
    </item>
    
    <item>
      <title>Hastings Beetle Workshop</title>
      <link>/2010/05/12/hastings-beetle-workshop/</link>
      <pubDate>Wed, 12 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/12/hastings-beetle-workshop/</guid>
      <description>Bob Costantino and Brett Melbourne are joining us for the next two days to talk about stochastic population dynamics in Tribolium.
 Morning Session, 9a - 11a
 Outline the individual based model, toolbox  Group lunch, noon-1:30
 My lab Presentation, 2p-3p
 Present multidimensional linear noise approximation approach to characterizing the demographically stochastic key class.  Afternoon session, 3p-4p
 Follow-up on understanding noise propagation in age structure dynamics.</description>
    </item>
    
    <item>
      <title>Roi and Sam Comparative Phylogenetics R Workshop</title>
      <link>/2010/05/12/roi-and-sam-comparative-phylogenetics-r-workshop/</link>
      <pubDate>Wed, 12 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/12/roi-and-sam-comparative-phylogenetics-r-workshop/</guid>
      <description>Day 2: 4p - 6:30p  Attending the R workshop by Roi Holzmann and Sam Price from the Wainwright lab. Missed the introductory session on Monday. Course data currently available here. Resources: Springer R books pdfs available through UC Davis. In particular: R book w/ ape.  Speciation &amp;amp; Diversification 3rd session (4:10 - 5:10 pm): Packages: Laser, Geiger, Ape, apTreeshape &amp;amp; Diversitree
 Lineage through time plots ape and laser:   ltt.</description>
    </item>
    
    <item>
      <title>Demographic Noise</title>
      <link>/2010/05/11/demographic-noise/</link>
      <pubDate>Tue, 11 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/11/demographic-noise/</guid>
      <description>Crowley Model  Exploring the extent to which demographic stochasticity in a key class can reverberate through the entire population dynamics. Starting with a simple test case of a modified Crowley model:   Model is implemented on a branch of the warningSignals package. Model in crowley.c, Depends on modified gillespie.c library in this package. Branching necessary as implementation simplifies the gillespie function dependencies, but these changes would break compatibility with warning_signals.</description>
    </item>
    
    <item>
      <title>Peter Meeting</title>
      <link>/2010/05/11/peter-meeting/</link>
      <pubDate>Tue, 11 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/11/peter-meeting/</guid>
      <description>Discussed potential solution to the model choice scenario:
 Consider an ordered list of models, A, B, C, D Then the Neyman-Pearson Lemma (see earlier entry on this) lets us walk through the list in the following fashion: We generate the simulated data sets under model A and compare likelihood ratios in each case. If the likelihood ratio of the observed data falls outside the 95% confidence interval, than it with this confidence that we are saying the data justify the alternate model (model B).</description>
    </item>
    
    <item>
      <title>Alan Meeting</title>
      <link>/2010/05/10/alan-meeting/</link>
      <pubDate>Mon, 10 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/10/alan-meeting/</guid>
      <description>Updates  Likelihood calculation for beetle model. Proposed model and calculations Linear parameter change for warning signal model. Results in a few test cases. Likelihood methods within SDE framework, an outline of methods. Subtle problems, good approximations, powerful approaches.  
Questions  LPA vs ELLPA model Defining state space in individual-based model vs stage based model, setting initial conditions? Conclusion: Means non-Markovian system, so likelihood isn&amp;rsquo;t determined in one step approach.</description>
    </item>
    
    <item>
      <title>Warning Signals with SDEs</title>
      <link>/2010/05/09/warning-signals-with-sdes/</link>
      <pubDate>Sun, 09 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/09/warning-signals-with-sdes/</guid>
      <description>Summary  Have a functional likelihood calculation from the full individual-based simulation, see Friday. Accuracy needs more testing, and the computation is probably too slow for optimization routines. Have an implementation of the linear decrease in stability model with analytic conditional probability density. Needed a couple adjustments today. Need to add direct simulation to the warning signals package, currently retunrs only time-averaged/ensemble averaged stats. Can be approximated by setting the window equal to the timestep and ensembles equal to one.</description>
    </item>
    
    <item>
      <title>Likelihood calculation</title>
      <link>/2010/05/07/likelihood-calculation/</link>
      <pubDate>Fri, 07 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/07/likelihood-calculation/</guid>
      <description>Implemented the likelihood calculation in simulate.R code. See today&amp;rsquo;s revision changes via github beetle_sim() updated to return the full simulation to R. likelihood calculation by simulation done in parallel  library(beetles) sim &amp;lt;- beetle_sim() L &amp;lt;- likelihood(par=sim$par, X=sim$state[,2:6], Dt = sim$state[2,1]-sim$state[1,1] ) -sum(log(L))  Decent estimates of likelihood may be challenging: Modifying default settings for longer tome series:
&amp;gt; sim &amp;lt;- beetle_sim(dt = 7, T = 500) &amp;gt; L &amp;lt;- likelihood(par=sim$par, X=sim$state[,2:6], dt = sim$state[2,1]-sim$state[1,1], reps=100 ) &amp;gt; L2 &amp;lt;- likelihood(par=sim$par, X=sim$state[,2:6], dt = sim$state[2,1]-sim$state[1,1], reps=100 ) &amp;gt; -sum(log(L2)) [1] 2132.</description>
    </item>
    
    <item>
      <title>Goals</title>
      <link>/2010/05/06/goals/</link>
      <pubDate>Thu, 06 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/06/goals/</guid>
      <description>Model choice exercise with sdes general likelihood calculation from simulation  Test Case *dX*~t~ = α~t~(θ − X~t~)*dt* + σ*d*t
*d*α~t~ = − β

Approach  The linear approximation to the warning signals dynamics can be captured by the OU process, look for changing α SDE models will also provide some of the coarser approximations for the structured population dynamics. Formulations of these still to do.  Conditional probability Solution to the time dependent OU process, see Gardiner 4th ed.</description>
    </item>
    
    <item>
      <title>Primates</title>
      <link>/2010/05/05/primates/</link>
      <pubDate>Wed, 05 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/05/primates/</guid>
      <description>Primates project now has a Github repository. Updates are embedded from here.
 Experimenting with distributing code and data effectively. Pluses and minuses of three options:
   zipped file with R code and data. Requires setting working directory, harder to update. Subsequent uploads must include all the data, rather than incremental. Directly grab repository over github. Simple to update and access, stores only incremental changes. Requires knowledge of git R package: Nicely integrates data, code, and documentation.</description>
    </item>
    
    <item>
      <title>Wednesday</title>
      <link>/2010/05/05/wednesday/</link>
      <pubDate>Wed, 05 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/05/wednesday/</guid>
      <description>Structured populations part of project migrated to github from the google code page. Finally switched to using STL for linked list in simulation. Have working simulation function ensemble run function also calculates the probability based on kernel-density estimation from the replicates. Working on likelihood calculation.  Code progress  Lots of fun trying to get full structured population simulator working accurately. See git log for details, but ended up abandoning two separate versions of custom-written C linked lists and just switched entire code over to C++ to use the STL&amp;rsquo;s linked list, which finally worked like a charm.</description>
    </item>
    
    <item>
      <title>Adaptive Dynamics</title>
      <link>/2010/05/04/adaptive-dynamics/</link>
      <pubDate>Tue, 04 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/04/adaptive-dynamics/</guid>
      <description>Wide gap, flat landscape  Waiting times on a flatter landscape: sigma_c ~ sigma_k. Waiting times are dominated by the number of times phase 3 collapses: the established invader in a dimorphic population (right panels). Collapse of phase 2: collapse of the dimorphism before third population can establish is much rarer (about an order of magnitude).   from the run3 dataset, with parameters.  Narrower gap, steeper landscape  with sigma_c &amp;lt;&amp;lt; sigma_k, branching is easy, neither phase is particularly limiting, though single collapses from both phases are very common.</description>
    </item>
    
    <item>
      <title>Alan Meeting</title>
      <link>/2010/05/04/alan-meeting/</link>
      <pubDate>Tue, 04 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/04/alan-meeting/</guid>
      <description>Goals next week: Bob &amp;amp; Brian beetle data: what an analysis would be with complete stochastic description. Compare models with different  Full model: Parameter list from current code:
/* Biological Parameters. eggs and pupa can get canibalized */ double b = 5; /* Birth rate (per day) */ double u_egg = 0, u_larva = 0.001, u_pupa = 0, u_adult = 0.003; /* Mortality rate (per day) */ double a_egg = 3.</description>
    </item>
    
    <item>
      <title>Adaptive Dynamics</title>
      <link>/2010/05/03/adaptive-dynamics/</link>
      <pubDate>Mon, 03 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/03/adaptive-dynamics/</guid>
      <description>Working on simulation based approach to summarize distribution of waiting times across different phases. What to do about zeros in phase two (when first dimorphism survives long enough to be invaded&amp;hellip;) Quantify number/distribution of failed attempts at each phase? How to represent these distributions across a parameter space in sigma_c, sigma_k, sigma_mu, and mu?  library(BranchingTime) sim &amp;lt;- branching_time(rep=1000, cpu=8) save(file = &amp;quot;run1.Rdat&amp;quot;) pdf(&amp;quot;distribution.pdf&amp;quot;) m &amp;lt;- max(sim$data) plot(density(sim$data[1,]), xlim = c(0,m), col=&amp;quot;black&amp;quot; ) lines(density(sim$data[2,] ), col = &amp;quot;blue&amp;quot;) lines(density(sim$data[3,] ), col = &amp;quot;green&amp;quot;) lines(density(sim$data[4,] ), col = &amp;quot;red&amp;quot;) legend(&#39;topright&#39;, c(&amp;quot;1&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;3&amp;quot;, &amp;quot;4&amp;quot;), col=c(&amp;quot;black&amp;quot;, &amp;quot;blue&amp;quot;, &amp;quot;green&amp;quot;, &amp;quot;red&amp;quot;), pch = 15) dev.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/05/01/coexistence-of-the-early-dimorphism/</link>
      <pubDate>Sat, 01 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/01/coexistence-of-the-early-dimorphism/</guid>
      <description>editorial note: These notes pre-date the formal start of my online laboratory notebook, Feb 2 2010: The Lab Notebook Goes Open and were adapted from a LaTeX document in which I kept notes on this topic during my summer at IIASA. Lacking a proper notebook then, documents like this one were updated periodically and occassionally branched into new ones. The post date represents the last time the LaTeX document was edited in the course of that research.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/05/01/phase1/</link>
      <pubDate>Sat, 01 May 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/05/01/phase1/</guid>
      <description>editorial note: These notes pre-date the formal start of my online laboratory notebook, Feb 2 2010: The Lab Notebook Goes Open and were adapted from a LaTeX document in which I kept notes on this topic during my summer at IIASA. Lacking a proper notebook then, documents like this one were updated periodically and occassionally branched into new ones. The post date represents the last time the LaTeX document was edited in the course of that research.</description>
    </item>
    
    <item>
      <title>Adaptive Dynamics</title>
      <link>/2010/04/30/adaptive-dynamics/</link>
      <pubDate>Fri, 30 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/30/adaptive-dynamics/</guid>
      <description>Modified code phase definitions: phasetime[0] is the first time dimorphism is established. Dimorphism may be lost and restablished, last (most recent) time it establishes is phasetime1. Other times are still the most recent time at which the phase was accomplished.
 Fiddling with analytic approximations. These shouldn&amp;rsquo;t integrate to evaluate at each value, but should be done in a fully discretized system. Prototyping in R, the discrete version is probably fast enough to handle in scripted code alone.</description>
    </item>
    
    <item>
      <title>Adaptive Dynamics</title>
      <link>/2010/04/29/adaptive-dynamics/</link>
      <pubDate>Thu, 29 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/29/adaptive-dynamics/</guid>
      <description>Manuscript writing.  Phylogenetics Submitted Lightning talk to iEvoBio
PDG group will be discussing
 Rabosky DL and Lovette IJ. .&amp;rdquo;) pmid:18611849. PubMed HubMed [1]  tomorrow, along with critique and response.
 Waiting to hear back from Peter on manuscript. Should follow up with Ralph on likelihood ratio discussion with Ethan. Transcluding exploratory work on primate phylogeny data:  Embedded:

Primate Phylogeny Carl Boettiger 00:37, 30 April 2010 (EDT):</description>
    </item>
    
    <item>
      <title>Meetings</title>
      <link>/2010/04/28/meetings/</link>
      <pubDate>Wed, 28 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/28/meetings/</guid>
      <description>Theory Coffee 10-11a: Varied discussion, including NEON project and future of large data.
 Hastings Lab Meeting 2-3p: David Kling presents bioeconomic model on assisted migration. Model focuses on dynamic and spatial aspects, reflects pattern of dispersal common in ideal free distribution with dynamic carrying capacity, adds linear and quadratic costs.
 (Fire alarms in Wickson Hall don&amp;rsquo;t make for a productive day).</description>
    </item>
    
    <item>
      <title>iEvoBio lightning talk</title>
      <link>/2010/04/27/ievobio-lightning-talk/</link>
      <pubDate>Tue, 27 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/27/ievobio-lightning-talk/</guid>
      <description>Submitting a five minute lighting talk on open science. Submitted version here, final text below. See the page revision history for earlier drafts and the original call below. Special thanks to Sam, Alistair, Betta, Shaun, and Alex for feedback.
My experiment with open science: Why the benefits of sharing go beyond source code The practice and philosophy of open source run deep within the iEvoBio community. Sharing source code has made software development faster and more reliable.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/04/26/teaching/</link>
      <pubDate>Mon, 26 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/26/teaching/</guid>
      <description>GTC: Assessment  Today I&amp;rsquo;m facilitating the GTC session discussing Assessment. Here&amp;rsquo;s our VUE map of the activity.  
What better way to begin a discussion about assessment than with an assessment? We began with a somewhat tongue-in-cheek quiz about the &amp;ldquo;right&amp;rdquo; way to conduct an assessment, modelling some common faults in poor assessments while also serving as a brainstorm to get some ideas out there. We presented some background theory on assessment, drawing from the excellent text: Handelsman, J.</description>
    </item>
    
    <item>
      <title>Adaptive Dynamics</title>
      <link>/2010/04/26/adaptive-dynamics/</link>
      <pubDate>Mon, 26 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/26/adaptive-dynamics/</guid>
      <description>Matching theoretical approximations to simulation:
 Implemented the first analytic approximation, calculating the waiting time to complete phase 1. Established dimophisms are often still lost, hence the first successful completion of phase 1 (dimorphic population in coexistence region with each above threshold size) doesn&amp;rsquo;t match the time of the last completion of phase 1. Phase 2, an established third population seems to happen soon after the last successful phase 1, giving the illusion this step is easy rather than the reality that this process requires fast traversal to persist past the coexistence time.</description>
    </item>
    
    <item>
      <title>Adaptive Dynamics</title>
      <link>/2010/04/23/adaptive-dynamics/</link>
      <pubDate>Fri, 23 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/23/adaptive-dynamics/</guid>
      <description>Computing Challenges  10 - 1p Adding solutions to yesterday&amp;rsquo;s puzzles, see Yesterday&amp;rsquo;s Entry The random number generator solution is imperfect, as it limits the total number of seeds to 1e9 since coercing to an integer will create NAs with larger numbers.  
 seeds &amp;lt;- 1e9*runif(reps) out &amp;lt;- sfSapply(1:reps, function(i){ branch_simulation(seed=seeds[i]) })  Analytic Solutions Git Log  Created commit da58a6e: random number seeds now set to avoid parallel cores running with same seed</description>
    </item>
    
    <item>
      <title>Adaptive Dynamics</title>
      <link>/2010/04/22/adaptive-dynamics/</link>
      <pubDate>Thu, 22 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/22/adaptive-dynamics/</guid>
      <description>compiling with R and C and parallel computing  Problem: cannot get the R code to take advantage of parallelization via openMP.
 Solution:
  C++ file mangles names in .so, changing the .C call. to get the object name:
objdump -x file.so  Carl Boettiger 03:01, 25 May 2010 (EDT): More standard solution: enclose cpp code in
 extern C {  
 Problem: Trouble getting R to export the C library to all nodes.</description>
    </item>
    
    <item>
      <title>Adaptive Dynamics</title>
      <link>/2010/04/21/adaptive-dynamics/</link>
      <pubDate>Wed, 21 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/21/adaptive-dynamics/</guid>
      <description>Wrapping up paper on waiting time to branching in adaptive dynamics. Cleaning up code from summer. Now in a local git repository in adaptiveDynamics/code Moved ensemble parallelization to higher level, so parallelization can be performed in R or C. Adding documentation  Current status  Calculates the waiting time to complete phase 1, phase 2, and phase 3 successfully from individual-based simulation.  Phase 1 ~ Completed when 2 branches exist over threshold Phase 2 ~ Completed when a third population has established over threshold exterior to a stable pair Phase 3 ~ Completed when two populations over threshold are separated in traitspace by more than finishline units</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/04/20/waiting-time/</link>
      <pubDate>Tue, 20 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/20/waiting-time/</guid>
      <description>editorial note: These notes pre-date the formal start of my online laboratory notebook, Feb 2 2010: The Lab Notebook Goes Open and were adapted from a LaTeX document in which I kept notes on this topic during my summer at IIASA. Lacking a proper notebook then, documents like this one were updated periodically and occassionally branched into new ones. The post date represents the last time the LaTeX document was edited in the course of that research.</description>
    </item>
    
    <item>
      <title>Alan Meeting</title>
      <link>/2010/04/20/alan-meeting/</link>
      <pubDate>Tue, 20 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/20/alan-meeting/</guid>
      <description>From 03/31, see below for more!
Outline Title
On the ability to detect leading indicators of catastrophe in unreplicated time series
Introduction Background on Warning Signals
 literature Saddle Node bifurcation Detecting decreasing stabilization &amp;ndash; gradual vs changepoint estimation  Reasons detection can fail:
 Ergodicity: ensembles vs single instances Sufficient statistical power Appropriate dynamics  Methods
 Defining an indicator &amp;ndash; significant Kendall rank correlation coefficient τ as in doi:10.</description>
    </item>
    
    <item>
      <title>R-sig-phylo</title>
      <link>/2010/04/20/r-sig-phylo/</link>
      <pubDate>Tue, 20 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/20/r-sig-phylo/</guid>
      <description>A couple interesting discussions on R-sig-phylo   estimating alpha and sigma reliably, knowing when you hit a likelihood ridge. See discussion. strange behavior in ace. Tried new ace function, same problem.  
Research  Working on logs paper Waiting on Primate data Waiting on feedback on Labrids paper  
DoE Conference Registration  Submitted Poster title and abstract corresponding to my iEvoBio proposal.  Reading  podcast on the Science Careers story.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/2010/04/19/research/</link>
      <pubDate>Mon, 19 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/19/research/</guid>
      <description>Sent Peter updated draft of Labrids manuscript Writing up logarithms manuscript finally&amp;hellip; Contacting Helen re. primates data Created Labrid Functional Morphology literature collection:  Research collected using Mendeley
 Started stochastic methods and model inference collection:  Research collected using Mendeley
Various To Do  Add Peter&amp;rsquo;s bootstrap references and books to stochastic methods and model inference library. Add Science of Science papers to Future of Science collection. Adding tags, abstracts, etc to Mendeley public Library Personal/extended task view (and opinion?</description>
    </item>
    
    <item>
      <title>MATICCE</title>
      <link>/2010/04/18/maticce/</link>
      <pubDate>Sun, 18 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/18/maticce/</guid>
      <description>Testing out Andrew Hipp&amp;rsquo;s maticce package, doi:10.1093/bioinformatics/btp625. Goal of package is to model-average over trees and regimes. Takes a brownie approach to regimes, identifying nodes at which a transition may have occurred.  
The Approach Takes a brute force approach to avoid user-defined paintings in the ouch framework. Users identify nodes of interest, software tries combinations of possible shifts.
runBatchHansen()  User identifies a set of nodes of interest, and optionally a maximum number of transitions.</description>
    </item>
    
    <item>
      <title>iEvoBio Submission</title>
      <link>/2010/04/16/ievobio-submission/</link>
      <pubDate>Fri, 16 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/16/ievobio-submission/</guid>
      <description>Quantifying Information in a Phylogenetic Tree: The Robustness of Phylogenetic Signal Since Felsenstein (1985)&amp;rsquo;s influential paper on phylogenetic contrasts, phylogenetically-based inferences of evolutionary patterns have gotten increasingly more complex (Hansen, 1997; Butler and King, 2004; Freckleton and Harvey, 2006; O&amp;rsquo;Meara et al., 2006; Pagel and Meade, 2006). More and more sophisticated models are applied to datasets of species mean traits on a phylogenetic tree in an attempt to answer such questions as reconstructing ancestral states, identify changes in rates of character evolution across time and across clades, identify the number and location of evolutionary optima or the strength of stabilizing selection.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/04/15/branching-paper/</link>
      <pubDate>Thu, 15 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/15/branching-paper/</guid>
      <description>editorial note: These notes pre-date the formal start of my online laboratory notebook, Feb 2 2010: The Lab Notebook Goes Open and were adapted from a LaTeX document in which I kept notes on this topic during my summer at IIASA. Lacking a proper notebook then, documents like this one were updated periodically and occassionally branched into new ones. The post date represents the last time the LaTeX document was edited in the course of that research.</description>
    </item>
    
    <item>
      <title>Wednesday</title>
      <link>/2010/04/14/wednesday/</link>
      <pubDate>Wed, 14 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/14/wednesday/</guid>
      <description>10-2p Finish preparing for EDG talk.
 2-3p. Talk went pretty well. Could still polish slides up for them to be useful, likewise for outline.
 3-4 OA meeting
 4-9p awesome talk in ESLP with Katie Maynard.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/04/13/teaching/</link>
      <pubDate>Tue, 13 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/13/teaching/</guid>
      <description>Misc / Notes  Starting to prepare for GTC sections  Technology and Education  Open courses backed by learning research: Carnegie Mellon Wallwisher online notice board example Open education featured in NY Times  Assessment  XP instead of grades? Lee Sheldon system another Sheldon method post</description>
    </item>
    
    <item>
      <title>Tuesday</title>
      <link>/2010/04/13/tuesday/</link>
      <pubDate>Tue, 13 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/13/tuesday/</guid>
      <description>Preparing for EDG talk</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/04/12/teaching/</link>
      <pubDate>Mon, 12 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/12/teaching/</guid>
      <description>Notes potentially for my EDG talk.
&amp;ldquo;Keeping Up&amp;rdquo; &amp;ndash; a talk to EDG? Science is growing. Fast. Number of papers published. Genomes on Genbank. Software on CRAN. Everyone&amp;rsquo;s felt the pressure. So what do we do? Keeping with tradition, I&amp;rsquo;ll present my own work in developing comparative phylogenetic methods to identify niche differentiation in Labrid fish. I will try and use this context to pose the question &amp;ndash; what do we do about this information explosion?</description>
    </item>
    
    <item>
      <title>Primate chronogram</title>
      <link>/2010/04/12/primate-chronogram/</link>
      <pubDate>Mon, 12 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/12/primate-chronogram/</guid>
      <description>From User:Daniel Mietchen/Notebook/Evolutionary MRI/2010/04/12:
 Jinchuan Xing recommended New perspectives on anthropoid origins whose Fig. 2 goes into our direction.</description>
    </item>
    
    <item>
      <title>Effective warning signals</title>
      <link>/2010/04/11/effective-warning-signals/</link>
      <pubDate>Sun, 11 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/11/effective-warning-signals/</guid>
      <description>Predicting variance of variance by direct calculation &amp;ndash; still need to crunch some math for the expected convergence.
 Still, the approach should be able to do more than describe single points as unexpected deviates. Still need to address gradual change vs change point analysis. Essentially the same as the phyolgenentic problem &amp;ndash; one rate vs two rates. Model selection approaches? So far theory is essentially built on a model selection between linear models.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/2010/04/09/research/</link>
      <pubDate>Fri, 09 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/09/research/</guid>
      <description>Working on bootstrapping theta parameters bootstrapping multiple parameters doesn&amp;rsquo;t seem effective in the context of the boot package, despite claiming it can use a vector of stats. Certainly part of challenge is that different models have different numbers of parameters, so this isn&amp;rsquo;t a fixed size vector. Approaching manually for the moment, inhibits use of bootstrap confidence intervals function from the boot package. Some irregular behavior in bootstrapping parameters &amp;ndash; have to load package and then reload likelihood_bootstrap library source file or else bootstraps are NAs, needs further investigation.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/04/08/comparative-phylogenetics-notebook/</link>
      <pubDate>Thu, 08 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/08/comparative-phylogenetics-notebook/</guid>
      <description>Research  Wrote summary function using bootstrap confidence intervals for the bootstraps of the likelihoods directly. On interpreting the bootstraps of likelihoods directly:   The extent to which the distributions themselves are distinct provides an indication of the ability to distinguish between models on the given phylogenetic tree and the actual data. For instance, if the tree was a star tree and the data produced by either BM or OU1, then all distributions would fall on top of one another.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/2010/04/08/research/</link>
      <pubDate>Thu, 08 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/08/research/</guid>
      <description>Reviewed timescales manuscript. Revisiting  Meeting  Basically I want to apply central limit theorem for stationary processes (accounts for covariances), assuming mean zero  where
 Discussion of Freidlin-Wentzell theory in connection to Arrhenius law and the well-defined stochastic tipping point which occurs before the branch point. Kurtz results don&amp;rsquo;t really help in the case of ergodicity, can make statements about the (even non-stationary) ensemble limit.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/2010/04/07/research/</link>
      <pubDate>Wed, 07 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/07/research/</guid>
      <description>Goal: complete outline for tomorrow&amp;rsquo;s meeting.  Notes Theory Coffee  Two more days before eve speaker nominations are due. Potentially nominating:
 Brice Kendall Ray Hillborn Model choice (Ecological Detective).  Discussion of post-doc / job application process.
  Education  NIMBioS Computational Biology Curriculum Development July 6-9</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/2010/04/06/research/</link>
      <pubDate>Tue, 06 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/06/research/</guid>
      <description>Seem to have successfully fixed the behavior when getting over parameterized models. See diffs against the git log for details.
 Will work on acceleration of code (avoiding refitting), meanwhile a little more trouble shooting and queuing some long runs.
 ace function fails on certain data sets for unknown reasons. Think rewriting this from scratch will be an important step.
  Mixture Models in Bayesian context  Josh sent me this paper regarding our discussion on model choice in Bayesian context last Friday.</description>
    </item>
    
    <item>
      <title>Towards a meaningful warning signal metric</title>
      <link>/2010/04/06/towards-a-meaningful-warning-signal-metric/</link>
      <pubDate>Tue, 06 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/06/towards-a-meaningful-warning-signal-metric/</guid>
      <description>Most papers do not give a statistical approach, but merely argue for the existence of a trend. Kendall&amp;rsquo;s tau approach proved very unreliable. While the preliminary de-trending approach is unjustified in that the simulated data is known to be absent from trends, as a kind of windowed averaging it may sense as a way to detect changes. Should distinguish between the gradual slow changes and change-point estimation. Perhaps change-point provides a more rigorous starting point.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/2010/04/05/research/</link>
      <pubDate>Mon, 05 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/05/research/</guid>
      <description>Bootstrapping procedures should have the option to refit the painting. Currently use the fixed painting but refit parameters. wrote the function peaks_update() which update the painting as well as the OU peak parameters.  20 replicates, bootstraps the painting step as well
Computing / Package  LR_bootstrap and model_bootstrap should be the same function call with an optional second model for the LR bootstrapping. Similarly the LR_bootstrap_all and model_bootstrap_all() should be the same function call.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/2010/04/04/research/</link>
      <pubDate>Sun, 04 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/04/research/</guid>
      <description>Trouble-shooting on parameter refitting version of LR bootstraps.  
NESCent  Considering a visit to NESCent, meet researchers and learn about programs, post-docs, etc.  People  Todd Vision, UNC &amp;ndash; Ass. Director Informatics. Contact Re: Dryad project. Consider a white paper on interdisciplinary evolutionary synthesis. Brian Weigmann NCSU Diptera Systematics. Ass. Director Outreach NESCent Allen Rodrigo Director NESCent. (Computational evolutionary biology). Discuss possible catalysis meeting, working group, visiting scholar.</description>
    </item>
    
    <item>
      <title>Warning Signals Research</title>
      <link>/2010/04/03/warning-signals-research/</link>
      <pubDate>Sat, 03 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/03/warning-signals-research/</guid>
      <description>Deuterium early warning signal used for Glaciation I-IV presented in Dakos 2008:  Deuterium signal over past 4 glaciations
 Does smoothing to remove trends &amp;ndash; longer-scale fluctuations? Seems unnatural, many of those are part of the signal. Also applied to simulated time series &amp;ndash; even those these are at stationarity! Bandwidth chosen by visual inspection. Get the CaCO3 presented in Scheffer 2010 and Dakos 2008. &amp;ndash; Done: CaCO3</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/2010/04/02/research/</link>
      <pubDate>Fri, 02 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/02/research/</guid>
      <description>Graham &amp;amp; Peter Meeting Fig 1
Fig 2
 Decided that bootstrapping against fixed model parameters would be more difficult to interpret, Fig 1. Simulated data results with refitting seem strange (Fig. 2), perhaps related to fitting of the tree. Observed LR for data should at least remain symmetric, so something has gone wrong. Expected pattern should be deducible simply by upper left triangle of graphs, should accept the first model where the data becomes typical.</description>
    </item>
    
    <item>
      <title>Warning Signals</title>
      <link>/2010/04/02/warning-signals/</link>
      <pubDate>Fri, 02 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/02/warning-signals/</guid>
      <description>Current Puzzles &amp;amp; Goals 1 rep
100 reps
 Kendall&amp;rsquo;s tau unreliable, exploring alternatives. Sliding window for identifying when warning is first detected? Goal is to detect any decrease in stability or distance from critical point? Chasing down data from Scheffer. Climate data reuses the CaCO3 from Dakos. Chasing down data from Dakos   Fig. 1 M Cariaco Basin, data file Vostok deuterium CaCO3 data Tropical Pacific core 1218   Warning signals examples with actual tipping points (Figures left).</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/2010/04/01/research/</link>
      <pubDate>Thu, 01 Apr 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/04/01/research/</guid>
      <description>Single replicate. Almost all warning signals have significant correlation despite the constant environment.
False warning signals remain just as common when signals are averaged across 100 replicates?
 Exploring statistical qualification of early warning signals. Dakos et. al. (2008) use a correlation significance test (based on Kendall&amp;rsquo;s tau) on the autocorrelation to detect the warning signals. Correlation significance test seems a very poor estimate of signal, high false positive rate at any threshold p-value for sufficiently frequent sampling.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/03/31/comparative-phylogenetics-notebook/</link>
      <pubDate>Wed, 31 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/31/comparative-phylogenetics-notebook/</guid>
      <description>Research Labrid Paper Outline Biology Letters format, 2500 words, 2 figures.
Fig 1?
Fig 2?
 Title: Phylogenetic Evidence for Multiple Morphological Niches in Coral Reef Fish Summary (&amp;lt; 200 words)
 We present phylogenetic evidence for two distinct evolutionary optima in the fin morphology of Labrid Fish.  Keywords: Evolution, Phylogenetics, Comparative Methods, Labrids, Multiple Niches
 Introduction
 Labrid Fin Morphology Is clustering in Trait space evidence of Selection or Phylogenetic Inertia?</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/2010/03/31/research/</link>
      <pubDate>Wed, 31 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/31/research/</guid>
      <description>Writing up work just on ensemble vs single instance detection of regime shifts. See this entry

Outline Title
On the ability to detect leading indicators of catastrophe in unreplicated time series
Introduction Background on Warning Signals
 literature Saddle Node bifurcation Detecting decreasing stabilization &amp;ndash; gradual vs changepoint estimation  Reasons detection can fail:
 Ergodicity: ensembles vs single instances Sufficient statistical power Appropriate dynamics  Methods
 Defining an indicator &amp;ndash; significant Kendall rank correlation coefficient τ as in doi:10.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/2010/03/30/research/</link>
      <pubDate>Tue, 30 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/30/research/</guid>
      <description>Current Situation &amp;amp; Challenges 2000 bootstraps of models fitted to simulated ou2 data
 A single data set is produced by simulation under a specified ou2 model on the Labrid tree (actually one that was fitted to the original Labrid data). Each model (Brownian motion and 1 to 5 separate OU peaks (assigned by my partition function) is fitted to this dataset. Each fitted model is used to generate 2000 replicate datasets For each replicate dataset, the model used to generate it is compared to each other model in likelihood ratio test 2(log(L~1~) − log(L~2~)), where L~1~ is the likelihood of the model that generated the data.</description>
    </item>
    
    <item>
      <title>Still puzzling on LR</title>
      <link>/2010/03/26/still-puzzling-on-lr/</link>
      <pubDate>Fri, 26 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/26/still-puzzling-on-lr/</guid>
      <description> The likelihood ratios when parameters are not held fixed, using data originally generated from a two peak model. Has 1000 bootstrap replicates per plot.   The likelihood ratios when parameters are held fixed, after being generated from a two-peak model. (2000 replicates each)   parameters held fixed, three peak model (200 replicates each)  </description>
    </item>
    
    <item>
      <title>Entry title</title>
      <link>/2010/03/25/entry-title/</link>
      <pubDate>Thu, 25 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/25/entry-title/</guid>
      <description>Insert content here&amp;hellip;</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/2010/03/25/research/</link>
      <pubDate>Thu, 25 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/25/research/</guid>
      <description>New Simulations  Now have code to run partitioned models on the Anoles dataset, compare partitioned models to the paintings chosen by Butler and King. Preliminary figures below. Models with _s are partitioned by my algorithm, others are the the original ones from earlier.   Also have examples with simulated data with a known number of partitions, to check the method. Tested with data produced at two peaks on the Labrid tree, the pattern seems similar to that of the Labrids &amp;ndash; comparisons involving any model with more than 2 peaks produce LR ratios that become very unlikely in either pairwise comparison.</description>
    </item>
    
    <item>
      <title>Parallel R</title>
      <link>/2010/03/24/parallel-r/</link>
      <pubDate>Wed, 24 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/24/parallel-r/</guid>
      <description>Parallelized LR_bootstrap_all() and model_bootstrap_all() bootstrapping functions. Lets the bootstrapping of different models (or LRs between models) to be performed on different machines. Using the snowfall package in R for easy parallel computing. The parallel loop is done through the sfLapply() function. Had to get libraries and functions exported to all loops using sfLibrary() and sfExportAll(). R-sig-hpc mailing list was very helpful at getting this up and running at 4am.</description>
    </item>
    
    <item>
      <title>Bootstrapping Likelihood ratios</title>
      <link>/2010/03/23/bootstrapping-likelihood-ratios/</link>
      <pubDate>Tue, 23 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/23/bootstrapping-likelihood-ratios/</guid>
      <description>Bootstraps of the likelihood ratio, holding the parameters fixed, finally completed.  Anoles: Summary Anoles table:
&amp;gt; summary(anoles_boots) [,1] [,2] [,3] [,4] [,5] [1,] 0.500000000 0.981399498 0.26514573 0.06668672 0.018154938 [2,] 0.009580545 0.500000000 0.15610274 0.04819938 0.011616566 [3,] 0.039233893 0.075349644 0.50000000 0.05699877 0.005443493 [4,] 0.004211230 0.004592917 0.01389950 0.50000000 0.006648916 [5,] 0.173457542 0.198303402 0.38893099 0.33891430 0.500000000 &amp;gt;  Labrids: &amp;gt; summary(labrid_boots) [,1] [,2] [,3] [,4] [1,] 0.5000000 6.036842e-05 0.0000000 0.0 [2,] 0.5424613 5.</description>
    </item>
    
    <item>
      <title>Phylogenetic Tree formats</title>
      <link>/2010/03/22/phylogenetic-tree-formats/</link>
      <pubDate>Mon, 22 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/22/phylogenetic-tree-formats/</guid>
      <description>Consider a tree with N nodes. has tips and internal nodes.  ape Format: class &amp;ldquo;phylo&amp;rdquo;  Elements of the data structure: phy$edge &amp;ndash; Topology. 2 by N-1 matrix. First column has internal nodes only, each node appearing twice. Internal nodes range from 1+(N+1)/2 to N-1, while the tip numbers go from 1 to (N+1)/2. Each node appears once in the second column, and is a child of the node identified in the first column.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/2010/03/20/research/</link>
      <pubDate>Sat, 20 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/20/research/</guid>
      <description>Bootstrap the fitted models (rather than allow the parameters to be refit, simply evaluate the likelihood of the model under each simulated dataset) Directly evaluate Neyman-Pearson lemma for each pairwise model comparison. Also analyze the bootstrapped likelihoods directly (and without refitting) for each model.  To Do  Add a summary function for the likelihood_ratio_bootstrap.R library final wrapper function for infer_niches.R partitioning library More error handling and documentation Example of partitioning Anoles then bootstrapping Bootstrapping likelihoods directly  References on thinking about bootstrapping model comparisons  The original Neyman-Pearson paper Testing Statistical Hypotheses Text by Lehmann &amp;amp; Romano Permutation, Parametric and Bootstrap Tests of Hypotheses by Good Thanks to Peter on these; Bibsonomy collection  ouch2ape.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/2010/03/19/research/</link>
      <pubDate>Fri, 19 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/19/research/</guid>
      <description>Bootstrapped against 2000 replicate simulations overnight on both the Anoles dataset and the Labrids dataset. Distributions that overlap zero represent replicates that choose the wrong model. The Anoles data below; the first column corresponds to the likelihood ratios shown in Butler &amp;amp; King (2004), comparing each model against BM.   The Labrid dataset:   Find matching figures for the case of parameters held fixed on more recent entry</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/2010/03/18/research/</link>
      <pubDate>Thu, 18 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/18/research/</guid>
      <description>A some point I&amp;rsquo;ll want to think more seriously about incorporating geographic information into comparative analyses. At some level this data is more available than appropriate continuous traits, as illustrated in the example phylogenetics wiki from Prof. Roderic Page that I just came across.  Today&amp;rsquo;s Goals  Repeating last night&amp;rsquo;s bootstraps on the likelihood ratio. Need to clean up and incorporate my bootstrap codes first. Should also explore the bootstrapping of the partitioning functions from yesterday.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/2010/03/17/research/</link>
      <pubDate>Wed, 17 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/17/research/</guid>
      <description>Maximum likelihood assignment based on arbitrary number of partitions now completed. Working on stochastic assignment. Now have functions for:   partitioning data into k groups, inferring an ancestral state painting based on this partition inferring a continuous model with k OU regimes based on this painting   need to add my function for the proper model-comparison bootstrap of likelihood ratio values rather than the likelihoods themselves. See my original entry on this approach.</description>
    </item>
    
    <item>
      <title>Graham &amp; Peter Meeting</title>
      <link>/2010/03/16/graham-and-peter-meeting/</link>
      <pubDate>Tue, 16 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/16/graham-and-peter-meeting/</guid>
      <description>Discussed inverse problem approach. Discussed bootstrapping likelihoods directly vs bootstrapping likelihood ratio Integrating over uncertainty in the likelihood assignment  
Research Progress  Completed writing the bootstrapping function for the partition scheme, ouch2ape function completed for converting ouch tree formats back to ape. modifies code from r-forge More details and log on the repository  Goals for Wainwright meeting tomorrow  Repeat Labrid Fin analysis with tripartition Bootstrap likelihood ratio functions</description>
    </item>
    
    <item>
      <title>Computing</title>
      <link>/2010/03/15/computing/</link>
      <pubDate>Mon, 15 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/15/computing/</guid>
      <description>Exploring parallel computing options. OpenMP for distributed memory applications. learning git &amp;ndash; need to get used to the branch and merge, install on one.  Research The failure of the Anoles data set to robustly select the more common model can easily be explained by the likelihood distribution: Not surprising since this dataset consists of only 23 taxa. The Labrid tree of 114 taxa clearly resolves the difference between the different models.</description>
    </item>
    
    <item>
      <title>Post-Workshop</title>
      <link>/2010/03/14/post-workshop/</link>
      <pubDate>Sun, 14 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/14/post-workshop/</guid>
      <description>Working on a couple new ideas:
 Multiple partitions Community phylogenetics nulls Diversification rates w/ stationary distributions  Tools exploration  Finding my forum a very useful tool for recording and organizing around idea. Nice complement to this notebook which helps me organize temporally instead. Becoming convinced I should transition from svn to git. Created a git-hub account and have started learning the basic git commands. The Git community book and the website video tutorials have been very helpful.</description>
    </item>
    
    <item>
      <title>Bodega Workshop Presentations</title>
      <link>/2010/03/12/bodega-workshop-presentations/</link>
      <pubDate>Fri, 12 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/12/bodega-workshop-presentations/</guid>
      <description>Final day of Bodega Phylogenetics workshop: a full day of student presentations. (High resolution images for the trees available by clicking on them)
Principle figures from my investigation of the Labrid data. While morphospace doesn&amp;rsquo;t present an obvious clustering, it can be effectively divided by my maximum likelihood partitioning scheme on fin angle. A smoothed density plot of fin angle alone reveals two identifiable modes in the traitspace.
Based on the discretized partition, ancestral states are reconstructed under both the equal rates and independent rates model.</description>
    </item>
    
    <item>
      <title>Phylogenetics Workshop Day 5</title>
      <link>/2010/03/11/phylogenetics-workshop-day-5/</link>
      <pubDate>Thu, 11 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/11/phylogenetics-workshop-day-5/</guid>
      <description>Last day of lectures: Lineage Diversification
Brian Moore: Rates of Lineage Diversification Bodega Wiki slides &amp;amp; tutorial
 Detecting significant diversification rate variation across tree locate shifts along branches and through time (niche-filling, density dep models?) correlates of differential rates parameter estimation speciation/extinction  correlates of differential rates  Apply Felsenstein pruning algorithm to calc likelihood and hence fit model this is just the definition of a joint probability! Use this to estimate the model, then do rejection sampling to create the tree painting.</description>
    </item>
    
    <item>
      <title>Bodega Workshop Day 4</title>
      <link>/2010/03/10/bodega-workshop-day-4/</link>
      <pubDate>Wed, 10 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/10/bodega-workshop-day-4/</guid>
      <description>Morphological Evolution Day:
 Peter Wainwright Sam Price Johnathan Eisen  We have the afternoon session off for field trips and research.

Peter Wainwright, Comparative Analysis of Morphological Diversity  Fantastic diversity in morphology, corresponds to niche! But morphological diversity isn&amp;rsquo;t evenly distributed across tree of life. (See slides, parallels Peter&amp;rsquo;s section on core and gives the best biological coverage we&amp;rsquo;ve had this week).  What changes morphological diversification rate</description>
    </item>
    
    <item>
      <title>Bodega Phylogenetics Workshop Day 3</title>
      <link>/2010/03/09/bodega-phylogenetics-workshop-day-3/</link>
      <pubDate>Tue, 09 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/09/bodega-phylogenetics-workshop-day-3/</guid>
      <description>Rich Glor, Character Evolution Official slides and tutorial
 Weakness of ancestral state reconstruction
 Cunningham 1999 Losos 1999  Testing hypotheses with ancestral reconstruction
 Parsimony Farris method. Downward/upward pass. Gives a maximum parsimony reconstruction. May miss other ones. Apparently this Parsimony analysis can be done for continuous traits as well, needs a measure of distance Likelihood Pagel 1994 Schluter 1997   R tutorial (see anolis_cheat.R)
 Discrete trait ancestral state reconstruction</description>
    </item>
    
    <item>
      <title>Bodega Phylogenetics Workshop Day 2</title>
      <link>/2010/03/08/bodega-phylogenetics-workshop-day-2/</link>
      <pubDate>Mon, 08 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/08/bodega-phylogenetics-workshop-day-2/</guid>
      <description>Marine lab researchers are back, and network speeds have just about given up (down to bytes/s). This post is composed offline and will be uploaded to the notebook. Details are well logged on the Bodgea Phylogenetics Wiki so these are reasonably sketchy with my comments.
My Updates to Bodega Phylogenetics Wiki Made several contributions to the Bodega Phylogenetics Wiki today:
 User page Phylogenetics on Linux Becoming a Programmer Edits on Advice for Aspiring Phylogeneticists  Today&amp;rsquo;s agenda  BEAST continued.</description>
    </item>
    
    <item>
      <title>Bodega Phylogenetics Workshop Day 1</title>
      <link>/2010/03/07/bodega-phylogenetics-workshop-day-1/</link>
      <pubDate>Sun, 07 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/07/bodega-phylogenetics-workshop-day-1/</guid>
      <description>Lecture notes for the phyolgenetics workshop. These are taken in real time, so may contain errors. I&amp;rsquo;ll see if I keep this up throughout the course. See course website.
Huelsenbeck 9a-11a
 Parameters θ Observation X p(X | θ) is known as the likelihood. Adjust parameter to maximize likelihood. Coin toss example  θ = prob of heads on a single toss of a coin, X is # of heads observed on n tosses.</description>
    </item>
    
    <item>
      <title>Friday</title>
      <link>/2010/03/05/friday/</link>
      <pubDate>Fri, 05 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/05/friday/</guid>
      <description>11a Sebastian Meeting (see Stochastic Population Dynamics Notebook)
12p - 1p
 Lunch talk in joint lab group (Schreiber Coop Moore Rannala Eisen) on coalescents for wARG. Remember to check out kcachegrind as interface to valgrind and profiler, and also mauve as a dynamic sequence alignment display tool.  Comparative Phylogenetics Discussion group 4-5p. Discussing:
 Van Bocxlaer I, Loader SP, Roelants K, Biju SD, Menegon M, and Bossuyt F.</description>
    </item>
    
    <item>
      <title>Meeting</title>
      <link>/2010/03/05/meeting/</link>
      <pubDate>Fri, 05 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/05/meeting/</guid>
      <description>Basically I want to apply central limit theorem for stationary processes (accounts for covariances), assuming mean zero  where
 Discussion of Freidlin-Wentzell theory in connection to Arrhenius law and the well-defined stochastic tipping point which occurs before the branch point. Kurtz results don&amp;rsquo;t really help in the case of ergodicity, can make statements about the (even non-stationary) ensemble limit.</description>
    </item>
    
    <item>
      <title>Big Picture Comparative Phylogenetics</title>
      <link>/2010/03/04/big-picture-comparative-phylogenetics/</link>
      <pubDate>Thu, 04 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/04/big-picture-comparative-phylogenetics/</guid>
      <description>A Task View on Phylogenetic Comparative Methods (in R on CRAN) has been released today, maintained by Brian O&amp;rsquo;Meara. Quite thorough and concise.
 Follow-up discussion on:
 List is useful, but would be nice to be able to expand / collapse the list to see more / less details about the functions available. More detail makes it harder to maintain, perhaps get the developers involved? List is also quite provocative source to realize what&amp;rsquo;s missing (there&amp;rsquo;s no way to estimate ancestral states under OU using existing software?</description>
    </item>
    
    <item>
      <title>Solution to the strange behavior in ouch</title>
      <link>/2010/03/03/solution-to-the-strange-behavior-in-ouch/</link>
      <pubDate>Wed, 03 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/03/solution-to-the-strange-behavior-in-ouch/</guid>
      <description>Looks like my troubles actually stem from a bug in the code. I summarize the problem here, just as I posted in my query to R sig phylo. Essentially the program erroneously squares alpha at the moment, explaining the pattern I found yesterday. Giving it root alpha preemptively should be a good work around.

data(bimac) tree &amp;lt;- with(bimac,ouchtree(node,ancestor,time/max(time),species)) print(h2 &amp;lt;- hansen(log(bimac[&#39;size&#39;]),tree,bimac[&#39;OU.1&#39;],alpha=1,sigma=1))  The print command says alpha = 0.</description>
    </item>
    
    <item>
      <title>Power in trees</title>
      <link>/2010/03/02/power-in-trees/</link>
      <pubDate>Tue, 02 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/02/power-in-trees/</guid>
      <description>Back to Phylogenetics after a week with only population dynamics.  Exploration  data created by brown simulation on the star tree in ouch matches the expected variance, σ^2^t. This variance is slightly reduced when simulated on the Felsenstein tree, as might be intuitively expected due to the increased correlations. The degree of decrease should be analytically attainable, but isn&amp;rsquo;t obvious to me at the moment. Example using functions in felsenstein_tree.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/03/01/teaching/</link>
      <pubDate>Mon, 01 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/01/teaching/</guid>
      <description>Evolution of Mimicry &amp;amp; Levels of Selection  Today my turn to help facilitate in Begun&amp;rsquo;s Monte Carlo on designing a course on evolution for non-majors. Worked with Elizabeth on an interactive case study teaching levels of selection through the example of mimicry in butterflies. Following a brief introduction, we gave a pilot run of a hands-on activity to explore population dynamics in a predator-control-model-mimic (jay-cabbage-monarch-viceroy) system. Here&amp;rsquo;s the description.</description>
    </item>
    
    <item>
      <title>Parallel at last</title>
      <link>/2010/03/01/parallel-at-last/</link>
      <pubDate>Mon, 01 Mar 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/03/01/parallel-at-last/</guid>
      <description>svn revision 27 should have functional parallel code! Certainly I&amp;rsquo;ve gotten much better at openmp in the past few days. Difficult to maintain a general API that is agnostic to the model details and still knows enough about the data formats to declare them appropriately for each thread. My lesson for my future coding: by writing with parallelization concepts in mind from the start I should be able to significantly reduce the overhead time when I go back and add openmp directives.</description>
    </item>
    
    <item>
      <title>Parallelizing Code</title>
      <link>/2010/02/28/parallelizing-code/</link>
      <pubDate>Sun, 28 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/28/parallelizing-code/</guid>
      <description>A solution!  After a good bit more exploring permutations of openmp commands and experimenting with code (should have been done in a branch version so would be in the version management, instead done in my local experimental sandbox so will have to implement and merge into real code still!) was able to understand the root of my problem and pose a coherent question. Posting that question on stack overflow solved my problem in under an hour.</description>
    </item>
    
    <item>
      <title>Friday</title>
      <link>/2010/02/26/friday/</link>
      <pubDate>Fri, 26 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/26/friday/</guid>
      <description>Not much chance for progress.
 11-noon (I was interviewed by Science Careers reporter). noon-1 Lunch w/ John Huelsenbeck. Good perspective on having formula representation of models rather than on/off switch for parameters! Will have to implement eventually in the phylogenetics project. 1-1:30 Wainwrighters lunch meeting. 1:30-3:30 prep Monte Carlo for teaching non-majors evolution course &amp;ndash; case study on mimicry and levels of selection. Presenting Monday, we&amp;rsquo;ll see how it goes in [User:Carl_Boettiger/Notebook/Teaching] 4-6 Phylogenetics discussion group (followed by CPB happy hour = more phylogenetics discussion).</description>
    </item>
    
    <item>
      <title>The Ergodicity Question- Time averaging vs Ensemble averaging</title>
      <link>/2010/02/25/the-ergodicity-question--time-averaging-vs-ensemble-averaging/</link>
      <pubDate>Thu, 25 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/25/the-ergodicity-question--time-averaging-vs-ensemble-averaging/</guid>
      <description>11am &amp;ndash; 3pm
 Tried time averaging over the entire time window (set sample_size to 1 less than max time); in close agreement with the ensemble predictions (getting around 1355). Mystery doesn&amp;rsquo;t seem to actually be a problem in the method, but just innate variability! Even over reasonable time-averages and ensemble averages there&amp;rsquo;s significant deviation from the expected variance! This variation around the warning signal/leading indicator is exactly what might frustrate the warning signal.</description>
    </item>
    
    <item>
      <title>Thursday</title>
      <link>/2010/02/25/thursday/</link>
      <pubDate>Thu, 25 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/25/thursday/</guid>
      <description>Some exploration with felsenstein_tree.R, see svn log.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/02/24/derin-and-alan-meeting/</link>
      <pubDate>Wed, 24 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/24/derin-and-alan-meeting/</guid>
      <description>1-2pm
 Discussion of reasons early warning signals fail   Insufficient signal-to-noise ratio for early warning Ensemble vs time average &amp;ndash; satisfying ergodicity assumption? Role of bifurcation type. existing literature focuses mostly on 1D saddle node. Role of chaos (certainly frustrates warning signals, but not required).   How general are warning signals? Normal forms of bifurcations. Fitting a good model vs. general warning signals. Problem of extrapolation. Classification scheme of warning signals &amp;ndash; TREE paper(?</description>
    </item>
    
    <item>
      <title>Comparing to Analytic Dynamics</title>
      <link>/2010/02/23/comparing-to-analytic-dynamics/</link>
      <pubDate>Tue, 23 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/23/comparing-to-analytic-dynamics/</guid>
      <description>Goal for today: implement analytic calculations for warning signals.
 10am-12pm  Abstraction/functionalizing code.
 4pm-7pm  Implement GSL ode solvers for linear noise approximation:
Recall our dynamics are d(n) = *e*n + a
and defining the jump moments (van Kampen) α~1~(n) = b(n) − d(n)
α~2~(n) = b(n) + d(n)

recall that we have a linear Fokker-Planck equation whose solution is Gaussian and specified by the first two moments:  These are implemented in code using GSL ode library.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/02/22/teaching/</link>
      <pubDate>Mon, 22 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/22/teaching/</guid>
      <description>GTC Session: Student Centered Learning: Successes, Failures and Strategies  Gabrielle and I facilitated a GTC section on Student-Centered learning. Details in the GTC blog post. Small group of about a dozen of us, still worked to break into four groups for the discussion section. Overall went very well, don&amp;rsquo;t have a lot of comments to add about the experience or things I&amp;rsquo;d do differently. Did get some positive feedback and comments that we could have used much more time to explore these ideas!</description>
    </item>
    
    <item>
      <title>Monday</title>
      <link>/2010/02/22/monday/</link>
      <pubDate>Mon, 22 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/22/monday/</guid>
      <description> Not a very successful day research-wise. Begun&amp;rsquo;s Monte Carlo and then my facilitation at GTC seminar went well though.  </description>
    </item>
    
    <item>
      <title>Implementing an example of low and high power trees</title>
      <link>/2010/02/20/implementing-an-example-of-low-and-high-power-trees/</link>
      <pubDate>Sat, 20 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/20/implementing-an-example-of-low-and-high-power-trees/</guid>
      <description>Code implementation in felsenstein_tree.R
 I consider a star tree and a Felsenstein tree each of N nodes; M = (N+1)/2 tips. I consider an uncorrelated data set of M normal random variables, such as would be generated by either BM or OU models on the star tree. I produce a correlated data set such as would be generated by Brownian motion on the felsenstein tree. I generate 8 model fits &amp;ndash; fitting BM and OU to each tree under each data set.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/02/19/teaching/</link>
      <pubDate>Fri, 19 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/19/teaching/</guid>
      <description>Faculty Mentoring Faculty Presentation &amp;ldquo;Short Cuts to Excellent Teaching: A Primer&amp;rdquo;  by James Shaffrath, from Exercise Biology, The Department of Neurobiology, Physiology and Behavior  Just saw this presentation in the Faculty Mentoring Faculty program. Good program, though pretty basic, not really touching on peer learning but focusing on lecture content and style. Things like rolling lexicon (using both jargon and simple phrases), being present, being engaging. The broad introduction was definitely the best part, and an inspiring view about the role of education.</description>
    </item>
    
    <item>
      <title>Power in trees continues</title>
      <link>/2010/02/19/power-in-trees-continues/</link>
      <pubDate>Fri, 19 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/19/power-in-trees-continues/</guid>
      <description>Discussion of power in trees need a counterpoint to the example of the star tree as being devoid of information content. The best example here is probably the example tree used in the introduction of Felsenstein 1985: two star trees sharing a common ancestor. Implemented the basic creation of a balanced tree of arbitrary depth having this structure. The balanced tree has 2^h^ − 1 nodes, all internal nodes occuring at time = 1&amp;frasl;2 and all tips at time = 1.</description>
    </item>
    
    <item>
      <title>Power in Trees</title>
      <link>/2010/02/18/power-in-trees/</link>
      <pubDate>Thu, 18 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/18/power-in-trees/</guid>
      <description>Following up after yesterday&amp;rsquo;s meeting, I am working on implementing the confidence interval analysis and quantifying information in trees. This second point I will develop by comparing the Felsenstein example tree (information-rich) to the star tree (uninformative), and develop this discussion in the context of assessing the importance of phylogenetic corrections and phylogenetic intertia (my original theme again: noise or data??).
Primate Brain Morphometry Daniel Mietchen contacted me through openwetware 11 days ago with interest in applying phylogenetic comparative methods to Primate Brain Morphometry data.</description>
    </item>
    
    <item>
      <title>Hastings Meeting</title>
      <link>/2010/02/17/hastings-meeting/</link>
      <pubDate>Wed, 17 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/17/hastings-meeting/</guid>
      <description>Discussion of cases where variance decreases before crash &amp;ndash; misleading warning signals. Schreiber 2003 Aaron King and Bill Schaffer JMB Hamiltonian vs Dissipative/gradient systems. Are Hamiltonian systems non-biological? Follow up with Darren  Reasons Warning Signals fail  Present (saddle-node model) but insufficient sensitivity to detect (lack ensembles, lack sampling frequency) dissipative but warning signals are backwards (other higher dimensional bifurcations, limit cycles &amp;ndash;&amp;gt; no potential) Hamiltonian instead of dissipative (centers, stochastically become random walks)  Code Updates Early warning signals code now does ensemble averaging, which works!</description>
    </item>
    
    <item>
      <title>Meeting Goals</title>
      <link>/2010/02/17/meeting-goals/</link>
      <pubDate>Wed, 17 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/17/meeting-goals/</guid>
      <description>Discussion of information in phyologenetic trees analysis  Review manuscript outline. More examples of comparisons? Sequence of presentation? Parametric bootstrapping approach; see this entry. Quantifying information in a tree a priori to any trait data Stationary distribution fits vs full model fits as measure of phylogenetic signal  Discussion of Regimes model  Review project status of implementing the more complicated regimes model, discussed here</description>
    </item>
    
    <item>
      <title>Updating manuscript</title>
      <link>/2010/02/16/updating-manuscript/</link>
      <pubDate>Tue, 16 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/16/updating-manuscript/</guid>
      <description>The progress of the past few days has lead to substantial revision proposals in my manuscript draft. Rewriting for discussion with Brian tomorrow. Currently revised outline:
 Intro
 Biological Motivation Comparative Methods and Comparing Models Model choice paradigm: the right direction, but incomplete  Simple Example
 The Star Tree Two hypotheses: stabilizing vs disruptive selection Information Criteria approach is insufficient Likelihood surfaces Likelihood ratio distribution  Anoles Example</description>
    </item>
    
    <item>
      <title>Implementing warning signals metrics</title>
      <link>/2010/02/15/implementing-warning-signals-metrics/</link>
      <pubDate>Mon, 15 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/15/implementing-warning-signals-metrics/</guid>
      <description>The code now contains implementation of the basic warning signals metrics computed over a given window size into the past.
 mean variance skew lag-1 autocorrelation lag-n autocorrelation  These are implemented through the fixed interval sampler function. Recall that the Gillespie simulation API permits two kinds of events, random events occurring with exponential time distribution and events occurring at fixed (scheduled) times, which can be used for discretizations of deterministic continuous time dynamics (i.</description>
    </item>
    
    <item>
      <title>Parametric bootstrapping</title>
      <link>/2010/02/15/parametric-bootstrapping/</link>
      <pubDate>Mon, 15 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/15/parametric-bootstrapping/</guid>
      <description>There are several ways we can frame the bootstrapping question. What is the probability that we see a given likelihood ratio statistic (that the log likelihoods differ by a certain spread) just by chance? We have two versions of chance &amp;ndash; the chance we see this ratio when model a is correct and the chance we see this ratio when model b is correct. We simulate 2000 data sets under each model, generating a distribution of likelihood ratio scores for each data set.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/02/14/speciation/</link>
      <pubDate>Sun, 14 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/14/speciation/</guid>
      <description>editorial note: These notes pre-date the formal start of my online laboratory notebook, Feb 2 2010: The Lab Notebook Goes Open and were adapted from a LaTeX document in which I kept notes on this topic during my summer at IIASA. Lacking a proper notebook then, documents like this one were updated periodically and occassionally branched into new ones. The post date represents the last time the LaTeX document was edited in the course of that research.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/02/11/teaching/</link>
      <pubDate>Thu, 11 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/11/teaching/</guid>
      <description>Regime Shifts Seminar take two  Today I was again up for the regime shifts class to cover the details Alan&amp;rsquo;s Ecology Letters paper. Board lecture style on content I&amp;rsquo;m comfortable with, so enjoyable for me but hardly much of an experiment in effective teaching. Still, something that can be done well or poorly, so I think today went well. Began with individuals at the board to review the four principle figures from the previous class &amp;ndash; birth rates and death rates, difference in rates, the bifurcation diagram and the potential landscape.</description>
    </item>
    
    <item>
      <title>Follow-up on Parametric Bootstrapping</title>
      <link>/2010/02/10/follow-up-on-parametric-bootstrapping/</link>
      <pubDate>Wed, 10 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/10/follow-up-on-parametric-bootstrapping/</guid>
      <description>Continuing on yesterday&amp;rsquo;s discussion of parametric boostrapping implementation. Peter sent some very helpful comments and agreed to having them here for reference; I&amp;rsquo;ve added some links.  &amp;ldquo;I&amp;rsquo;ve read up a bit on the bootstrap just now. First off, although parametric and nonparametric bootstrapping has always seemed very different to me, they fit in the same natural framework. The general idea is that in reality, there&amp;rsquo;s some real parameters x and some probability distribution P that&amp;rsquo;s given us some data.</description>
    </item>
    
    <item>
      <title>Meeting w- Alan</title>
      <link>/2010/02/10/meeting-w--alan/</link>
      <pubDate>Wed, 10 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/10/meeting-w--alan/</guid>
      <description>Weekly check-in, following up on last week&amp;rsquo;s meeting.  Goals for meeting  Discuss goals for regime shifts seminar tomorrow Discuss my manuscript outline on detection limits for early warning signals Discuss energy model formulation for analytic approximations to Tribolium model.  Meeting Notes  Early warning signals - starting in simple models, proof of principle. Discuss three challenges to detection:   ergodicity sensitivity complexity   Eventually develop robust tools to give confidence estimates (parametric bootstrap) on potential early warning signals.</description>
    </item>
    
    <item>
      <title>Code Development for Exploring Regimes Shifts</title>
      <link>/2010/02/09/code-development-for-exploring-regimes-shifts/</link>
      <pubDate>Tue, 09 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/09/code-development-for-exploring-regimes-shifts/</guid>
      <description>Just committed changes to the google project. warning_signals.c now provides a fully functional, ensemble enabled simulation written with functional API for general Gillespie simulations (at last! I&amp;rsquo;ve come quite a way in my C coding from those early Gillespie simulations for adaptive dynamics two years ago). Still need to pull the API out of the single file. Doxygen-compatible literate programming included, but needs significant expansion before it can really be used effectively as an API for other users.</description>
    </item>
    
    <item>
      <title>Meeting with Graham and Peter</title>
      <link>/2010/02/09/meeting-with-graham-and-peter/</link>
      <pubDate>Tue, 09 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/09/meeting-with-graham-and-peter/</guid>
      <description>Discussion of Model Comparisons Primary focus of today&amp;rsquo;s discussion was rooted in Sunday&amp;rsquo;s entry
 On plotting quirks, haven&amp;rsquo;t figured out lattice but here&amp;rsquo;s yet another newer plotting engine for R I need to revisit how OUCH computes likelihood ratios and P values. Since some parameters are bounded to the positive real line (and may be small) the standard chi square isn&amp;rsquo;t correct. I should repeat the AIC-style analysis for likelihood ratios, though this is just a shift of where I put the zero line.</description>
    </item>
    
    <item>
      <title>Exploring Difficulties with Existing Methods continued</title>
      <link>/2010/02/08/exploring-difficulties-with-existing-methods-continued/</link>
      <pubDate>Mon, 08 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/08/exploring-difficulties-with-existing-methods-continued/</guid>
      <description>Working on manuscript for this today, hope to have a draft soon.
 Just added a basic example using a star-burst tree to illustrate the challenges associated with this kind of model choice inference.
 Sent draft to Brian and Peter, and Wainwright lab.
 Still needs a figure explaining the BM, OU(1) and OU(LP) models for those not familiar with Butler and King 2004 paper, general polishing.</description>
    </item>
    
    <item>
      <title>Updates to Code</title>
      <link>/2010/02/08/updates-to-code/</link>
      <pubDate>Mon, 08 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/08/updates-to-code/</guid>
      <description>Mostly organizational updates at the moment. Restructured the directory tree, and added proper literate programming headers to the code using Doxygen markup.  code</description>
    </item>
    
    <item>
      <title>Exploring Difficulties with Existing Methods</title>
      <link>/2010/02/07/exploring-difficulties-with-existing-methods/</link>
      <pubDate>Sun, 07 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/07/exploring-difficulties-with-existing-methods/</guid>
      <description>Model choice plays an increasingly dominant role in comparative phylogenetics. The software OUCH of Butler and King (2004) is built around the model comparison framework and returns a variety of information criteria for choosing between different models fitted to the tree.
 I&amp;rsquo;ve written a short R script to explore how robust these inferences are, and the results are rather surprising. None of the inferences holds up to the classical P value standard of 95% probability of being right, and the inference can be wrong more often than it is right &amp;ndash; a coin flip out-performs the model choice method based on these information criteria in certain cases.</description>
    </item>
    
    <item>
      <title>Lunch with Wainwright Lab</title>
      <link>/2010/02/05/lunch-with-wainwright-lab/</link>
      <pubDate>Fri, 05 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/05/lunch-with-wainwright-lab/</guid>
      <description>Friday lunch with Wainwright lab continues to be a very useful chance to bounce ideas off of lab members with an excellent grasp of both the models involved and the real biology, morphology and evolution in question. Today&amp;rsquo;s discussion hit several topics.
 Should regime transitions be restricted to nodes? The general consensus was No. On one hand, the position of nodes may contain information about the timing of an actual environmental change responsible for a regime shift.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/02/04/teaching/</link>
      <pubDate>Thu, 04 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/04/teaching/</guid>
      <description>Early Warning Signals to Regime Shifts Seminar  I was just responsible for covering a relatively technical paper on the idea of detecting early warning signals to regime shifts. This is a class of about 10 people. First half we took turns on the board, relying entirely on graphical analysis, and going from a birth death model through stability analysis to illustrate bi-stability to the bifurcation diagram and the energy landscape representation.</description>
    </item>
    
    <item>
      <title>Hastings Meeting</title>
      <link>/2010/02/03/hastings-meeting/</link>
      <pubDate>Wed, 03 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/03/hastings-meeting/</guid>
      <description>Meeting with Dr. Alan Hastings soon to discuss progress on this project. We&amp;rsquo;ll also see what he thinks of the open lab notebook. There&amp;rsquo;s a lot I want to cover in this meeting.  Warning Signals  Tomorrow I&amp;rsquo;m leading a discussion in seminar on regime shift literature, so I need to review major ideas of the paper with Alan. Particularly need to be clear on the role of dimensionality and if/when the population dynamics lack an appropriate Hamiltonian and whether that&amp;rsquo;s an important part of the argument.</description>
    </item>
    
    <item>
      <title>The Lab Notebook Goes Open</title>
      <link>/2010/02/02/the-lab-notebook-goes-open-/</link>
      <pubDate>Tue, 02 Feb 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/02/02/the-lab-notebook-goes-open-/</guid>
      <description>(Originally posted on OpenWetWare)
 This is the first entry in my lab notebook, but not the beginning of the project. I have been exploring demographic and colored environmental noise since beginning my graduate program at UC Davis. Much of that time has been spent in building the appropriate tool set though, so now it&amp;rsquo;s time to dive in.
 A good starting point is Denis et. al. (2001) Ecological Monographs 71.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/01/25/teaching/</link>
      <pubDate>Mon, 25 Jan 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/01/25/teaching/</guid>
      <description>Clash of Old and New Today was my day to facilitate for a graduate student discussion seminar. The seminar is well attended by quite a handful of faculty and post-docs, some thirty people. The discussion is almost always dominated by a few faculty, which is a great source of information but offers little opportunity for students to ask questions or wrestle with ideas themselves. To get at this, I tried breaking the class into small groups for the first half and passing out different sets of discussion questions.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2010/01/18/progresschallenges/</link>
      <pubDate>Mon, 18 Jan 2010 00:00:00 +0000</pubDate>
      
      <guid>/2010/01/18/progresschallenges/</guid>
      <description>editorial note: These notes pre-date the formal start of my online laboratory notebook, Feb 2 2010: The Lab Notebook Goes Open and were adapted from a LaTeX document in which I kept notes on this topic during my summer at IIASA. Lacking a proper notebook then, documents like this one were updated periodically and occassionally branched into new ones. The post date represents the last time the LaTeX document was edited in the course of that research.</description>
    </item>
    
    <item>
      <title>CPB thesis proposal</title>
      <link>/2010/01/10/cpb-thesis-proposal/</link>
      <pubDate>Sun, 10 Jan 2010 14:07:20 +0000</pubDate>
      
      <guid>/2010/01/10/cpb-thesis-proposal/</guid>
      <description>In the spirit of archiving work in the lab notebook, this was my PhD dissertation proposal, a requirement to advance to candidacy submitted before our oral defense in the second or third year. Following some excellent advice, this is focused more narrowly than my actual dissertation. As a historical note, I started keeping an open lab notebook the month following this, on OpenWetWare (so work leading up to this isn&amp;rsquo;t archived, though admittedly first two years were largely coursework).</description>
    </item>
    
    <item>
      <title></title>
      <link>/2009/08/25/diffusion-solution/</link>
      <pubDate>Tue, 25 Aug 2009 00:00:00 +0000</pubDate>
      
      <guid>/2009/08/25/diffusion-solution/</guid>
      <description>editorial note: These notes pre-date the formal start of my online laboratory notebook, Feb 2 2010: The Lab Notebook Goes Open and were adapted from a LaTeX document in which I kept notes on this topic during my summer at IIASA. Lacking a proper notebook then, documents like this one were updated periodically and occassionally branched into new ones. The post date represents the last time the LaTeX document was edited in the course of that research.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2009/08/25/drift-effects/</link>
      <pubDate>Tue, 25 Aug 2009 00:00:00 +0000</pubDate>
      
      <guid>/2009/08/25/drift-effects/</guid>
      <description>editorial note: These notes pre-date the formal start of my online laboratory notebook, Feb 2 2010: The Lab Notebook Goes Open and were adapted from a LaTeX document in which I kept notes on this topic during my summer at IIASA. Lacking a proper notebook then, documents like this one were updated periodically and occassionally branched into new ones. The post date represents the last time the LaTeX document was edited in the course of that research.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2009/08/25/stochastic-methods/</link>
      <pubDate>Tue, 25 Aug 2009 00:00:00 +0000</pubDate>
      
      <guid>/2009/08/25/stochastic-methods/</guid>
      <description>editorial note: These notes pre-date the formal start of my online laboratory notebook, Feb 2 2010: The Lab Notebook Goes Open and were adapted from a LaTeX document in which I kept notes on this topic during my summer at IIASA. Lacking a proper notebook then, documents like this one were updated periodically and occassionally branched into new ones. The post date represents the last time the LaTeX document was edited in the course of that research.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2009/07/28/branching-times/</link>
      <pubDate>Tue, 28 Jul 2009 00:00:00 +0000</pubDate>
      
      <guid>/2009/07/28/branching-times/</guid>
      <description>editorial note: These notes pre-date the formal start of my online laboratory notebook, Feb 2 2010: The Lab Notebook Goes Open and were adapted from a LaTeX document in which I kept notes on this topic during my summer at IIASA. Lacking a proper notebook then, documents like this one were updated periodically and occassionally branched into new ones. The post date represents the last time the LaTeX document was edited in the course of that research.</description>
    </item>
    
    <item>
      <title></title>
      <link>/2008/06/09/popbio-core-review-notes/</link>
      <pubDate>Mon, 09 Jun 2008 00:00:00 +0000</pubDate>
      
      <guid>/2008/06/09/popbio-core-review-notes/</guid>
      <description> Embedded versions of my summary sheets for the Population Biology graduate group core course, organized by faculty member&amp;rsquo;s section.
Schreiber: Single species population dynamics Schoener: multispecies population dynamics Stachowicz: Community ecology Sih: Animal behavior Turelli: Population genetics and speciation Wainwright: macroevolution and comparative phylogenetics </description>
    </item>
    
  </channel>
</rss>