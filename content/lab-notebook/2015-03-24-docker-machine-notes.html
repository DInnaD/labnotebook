---
categories:
- computing
date: 2015-03-24T00:00:00Z
tags:
- docker
url: /2015/03/24/docker-machine-notes/
---



<p>Docker recently released <code>docker-machine</code> to make managing multiple remote machines locally easier. Docker distributes binaries of <code>docker-machine</code> for most major architectures ready-to-go, potentially making it easier to get started on Windows and Mac as well.</p>
<p>Set credentials in environmental variables so we don’t have to pass them on the command line each time:</p>
<pre class="bash"><code>DIGITALOCEAN_ACCESS_TOKEN = XXX</code></pre>
<p>and create the docker-machine:</p>
<pre><code>docker-machine create --driver digitalocean --digitalocean-size &quot;1gb&quot; server-name</code></pre>
<p>where <code>server-name</code> is any name you want to give your server and <code>DO_PAT</code> is your access token (say, saved as an environmental variable). Here we launch a 1GB instance, the default is 512MB on digitalocean. Many other providers work just as well (including virtualbox). You need to set your terminal to use the active <code>docker-machine</code> for all <code>docker</code> commands, instead of the local <code>docker</code> installation:</p>
<pre class="bash"><code>eval &quot;$(docker-machine env server-name)&quot;</code></pre>
<p>sets three environmental variables that point your <code>docker</code> commands to the new remote machine, <code>server-name</code>. Wow. We can now launch any service of interest:</p>
<pre class="bash"><code>docker run -d -p 8787:8787 -e PASSWORD=something rocker/hadleyverse</code></pre>
<p>and it will run on the server. Get the IP address of the active machine with <code>docker-machine ip</code>, e.g. open the server in the browser (from a Ubuntu-based client)</p>
<pre class="bash"><code>xdg-open http://`docker-machine ip`:8787</code></pre>
<p>When we’re finished with the instance, we can destroy the machine so we will no longer be billed, using the same syntax as we would for a container:</p>
<pre class="bash"><code>docker-machine rm -f server-name</code></pre>
<p>If we have a locally installed docker instance, we may also want to unset the environmental variables set by machine:</p>
<pre class="bash"><code>unset DOCKER_TLS_VERIFY
unset DOCKER_CERT_PATH
unset DOCKER_HOST</code></pre>
<p>You can see a list of active machines with <code>docker-machine ls</code> and switch between machines with <code>docker-machine env</code> as shown above.</p>
<p>Spawning a new machine adds a bit more overhead than launching a container on an existing local or remote server instance, but not much; and is easily scripted. Of course the latency is higher too: the start-up time for the DO instance takes two minutes, and pulling a sizable image onto DO machine takes another two minutes or so. <code>docker-machine</code> actually prints the start-up time in seconds as it brings up the machine, in case you want to compare between services.</p>
<div id="docker-compose" class="section level2">
<h2>Docker Compose</h2>
<p>Docker compose is just fig, which is just a yaml config file / wrapper for (some of) the <code>docker run</code> command-line options. As with <code>docker-machine</code>, this simplicity is definitely a strength. Rather intuitively, <code>docker-machine</code> respects <code>docker-compose</code>, in that after setting the environmental variables as described above, <code>docker-compose up</code> runs on the remote machine, just like <code>docker run</code> does.</p>
<hr />
</div>
<div id="docker-swarm" class="section level2">
<h2>Docker swarm</h2>
<p>Docker swarm is rather analogous to CoreOS; it’s essential feature being a discovery service that allows the cluster to form. Swarm is mostly easily set up using docker-machine, though in my googling most tutorials fail to mention this. The <a href="https://docs.docker.com/machine/#using-docker-machine-with-docker-swarm">official docker-machine docs</a> are probably the best reference on this.</p>
<p>Docker swarm provides rather limited functionality so far. A nice <a href="http://blog.docker.com/2015/02/scaling-docker-with-swarm/">docker blog post on swarm</a> In particular, it doesn’t yet support two key features found in CoreOS scheduling: fault-tolerant scheduling; which can move a container to another host if a machine goes down; nor does it yet support Master election; so the swarm breaks if the master goes down.</p>
<p>It currently provides only relatively obvious scheduling – a bin-packing algorithm if you put constraints on resources a container can use, affinities to make sure <code>--link</code>, <code>--volumes-from</code> and other such containers end up on the same instance. Instances can be annotated with labels that can be used as constraints, such as <code>storage=ssd</code>, though it’s <a href="https://github.com/docker/machine/issues/1002">not clear</a> how to add these from docker-machine. As long as swarm does not support fault-tolerant scheduling and master election though, these features are not as essential. Dynamically moving a container when a machine has failed means that no human is around to consider what resources the swarm has and where to schedule the container. But for merely adding a new container to an existing swarm, it’s not particularly hard for a human to look at the existing resources and just pick manually where to stick the container without the help of swarm’s algorithms.</p>
<p>Swarm doesn’t really understand docker-compose yet either, in that compose is essentially written as a single-host tool.</p>
</div>
