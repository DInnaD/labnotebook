---
categories:
- ecology
date: 2015-07-30T00:00:00Z
tags:
- gpmanagement
- gp
- nimble
- mdptoolbox
url: /2015/07/30/gpdp-via-mdptoolbox-cont/
---



<pre class="r"><code>knitr::opts_chunk$set(eval=FALSE)
## gp management no longer working</code></pre>
<pre class="r"><code>knitr::opts_chunk$set(comment=NA)
#devtools::install_github(&quot;cboettig/gpmanagement@b3b765cbceb51c9b0b8cb2724e395353ec365df9&quot;)
library(&quot;MDPtoolbox&quot;)
library(&quot;gpmanagement&quot;)
library(&quot;tidyr&quot;)
library(&quot;dplyr&quot;)
library(&quot;ggplot2&quot;)
library(&quot;lazyeval&quot;)</code></pre>
<div id="true-model" class="section level3">
<h3>True model</h3>
<pre class="r"><code>p &lt;- c(2, 100, 50)
f &lt;- function (x, h){
  sapply(x, function(x) {
    x &lt;- pmax(0, x - h)
    x * exp(p[1] * (1 - x/p[2]) * (x - p[3])/p[2])
  })
}

sigma_g &lt;- 0.1
pdfn &lt;- function(x, mu, sigma = sigma_g){
  dlnorm(x, log(mu), sdlog = sigma)
}

z_g &lt;- function() rlnorm(1, 0, sigma_g)</code></pre>
<pre class="r"><code>set.seed(0)
Tobs &lt;- 40

W &lt;- Tobs

x &lt;- numeric(Tobs)
x[1] &lt;- 60
for(t in 1:(Tobs-1))
  x[t+1] = z_g() * f(x[t], h=0)
obs &lt;- data.frame(x = c(rep(0, W), 
                        pmax(rep(0,Tobs-1), x[1:(Tobs-1)])), 
                  y = c(rep(0, W), 
                        x[2:Tobs]))
xObs &lt;- obs$x
yObs &lt;- obs$y
xPred &lt;- seq(0, max(xObs), length = 50)</code></pre>
<pre class="r"><code>qplot(seq_along(x), x) + geom_line()</code></pre>
<pre class="r"><code>xObs &lt;- rep(0,5)
yObs &lt;- rep(0,5)</code></pre>
<hr />
<p>Now the GP estimation from NIMBLE. Updated to compute the prior for the length scale using Daniel’s scaling argument.</p>
<pre class="r"><code> priors_template &lt;- nimbleCode({
        rho ~ dunif(0, X)
        sigGP ~ dunif(0, 1e5)
        sigOE ~ dunif(0, 1e5)
        })  

nimbleCodeSub &lt;- function(code, .values){
  as.expression(sapply(code, lazyeval::interp, .values = .values)[-1])
}
  
priors &lt;- nimbleCodeSub(priors_template, 
                        .values = list(X = diff(range(xObs))/(2*sqrt(6))) )</code></pre>
<p>(Note that at this time all nimble run calls must be made in one block since we cannot cache nimble pointers).</p>
<pre class="r"><code>fit &lt;- gp_setup(xObs, yObs, xPred, priors = priors)

## Fit the GP
system.time(fit$Cmcmc$run(100000))
samples &lt;- as.matrix(fit$Cmcmc$mvSamples)

## Perform prediction
system.time(fit$Cpred$run(samples))

## Extract variables for future use
E &lt;- fit$Cpred$getE()
C &lt;- fit$Cpred$getC()
samples &lt;- as.data.frame(samples)</code></pre>
<p>Posteriors</p>
<pre class="r"><code>df &lt;- tidyr::gather(samples)
ggplot(df) + 
  geom_density(aes(value)) + 
  facet_wrap(~key, scale=&#39;free&#39;)</code></pre>
<pre class="r"><code>obs &lt;- data.frame(x = xObs, y = yObs)
pred &lt;- data.frame(x = xPred, y = E, ymin = E - sqrt(diag(C)), ymax = E + sqrt(diag(C)))
ggplot2::ggplot(pred) + 
  geom_ribbon(aes(x = x,y = y, ymin = ymin, ymax = ymax), fill = &quot;grey80&quot;) +
  geom_line(aes(x = x, y = y), size=1) + 
  geom_point(data = obs, aes(x,y)) +
  geom_line(data = data.frame(x = xPred, true = f(xPred,0)), aes(x,true), col=&quot;red&quot;) + 
  coord_cartesian(xlim = range(c(xObs, xPred)), ylim = range(c(yObs,E))) +
  theme_bw() </code></pre>
<hr />
</div>
<div id="decision-theory" class="section level2">
<h2>Decision theory</h2>
<pre class="r"><code>states &lt;- xPred # Vector of all possible states
actions &lt;- states # Vector of actions: harvest</code></pre>
<p>Let’s consider a slight variation of the most trivial utility function: one which explicitly adds a cost to completely exhausting the stock (or reducing the stock by more than, say 95% in this case.) This should be somewhat similar to the impact of no discount rate.</p>
<pre class="r"><code># Utility function
discount = 0.99

#get_utility &lt;- function(x,h) pmin(x,h)
#R &lt;- outer(states, actions, get_utility)

R &lt;- sapply(actions, function(h){
      sapply(states, function(x){
  if(h &lt; 0.95 * x)
    h
  else 
     - 1 * max(states)
  })
})</code></pre>
<p>Implementing policy</p>
<pre class="r"><code>z &lt;- function() rlnorm(1, meanlog = 0, sdlog = sigma_g)

simulate_policy &lt;- function(states, actions, policy, f, z, s0, steps = 50, utility = function(s,a) NA, discount = 1){
  s &lt;- numeric(steps)
  a &lt;- numeric(steps)
  u &lt;- numeric(steps)
  s[1] &lt;- s0
  for(t in 1:(steps-1)){
    
    a[t] &lt;- actions[policy[which.min(abs(states - s[t]))]]
    s[t+1] &lt;- z() * f(s[t], a[t])
    u[t] &lt;- utility(s[t], a[t]) * discount ^ t
  }
  
  # Final action determined but not implemented
  a[steps] &lt;- actions[policy[which.min(abs(states - s[t]))]]

  data.frame(time = 1:steps, state = s, action = a, utility = u)
}</code></pre>
<div id="gp-model" class="section level3">
<h3>GP model</h3>
<pre class="r"><code>gp_matrix &lt;- function(states, actions, E, C){
  
  transition &lt;- array(0, dim = c(length(states), length(states), length(actions)))
  K &lt;- length(states)
  sigmas &lt;- sqrt(diag(C))
  
  for (k in 1:length(states)) {
    for (i in 1:length(actions)) {
      nextpop &lt;- E[k] - actions[i]
      if(nextpop &lt;= 0) {
        transition[k, , i] &lt;- c(1, rep(0, K - 1))
      } else {
        transition[k, , i] &lt;- dnorm(states, nextpop, sigmas[i]) / sum(dnorm(states, nextpop, sigmas[i]))
      }
    }
  }
  transition
}

P_gp &lt;- gp_matrix(states, actions, E, C)</code></pre>
<pre class="r"><code>mdp_check(P = P_gp, R = R)

gp &lt;- mdp_value_iteration(P_gp, R, discount = discount, epsilon = 0.00001, max_iter = 5e3, V0 = numeric(length(states)))</code></pre>
<pre class="r"><code>ggplot(data.frame(stock = states, escapement = states - actions[gp$policy])) +
  geom_point(aes(stock, escapement)) + xlab(&quot;Population size&quot;) + ylab(&quot;Escapement&quot;)</code></pre>
<pre class="r"><code>data.frame(reps = 1:50) %&gt;% 
  group_by(reps) %&gt;% 
  do(simulate_policy(states,actions, gp$policy, f, z, s0 = 100, steps = 20, utility = pmin, discount = discount)[c(&quot;time&quot;, &quot;state&quot;, &quot;utility&quot;)]) -&gt;
  sims 

mean(sims$utility)</code></pre>
<pre class="r"><code>ggplot(sims) + geom_line(aes(time, state, group = reps), alpha = 0.3, col = &quot;darkblue&quot;)</code></pre>
<div id="simulate-under-the-true-model" class="section level4">
<h4>Simulate under the true model</h4>
<pre class="r"><code>data.frame(reps = 1:50) %&gt;% 
  group_by(reps) %&gt;% 
  do(simulate_policy(states, actions, gp$policy, f, z, s0 = 100, steps = 20, utility = pmin, discount = discount)[c(&quot;time&quot;, &quot;state&quot;, &quot;utility&quot;)]) -&gt;
  sims 

mean(sims$utility)</code></pre>
<p>(Average utility is approximate here since it does not include penalty; since a function and not a matrix is requred by this function at this time.)</p>
<pre class="r"><code>ggplot(sims) + geom_line(aes(time, state, group = reps), alpha = 0.3, col = &quot;darkblue&quot;)</code></pre>
<hr />
</div>
</div>
<div id="comparison-to-true-model" class="section level3">
<h3>Comparison to true model</h3>
<pre class="r"><code>P &lt;- transition_matrix(states, actions, f, pdfn)
#get_utility &lt;- function(x,h) pmin(x,h)
#R &lt;- outer(states, actions, get_utility)</code></pre>
<pre class="r"><code>mdp_check(P = P, R = R)
mdp &lt;- mdp_value_iteration(P, R, discount = discount, epsilon = 0.001, max_iter = 5e3, V0 = numeric(length(states)))</code></pre>
<pre class="r"><code>ggplot(data.frame(stock = states, 
                  escapement = states - actions[gp$policy], 
                  optimal_escapement = states - actions[mdp$policy])) +
  geom_point(aes(stock, escapement)) + 
  geom_point(aes(stock, optimal_escapement), col=&quot;red&quot;, alpha=.4) + 
  xlab(&quot;Population size&quot;) + ylab(&quot;Escapement&quot;)</code></pre>
<p>Note that the altered award structure has almost no effect on the optimal policy given the true model, other than to avoid harvesting directly to zero even when the stock cannot persist, due to the explicit penalty for doing so.</p>
<pre class="r"><code>data.frame(reps = 1:50) %&gt;% 
  group_by(reps) %&gt;% 
  do(simulate_policy(states,actions, mdp$policy, f, z, s0 = 100, steps = 20, utility = pmin, discount = discount)[c(&quot;time&quot;, &quot;state&quot;, &quot;utility&quot;)]) -&gt;
  sims 

mean(sims$utility)</code></pre>
<pre class="r"><code>ggplot(sims) + geom_line(aes(time, state, group = reps), alpha = 0.3, col = &quot;darkblue&quot;)</code></pre>
</div>
</div>
