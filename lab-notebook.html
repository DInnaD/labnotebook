<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  <head prefix="dc: http://purl.org/dc/terms/ og: http://ogp.me/ns#"> <!-- namespaces used in metadata.html -->
  <meta http-equiv='Content-Type' content='text/html; charset=utf-8'/>
  <title>Lab Notebook</title>
  <meta name="author" content="Carl Boettiger" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <!-- HTML5 metadata -->
<meta name="keywords" content="" />
<meta name="description" content="" />
<!-- RDFa Metadata (in DublinCore) -->
<meta property="dc:title" content="Lab Notebook" />
<meta property="dc:creator" content="Carl Boettiger" />
<meta property="dc:date" content="" />
<meta property="dc:format" content="text/html" />
<meta property="dc:language" content="en" />
<meta property="dc:identifier" content="/lab-notebook.html" />
<meta property="dc:rights" content="CC0" />
<meta property="dc:source" content="Lab Notebook" />
<meta property="dc:subject" content="Ecology" /> 
<meta property="dc:type" content="website" /> 
<!-- RDFa Metadata (in OpenGraph) -->
<meta property="og:title" content="Lab Notebook" />
<meta property="og:author" content="http://www.carlboettiger.info/index.html#me" />  <!-- Should be Liquid? URI? -->
<meta property="http://ogp.me/ns/profile#first_name" content="Carl"/>
<meta property="http://ogp.me/ns/profile#last_name" content="Boettiger"/>
<meta property="http://ogp.me/ns/article#published_time" content="" />
<meta property="og:site_name" content="Lab Notebook" /> <!-- Same as dc:source? -->
<meta property="og:url" content="http://www.carlboettiger.info/lab-notebook.html" />
<meta property="og:type" content="website" /> 
<!-- Google Scholar Metadata -->
<!--
<meta name="citation_author" content="Carl Boettiger"/>
<meta name="citation_date" content=""/>
<meta name="citation_title" content="Lab Notebook"/>
<meta name="citation_journal_title" content="Lab Notebook"/>
-->
<!--NOTE: see also the COinS Metadata in span element in footer -->




  <link href="/assets/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
  <!-- Help the browser identify the RSS feed automatically -->
  <link rel="alternate" type="application/rss+xml" title="Carl Boettiger's Lab Notebook" href="/blog.xml" />
</head>


  <body prefix="dc: http://purl.org/dc/terms/ foaf: http://xmlns.com/foaf/0.1/"> 
    <!-- Navbar  ================================================== -->

<nav class="navbar navbar-default" role="navigation">
  <div class="container-fluid">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/README.html"><i class="icon-info-sign"></i></a>
    </div>

 <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">

          <li  >
          <a href="/index.html">Home</a></li>
          <li  >
          <a href="/vita.html">Vita</a></li>
          <li  >
          <a href="/research.html">Research</a></li>
          <li  >
          <a href="/teaching.html">Teaching</a></li>
          <li  >
          <a href="/community.html">Community</a></li>
          <li  class="active" >
          <a href="/lab-notebook.html">Lab Notebook</a></li>

        </ul>

      <!-- Search site using Google's index -->
        <form class="navbar-form navbar-right" role="search" method="get" action="http://google.com/search">
          <div class="form-group">
            <input type="hidden" name="q" value="site:carlboettiger.info" />
            <input type="text" class="form-control search-query" name="q" placeholder="Search"/>
          </div>
          <button class="btn btn-mini" type="submit"><i class="icon-search"></i></button> 
       </form>

    </div><!--/.nav-collapse -->
  </div> <!-- /container -->
</nav>



    <div class="container"> <!-- Responsive grid layout, doesn't jump to full-width --> 
      <header>
        <h1 class="entry-title">Lab Notebook</h1>
        <h2>(<a href="http://www.carlboettiger.info/2012/09/28/Welcome-to-my-lab-notebook.html">Introduction</a>)</h2>
      </header>

      <div class="row feed">
  <div class="col-md-3 col-md-offset-1">
    <h4>  <a property="account" href="https://github.com/cboettig" onclick="recordOutboundLink(this, 'Outbound Links', 'Github'); return false;"><i class="icon-github" alt="github"></i> Coding </a></h4> 
    <div class="excerpt">
      <div class="scroll">
        <ul><li>cboettig pushed to master at cboettig/labnotebook: <em>link to ropensci</em> <a href="https://github.com/cboettig/labnotebook/compare/4f42e642fa...39ae1d4680">10:20 2014/11/26</a></li><li>cboettig pushed to master at rocker-org/ropensci: <em>chunk into more AUFS layers</em> <a href="https://github.com/rocker-org/ropensci/compare/57175ab8ec...96633b02d5">10:26 2014/11/25</a></li><li>cboettig pushed to gh-pages at cboettig/labnotebook: <em>Updating to cboettig/labnotebook@4f42e64.</em> <a href="https://github.com/cboettig/labnotebook/compare/009239a4e7...092c592a63">09:48 2014/11/25</a></li><li>cboettig pushed to sandbox at rocker-org/rocker: <em>image name had somehow been omitted, whoops</em> <a href="https://github.com/rocker-org/rocker/compare/977d747f1b...a932410dc7">09:42 2014/11/25</a></li><li>cboettig pushed to master at cboettig/labnotebook: <em>post new notes</em> <a href="https://github.com/cboettig/labnotebook/compare/9d7ff421e8...4f42e642fa">09:39 2014/11/25</a></li></ul>
      </div>
    </div>
  </div>
  <div class="col-md-3">
    <h4> <a property="account" href="https://twitter.com/cboettig" onclick="recordOutboundLink(this, 'Outbound Links', 'Twitter'); return false;"><i class="icon-twitter"></i> Discussing </a></h4> 
     <div class="excerpt">
      <div class="scroll">
       <ul><li><p>&amp; nice piece by @ConsLevin + discusses ecosystem-based management approaches to marine regime shifts: <a href="http://t.co/DOXGALys6q">http://t.co/DOXGALys6q</a></p>
 <a href="http://twitter.com/cboettig/statuses/537299064446914560">05:37 2014/11/25</a> </li><li><p>The opening review by @vdakos @FreshwaterSteve van Nes &amp; @MartenScheffer covers promise &amp; limitations of EWS <a href="http://t.co/fQuLH8SbOa">http://t.co/fQuLH8SbOa</a></p>
 <a href="http://twitter.com/cboettig/statuses/537298243378348032">05:34 2014/11/25</a> </li><li><p>Very nice special issue on Regime Shifts in Marine Systems in Phil Tr Roy Soc B <a href="http://t.co/G38MKRuAx3">http://t.co/G38MKRuAx3</a> !</p>
 <a href="http://twitter.com/cboettig/statuses/537297506258800640">05:31 2014/11/25</a> </li><li><p>@kevin_ushey Still wishing for an easy way to toggle off all the panels. 4 panels = too hard to use on my phone! <a href="https://t.co/WqIxVpl3E1">https://t.co/WqIxVpl3E1</a></p>
 <a href="http://twitter.com/cboettig/statuses/535592156086272001">12:34 2014/11/21</a> </li><li><p>.@kevin_ushey Dockerized @rstudio server daily build (with R daily build) <a href="https://t.co/faDuJU071q">https://t.co/faDuJU071q</a> #sofarsogood #bleedingedge #rstats</p>
 <a href="http://twitter.com/cboettig/statuses/535572186321276928">11:15 2014/11/20</a> </li></ul>
      </div>
    </div> 
  </div> 
  <div class="col-md-3">
    <h4> <a href="http://www.mendeley.com/groups/634301/theoretical-ecology/papers/" onClick="recordOutboundLink(this, 'Outbound Links', 'Mendeley'); return false;"><i class="icon-book"></i> Reading </a></h4> 
    <div class="excerpt">
      <div class="scroll">
<ul><li>Assessing trade-offs to inform ecosystem-based fisheries management of forage fish.: Scientific reports (2014). Pages: 7110. Andrew Olaf Shelton, Jameal F Samhouri, Adrian C Stier, Philip S Levin et al. <a href="http://www.mendeley.com/c/7393588154/g/634301/shelton-2014-assessing-trade-offs-to-inform-ecosystem-based-fisheries-management-of-forage-fish/">07:08 2014/11/25</a></li><li>The Southern Kalahari: a potential new dust source in the Southern Hemisphere?: Environmental Research Letters (2012). Volume: 7, Issue: 2. Pages: 024001. Abinash Bhattachan, Paolo D’Odorico, Matthew C Baddock, Ted M Zobeck, Gregory S Okin, Nicolas Cassar et al. <a href="http://www.mendeley.com/c/7318874474/g/634301/bhattachan-2012-the-southern-kalahari-a-potential-new-dust-source-in-the-southern-hemisphere/">11:45 2014/11/04</a></li><li>Resilience and recovery potential of duneland vegetation in the southern Kalahari: Ecosphere (2014). Volume: 5, Issue: January. Pages: 1-14. A Bhattachan, P D'Odorico, K Dintwe et al. <a href="http://www.mendeley.com/c/7318874484/g/634301/bhattachan-2014-resilience-and-recovery-potential-of-duneland-vegetation-in-the-southern-kalahari/">11:45 2014/11/04</a></li><li>Potential dust emissions from the southern Kalahari's dunelands: Journal of Geophysical Research: Earth Surface (2013). Volume: 118, Issue: 1. Pages: 307-314. Abinash Bhattachan, Paolo D'Odorico, Gregory S. Okin, Kebonyethata Dintwe et al. <a href="http://www.mendeley.com/c/7318874504/g/634301/bhattachan-2013-potential-dust-emissions-from-the-southern-kalaharis-dunelands/">11:45 2014/11/04</a></li></ul>
      </div>
    </div>
  </div> 
</div>

<hr>
<div class="row postpreview">
  <div class="col-md-11 col-md-offset-1">
    <div class="row">
      <h4> <a href="http://www.carlboettiger.info/atom.xml"
              onClick="recordOutboundLink(this,
              'Outbound Links', 'RSS'); return false;"
              style="color: inherit;"
              ><i class="icon-rss" ></i> Entries</a></h4>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/11/24/coreos-docker-registries-etc.html">Coreos Docker Registries Etc</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 24 Nov 2014</p>

<article>
<div class="excerpt">
<h2 id="a-secure-docker-registry">A secure docker registry</h2>
<p>Running one’s own docker registry is far more elegant than moving tarballs between machines (e.g. when migrating between servers, particularly for images that may contain sensitive data such as security credentials). While it’s super convenient to have a containerized version of the Docker registry ready for action, it doesn’t do much good without putting it behind an HTTPS server (otherwise we have to restart our entire docker service with the insecure flag to permit communication with an unauthenticated registry – doesn’t sound like a good idea). So this meant learning how to use <code>nginx</code> load balancing, which I guess is useful to know more generally.</p>
<h3 id="first-pass-nginx-on-ubuntu-server">First pass: nginx on ubuntu server</h3>
<p>After a few false starts, decided the <a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-a-private-docker-registry-on-ubuntu-14-04">digitalocean guide</a> is easily the best (though steps 1-3 can be skipped by using a containerized <code>registry</code> instead). This runs <code>nginx</code> directly from the host OS, which is in some ways more straight forward but less portable. A few notes-to-self in working through the tutorial:</p>
<ul>
<li><p>Note: At first, nginx refuses to run because there’s was <code>default</code> configuration in <code>cd /etc/nginx/sites-enabled</code> that tries to create a conflict. Remove this and things go pretty nicely.</p></li>
<li><p>Note: Running the registry container explicitly on port <code>127.0.0.1</code> provides an internal-only port that we can then point to from nginx. (Actually this will no longer matter when we use a containerized <code>nginx</code>, since we will simply not export these ports at all, but only expose the port of the <code>nginx</code> load balancer). Still, good to finally be aware of the difference between <code>127.0.0.1</code> and <code>0.0.0.0</code> (the publicly visible localhost, and the default if we supply only a port) in this context.</p></li>
<li><p>Note: Running and configuring <code>nginx</code> Note that keys are specific to the url. This is necessary for the server signing request, but I believe could have been omitted in the root certificate. Here’s how w ego about creating a root key and certificate (<code>crt</code>), a server key, server signing request (<code>csr</code>), and then sign the latter with the former to get the server certificate.</p></li>
</ul>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">openssl</span> genrsa -out dockerCA.key 2048
<span class="kw">openssl</span> req -x509 -new -nodes -key dockerCA.key -days 10000 -out dockerCA.crt -subj <span class="st">&#39;/C=US/ST=Oregon/L=Portland/CN=coreos.carlboettiger.info&#39;</span>
<span class="kw">openssl</span> genrsa -out docker-registry.key 2048
<span class="kw">openssl</span> req -new -key docker-registry.key -out docker-registry.csr -subj <span class="st">&#39;/C=US/ST=Oregon/L=Portland/CN=coreos.carlboettiger.info&#39;</span>
<span class="kw">openssl</span> x509 -req -in docker-registry.csr -CA dockerCA.crt -CAkey dockerCA.key -CAcreateserial -out docker-registry.crt -days 10000</code></pre>
<p>Note that we also need the <code>htpasswd</code> file from above, which needs <code>apache2-utils</code> and so cannot be generated directly from the CoreOS terminal (though the <code>openssl</code> certs can):</p>
<pre><code>sudo htpasswd -bc /etc/nginx/docker-registry.htpasswd $USERNAME $PASSWORD</code></pre>
<p>Having created these ahead of time, I end up just copying my keys into the Dockerfile for my <code>nginx</code> instance (if we generated them on the container, we’d still need to get <code>dockerCA.crt</code> off the container to authenticate the client machines. Makes for a simple Dockerfile that we then build locally:</p>
<pre><code>FROM ubuntu:14.04
RUN apt-get update &amp;&amp; apt-get install -y apache2-utils curl nginx openssl supervisor
COPY docker-registry /etc/nginx/sites-available/docker-registry
RUN ln -s /etc/nginx/sites-available/docker-registry /etc/nginx/sites-enabled/docker-registry

## Copy over certificates ##
COPY docker-registry.crt /etc/ssl/certs/docker-registry 
COPY docker-registry.key /etc/ssl/private/docker-registry 
COPY docker-registry.htpasswd /etc/nginx/docker-registry.htpasswd


EXPOSE 8080

## use supervisord to persist
COPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf
CMD [&quot;/usr/bin/supervisord&quot;]</code></pre>
<p>Note that we need to install the <code>dockerCA.crt</code> certificate on any client that wants to access the private registry. On Ubuntu this looks like:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">sudo</span> mkdir /usr/local/share/ca-certificates/docker-dev-cert
<span class="kw">sudo</span> cp devdockerCA.crt /usr/local/share/ca-certificates/docker-dev-cert
<span class="kw">sudo</span> update-ca-certificates 
<span class="kw">sudo</span> service docker restart</code></pre>
<p>But on CoreOS we use a different directory (and restarting the docker service doesn’t seem possible or necessary):</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">sudo</span> cp dockerCA.crt /etc/ssl/certs/docker-cert
<span class="kw">sudo</span> update-ca-certificates  </code></pre>
<ul>
<li><p>Note: Could not get the official <code>nginx</code> container to run the <code>docker-registry</code> config file as <code>/etc/nginx/nginx.conf</code>, either with or without adding <code>daemon off;</code> at the top of <code>/etc/nginx/nginx.conf</code>. With, it complains this is a duplicate, (despite being recommended on the <a href="https://registry.hub.docker.com/_/nginx">nginx container documentation</a>, though admittedly this already appears in the default command <code>[&quot;nginx&quot; &quot;-g&quot; &quot;daemon off;&quot;]</code>). Without, the error says that <code>upstream</code> directive is not allowed here. Not sure what to make of these errors, ended up running an ubuntu container and then just installing <code>nginx</code> etc following the digitalocean guide. Ended up dropping the <code>daemon off;</code> from the config file and running <code>service nginx start</code> through <code>supervisord</code> to ensure that the container stays up. Oh well.</p></li>
<li><p>Note: I got a 502 error when calling <code>curl</code> against the the <code>nginx</code> container-provided URL (with or without SSL enabled), since from inside the <code>nginx</code> container we cannot access the host addresses. The simplest solution is to add <code>--net=&quot;host&quot;</code> when we <code>docker run</code> the <code>nginx</code> container, but this isn’t particularly secure. Instead, we’ll link directly to the ports of the <code>registry</code> container like this:</p></li>
</ul>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">docker</span> run  --name=registry -p 8080:8080 registry
<span class="kw">docker</span> run --name=nginx --net=container:registry nginx</code></pre>
<p>Note that we do not need to export the registry port (e.g. <code>-p 5000:5000</code>) at all, but we do need to export the <code>nginx</code> load-balancer port <em>from the <code>registry</code> container</em> first, since we will simply be linking it’s network with the special <code>--net=container:registry</code>.</p>
<p>Note that we would probably want to link a local directory to provide persistent storage for the <code>registry</code>; in the above example images committed to registry are lost when the container is destroyed.</p>
<p>We can now log in:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">docker</span> login https://<span class="kw">&lt;</span>YOUR-DOMAIN<span class="kw">&gt;</span>:8080</code></pre>
<p>We can now reference our private registry by using its full address in the namespace of the image in commands to <code>docker pull</code>, <code>push</code>, <code>run</code> etc.</p>
<h2 id="migrating-gitlab-between-servers">Migrating gitlab between servers</h2>
<p>This migration was my original motivation to configure the private docker registry; ironically it isn’t necessary for this case (though it’s useful for the drone image, for instance).</p>
<p>Note that there is no need to migrate the redis and postgresql containers manually. Migrating the backup file over to the corresponding location in the linked volume and then running the backup-restore is sufficient. Upgrading is also surprisingly smooth; we can backup (just in case), then stop and remove the container (leaving the <code>redis</code> and <code>postgresql</code> containers running), pull and relaunch with otherwise matched option arguments and the upgrade runs automatically.</p>
<p>When first launching the <code>gitlab</code> container on a tiny droplet running coreos, my droplet seems invariably to hang. Rebooting from the digitalocean terminal seems to fix this. A nice feature of <code>fleet</code> is that all the containers are restarted automatically after reboot, unlike when running these directly from <code>docker</code> on my ubuntu machine.</p>
<h2 id="notes-on-fleet-unit-files">Notes on fleet unit files</h2>
<p>Fleet unit files are actually pretty handy and straight forward. One trick is that we must quote commands in which we want to make use of environmental variables. For instance, one must write:</p>
<pre><code>Environment=&quot;VERSION=1.0&quot;
ExecStart=/bin/bash -c &quot;/usr/bin/docker run image:${VERSION}&quot;</code></pre>
<p>in a <code>Service</code> block, rather than <code>ExecStart=/usr/bin/docker run ...</code> directly, for the substitution to work. It seems if we are using the more standard practice of environment files (which after all is the necessary approach to avoid having to edit the unit file directly one way or another anyway), we can avoid the <code>bin/bash</code> wrapper and insert the environment reference directly.</p>
<p>If we’re not doing anything fancy wrt load balancing between different servers, we don’t have that much use for the corresponding “sidekick” unit files that keep our global <code>etcd</code> registry up to date. Perhaps these will see more use later.</p>
<h2 id="cloud-config">Cloud-config</h2>
<p>Note that we need to refresh the discovery url pretty-much anytime we completely destroy the cluster.</p>
<p>A few edits to my cloud-config to handle initiating swap, essential for running most things (gitlab, rstudio) on tiny droplets. Still requires one manual reboot for the allocation to take effect. Adds this to the <code>units</code> section of <code>#cloud-config</code>:</p>
<pre><code>    ## Configure SWAP as per https://github.com/coreos/docs/issues/52
    - name: swap.service
      command: start
      content: |
        [Unit]
        Description=Turn on swap

        [Service]
        Type=oneshot
        Environment=&quot;SWAPFILE=/1GiB.swap&quot;
        RemainAfterExit=true
        ExecStartPre=/usr/sbin/losetup -f ${SWAPFILE}
        ExecStart=/usr/bin/sh -c &quot;/sbin/swapon $(/usr/sbin/losetup -j ${SWAPFILE} | /usr/bin/cut -d : -f 1)&quot;
        ExecStop=/usr/bin/sh -c &quot;/sbin/swapoff $(/usr/sbin/losetup -j ${SWAPFILE} | /usr/bin/cut -d : -f 1)&quot;
        ExecStopPost=/usr/bin/sh -c &quot;/usr/sbin/losetup -d $(/usr/sbin/losetup -j ${SWAPFILE} | /usr/bin/cut -d : -f 1)&quot;

        [Install]
        WantedBy=local.target

    - name: swapalloc.service
      command: start
      content: |
        [Unit]
        Description=Allocate swap

        [Service]
        Type=oneshot
        ExecStart=/bin/sh -c &quot;sudo fallocate -l 1024m /1GiB.swap &amp;&amp; sudo chmod 600 /1GiB.swap &amp;&amp; sudo chattr +C /1GiB.swap &amp;&amp; sudo mkswap /1GiB.swap&quot;
</code></pre>
<p>More probably be structured more elegantly, but it works. (Not much luck trying to tweak this into a bunch of <code>ExecStartPre</code> commands though.</p>
<h2 id="nfs-sharing-on-coreos">NFS sharing on CoreOS?</h2>
<p>Couldn’t figure this one out. <a href="http://serverfault.com/questions/647014/share-disks-through-nfs-on-a-coreos-cluster">My SO Q here</a></p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/11/24/coreos-docker-registries-etc.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/11/19/coreos-and-other-infrastructure-notes.html">Coreos And Other Infrastructure Notes</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 19 Nov 2014</p>

<article>
<div class="excerpt">
<h2 id="coreos">CoreOS?</h2>
<p>Security model looks excellent. Some things not so clear:</p>
<ul>
<li><p>In a single node setup, what happens with updates? Would containers being run directly come down and not go back up automatically? In general, how effective or troublesome is it to run a single, low-demand app on a single node CoreOS rather than, say, an ubuntu image (e.g. just to benefit from the security updates model)? For instance, would an update cause a running app to exit in this scenario? (Say, if the container is launched directly with <code>docker</code> and not through <code>fleet</code>?) (Documentation merely notes that cluster allocation / fleet algorithm is fastest with between 3 &amp; 9 nodes).</p></li>
<li><p>If I have a heterogenous cluster with one more powerful compute node, is there a way to direct that certain apps are run on that node and that other apps are not?</p></li>
<li><p>Looks like one needs a load-balancer to provide a consistent IP for containers that might be running on any node of the cluster?</p></li>
<li><p><a href="https://github.com/coreos/docs/issues/52">Enabling swap</a>. Works, but is there a way to do this completely in <code>cloud-config</code>?</p></li>
</ul>
<h2 id="setting-up-my-domain-names-for-digitalocean">Setting up my domain names for DigitalOcean</h2>
<p>In Dreamhost DNS management:</p>
<ul>
<li>I have my top-level domain registered through Dreamhost, uses dreamhost’s nameservers.</li>
<li>A-level entry for top level domain points to (the new) Github domain IP address</li>
<li>Have CNAME entries for <code>www</code> and <code>io</code> pointing to <code>cboettig.github.io</code></li>
</ul>
<p><strong>First step</strong></p>
<ul>
<li>Add an A-level entry, <code>server.carlboettiger.info</code>, pointing to DigitalOcean server IP</li>
</ul>
<p>Then go over to DigitalOcean panel.</p>
<p>From DigitalOcean DNS management:</p>
<ul>
<li>add new (A level) DNS entry as <code>server.carlboettiger.info</code> pointing to DO server IP</li>
<li>Delete the existing three NS entries <code>ns1.digitalocean.com</code> etc.</li>
<li>Add three new NS entries using <code>ns1.dreamhost.com</code> etc</li>
</ul>
<p>Things should be good to go!</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/11/19/coreos-and-other-infrastructure-notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/11/14/nimble-explore.html">Nimble Explore</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 14 Nov 2014</p>

<article>
<div class="excerpt">
<p>A quick first exploration of <a href="http://r-nimble.org">NIMBLE</a> and some questions.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;nimble&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;sde&quot;</span>)</code></pre>
<p>Let’s simulate from a simple OU process: <span class="math">\(dX = \alpha (\theta - X) dt + \sigma dB_t\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">123</span>)
d &lt;-<span class="st"> </span><span class="kw">expression</span>(<span class="fl">0.5</span> *<span class="st"> </span>(<span class="dv">10</span>-x))
s &lt;-<span class="st"> </span><span class="kw">expression</span>(<span class="dv">1</span>) 
data &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">sde.sim</span>(<span class="dt">X0=</span><span class="dv">6</span>,<span class="dt">drift=</span>d, <span class="dt">sigma=</span>s, <span class="dt">T=</span><span class="dv">100</span>, <span class="dt">N=</span><span class="dv">400</span>))</code></pre>
<pre><code>## sigma.x not provided, attempting symbolic derivation.</code></pre>
<p>i.e. <span class="math">\(\alpha = 0.5\)</span>, <span class="math">\(\theta = 10\)</span>, <span class="math">\(\sigma=1\)</span>, starting at <span class="math">\(X_0 = 6\)</span> and running for 100 time units with a dense sampling of 400 points.</p>
<p>Le’t now estimate a Ricker model based upon (set aside closed-form solutions to this estimate for the moment, since we’re investigating MCMC behavior here).</p>
<pre class="sourceCode r"><code class="sourceCode r">code &lt;-<span class="st"> </span><span class="kw">modelCode</span>({
      K ~<span class="st"> </span><span class="kw">dunif</span>(<span class="fl">0.01</span>, <span class="fl">40.0</span>)
      r ~<span class="st"> </span><span class="kw">dunif</span>(<span class="fl">0.01</span>, <span class="fl">20.0</span>)
  sigma ~<span class="st"> </span><span class="kw">dunif</span>(<span class="fl">1e-6</span>, <span class="dv">100</span>)

  iQ &lt;-<span class="st"> </span><span class="dv">1</span> /<span class="st"> </span>(sigma *<span class="st"> </span>sigma)

  x[<span class="dv">1</span>] ~<span class="st"> </span><span class="kw">dunif</span>(<span class="dv">0</span>, <span class="dv">10</span>)

  for(t in <span class="dv">1</span>:(N<span class="dv">-1</span>)){
    mu[t] &lt;-<span class="st"> </span><span class="kw">log</span>(x[t]) +<span class="st"> </span>r *<span class="st"> </span>(<span class="dv">1</span> -<span class="st"> </span>x[t]/K) 
    x[t<span class="dv">+1</span>] ~<span class="st"> </span><span class="kw">dlnorm</span>(mu[t], iQ) 
  }
})

constants &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">N =</span> <span class="kw">length</span>(data$x))
inits &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">K =</span> <span class="dv">6</span>, <span class="dt">r =</span> <span class="dv">1</span>, <span class="dt">sigma =</span> <span class="dv">1</span>)

Rmodel &lt;-<span class="st"> </span><span class="kw">nimbleModel</span>(<span class="dt">code=</span>code, <span class="dt">constants=</span>constants, <span class="dt">data=</span>data, <span class="dt">inits=</span>inits)</code></pre>
<p>NIMBLE certainly makes for a nice syntax so far. Here we go now: create MCMC specification and algorithm</p>
<pre class="sourceCode r"><code class="sourceCode r">mcmcspec &lt;-<span class="st"> </span><span class="kw">MCMCspec</span>(Rmodel)
Rmcmc &lt;-<span class="st"> </span><span class="kw">buildMCMC</span>(mcmcspec)</code></pre>
<p>Note that we can also query some details regarding our specification (set by default)</p>
<pre class="sourceCode r"><code class="sourceCode r">mcmcspec$<span class="kw">getSamplers</span>()</code></pre>
<pre><code>## [1] RW sampler;   targetNode: K,  adaptive: TRUE,  adaptInterval: 200,  scale: 1
## [2] RW sampler;   targetNode: r,  adaptive: TRUE,  adaptInterval: 200,  scale: 1
## [3] RW sampler;   targetNode: sigma,  adaptive: TRUE,  adaptInterval: 200,  scale: 1</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">mcmcspec$<span class="kw">getMonitors</span>()</code></pre>
<pre><code>## thin = 1: K, r, sigma, x</code></pre>
<p>Now we’re ready to compile model and MCMC algorithm</p>
<pre class="sourceCode r"><code class="sourceCode r">Cmodel &lt;-<span class="st"> </span><span class="kw">compileNimble</span>(Rmodel)
Cmcmc &lt;-<span class="st"> </span><span class="kw">compileNimble</span>(Rmcmc, <span class="dt">project =</span> Cmodel)</code></pre>
<p>Note we could have specified the <code>Rmodel</code> as the “project” (as shown in the example from the Nimble website), but this is more explicit. Rather convenient way to add to an existing model in this manner.</p>
<p>And Now we can execute the MCMC algorithm in blazing fast C++ and then extract the samples</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">Cmcmc</span>(<span class="dv">10000</span>)</code></pre>
<pre><code>## NULL</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">samples &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">as.matrix</span>(<span class="kw">nfVar</span>(Cmcmc, <span class="st">&#39;mvSamples&#39;</span>)))</code></pre>
<p>How do these estimates compare to theory:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(samples$K)</code></pre>
<pre><code>## [1] 10.05681</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(samples$r)</code></pre>
<pre><code>## [1] 0.180207</code></pre>
<hr />
<p>Some quick impressions:</p>
<ul>
<li><p>Strange that <code>Rmodel</code> call has to be repeated before we can set up a custom MCMC (<a href="http://r-nimble.org/examples">nimble docs</a>). How/when was this object altered since it was defined in the above code? Seems like this could be problematic for interpreting / reproducing results?</p></li>
<li><p>What’s going on with <code>getSamplers()</code> and <code>getMonitors()</code>? Guessing these are in there just to show us what the defaults will be for our model?</p></li>
<li><p>why do we assign <code>Cmodel</code> if it seems we don’t use it? (the compilation needs to be done but isn’t explicitly passed to the next step). Seems we can use <code>Cmodel</code> instead of <code>Rmodel</code> in the <code>Cmcmc &lt;- compileNimble(Rmcmc, project = Cmodel)</code>, which makes the dependency more explicit, at least that notation is more explicit. Seems like it should be possiple to omit the first <code>compileNimble()</code> and have the second call the <code>compileNimble</code> automatically if it gets an object whose class is that of <code>Rmodel</code> instead?</p></li>
<li><p>Repeated calls to <code>Cmcmc</code> seem not to give the same results. Are we adding additional mcmc steps by doing this?</p></li>
<li><p>Thinking an <code>as.data.frame</code> would be nicer than <code>as.matrix</code> in the <code>nfVar</code> <code>mvSamples</code> coercion.</p></li>
<li><p>Don’t understand what <code>simulate</code> does (or why it always returns NULL?).</p></li>
</ul>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/11/14/nimble-explore.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

    <div class="row">
      
        <div class="col-md-3">
          <header><h4><a href="/2014/11/07/dear-docker-hub-users.html">Dear DockerHub users: please configure your repository links</a></h4></header>
<p><span>(for security's sake!)</span></p>
<p style="font-style:italic"> 07 Nov 2014</p>

<article>
<div class="excerpt">
<p>The DockerHub is a great resource for discovering and distributing Dockerfiles. Many users sharing public images take advantage of the Docker Hub’s <em>Automated Build</em> configuration, which is excellent as this automatically allows the Hub to display the Dockerfile and provides some medium of security above simply downloading and running some untrusted binary black box.</p>
<p>Unfortunately, far fewer users configure <em>Repository Links</em> to trigger builds to update even when the resulting Dockerfile is unchanged. As a result, many excellent Docker containers that are not under active development have not been rebuilt in several months, meaning that they still contain widely known dangerous security flaws such as <a href="http://en.wikipedia.org/wiki/Shellshock_(software_bug)">Shellshock</a> (September 2014).</p>
<p>This problem is easily avoided by configuring the <em>Repository Links</em> setting to point to the repository being used as a base image in <code>FROM</code>. The official base images such as <code>debian</code> and <code>ubuntu</code> (e.g. the images with no additional namespace) are regularly updated to patch security vulnerabilities as soon as they are discovered, resulting in updates being made every few days on average. Setting the repository link to the <code>FROM</code> source allows your repository to be rebuilt as soon as its base image has been updated, ensuring that you inherit those updates.</p>
<p>Naturally this strategy does not help if your <code>FROM</code> image isn’t an official base image and hasn’t configured <em>Repository Links</em> (or if such a break in the chain appears anywhere along the <code>FROM</code> recursion). In such cases, having a <code>RUN apt-get update &amp;&amp; apt-get upgrade -y</code> command (or equivalent option for your distribution) might be a good idea to make sure that your image at least gets the latest updates, but you’ll still need to set up some automatic or manual <em>Build Triggers</em> to ensure this is run regularly; or better yet, just <em>avoid building on or using stale images</em>.</p>
<p>If you do have a reliable <em>Repository Links</em> chain to an official image, then <code>apt-get upgrade</code> is not necessary (and in fact is not advised in Best Practices). Instead, make sure all images in the chain call <code>apt-get update</code> in the same RUN line as <code>apt-get install -y ...</code>, which will ensure that cache is broken and the latest versions of the packages are installed. See the official <a href="https://docs.docker.com/articles/dockerfile_best-practices/">Dockerfile Best Practices</a> for more information.</p>
<hr />
<p><em>NB: I’m not a security professional; this just looks like common sense usage</em></p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/11/07/dear-docker-hub-users.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/11/05/notes.html">linking binaries from other containers</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 05 Nov 2014</p>

<article>
<div class="excerpt">
<p>Been thinking about this for a while, but <span class="citation" data-cites="benmarwick">@benmarwick</span> ’s examples with <code>--volumes-from</code> convinced me to give this a try.</p>
<p>While there’s an obvious level of convenience in having something like LaTeX bundled into the <code>hadleyverse</code> container so that users can build nice pdfs, if often feels not very docker-esque to me to just throw the kitchen sink into a container. At the risk of some added complexity, we can provide LaTeX from a dedicated TeX container to a container that doesn’t have it built in, like <code>rocker/rstudio</code>. Check this out:</p>
<p>First, we run the docker container providing the texlive binaries as linked volume. Note that even after the 4 GB <code>texlive</code> container has been downloaded that this is slow to execute due to the volume linking flag (not really sure why that is).</p>
<pre><code>docker run --name tex -v /usr/local/texlive leodido/texlive true</code></pre>
<p>Once the above task is complete, we can run the <code>rstudio</code> container, which doesn’t have tex installed by itself, and access tex by linking:</p>
<pre><code>docker run -dP --volumes-from tex \
 -e PATH=$PATH:/usr/local/texlive/2014/bin/x86_64-linux/ \
 rocker/rstudio</code></pre>
<p>We can now log into RStudio, create a new Rnw file and presto, RStudio discovers the tex compilers and builds us a pdf. This does make our Docker execution lines a bit long, but that’s what <a href="www.fig.sh">fig</a> is for. (Or a good ole Makefile).</p>
<p>Note this requires we build <code>texlive</code> in a way that isolates it to it’s own path (e.g. <code>/usr/local/texlive</code>). The default installation with <code>apt-get</code> installs everything in separate locations that overlap with existing directories (like <code>/usr/bin</code>), which makes linking clumsy or impossible (we would need separate paths for all the components, e.g. since shared libraries aren’t found under the <code>bin</code> path, and we cannot link such a volume to another container without destroying everything in it’s <code>/usr/bin</code>, clearly not a good idea). Instead, if we use the standard <code>texlive</code> install script from <a href="https://www.tug.org/texlive/">https://www.tug.org/texlive/</a>, this installs everything into <code>/usr/local/texlive</code> which is much more portable as illustrated above. Not quite sure if it’s actually a good idea to build containers this way or not.</p>
<p>I’ll keep shipping latex inside the <code>hadleyverse</code> container (has about 300 MB of texlive that covers most common usecases), but this is certainly an intruging recipe to mix and match.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/11/05/notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/11/03/three-interfaces-for-Docker.html">Three Interfaces For Docker</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 03 Nov 2014</p>

<article>
<div class="excerpt">
<p>Here I outline three broad, different strategies for incorporating Docker into a user’s workflow, particularly from the perspective of an instructor getting a group of students up and running in a containerized environment, but also in the context of more generic collaborations. The options require progressively more setup and result in a progressively more ‘native’ feel to running Docker. My emphasis is on running Dockerized R applications and RStudio, though much the same thing can be accomplished with iPython notebooks and many other web apps.</p>
<p>Of course the great strength of Docker is the relative ease with which one can move between these three strategies while using the identical container, maintaining a consistent computational environment in each case.</p>
<h2 id="web-hosted-docker">Web-hosted Docker</h2>
<p>In this approach, RStudio-server is deployed on a web server and accessed through the browser. The use of Docker containers makes it easier for an instructor to deploy a consistent environment quickly with the desired software pre-installed and pre-configured.</p>
<h3 id="advantages">Advantages:</h3>
<ul>
<li>A user just needs a web browser and the URL of the server.</li>
<li>No need to install any local software.</li>
<li>No need to download big files.</li>
<li>Should work with any device that supports a modern browser, including most tablets.</li>
<li>Convenient to temporarily scale computation onto a larger system.</li>
</ul>
<h3 id="disadvantages">Disadvantages:</h3>
<ul>
<li>requires a network connection (at all times)</li>
<li>requires access to a server with sufficient computational power for the task.</li>
<li>Someone has to manage user &amp; network security (as with any web server).</li>
<li>Need additional mechanisms for moving files on and off the server, such as git.</li>
<li>No native interfaces available, must manage files, edit text etc. through the RStudio IDE</li>
</ul>
<h3 id="setup">Setup:</h3>
<p>A Docker container running RStudio can be deployed with a single command, see <a href="https://github.com/rocker-org/rocker/wiki/Using-the-RStudio-image">rocker wiki instructions on RStudio</a> for details. The instructor or team-member responsible for the setup would simply need to install docker on server. If multiple students will be accessing a single RStudio-server instance, it must be configured for multiple users. Alternately multiple containers can be run on different ports of the same server. (See wiki).</p>
<p>Hint: Users can also take advantage of the new R package <a href="https://github.com/sckott/analogsea">analogsea</a> to quickly launch and manage an RStudio Server instance on the Digital Ocean cloud platform. <code>analogsea</code> can also facilitate transfers of code and other files onto and off of the server.</p>
<h2 id="self-hosted-docker">Self-hosted Docker</h2>
<p>In this approach, the user installs docker (via <code>boot2docker</code>, if necessary) on their local machine, but still interacts with the container using the same web-based interface (e.g. <code>rstudio-server</code>, <code>ipython-notebook</code>) that one would use in the cloud-hosted model.</p>
<h3 id="advantages-1">Advantages:</h3>
<ul>
<li>No need for a network connection (at least once the container image is downloaded / transfered)</li>
<li>No need to have a server available (with the associated cost and security overhead)</li>
</ul>
<h3 id="disadvantages-1">Disadvantages:</h3>
<ul>
<li>More initial setup: install <code>docker</code> locally, or install <code>boot2docker</code> for Mac/Windows users.</li>
<li>Need to use <code>git</code> or <code>docker copy</code> to move files from the container to the host or vice versa.</li>
</ul>
<p>Hint: Users might also check out the R package <a href="https://github.com/wch/harbor">harbor</a> for interacting with Docker locally from R.</p>
<h3 id="setup-1">Setup:</h3>
<p>Setup is much the same as on a remote server, though there is no need to set custom usernames or passwords since the instance will be accessible only to local users. See <a href="https://github.com/rocker-org/rocker/wiki/Using-the-RStudio-image">rocker wiki instructions on RStudio</a> for details.</p>
<h2 id="integrated-docker">Integrated Docker</h2>
<p>This approach is the same as the self-hosted approach, except that we link shared volumes with the host. At minimum this makes it easier to move files on and off the container without learning git.</p>
<p>An intriguing advantage of this approach is that it does not restrict the user to the RStudio IDE as a way of editing text, managing files and versions, etc. Most users do not rely exclusively on RStudio for these tasks, and may find that restriction limiting. The integrated approach may be more suited for experienced users who are set in their ways and do not need a pixel-identical work environment of RStudio useful for following directions in a classroom. In the integrated approach, a user can continue to rely on whatever their preferred native tools are, while ensuring that code execution occurs (invisibly) on a Dockerized container.</p>
<h3 id="advantages-2">Advantages</h3>
<ul>
<li>Can use native OS tools (text editors, file browsers, version control front ends, etc) for all interactions</li>
<li>No network required (once image is downloaded / transfered).</li>
<li>No servers required</li>
</ul>
<h3 id="disadvantages-2">Disadvantages</h3>
<ul>
<li>Additional setup beyond self-hosting: mapping shared volumes, managing user permissions.</li>
<li>Potentially less well suited for classroom use, which may benefit from everyone using the identical RStudio interface rather than a range of different text editors, etc. (Of course one can still share volumes while using RStudio as the IDE).</li>
<li>Cannot open external windows (e.g. if running R in terminal instead of RStudio, the container running R cannot open an X11 window to display plots. Instead, a user must do something like <code>ggsave()</code> after plotting interactively to view the resulting graphic in the native file browser. (This is more tedious in base graphics that need <code>dev.off()</code> etc.). Of course this is not an issue when using RStudio with linked volumes.</li>
</ul>
<h3 id="setup-2">Setup</h3>
<p>The key here is simply to link the working directory on the host to the file system on the container. That way any changes made to the host copy using the host OS tools are immediately available to the container, and vice versa. Setup requires a bit more effort on Windows at this time, though is natively supported for Mac in Docker 1.3. Some care may also be necessary not to change the permissions of the file. See details in the <a href="https://github.com/rocker-org/rocker/wiki/Shared-files-with-host-machine">rocker wiki on shared files</a></p>
<h4 id="aliases">aliases</h4>
<p>The most aggressive form of the integrated approach is to literally alias common commands like <code>R</code> or <code>rstudio</code> as the corresponding docker calls in <code>.bashrc</code>, e.g.</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">alias</span> R=<span class="st">&#39;docker run --rm -it --user docker -v $(pwd):/home/docker/`basename $PWD` -w /home/docker/`basename $PWD` rocker/hadleyverse R&#39;</span></code></pre>
<p>makes the command <code>R</code> launch an instance of the <code>rocker/hadleyverse</code> container sharing the current working directory. Clearly different containers could be substituted in place of <code>rocker/hadleyverse</code>, including custom extensions. This helps ensure that R is always run in the portable, Dockerized environment. Other than the lack of X11 display for plots, this works and feels identical to an interactive R terminal session.</p>
<h4 id="other-tweaks">Other tweaks</h4>
<p>Mac/Windows users might also want to customize <code>boot2docker</code>’s resources to make more of the host computer’s memory and processors available to Docker.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/11/03/three-interfaces-for-Docker.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

    <div class="row">
      
        <div class="col-md-3">
          <header><h4><a href="/2014/10/28/jekyll-free.html">Goodbye Jekyll?</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 28 Oct 2014</p>

<article>
<div class="excerpt">
<p>The great strength of Jekyll is in providing a really convenient HTML templating system through the <code>_layouts</code> and <code>_includes</code> directories and Liquid variables (including the auto-populated ones like <code>page.previous.url</code>).</p>
<p>For quickly deploying simple sites though, this is often unnecessary: one or two layout files will suffice, and an <code>_includes</code> directory is not so useful with only a single layout. The ease of maintenance by having a template divided into modular chunks is somewhat trumped by the greater simplicity of copying a single template or set of templates over into a new directory.</p>
<p>And deploying Jekyll could be easier, particularly with pandoc as the parser. Despite plugins that nicely let pandoc act just like the built-in parsers and a CI setup with Travis to support automated building of my site on push, setting these components up repeatedly on every new repository is a bit tedious. Occassional updates of Jekyll and related gems have also broken my build pipeline more than once, though this is less of an issue now that I’ve added bundler and a Gemfile to restrict gem versions and provide a Dockerized setup for local deploying. These things keep the overhead low for my main site, but are an overhead to replicate.</p>
<p>Meanwhile, I’ve found Pandoc’s templating system to be immensely powerful, particularly with the yaml headers now supported. To provide a lightweight way to deploy a website on a gh-pages branch of a new repository, I’ve found this system works quite well. I’ve illustrated this on my <a href="https://github.com/cboettig/tree/gh-pages">gh-pages branch of my template</a> repository. Previously, this used Jekyll with the built-in redcarpet markdown parser to deploy markdown files in a style consistent with my notebook.</p>
<p>Now, I’ve stripped this down to simply use a pandoc template, pandoc YAML, and a Makefile to accomplish much the same thing.</p>
<p>I was dissapointed to see that the <code>_output.yaml</code> used by rmarkdown for building multi-page websites did not leverage the generic <code>metadata.yaml</code> approach already built into pandoc. This prevents us specifying custom generic metadata the way one does in Jekyll with <code>_config.yaml</code>, as I describe in <a href="https://github.com/rstudio/rmarkdown/issues/297">rmarkdown#297</a> I can work around this with the Makefile by calling pandoc manually with the additional <code>metadta.yaml</code> file, as follows:</p>
<pre class="Make"><code>%.html: %.Rmd
  R --vanilla --slave -e &quot;knitr::knit(&#39;$&lt;&#39;)&quot;
  pandoc --template _layouts/default.html metadata.yaml -o $@ $(basename $&lt;).md
  rm $(basename $&lt;).md

%.html: %.md
  pandoc --template _layouts/default.html metadata.yaml -o $@ $&lt; 
</code></pre>
<p>Note the <code>Rmd</code> building is somewhat more cumbersome since we have to bypass <code>rmarkdown:render</code> for this to work.</p>
<p>I had to collapse all my <code>_includes</code> and nested <code>_layouts</code> into a single <code>layout</code>, replace the Jekyll Liquid blocks, <code>{{</code> with pandoc-template <code>$</code> ones, and write out a basic <code>metadata.yaml</code> file, and things are <a href="http://io.carlboettiger.info/template/">good to go</a>.</p>
<hr />
<p>Nonetheless, I sometimes wish I could break templates into more re-usable components; similar to the the way <code>_includes</code> provides re-usable components for the templates specified in the <code>_layouts</code> directory of a jekyll site.</p>
<p>My first thought was to simply add the re-usable elements into a metadata block itself. (This seemed particularly promising since we can already have an external metadata.yaml to provide a metadata block we can use across multiple file). However, it seems that Pandoc always escape the html contents in my yaml metadata. For instance, if I add the block:</p>
<pre><code>---
header: |
    &lt;header class=&quot;something&quot;&gt;&lt;h1&gt;$title$&lt;/h1&gt;&lt;/header&gt;
---</code></pre>
<p>and then in my template add <code>$header$</code>, I get the above block but with all the angle brackets escaped. I had thought since I have denoted this as a literal block with ‘|’ in the yaml I would get this block unaltered. How can I prevent pandoc from escaping the html? (I realize that still wouldn’t parse the <code>$title$</code> metadata, but that’s a separate issue).</p>
<p>The other approach I considered is to exploit the <code>--include-before-body</code> and <code>--include-after-body arguments</code>. While more limited since I am restricted to these two variables, this approach does allow me to specify a file with a re-usable component block and avoids the issue of HTML escaping observed above. Other than the limit of two such variables, the other limit to this approach is that metadata elements like <code>$title$</code> are processed only in templates, not in files.</p>
<p>It seems like pandoc is thus really close to being able to support templates that are made from re-usable blocks rather than completely specified from scratch, but not quite there. I realize pandoc isn’t trying to be a replacement for static website generation, but still feel that re-usable blocks would make the existing template system a bit more flexible and user-friendly.</p>
<p>Quite a few of pandoc’s current functions already approximate this behavior in a hard-wired fashion; e.g. <code>$highlight-css$</code> uses the <code>--highlight-style</code> option to select among a bunch of pre-defined highlight blocks. Thus I suspect pandoc might be easier to extend in the future if such features could just be added through an include mechanism rather than this hardwired approach.</p>
<p><em>See this as a query to <a href="https://groups.google.com/forum/#!topic/pandoc-discuss/pe63zLmNwtk">pandoc-discuss</a></em></p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/10/28/jekyll-free.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/10/21/docker-and-user-permissions-crazyness.html">Docker And User Permissions Crazyness</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 21 Oct 2014</p>

<article>
<div class="excerpt">
<p>Lots of crazyness getting to the bottom of permissions changes, as discussed in:</p>
<ul>
<li><a href="https://github.com/rocker-org/rocker/issues/50">rocker issues tracker</a></li>
<li><a href="http://stackoverflow.com/questions/26500270">Stackoverflow question</a></li>
<li><a href="https://groups.google.com/forum/#!topic/docker-user/VFdFuZ4Ze_A">Docker mailing list</a></li>
</ul>
<p>Long story short: docker cares only about UIDs, so we have to explicitly make sure these match. Some very good answers including from Docker core-team members on the discussion list. Overall approach outlined at the end of the rocker issues tracker.</p>
<p>Here’s the SO version of the question, for my reference:</p>
<hr />
<p>Consider the following trivial Dockerfile:</p>
<pre><code>FROM debian:testing
RUN  adduser --disabled-password --gecos &#39;&#39; docker
RUN  adduser --disabled-password --gecos &#39;&#39; bob </code></pre>
<p>in a working directory with nothing else. Build the docker image:</p>
<pre><code>docker build -t test .</code></pre>
<p>and then run a bash script on the container, linking the working directory into a new subdir on bob’s home directory:</p>
<pre><code>docker run --rm -it -v $(pwd):/home/bob/subdir test </code></pre>
<p>Who owns the contents of <code>subdir</code> on the container? On the container, run:</p>
<pre><code>cd /home/bob/subdir
ls -l</code></pre>
<p>ad we see:</p>
<pre><code>-rw-rw-r-- 1 docker docker 120 Oct 22 03:47 Dockerfile</code></pre>
<p>Holy smokes! <code>docker</code> owns the contents! Back on the host machine outside the container, we see that our original user still owns the <code>Dockerfile</code>. Let’s try and fix the ownership of <code>bob</code>’s home directory. On the container, run:</p>
<pre><code>chown -R bob:bob /home/bob
ls -l </code></pre>
<p>and we see:</p>
<pre><code>-rw-rw-r-- 1 bob bob 120 Oct 22 03:47 Dockerfile</code></pre>
<p>But wait! outside the container, we now run <code>ls -l</code></p>
<pre><code>-rw-rw-r-- 1 1001 1001 120 Oct 21 20:47 Dockerfile</code></pre>
<p>we no longer own our own file. Terrible news!</p>
<hr />
<p>If we had only added one user in the above example, everything would have gone more smoothly. For some reason, Docker seems to be making any home directory owned by the <em>first</em> non-root user it encounters (even if that user is declared on an earlier image). Likewise, this <em>first</em> user is the one that corresponds to the same ownership permissions as my home user.</p>
<p><strong>Question 1</strong> Is that correct? Can someone point me to documentation of this, I’m just conjecturing based on the above experiment.</p>
<p><strong>Question 2</strong>: Perhaps this is just because they both have the same numerical value on the kernel, and if I tested on a system where my home user was not id <code>1000</code> then permissions would get changed in every case?</p>
<p><strong>Question 3</strong>: The real question is, of course, ‘what do I do about this?’ If <code>bob</code> is logged in as <code>bob</code> on the given host machine, he should be able to run the container as <code>bob</code> and not have file permissions altered under his host account. As it stands, he actually needs to run the container as user <code>docker</code> to avoid having his account altered.</p>
<p>I hear you asking <em>Why do I have such a weird Dockerfile anyway?</em>. I wonder too sometimes. I am writing a container for a webapp (RStudio-server) that permits different users to log in, which simply uses the user names and credentials from the linux machine as the valid user names. This brings me the perhaps unusual motivation of wanting to create multiple users. I can get around this by creating the user only at runtime and everthing is fine. However, I use a base image that has added a single <code>docker</code> user so that it can be used interactively without running as root (as per best practice). This ruins everything since that user becomes the <em>first</em> user and ends up owning everything, so attempts to log on as other users fail (the app cannot start because it lacks write permissions). Having the startup script run <code>chown</code> first solves this issue, but at the cost of linked volumes changing permissions (obviously only a problem if we are linking volumes).</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/10/21/docker-and-user-permissions-crazyness.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/10/20/notes.html">Notes</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 20 Oct 2014</p>

<article>
<div class="excerpt">
<p>Keep thinking about this quote from Jeroen Oom’s <a href="http://arxiv.org/abs/1406.4806">recent piece on the arxiv</a>:</p>
<blockquote>
<p>The role and shape of data is the main characteristic that distinguishes scientific computing. In most general purpose programming languages, data structures are instances of classes with well-defined fields and methods. […] Strictly defined structures make it possible to write code implementing all required operations in advance without knowing the actual content of the data. <em>It also creates a clear separation between developers and users</em> [emphasis added]. Most applications do not give users direct access to raw data. Developers focus in implementing code and designing data structures, whereas users merely get to execute a limited set of operations.</p>
</blockquote>
<blockquote>
<p>This paradigm does not work for scientific computing. Developers of statistical software have relatively little control over the structure, content, and quality of the data. Data analysis starts with the user supplying a dataset, which is rarely pretty. Real world data come in all shapes and formats. They are messy, have inconsistent structures, and invisible numeric properties. Therefore statistical programming languages define data structures relatively loosely and instead implement a rich lexicon for interactively manipulating and testing the data. Unlike software operating on well-defined data structures, it is nearly impossible to write code that accounts for any scenario and will work for every possible dataset. Many functions are not applicable to every instance of a particular class, or might behave differently based on dynamic properties such as size or dimensionality. <em>For these reasons there is also less clear of a separation between developers and users in scientific computing.</em> The data analysis process involves simultaneously debugging of code and data where the user iterates back and forth between manipulating and analyzing the data. Implementations of statistical methods tend to be very flexible with many parameters and settings to specify behavior for the broad range of possible data. And still the user might have to go through many steps of cleaning and reshaping to give data the appropriate structure and properties to perform a particular analysis.</p>
</blockquote>
<p>Good inspiration for this week’s assignment:</p>
<h2 id="notes-for-swc-training-short-motivational-pitch-on-r">Notes for SWC training: short motivational pitch on R</h2>
<blockquote>
<p>What’s the difference between a novice programmer and a professional programmer?<br />The novice pauses a moment before doing something stupid.</p>
</blockquote>
<p>In this course, we’ll be learning about the R programming environment. You may already have heard of R or have used it before.</p>
<p>It’s the number one language for statistical programming. It’s used by most major companies, putting these skills in high demand.</p>
<p>Recently DICE Magazine showed that programmers with expertise in R topped the tech survey salary charts (at $115,531, above Hadoop, MapReduce, C, or Cloud, mobile or UI/UX design).</p>
<p>You may not (always) like the R programming environment. The syntax is often challenging, it can do counterintuitive things, and it’s terrible at mind reading.</p>
<p>Try not to take this out on your hardware. Hardware is expensive.</p>
<p>R’s strength lies in data.</p>
<p>No other major language has key statistical concepts like ‘missing data’ baked in at the lowest level.</p>
<p>We will not be approaching R as a series of recipes to perform predifined tasks.</p>
<p>In scientific research we can seldom predict just what our data will look like in advance or what our analysis will require. This makes it impossible to always rely on pre-made software and graphical interfaces you may be familar with, and blurs the lines between <em>users</em> <em>developers</em>. Unlike other languages such as C, Java or Python that are often used to build ‘end-user’ software in which the underlying language is completely invisible, R does not make this distnction. R gives a lto of power to the end user. And with great power comes great responsibility.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/10/20/notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

  </div>
</div> <!--end row -->

<div class="row socialicons">
  <div class="col-md-11 col-md-offset-1">
      <p> <a href="/archive.html"><i class="icon-calendar"></i> All entries by date</a></p> 
      <p> <a href="/categories.html"><i class="icon-list"></i> All entries by category</a> </p>
      <p> <a href="/tags.html"><i class="icon-tags"></i> All entries by tag</a> </p>
  </div> <!--end col-md-9 -->
</div> <!--end row -->




      <footer class="footer">

<!--************** FOAF information to social networks ***************************** -->
  <div class="row">
    <div class="col-md-3 col-xs-4 socialicons" style="font-size:20px" typeof="foaf:Person" about="http://www.carlboettiger.info#me">
      <p>
          <script type="text/javascript" src="/assets/js/obfuscate-email-link.js"></script> 

          <a rel="foaf:account" href="https://twitter.com/cboettig" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Twitter'); 
             return false;"><span class="showtooltip" title="follow me on twitter (reading, discussing)"><i class="fa fa-twitter"></i></span></a> 

          <a rel="foaf:account" href="https://github.com/cboettig" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Github'); 
             return false;"><span class="showtooltip" title="follow me on Github (code, research)"><i class="fa fa-github"></i></span></a>
      <!--
          <a rel="foaf:account" href="https://plus.google.com/" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'GPlus'); 
             return false;"><i class="fa fa-google-plus"></i></a>

          <a rel="foaf:account" href="http://www.mendeley.com/profiles/carl-boettiger" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Mendeley'); 
             return false;"><img src="/assets/img/icon-mendeley.png" /></a> 

           citations on google-scholar

           stackoverflow
      -->
      <a rel="foaf:weblog" type="application/atom+xml" href="/blog.xml"  
         class="showtooltip" title="RSS feeds for my blog-style entries. See the feed on my lab notebook (/atom.xml) to follow all entries instead." 
         onclick="recordOutboundLink(this, 'Outbound Links', 'RSS'); 
         return false;"><i class="fa fa-rss"></i></a>
       </p>
    </div>

    
    <!--**************** End social links **************************** -->


    <div class="col-md-4 col-md-offset-1 col-xs-4">
      <p><a onclick="recordOutboundLink(this, 'Outbound Links', 'ONS_claim'); return false;" href="http://onsclaims.wikispaces.com/"><img src="/assets/img/ons-aci2-icon.svg" alt="ONS" class="showtooltip" title="An Open Notebook Science (ONS) project claim: Entry provides all content (AC) immediately (I) or without significant delay.  See link for details"/></a></p>
    </div>


    <div class="col-md-3 col-md-offset-1 col-xs-4">
      <p>
      <a rel="license" property="http://creativecommons.org/ns#license" href="http://creativecommons.org/publicdomain/zero/1.0/" onclick="recordOutboundLink(this, 'Outbound Links', 'CC0'); return false;"><img src="/assets/img/cc-zero.svg" alt="CC0"/></a> 
      </p>
    </div>
  </div>


  
<!-- COinS metadata (for citation managers like Zotero etc), goes in body text -->
  <span
      class="Z3988" 
      title="ctx_ver=Z39.88-2004
      &amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc
      &amp;rfr_id=info%3Asid%2Focoins.info%3Agenerator
      &amp;rft.title=Lab Notebook
      &amp;rft.creator=Carl Boettiger
      &amp;rft.date=
      &amp;rft.language=EN
      &amp;rft.rights=CC0
      &amp;rft_id=http://www.carlboettiger.info/lab-notebook.html">
  </span>


</footer>




          <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->

    <!-- JQuery, used on a few pages (still?) -->
    <!-- <script type="text/javascript" src="/assets/js/jquery.js"></script> -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <!-- Equations using MathJax -->
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "all"} } });       </script>
    <!-- Twitter Bootstrap Javascript -->
    <!--  <script src="/assets/js/bootstrap.min.js"></script> -->
    <script src="//netdna.bootstrapcdn.com/bootstrap/3.1.1/js/bootstrap.min.js"></script>


    

        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-18401403-1']);
          _gaq.push(['_trackPageview']);
          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
  </script>



<script type="text/javascript">
function recordOutboundLink(link, category, action) {
  try {
    var pageTracker=_gat._getTracker("UA-18401403-1");
    pageTracker._trackEvent(category, action);
    setTimeout('document.location = "' + link.href + '"', 100)
  }catch(err){}
}
</script>




    </div>
  </body>
</html>
   
