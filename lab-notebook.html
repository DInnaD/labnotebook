<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  <head prefix="dc: http://purl.org/dc/terms/ og: http://ogp.me/ns#"> <!-- namespaces used in metadata.html -->
  <meta http-equiv='Content-Type' content='text/html; charset=utf-8'/>
  <title>Lab Notebook</title>
  <meta name="author" content="Carl Boettiger" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <!-- HTML5 metadata -->
<meta name="keywords" content="" />
<meta name="description" content="" />
<!-- RDFa Metadata (in DublinCore) -->
<meta property="dc:title" content="Lab Notebook" />
<meta property="dc:creator" content="Carl Boettiger" />
<meta property="dc:date" content="" />
<meta property="dc:format" content="text/html" />
<meta property="dc:language" content="en" />
<meta property="dc:identifier" content="/lab-notebook.html" />
<meta property="dc:rights" content="CC0" />
<meta property="dc:source" content="Lab Notebook" />
<meta property="dc:subject" content="Ecology" /> 
<meta property="dc:type" content="website" /> 
<!-- RDFa Metadata (in OpenGraph) -->
<meta property="og:title" content="Lab Notebook" />
<meta property="og:author" content="http://www.carlboettiger.info/index.html#me" />  <!-- Should be Liquid? URI? -->
<meta property="http://ogp.me/ns/profile#first_name" content="Carl"/>
<meta property="http://ogp.me/ns/profile#last_name" content="Boettiger"/>
<meta property="http://ogp.me/ns/article#published_time" content="" />
<meta property="og:site_name" content="Lab Notebook" /> <!-- Same as dc:source? -->
<meta property="og:url" content="http://www.carlboettiger.info/lab-notebook.html" />
<meta property="og:type" content="website" /> 
<!-- Google Scholar Metadata -->
<!--
<meta name="citation_author" content="Carl Boettiger"/>
<meta name="citation_date" content=""/>
<meta name="citation_title" content="Lab Notebook"/>
<meta name="citation_journal_title" content="Lab Notebook"/>
-->
<!--NOTE: see also the COinS Metadata in span element in footer -->




  <link href="/assets/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
  <!-- Help the browser identify the RSS feed automatically -->
  <link rel="alternate" type="application/rss+xml" title="Carl Boettiger's Lab Notebook" href="/blog.xml" />
</head>


  <body prefix="dc: http://purl.org/dc/terms/ foaf: http://xmlns.com/foaf/0.1/"> 
    <!-- Navbar  ================================================== -->

<nav class="navbar navbar-default" role="navigation">
  <div class="container-fluid">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/README.html"><i class="icon-info-sign"></i></a>
    </div>

 <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">

          <li  >
          <a href="/index.html">Home</a></li>
          <li  >
          <a href="/vita.html">Vita</a></li>
          <li  >
          <a href="/research.html">Research</a></li>
          <li  >
          <a href="/teaching.html">Teaching</a></li>
          <li  >
          <a href="/community.html">Community</a></li>
          <li  class="active" >
          <a href="/lab-notebook.html">Lab Notebook</a></li>

        </ul>

      <!-- Search site using Google's index -->
        <form class="navbar-form navbar-right" role="search" method="get" action="http://google.com/search">
          <div class="form-group">
            <input type="hidden" name="q" value="site:carlboettiger.info" />
            <input type="text" class="form-control search-query" name="q" placeholder="Search"/>
          </div>
          <button class="btn btn-mini" type="submit"><i class="icon-search"></i></button> 
       </form>

    </div><!--/.nav-collapse -->
  </div> <!-- /container -->
</nav>



    <div class="container"> <!-- Responsive grid layout, doesn't jump to full-width --> 
      <header>
        <h1 class="entry-title">Lab Notebook</h1>
        <h2>(<a href="http://www.carlboettiger.info/2012/09/28/Welcome-to-my-lab-notebook.html">Introduction</a>)</h2>
      </header>

      <div class="row feed">
  <div class="col-md-3 col-md-offset-1">
    <h4>  <a property="account" href="https://github.com/cboettig" onclick="recordOutboundLink(this, 'Outbound Links', 'Github'); return false;"><i class="icon-github" alt="github"></i> Coding </a></h4> 
    <div class="excerpt">
      <div class="scroll">
        <ul><li>cboettig created repository cboettig/notes: <em></em> <a href="https://github.com/cboettig/notes">06:08 2014/12/07</a></li><li>cboettig pushed to master at cboettig/labnotebook: <em>draft explore draft lsn</em> <a href="https://github.com/cboettig/labnotebook/compare/fe206e5e3f...5fbe55e6e3">06:02 2014/12/07</a></li><li>cboettig released v2.0.0 at ropensci/RNeXML: <em></em> <a href="https://github.com/ropensci/RNeXML/releases/tag/v2.0.0">09:56 2014/12/06</a></li><li>cboettig created tag v2.0.0 at ropensci/RNeXML: <em></em> <a href="https://github.com/ropensci/RNeXML/tree/v2.0.0">09:55 2014/12/06</a></li><li>cboettig pushed to master at ropensci/RNeXML: <em>formatting tweaks for 2.0.0</em> <a href="https://github.com/ropensci/RNeXML/compare/853324db9b...d2cfba00a7">09:53 2014/12/06</a></li></ul>
      </div>
    </div>
  </div>
  <div class="col-md-3">
    <h4> <a property="account" href="https://twitter.com/cboettig" onclick="recordOutboundLink(this, 'Outbound Links', 'Twitter'); return false;"><i class="icon-twitter"></i> Discussing </a></h4> 
     <div class="excerpt">
      <div class="scroll">
       <ul><li><p>Some excellent investigative journalism on compliance with open data polices from @Richvn + @TimHVines in @Nature <a href="http://t.co/0bCybpZRYz">http://t.co/0bCybpZRYz</a></p>
 <a href="http://twitter.com/cboettig/statuses/540273123070058496">10:35 2014/12/03</a> </li><li><p>Wow, all kinds of great discussions on #ReproducilbeResearch breaking out in advance of our gathering next week: <a href="https://t.co/Q4puZu0G71">https://t.co/Q4puZu0G71</a></p>
 <a href="http://twitter.com/cboettig/statuses/540236836376178688">08:11 2014/12/03</a> </li><li><p>RT @recology_: [Blog] How do I import data and do stuff w/ taxonomic names in #rstats taxize?   <a href="http://t.co/erCamVgzBp">http://t.co/erCamVgzBp</a></p>
 <a href="http://twitter.com/cboettig/statuses/539832474281320448">05:24 2014/12/02</a> </li><li><p>RT @sean_tuck: MODISTools – downloading and processing MODIS remotely sensed data in R <a href="http://t.co/mLPuLma7Vb">http://t.co/mLPuLma7Vb</a> #shamelessSelfPromotion @hele…</p>
 <a href="http://twitter.com/cboettig/statuses/539832199378264064">05:23 2014/12/02</a> </li><li><p>RT @BrunaLab: Deadline soon! All systems/species welcome (yes, even plants). Faculty position in Global Change Ecology <a href="http://t.co/x8jxC2Wb%E2%80%A6">http://t.co/x8jxC2Wb…</a></p>
 <a href="http://twitter.com/cboettig/statuses/539829444727144450">05:12 2014/12/02</a> </li></ul>
      </div>
    </div> 
  </div> 
  <div class="col-md-3">
    <h4> <a href="http://www.mendeley.com/groups/634301/theoretical-ecology/papers/" onClick="recordOutboundLink(this, 'Outbound Links', 'Mendeley'); return false;"><i class="icon-book"></i> Reading </a></h4> 
    <div class="excerpt">
      <div class="scroll">
<ul><li>Assessing trade-offs to inform ecosystem-based fisheries management of forage fish.: Scientific reports (2014). Pages: 7110. Andrew Olaf Shelton, Jameal F Samhouri, Adrian C Stier, Philip S Levin et al. <a href="http://www.mendeley.com/c/7393588154/g/634301/shelton-2014-assessing-trade-offs-to-inform-ecosystem-based-fisheries-management-of-forage-fish/">07:08 2014/11/25</a></li><li>The Southern Kalahari: a potential new dust source in the Southern Hemisphere?: Environmental Research Letters (2012). Volume: 7, Issue: 2. Pages: 024001. Abinash Bhattachan, Paolo D’Odorico, Matthew C Baddock, Ted M Zobeck, Gregory S Okin, Nicolas Cassar et al. <a href="http://www.mendeley.com/c/7318874474/g/634301/bhattachan-2012-the-southern-kalahari-a-potential-new-dust-source-in-the-southern-hemisphere/">11:45 2014/11/04</a></li><li>Resilience and recovery potential of duneland vegetation in the southern Kalahari: Ecosphere (2014). Volume: 5, Issue: January. Pages: 1-14. A Bhattachan, P D'Odorico, K Dintwe et al. <a href="http://www.mendeley.com/c/7318874484/g/634301/bhattachan-2014-resilience-and-recovery-potential-of-duneland-vegetation-in-the-southern-kalahari/">11:45 2014/11/04</a></li><li>Potential dust emissions from the southern Kalahari's dunelands: Journal of Geophysical Research: Earth Surface (2013). Volume: 118, Issue: 1. Pages: 307-314. Abinash Bhattachan, Paolo D'Odorico, Gregory S. Okin, Kebonyethata Dintwe et al. <a href="http://www.mendeley.com/c/7318874504/g/634301/bhattachan-2013-potential-dust-emissions-from-the-southern-kalaharis-dunelands/">11:45 2014/11/04</a></li></ul>
      </div>
    </div>
  </div> 
</div>

<hr>
<div class="row postpreview">
  <div class="col-md-11 col-md-offset-1">
    <div class="row">
      <h4> <a href="http://www.carlboettiger.info/atom.xml"
              onClick="recordOutboundLink(this,
              'Outbound Links', 'RSS'); return false;"
              style="color: inherit;"
              ><i class="icon-rss" ></i> Entries</a></h4>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/11/26/coreos-cluster-gotchas.html">Coreos Cluster Gotchas</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 26 Nov 2014</p>

<article>
<div class="excerpt">
<p>Overall impression is that CoreOS is a promising way to easily set up a highly available cluster (e.g. when most important thing is that a service stays up when a node goes down) since it can migrate a containerized app to a new machine rather than having to already have the same app running on all machines. Either way a load-balancer needs to handle the addressing, which is do-able but somewhat tricky.</p>
<p>Less useful in the role of a simple server; as admin on the base system is somewhat more limited (e.g. network stats, NFS sharing, etc), and more pointedly I seem to continually run afoul of stability issues in Fleet when cluster changes size, with no way to recover without destroying and relaunching the entire cluster.</p>
<p>The most compelling features for me, the automated updating and the restarting containers on system reboot, can be replicated rather straight forwardly on a normal distribution.</p>
<p>Fleet cannot pick a leader in a cluster of size 2 (no majority) and fails when CoreOS loses a majority. A cluster of size 3 can replace 1 node, but if 2 nodes fail, the cluster is hosed. See <a href="https://coreos.com/docs/cluster-management/scaling/etcd-optimal-cluster-size/">optimal cluster size</a> and <a href="https://github.com/coreos/etcd/issues/863#issuecomment-60523183">etcd/issues/863</a>. Rescaling may assign the new node a new address, and the majority must approve the new peer. If there’s not a majority available (e.g. cluster goes from 3 to 1) you’re stuck.</p>
<p>In the etcd &gt; 0.5.0 (alpha channel now methinks) some recovery is possible, see: <a href="https://github.com/coreos/etcd/issues/1242">etcd/issues/1242</a></p>
<p>On Amazon, CoreOS provides ability to launch an AWS auto-scaling group as a CloudFormation configuration, which can set a minimum cluster size and always restart when a node goes down. Setting the minumum below 3 results in an invalid cluster (failed etcd connection due to lacking majority) and needs to be destroyed. Need to destroy the autoscaling group, cannot simply remove instances (since they will be regenerated). Also remember to adjust the security groups to set outside access for the appropriate service ports.</p>
<p>Persistant URL address is challenging when nodes keep changing. If one node is guarenteed to be up, we can have it run the nginx load balancer to redirect to the other nodes (using toml nginx templates).</p>
<hr />
<h3 id="coreos-docker-part-ways">CoreOS &amp; Docker part ways?</h3>
<p>Update: and <a href="https://coreos.com/blog/rocket/">now it seems CoreOS isn’t happy with Docker and seeks to invent their own runtime</a>… time will tell if it gets critical mass to be viable, but doesn’t seem like it is well aligned with my own use cases of quickly deploying basic services (RStudio, Gitlab, Drone, Docker Registry).</p>
<p>Also, lots of competition/ecosystem for container orchistration alternatives to fleet/CoreOS, though the use case for many of these isn’t entirely clear for my needs. In particular, see:</p>
<ul>
<li><a href="http://aws.amazon.com/ecs/">Amazon’s container service</a></li>
<li><a href="https://github.com/GoogleCloudPlatform/kubernetes">Google’s container service</a></li>
<li>and of course, Docker’s own fig.org.</li>
</ul>
<p>Again all seem to emphasize more the stable, complex service model in the cloud and aren’t really necesary for the portable research software dev model.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/11/26/coreos-cluster-gotchas.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/11/24/coreos-docker-registries-etc.html">Coreos Docker Registries Etc</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 24 Nov 2014</p>

<article>
<div class="excerpt">
<h2 id="a-secure-docker-registry">A secure docker registry</h2>
<p>Running one’s own docker registry is far more elegant than moving tarballs between machines (e.g. when migrating between servers, particularly for images that may contain sensitive data such as security credentials). While it’s super convenient to have a containerized version of the Docker registry ready for action, it doesn’t do much good without putting it behind an HTTPS server (otherwise we have to restart our entire docker service with the insecure flag to permit communication with an unauthenticated registry – doesn’t sound like a good idea). So this meant learning how to use <code>nginx</code> load balancing, which I guess is useful to know more generally.</p>
<h3 id="first-pass-nginx-on-ubuntu-server">First pass: nginx on ubuntu server</h3>
<p>After a few false starts, decided the <a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-a-private-docker-registry-on-ubuntu-14-04">digitalocean guide</a> is easily the best (though steps 1-3 can be skipped by using a containerized <code>registry</code> instead). This runs <code>nginx</code> directly from the host OS, which is in some ways more straight forward but less portable. A few notes-to-self in working through the tutorial:</p>
<ul>
<li><p>Note: At first, nginx refuses to run because there’s was <code>default</code> configuration in <code>cd /etc/nginx/sites-enabled</code> that tries to create a conflict. Remove this and things go pretty nicely.</p></li>
<li><p>Note: Running the registry container explicitly on port <code>127.0.0.1</code> provides an internal-only port that we can then point to from nginx. (Actually this will no longer matter when we use a containerized <code>nginx</code>, since we will simply not export these ports at all, but only expose the port of the <code>nginx</code> load balancer). Still, good to finally be aware of the difference between <code>127.0.0.1</code> and <code>0.0.0.0</code> (the publicly visible localhost, and the default if we supply only a port) in this context.</p></li>
<li><p>Note: Running and configuring <code>nginx</code> Note that keys are specific to the url. This is necessary for the server signing request, but I believe could have been omitted in the root certificate. Here’s how w ego about creating a root key and certificate (<code>crt</code>), a server key, server signing request (<code>csr</code>), and then sign the latter with the former to get the server certificate.</p></li>
</ul>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">openssl</span> genrsa -out dockerCA.key 2048
<span class="kw">openssl</span> req -x509 -new -nodes -key dockerCA.key -days 10000 -out dockerCA.crt -subj <span class="st">&#39;/C=US/ST=Oregon/L=Portland/CN=coreos.carlboettiger.info&#39;</span>
<span class="kw">openssl</span> genrsa -out docker-registry.key 2048
<span class="kw">openssl</span> req -new -key docker-registry.key -out docker-registry.csr -subj <span class="st">&#39;/C=US/ST=Oregon/L=Portland/CN=coreos.carlboettiger.info&#39;</span>
<span class="kw">openssl</span> x509 -req -in docker-registry.csr -CA dockerCA.crt -CAkey dockerCA.key -CAcreateserial -out docker-registry.crt -days 10000</code></pre>
<p>Note that we also need the <code>htpasswd</code> file from above, which needs <code>apache2-utils</code> and so cannot be generated directly from the CoreOS terminal (though the <code>openssl</code> certs can):</p>
<pre><code>sudo htpasswd -bc /etc/nginx/docker-registry.htpasswd $USERNAME $PASSWORD</code></pre>
<p>Having created these ahead of time, I end up just copying my keys into the Dockerfile for my <code>nginx</code> instance (if we generated them on the container, we’d still need to get <code>dockerCA.crt</code> off the container to authenticate the client machines. Makes for a simple Dockerfile that we then build locally:</p>
<pre><code>FROM ubuntu:14.04
RUN apt-get update &amp;&amp; apt-get install -y apache2-utils curl nginx openssl supervisor
COPY docker-registry /etc/nginx/sites-available/docker-registry
RUN ln -s /etc/nginx/sites-available/docker-registry /etc/nginx/sites-enabled/docker-registry

## Copy over certificates ##
COPY docker-registry.crt /etc/ssl/certs/docker-registry 
COPY docker-registry.key /etc/ssl/private/docker-registry 
COPY docker-registry.htpasswd /etc/nginx/docker-registry.htpasswd


EXPOSE 8080

## use supervisord to persist
COPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf
CMD [&quot;/usr/bin/supervisord&quot;]</code></pre>
<p>Note that we need to install the <code>dockerCA.crt</code> certificate on any client that wants to access the private registry. On Ubuntu this looks like:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">sudo</span> mkdir /usr/local/share/ca-certificates/docker-dev-cert
<span class="kw">sudo</span> cp devdockerCA.crt /usr/local/share/ca-certificates/docker-dev-cert
<span class="kw">sudo</span> update-ca-certificates 
<span class="kw">sudo</span> service docker restart</code></pre>
<p>But on CoreOS we use a different directory (and restarting the docker service doesn’t seem possible or necessary):</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">sudo</span> cp dockerCA.crt /etc/ssl/certs/docker-cert
<span class="kw">sudo</span> update-ca-certificates  </code></pre>
<ul>
<li><p>Note: Could not get the official <code>nginx</code> container to run the <code>docker-registry</code> config file as <code>/etc/nginx/nginx.conf</code>, either with or without adding <code>daemon off;</code> at the top of <code>/etc/nginx/nginx.conf</code>. With, it complains this is a duplicate, (despite being recommended on the <a href="https://registry.hub.docker.com/_/nginx">nginx container documentation</a>, though admittedly this already appears in the default command <code>[&quot;nginx&quot; &quot;-g&quot; &quot;daemon off;&quot;]</code>). Without, the error says that <code>upstream</code> directive is not allowed here. Not sure what to make of these errors, ended up running an ubuntu container and then just installing <code>nginx</code> etc following the digitalocean guide. Ended up dropping the <code>daemon off;</code> from the config file and running <code>service nginx start</code> through <code>supervisord</code> to ensure that the container stays up. Oh well.</p></li>
<li><p>Note: I got a 502 error when calling <code>curl</code> against the the <code>nginx</code> container-provided URL (with or without SSL enabled), since from inside the <code>nginx</code> container we cannot access the host addresses. The simplest solution is to add <code>--net=&quot;host&quot;</code> when we <code>docker run</code> the <code>nginx</code> container, but this isn’t particularly secure. Instead, we’ll link directly to the ports of the <code>registry</code> container like this:</p></li>
</ul>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">docker</span> run  --name=registry -p 8080:8080 registry
<span class="kw">docker</span> run --name=nginx --net=container:registry nginx</code></pre>
<p>Note that we do not need to export the registry port (e.g. <code>-p 5000:5000</code>) at all, but we do need to export the <code>nginx</code> load-balancer port <em>from the <code>registry</code> container</em> first, since we will simply be linking it’s network with the special <code>--net=container:registry</code>.</p>
<p>Note that we would probably want to link a local directory to provide persistent storage for the <code>registry</code>; in the above example images committed to registry are lost when the container is destroyed.</p>
<p>We can now log in:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">docker</span> login https://<span class="kw">&lt;</span>YOUR-DOMAIN<span class="kw">&gt;</span>:8080</code></pre>
<p>We can now reference our private registry by using its full address in the namespace of the image in commands to <code>docker pull</code>, <code>push</code>, <code>run</code> etc.</p>
<h2 id="migrating-gitlab-between-servers">Migrating gitlab between servers</h2>
<p>This migration was my original motivation to configure the private docker registry; ironically it isn’t necessary for this case (though it’s useful for the drone image, for instance).</p>
<p>Note that there is no need to migrate the redis and postgresql containers manually. Migrating the backup file over to the corresponding location in the linked volume and then running the backup-restore is sufficient. Upgrading is also surprisingly smooth; we can backup (just in case), then stop and remove the container (leaving the <code>redis</code> and <code>postgresql</code> containers running), pull and relaunch with otherwise matched option arguments and the upgrade runs automatically.</p>
<p>When first launching the <code>gitlab</code> container on a tiny droplet running coreos, my droplet seems invariably to hang. Rebooting from the digitalocean terminal seems to fix this. A nice feature of <code>fleet</code> is that all the containers are restarted automatically after reboot, unlike when running these directly from <code>docker</code> on my ubuntu machine.</p>
<h2 id="notes-on-fleet-unit-files">Notes on fleet unit files</h2>
<p>Fleet unit files are actually pretty handy and straight forward. One trick is that we must quote commands in which we want to make use of environmental variables. For instance, one must write:</p>
<pre><code>Environment=&quot;VERSION=1.0&quot;
ExecStart=/bin/bash -c &quot;/usr/bin/docker run image:${VERSION}&quot;</code></pre>
<p>in a <code>Service</code> block, rather than <code>ExecStart=/usr/bin/docker run ...</code> directly, for the substitution to work. It seems if we are using the more standard practice of environment files (which after all is the necessary approach to avoid having to edit the unit file directly one way or another anyway), we can avoid the <code>bin/bash</code> wrapper and insert the environment reference directly.</p>
<p>If we’re not doing anything fancy wrt load balancing between different servers, we don’t have that much use for the corresponding “sidekick” unit files that keep our global <code>etcd</code> registry up to date. Perhaps these will see more use later.</p>
<h2 id="cloud-config">Cloud-config</h2>
<p>Note that we need to refresh the discovery url pretty-much anytime we completely destroy the cluster.</p>
<p>A few edits to my cloud-config to handle initiating swap, essential for running most things (gitlab, rstudio) on tiny droplets. Still requires one manual reboot for the allocation to take effect. Adds this to the <code>units</code> section of <code>#cloud-config</code>:</p>
<pre><code>    ## Configure SWAP as per https://github.com/coreos/docs/issues/52
    - name: swap.service
      command: start
      content: |
        [Unit]
        Description=Turn on swap

        [Service]
        Type=oneshot
        Environment=&quot;SWAPFILE=/1GiB.swap&quot;
        RemainAfterExit=true
        ExecStartPre=/usr/sbin/losetup -f ${SWAPFILE}
        ExecStart=/usr/bin/sh -c &quot;/sbin/swapon $(/usr/sbin/losetup -j ${SWAPFILE} | /usr/bin/cut -d : -f 1)&quot;
        ExecStop=/usr/bin/sh -c &quot;/sbin/swapoff $(/usr/sbin/losetup -j ${SWAPFILE} | /usr/bin/cut -d : -f 1)&quot;
        ExecStopPost=/usr/bin/sh -c &quot;/usr/sbin/losetup -d $(/usr/sbin/losetup -j ${SWAPFILE} | /usr/bin/cut -d : -f 1)&quot;

        [Install]
        WantedBy=local.target

    - name: swapalloc.service
      command: start
      content: |
        [Unit]
        Description=Allocate swap

        [Service]
        Type=oneshot
        ExecStart=/bin/sh -c &quot;sudo fallocate -l 1024m /1GiB.swap &amp;&amp; sudo chmod 600 /1GiB.swap &amp;&amp; sudo chattr +C /1GiB.swap &amp;&amp; sudo mkswap /1GiB.swap&quot;
</code></pre>
<p>More probably be structured more elegantly, but it works. (Not much luck trying to tweak this into a bunch of <code>ExecStartPre</code> commands though.</p>
<h2 id="nfs-sharing-on-coreos">NFS sharing on CoreOS?</h2>
<p>Couldn’t figure this one out. <a href="http://serverfault.com/questions/647014/share-disks-through-nfs-on-a-coreos-cluster">My SO Q here</a></p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/11/24/coreos-docker-registries-etc.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/11/19/coreos-and-other-infrastructure-notes.html">Coreos And Other Infrastructure Notes</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 19 Nov 2014</p>

<article>
<div class="excerpt">
<h2 id="coreos">CoreOS?</h2>
<p>Security model looks excellent. Some things not so clear:</p>
<ul>
<li><p>In a single node setup, what happens with updates? Would containers being run directly come down and not go back up automatically? In general, how effective or troublesome is it to run a single, low-demand app on a single node CoreOS rather than, say, an ubuntu image (e.g. just to benefit from the security updates model)? For instance, would an update cause a running app to exit in this scenario? (Say, if the container is launched directly with <code>docker</code> and not through <code>fleet</code>?) (Documentation merely notes that cluster allocation / fleet algorithm is fastest with between 3 &amp; 9 nodes).</p></li>
<li><p>If I have a heterogenous cluster with one more powerful compute node, is there a way to direct that certain apps are run on that node and that other apps are not?</p></li>
<li><p>Looks like one needs a load-balancer to provide a consistent IP for containers that might be running on any node of the cluster?</p></li>
<li><p><a href="https://github.com/coreos/docs/issues/52">Enabling swap</a>. Works, but is there a way to do this completely in <code>cloud-config</code>?</p></li>
</ul>
<h2 id="setting-up-my-domain-names-for-digitalocean">Setting up my domain names for DigitalOcean</h2>
<p>In Dreamhost DNS management:</p>
<ul>
<li>I have my top-level domain registered through Dreamhost, uses dreamhost’s nameservers.</li>
<li>A-level entry for top level domain points to (the new) Github domain IP address</li>
<li>Have CNAME entries for <code>www</code> and <code>io</code> pointing to <code>cboettig.github.io</code></li>
</ul>
<p><strong>First step</strong></p>
<ul>
<li>Add an A-level entry, <code>server.carlboettiger.info</code>, pointing to DigitalOcean server IP</li>
</ul>
<p>Then go over to DigitalOcean panel.</p>
<p>From DigitalOcean DNS management:</p>
<ul>
<li>add new (A level) DNS entry as <code>server.carlboettiger.info</code> pointing to DO server IP</li>
<li>Delete the existing three NS entries <code>ns1.digitalocean.com</code> etc.</li>
<li>Add three new NS entries using <code>ns1.dreamhost.com</code> etc</li>
</ul>
<p>Things should be good to go!</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/11/19/coreos-and-other-infrastructure-notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

    <div class="row">
      
        <div class="col-md-3">
          <header><h4><a href="/2014/11/17/wssspe-feedback.html">Wssspe Feedback</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 17 Nov 2014</p>

<article>
<div class="excerpt">
<h3 id="wssspe-working-groups-reproducibility-reuse-and-sharing-neil-che-hong">WSSSPE working groups: Reproducibility, Reuse, and Sharing (Neil Che Hong)</h3>
<p>Our group focused on journal policies regarding software papers. Our objectives were:</p>
<ul>
<li><p>A Survey of journals that publish software papers. The Software Sustainability Institute already maintains <a href="http://www.software.ac.uk/resources/guides/which-journals-should-i-publish-my-software">a list</a></p></li>
<li><p>A summary of policies each of these journals has in place regarding software papers. (e.g. licensing requirements, repository requirements, required sections in the manuscripts regarding installation or tests, etc).</p></li>
<li><p>Developing a five-star rating system for ranking these policies.</p></li>
<li><p>Apply our rating system to each of these journals.</p></li>
<li><p>Solicit feedback &amp; iterate.</p></li>
</ul>
<p>We got about half way though this for some of the most recognized journals on the list; <a href="https://docs.google.com/document/d/1Mivadj16_9tPrw8Nxmhp72AtNC0BEVO-f7M84FXTbSU/edit?usp=drive_web">see Google Doc notes</a>.</p>
<h3 id="feedback-for-wssspe">Feedback for WSSSPE:</h3>
<p>WSSSPE’s conference-proceedings model of submitting a short papers that get five very thorough expert reviews ahead of time is really excellent. This is not common practice in my field, so this was my first time participating in such a model. Not only did I benefit from both the chance to write up our piece ahead of time and get expert feedback from people coming from a broader range of backgrounds than I can usually interact with, but also the ability to read the full papers and not just the abstracts of other attendees in advance of the workshop was an invaluable way to learn more, make the most of the time we had, and keep a record.</p>
<p>A full-day workshop is a big travel commitment (travel costs, 2 nights lodging, and using up most of the preceding and following day) while simultaneously being not much time to meet people, share ideas, and start working towards any actual products.</p>
<p>The format proposed at the end of the session that seemed most popular in the show of hands for future WSSSPEs – a two to three day event uncoupled from Supercomputing, based in the US in an easy city to fly into, and with more time to move ideas forward into products using a small group / hackathon model would address most of my criticsm.</p>
<h3 id="misc-notesdiscussions">Misc notes/discussions</h3>
<ul>
<li><p>Interesting discussion/ideas for tracking usage of software based on updating patterns, from James Horowitz and company: <a href="http://james.howison.name/pubs/wiggins2009heartbeat-meas0.pdf">Heartbeat (pdf)</a>.</p></li>
<li><p>Neil mentioned a similar workshop he had recently taken part in creating a <a href="http://m.f1000research.com/articles/3-271/v1">reviewer’s oath</a>, recently submitted as an opinion piece to F1000. Certainly more of a guideline than most journals give, if a bit pedantic at times (for instance, as much as I believe in signing my own reviews, I would not recommend it to someone else as a blanket policy in the same vein as basic ethics like acknowledging what I don’t know. I think the ‘Oath’ needs to treat this with greater nuiance.) Anyway, food for thought.</p></li>
</ul>
<p>(I didn’t manage to catch much with twitter this time, guess too much happening in in-person discussions).</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/11/17/wssspe-feedback.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/11/14/nimble-explore.html">Nimble Explore</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 14 Nov 2014</p>

<article>
<div class="excerpt">
<p>A quick first exploration of <a href="http://r-nimble.org">NIMBLE</a> and some questions.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;nimble&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;sde&quot;</span>)</code></pre>
<p>Let’s simulate from a simple OU process: <span class="math">\(dX = \alpha (\theta - X) dt + \sigma dB_t\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">123</span>)
d &lt;-<span class="st"> </span><span class="kw">expression</span>(<span class="fl">0.5</span> *<span class="st"> </span>(<span class="dv">10</span>-x))
s &lt;-<span class="st"> </span><span class="kw">expression</span>(<span class="dv">1</span>) 
data &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">sde.sim</span>(<span class="dt">X0=</span><span class="dv">6</span>,<span class="dt">drift=</span>d, <span class="dt">sigma=</span>s, <span class="dt">T=</span><span class="dv">100</span>, <span class="dt">N=</span><span class="dv">400</span>))</code></pre>
<pre><code>## sigma.x not provided, attempting symbolic derivation.</code></pre>
<p>i.e. <span class="math">\(\alpha = 0.5\)</span>, <span class="math">\(\theta = 10\)</span>, <span class="math">\(\sigma=1\)</span>, starting at <span class="math">\(X_0 = 6\)</span> and running for 100 time units with a dense sampling of 400 points.</p>
<p>Le’t now estimate a Ricker model based upon (set aside closed-form solutions to this estimate for the moment, since we’re investigating MCMC behavior here).</p>
<pre class="sourceCode r"><code class="sourceCode r">code &lt;-<span class="st"> </span><span class="kw">modelCode</span>({
      K ~<span class="st"> </span><span class="kw">dunif</span>(<span class="fl">0.01</span>, <span class="fl">40.0</span>)
      r ~<span class="st"> </span><span class="kw">dunif</span>(<span class="fl">0.01</span>, <span class="fl">20.0</span>)
  sigma ~<span class="st"> </span><span class="kw">dunif</span>(<span class="fl">1e-6</span>, <span class="dv">100</span>)

  iQ &lt;-<span class="st"> </span><span class="dv">1</span> /<span class="st"> </span>(sigma *<span class="st"> </span>sigma)

  x[<span class="dv">1</span>] ~<span class="st"> </span><span class="kw">dunif</span>(<span class="dv">0</span>, <span class="dv">10</span>)

  for(t in <span class="dv">1</span>:(N<span class="dv">-1</span>)){
    mu[t] &lt;-<span class="st"> </span><span class="kw">log</span>(x[t]) +<span class="st"> </span>r *<span class="st"> </span>(<span class="dv">1</span> -<span class="st"> </span>x[t]/K) 
    x[t<span class="dv">+1</span>] ~<span class="st"> </span><span class="kw">dlnorm</span>(mu[t], iQ) 
  }
})

constants &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">N =</span> <span class="kw">length</span>(data$x))
inits &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">K =</span> <span class="dv">6</span>, <span class="dt">r =</span> <span class="dv">1</span>, <span class="dt">sigma =</span> <span class="dv">1</span>)

Rmodel &lt;-<span class="st"> </span><span class="kw">nimbleModel</span>(<span class="dt">code=</span>code, <span class="dt">constants=</span>constants, <span class="dt">data=</span>data, <span class="dt">inits=</span>inits)</code></pre>
<p>NIMBLE certainly makes for a nice syntax so far. Here we go now: create MCMC specification and algorithm</p>
<pre class="sourceCode r"><code class="sourceCode r">mcmcspec &lt;-<span class="st"> </span><span class="kw">MCMCspec</span>(Rmodel)
Rmcmc &lt;-<span class="st"> </span><span class="kw">buildMCMC</span>(mcmcspec)</code></pre>
<p>Note that we can also query some details regarding our specification (set by default)</p>
<pre class="sourceCode r"><code class="sourceCode r">mcmcspec$<span class="kw">getSamplers</span>()</code></pre>
<pre><code>## [1] RW sampler;   targetNode: K,  adaptive: TRUE,  adaptInterval: 200,  scale: 1
## [2] RW sampler;   targetNode: r,  adaptive: TRUE,  adaptInterval: 200,  scale: 1
## [3] RW sampler;   targetNode: sigma,  adaptive: TRUE,  adaptInterval: 200,  scale: 1</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">mcmcspec$<span class="kw">getMonitors</span>()</code></pre>
<pre><code>## thin = 1: K, r, sigma, x</code></pre>
<p>Now we’re ready to compile model and MCMC algorithm</p>
<pre class="sourceCode r"><code class="sourceCode r">Cmodel &lt;-<span class="st"> </span><span class="kw">compileNimble</span>(Rmodel)
Cmcmc &lt;-<span class="st"> </span><span class="kw">compileNimble</span>(Rmcmc, <span class="dt">project =</span> Cmodel)</code></pre>
<p>Note we could have specified the <code>Rmodel</code> as the “project” (as shown in the example from the Nimble website), but this is more explicit. Rather convenient way to add to an existing model in this manner.</p>
<p>And Now we can execute the MCMC algorithm in blazing fast C++ and then extract the samples</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">Cmcmc</span>(<span class="dv">10000</span>)</code></pre>
<pre><code>## NULL</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">samples &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">as.matrix</span>(<span class="kw">nfVar</span>(Cmcmc, <span class="st">&#39;mvSamples&#39;</span>)))</code></pre>
<p>How do these estimates compare to theory:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(samples$K)</code></pre>
<pre><code>## [1] 10.05681</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(samples$r)</code></pre>
<pre><code>## [1] 0.180207</code></pre>
<hr />
<p>Some quick impressions:</p>
<ul>
<li><p>Strange that <code>Rmodel</code> call has to be repeated before we can set up a custom MCMC (<a href="http://r-nimble.org/examples">nimble docs</a>). How/when was this object altered since it was defined in the above code? Seems like this could be problematic for interpreting / reproducing results?</p></li>
<li><p>What’s going on with <code>getSamplers()</code> and <code>getMonitors()</code>? Guessing these are in there just to show us what the defaults will be for our model?</p></li>
<li><p>why do we assign <code>Cmodel</code> if it seems we don’t use it? (the compilation needs to be done but isn’t explicitly passed to the next step). Seems we can use <code>Cmodel</code> instead of <code>Rmodel</code> in the <code>Cmcmc &lt;- compileNimble(Rmcmc, project = Cmodel)</code>, which makes the dependency more explicit, at least that notation is more explicit. Seems like it should be possiple to omit the first <code>compileNimble()</code> and have the second call the <code>compileNimble</code> automatically if it gets an object whose class is that of <code>Rmodel</code> instead?</p></li>
<li><p>Repeated calls to <code>Cmcmc</code> seem not to give the same results. Are we adding additional mcmc steps by doing this?</p></li>
<li><p>Thinking an <code>as.data.frame</code> would be nicer than <code>as.matrix</code> in the <code>nfVar</code> <code>mvSamples</code> coercion.</p></li>
<li><p>Don’t understand what <code>simulate</code> does (or why it always returns NULL?).</p></li>
</ul>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/11/14/nimble-explore.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/11/13/draft-wssspe-thoughts.html">Draft Wssspe Thoughts</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 13 Nov 2014</p>

<article>
<div class="excerpt">
<p>Scratching out notes for lightning talk at WSSSPE…</p>
<p>(CB from ropensci, Karthik too. )</p>
<blockquote>
<p>Responses to the challenges of academic software can be divided into roughly two categories. Give them better tools! Give them better training!</p>
</blockquote>
<blockquote>
<p>We do software: over 50 packages for accessing data repositories, integrating and manipulating, annotating and publishing data. We do training: workshops, online tutorials, developing course materials. But most importantly, we aim to build community. At rOpenSci, it’s not about us and them, it’s about the community. Through mostly informal mechanisms – hackathons, workshops, blogging, and Github – we have brought people together to write software that does what they need it to do.</p>
</blockquote>
<blockquote>
<p>what does it look like? Engaging domain scientists. reviewing new contributions on Github – from bugs and Pull Requests to completely new packages. Hackathons, bringing people together to code away on whatever itch they’ve always wanted to scratch. Discussions on blogs on social media, conferences, and even here at WSSSPE. We want domain practioners to look up and see other domain practioners learning this process, learning to code, to write tests and rely on version control, and to think how things can be done differently.</p>
</blockquote>
<blockquote>
<p>Because the hardest part isn’t walking the path to sustainable software. The hardest part is knowing you want to walk it in the first place. At the end of the day, our success isn’t measured in software packages, publications, or grant dollars; but here, in new faces (on Github, blog, or live events) that say “I’m here! I get it!”</p>
</blockquote>
<blockquote>
<p>Thank you,</p>
</blockquote>
<hr />
<!--
We build tools in a language familiar to the domain scientists we expect
to use them, not just to save them time or make them more reproducible
in the future, but help them right now to do something they cannot
otherwise do.
-->

<!--

## Give them tools! ## 

- Native language tools: 
  Very widespread use of R in our focal disciplines)
- Save users time _today_: 
  Tools that do something users already want to do and can't (query arbitrary species distributions & plot on map!, yay! automatically publish data/metadata to repository, yay!), are easier to adopt than ones that make you re-learn how to do something you already know. 
- Save them even more time in the future
  all the reproducibility & sustainability goodness baked in

## Give them training! ## 

- Workshops
- self-driven tutorials
- train-the-trainers: modular teaching


## Give them community! ##

- Hackathons
- Real people
- Social media: Github, Website & blog, Twitter


--> 


 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/11/13/draft-wssspe-thoughts.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

    <div class="row">
      
        <div class="col-md-3">
          <header><h4><a href="/2014/11/13/discrete-grid-notes.html">Discrete Grid Notes</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 13 Nov 2014</p>

<article>
<div class="excerpt">
<p>Smoothing post-policy calc?</p>
<pre class="sourceCode r"><code class="sourceCode r">
fig3 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(policies, <span class="kw">aes</span>(stock, stock -<span class="st"> </span>value, <span class="dt">color=</span>method)) +
<span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">lwd=</span><span class="fl">1.2</span>, <span class="dt">method=</span><span class="st">&quot;loess&quot;</span>, <span class="dt">degree=</span><span class="dv">1</span>, <span class="dt">span=</span><span class="fl">0.2</span>, <span class="dt">level=</span><span class="dv">0</span>, <span class="dt">n=</span><span class="dv">50</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">facet_wrap</span>(~method) +
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;stock size, x(t)&quot;</span>) +<span class="st"> </span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;escapement, S(t)&quot;</span>)  +
<span class="st">  </span><span class="kw">scale_colour_manual</span>(<span class="dt">values=</span>colorkey, <span class="dt">guide=</span><span class="ot">FALSE</span>)
fig3

<span class="kw">library</span>(<span class="st">&quot;dplyr&quot;</span>)
s_policies &lt;-<span class="st"> </span><span class="kw">select_</span>(<span class="kw">ggplot_build</span>(fig3)$data[[<span class="dv">1</span>]], <span class="st">&quot;x&quot;</span>, <span class="st">&quot;PANEL&quot;</span>, <span class="st">&quot;y&quot;</span>)
s_policies$PANEL &lt;-<span class="st"> </span><span class="kw">mapvalues</span>(s_policies$PANEL, <span class="dt">from =</span> <span class="dv">1</span>:<span class="dv">6</span>, <span class="dt">to =</span> <span class="kw">levels</span>(policies$method))
<span class="kw">names</span>(s_policies) &lt;-<span class="st"> </span><span class="kw">names</span>(policies)

<span class="kw">library</span>(<span class="st">&quot;tidyr&quot;</span>)
opt_policy &lt;-<span class="st"> </span>s_policies %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">harvest =</span> stock -<span class="st"> </span>value) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(stock, method, <span class="dt">value =</span> harvest) %&gt;%
<span class="st">  </span><span class="kw">spread</span>(method, value) %&gt;%
<span class="st">  </span><span class="kw">select</span>(-stock)
OPT &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">sapply</span>(opt_policy, function(y) <span class="kw">sapply</span>(y, function(x) <span class="kw">which.min</span>(<span class="kw">abs</span>(x-x_grid)))))</code></pre>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/11/13/discrete-grid-notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/11/07/dear-docker-hub-users.html">Dear DockerHub users: please configure your repository links</a></h4></header>
<p><span>(for security's sake!)</span></p>
<p style="font-style:italic"> 07 Nov 2014</p>

<article>
<div class="excerpt">
<p>The DockerHub is a great resource for discovering and distributing Dockerfiles. Many users sharing public images take advantage of the Docker Hub’s <em>Automated Build</em> configuration, which is excellent as this automatically allows the Hub to display the Dockerfile and provides some medium of security above simply downloading and running some untrusted binary black box.</p>
<p>Unfortunately, far fewer users configure <em>Repository Links</em> to trigger builds to update even when the resulting Dockerfile is unchanged. As a result, many excellent Docker containers that are not under active development have not been rebuilt in several months, meaning that they still contain widely known dangerous security flaws such as <a href="http://en.wikipedia.org/wiki/Shellshock_(software_bug)">Shellshock</a> (September 2014).</p>
<p>This problem is easily avoided by configuring the <em>Repository Links</em> setting to point to the repository being used as a base image in <code>FROM</code>. The official base images such as <code>debian</code> and <code>ubuntu</code> (e.g. the images with no additional namespace) are regularly updated to patch security vulnerabilities as soon as they are discovered, resulting in updates being made every few days on average. Setting the repository link to the <code>FROM</code> source allows your repository to be rebuilt as soon as its base image has been updated, ensuring that you inherit those updates.</p>
<p>Naturally this strategy does not help if your <code>FROM</code> image isn’t an official base image and hasn’t configured <em>Repository Links</em> (or if such a break in the chain appears anywhere along the <code>FROM</code> recursion). In such cases, having a <code>RUN apt-get update &amp;&amp; apt-get upgrade -y</code> command (or equivalent option for your distribution) might be a good idea to make sure that your image at least gets the latest updates, but you’ll still need to set up some automatic or manual <em>Build Triggers</em> to ensure this is run regularly; or better yet, just <em>avoid building on or using stale images</em>.</p>
<p>If you do have a reliable <em>Repository Links</em> chain to an official image, then <code>apt-get upgrade</code> is not necessary (and in fact is not advised in Best Practices). Instead, make sure all images in the chain call <code>apt-get update</code> in the same RUN line as <code>apt-get install -y ...</code>, which will ensure that cache is broken and the latest versions of the packages are installed. See the official <a href="https://docs.docker.com/articles/dockerfile_best-practices/">Dockerfile Best Practices</a> for more information.</p>
<hr />
<p><em>NB: I’m not a security professional; this just looks like common sense usage</em></p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/11/07/dear-docker-hub-users.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/11/05/notes.html">linking binaries from other containers</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 05 Nov 2014</p>

<article>
<div class="excerpt">
<p>Been thinking about this for a while, but <span class="citation" data-cites="benmarwick">@benmarwick</span> ’s examples with <code>--volumes-from</code> convinced me to give this a try.</p>
<p>While there’s an obvious level of convenience in having something like LaTeX bundled into the <code>hadleyverse</code> container so that users can build nice pdfs, if often feels not very docker-esque to me to just throw the kitchen sink into a container. At the risk of some added complexity, we can provide LaTeX from a dedicated TeX container to a container that doesn’t have it built in, like <code>rocker/rstudio</code>. Check this out:</p>
<p>First, we run the docker container providing the texlive binaries as linked volume. Note that even after the 4 GB <code>texlive</code> container has been downloaded that this is slow to execute due to the volume linking flag (not really sure why that is).</p>
<pre><code>docker run --name tex -v /usr/local/texlive leodido/texlive true</code></pre>
<p>Once the above task is complete, we can run the <code>rstudio</code> container, which doesn’t have tex installed by itself, and access tex by linking:</p>
<pre><code>docker run -dP --volumes-from tex \
 -e PATH=$PATH:/usr/local/texlive/2014/bin/x86_64-linux/ \
 rocker/rstudio</code></pre>
<p>We can now log into RStudio, create a new Rnw file and presto, RStudio discovers the tex compilers and builds us a pdf. This does make our Docker execution lines a bit long, but that’s what <a href="www.fig.sh">fig</a> is for. (Or a good ole Makefile).</p>
<p>Note this requires we build <code>texlive</code> in a way that isolates it to it’s own path (e.g. <code>/usr/local/texlive</code>). The default installation with <code>apt-get</code> installs everything in separate locations that overlap with existing directories (like <code>/usr/bin</code>), which makes linking clumsy or impossible (we would need separate paths for all the components, e.g. since shared libraries aren’t found under the <code>bin</code> path, and we cannot link such a volume to another container without destroying everything in it’s <code>/usr/bin</code>, clearly not a good idea). Instead, if we use the standard <code>texlive</code> install script from <a href="https://www.tug.org/texlive/">https://www.tug.org/texlive/</a>, this installs everything into <code>/usr/local/texlive</code> which is much more portable as illustrated above. Not quite sure if it’s actually a good idea to build containers this way or not.</p>
<p>I’ll keep shipping latex inside the <code>hadleyverse</code> container (has about 300 MB of texlive that covers most common usecases), but this is certainly an intruging recipe to mix and match.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/11/05/notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

  </div>
</div> <!--end row -->

<div class="row socialicons">
  <div class="col-md-11 col-md-offset-1">
      <p> <a href="/archive.html"><i class="icon-calendar"></i> All entries by date</a></p> 
      <p> <a href="/categories.html"><i class="icon-list"></i> All entries by category</a> </p>
      <p> <a href="/tags.html"><i class="icon-tags"></i> All entries by tag</a> </p>
  </div> <!--end col-md-9 -->
</div> <!--end row -->




      <footer class="footer">

<!--************** FOAF information to social networks ***************************** -->
  <div class="row">
    <div class="col-md-3 col-xs-4 socialicons" style="font-size:20px" typeof="foaf:Person" about="http://www.carlboettiger.info#me">
      <p>
          <script type="text/javascript" src="/assets/js/obfuscate-email-link.js"></script> 

          <a rel="foaf:account" href="https://twitter.com/cboettig" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Twitter'); 
             return false;"><span class="showtooltip" title="follow me on twitter (reading, discussing)"><i class="fa fa-twitter"></i></span></a> 

          <a rel="foaf:account" href="https://github.com/cboettig" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Github'); 
             return false;"><span class="showtooltip" title="follow me on Github (code, research)"><i class="fa fa-github"></i></span></a>
      <!--
          <a rel="foaf:account" href="https://plus.google.com/" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'GPlus'); 
             return false;"><i class="fa fa-google-plus"></i></a>

          <a rel="foaf:account" href="http://www.mendeley.com/profiles/carl-boettiger" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Mendeley'); 
             return false;"><img src="/assets/img/icon-mendeley.png" /></a> 

           citations on google-scholar

           stackoverflow
      -->
      <a rel="foaf:weblog" type="application/atom+xml" href="/blog.xml"  
         class="showtooltip" title="RSS feeds for my blog-style entries. See the feed on my lab notebook (/atom.xml) to follow all entries instead." 
         onclick="recordOutboundLink(this, 'Outbound Links', 'RSS'); 
         return false;"><i class="fa fa-rss"></i></a>
       </p>
    </div>

    
    <!--**************** End social links **************************** -->


    <div class="col-md-4 col-md-offset-1 col-xs-4">
      <p><a onclick="recordOutboundLink(this, 'Outbound Links', 'ONS_claim'); return false;" href="http://onsclaims.wikispaces.com/"><img src="/assets/img/ons-aci2-icon.svg" alt="ONS" class="showtooltip" title="An Open Notebook Science (ONS) project claim: Entry provides all content (AC) immediately (I) or without significant delay.  See link for details"/></a></p>
    </div>


    <div class="col-md-3 col-md-offset-1 col-xs-4">
      <p>
      <a rel="license" property="http://creativecommons.org/ns#license" href="http://creativecommons.org/publicdomain/zero/1.0/" onclick="recordOutboundLink(this, 'Outbound Links', 'CC0'); return false;"><img src="/assets/img/cc-zero.svg" alt="CC0"/></a> 
      </p>
    </div>
  </div>


  
<!-- COinS metadata (for citation managers like Zotero etc), goes in body text -->
  <span
      class="Z3988" 
      title="ctx_ver=Z39.88-2004
      &amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc
      &amp;rfr_id=info%3Asid%2Focoins.info%3Agenerator
      &amp;rft.title=Lab Notebook
      &amp;rft.creator=Carl Boettiger
      &amp;rft.date=
      &amp;rft.language=EN
      &amp;rft.rights=CC0
      &amp;rft_id=http://www.carlboettiger.info/lab-notebook.html">
  </span>


</footer>




          <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->

    <!-- JQuery, used on a few pages (still?) -->
    <!-- <script type="text/javascript" src="/assets/js/jquery.js"></script> -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <!-- Equations using MathJax -->
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "all"} } });       </script>
    <!-- Twitter Bootstrap Javascript -->
    <!--  <script src="/assets/js/bootstrap.min.js"></script> -->
    <script src="//netdna.bootstrapcdn.com/bootstrap/3.1.1/js/bootstrap.min.js"></script>


    

        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-18401403-1']);
          _gaq.push(['_trackPageview']);
          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
  </script>



<script type="text/javascript">
function recordOutboundLink(link, category, action) {
  try {
    var pageTracker=_gat._getTracker("UA-18401403-1");
    pageTracker._trackEvent(category, action);
    setTimeout('document.location = "' + link.href + '"', 100)
  }catch(err){}
}
</script>




    </div>
  </body>
</html>
   
