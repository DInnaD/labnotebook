<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  <head prefix="dc: http://purl.org/dc/terms/ og: http://ogp.me/ns#"> <!-- namespaces used in metadata.html -->
  <meta http-equiv='Content-Type' content='text/html; charset=utf-8'/>
  <title>Lab Notebook</title>
  <meta name="author" content="Carl Boettiger" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <!-- HTML5 metadata -->
<meta name="keywords" content="" />
<meta name="description" content="" />
<!-- RDFa Metadata (in DublinCore) -->
<meta property="dc:title" content="Lab Notebook" />
<meta property="dc:creator" content="Carl Boettiger" />
<meta property="dc:date" content="" />
<meta property="dc:format" content="text/html" />
<meta property="dc:language" content="en" />
<meta property="dc:identifier" content="/lab-notebook.html" />
<meta property="dc:rights" content="CC0" />
<meta property="dc:source" content="Lab Notebook" />
<meta property="dc:subject" content="Ecology" /> 
<meta property="dc:type" content="website" /> 
<!-- RDFa Metadata (in OpenGraph) -->
<meta property="og:title" content="Lab Notebook" />
<meta property="og:author" content="http://www.carlboettiger.info/index.html#me" />  <!-- Should be Liquid? URI? -->
<meta property="http://ogp.me/ns/profile#first_name" content="Carl"/>
<meta property="http://ogp.me/ns/profile#last_name" content="Boettiger"/>
<meta property="http://ogp.me/ns/article#published_time" content="" />
<meta property="og:site_name" content="Lab Notebook" /> <!-- Same as dc:source? -->
<meta property="og:url" content="http://www.carlboettiger.info/lab-notebook.html" />
<meta property="og:type" content="website" /> 
<!-- Google Scholar Metadata -->
<!--
<meta name="citation_author" content="Carl Boettiger"/>
<meta name="citation_date" content=""/>
<meta name="citation_title" content="Lab Notebook"/>
<meta name="citation_journal_title" content="Lab Notebook"/>
-->
<!--NOTE: see also the COinS Metadata in span element in footer -->




  <link href="/assets/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
  <!-- Help the browser identify the RSS feed automatically -->
  <link rel="alternate" type="application/rss+xml" title="Carl Boettiger's Lab Notebook" href="/blog.xml" />
</head>


  <body prefix="dc: http://purl.org/dc/terms/ foaf: http://xmlns.com/foaf/0.1/"> 
    <!-- Navbar  ================================================== -->

<nav class="navbar navbar-default" role="navigation">
  <div class="container-fluid">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/README.html"><i class="icon-info-sign"></i></a>
    </div>

 <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">

          <li  >
          <a href="/index.html">Home</a></li>
          <li  >
          <a href="/vita.html">Vita</a></li>
          <li  >
          <a href="/research.html">Research</a></li>
          <li  >
          <a href="/teaching.html">Teaching</a></li>
          <li  >
          <a href="/community.html">Community</a></li>
          <li  class="active" >
          <a href="/lab-notebook.html">Lab Notebook</a></li>

        </ul>

      <!-- Search site using Google's index -->
        <form class="navbar-form navbar-right" role="search" method="get" action="http://google.com/search">
          <div class="form-group">
            <input type="hidden" name="q" value="site:carlboettiger.info" />
            <input type="text" class="form-control search-query" name="q" placeholder="Search"/>
          </div>
          <button class="btn btn-mini" type="submit"><i class="icon-search"></i></button> 
       </form>

    </div><!--/.nav-collapse -->
  </div> <!-- /container -->
</nav>



    <div class="container"> <!-- Responsive grid layout, doesn't jump to full-width --> 
      <header>
        <h1 class="entry-title">Lab Notebook</h1>
        <h2>(<a href="http://www.carlboettiger.info/2012/09/28/Welcome-to-my-lab-notebook.html">Introduction</a>)</h2>
      </header>

      <div class="row feed">
  <div class="col-md-3 col-md-offset-1">
    <h4>  <a property="account" href="https://github.com/cboettig" onclick="recordOutboundLink(this, 'Outbound Links', 'Github'); return false;"><i class="icon-github" alt="github"></i> Coding </a></h4> 
    <div class="excerpt">
      <div class="scroll">
        <ul><li>cboettig pushed to master at cboettig/labnotebook: <em>wee rant</em> <a href="https://github.com/cboettig/labnotebook/compare/a574c51cab...6978c3712b">09:44 2014/11/07</a></li><li>cboettig commented on pull request dlab-berkeley/collaboratool#90: <em>@davclark Just got around to updating the documentation as you suggested (so someone opening userconf.sh or supervisord.conf sees that they are sup…</em> <a href="https://github.com/dlab-berkeley/collaboratool/pull/90#issuecomment-62206302">08:23 2014/11/07</a></li><li>cboettig pushed to master at cboettig/collaboratool: <em>update documentation on Dockerfile and component files, showing how t…</em> <a href="https://github.com/cboettig/collaboratool/compare/738c1ddf40...ed9e633b50">07:29 2014/11/07</a></li><li>cboettig pushed to master at cboettig/earlywarning: <em>fix docker cp command</em> <a href="https://github.com/cboettig/earlywarning/compare/bd6008a409...72802581d1">05:33 2014/11/07</a></li><li>cboettig pushed to master at cboettig/earlywarning: <em>README added</em> <a href="https://github.com/cboettig/earlywarning/compare/b221a17eac...bd6008a409">05:31 2014/11/07</a></li></ul>
      </div>
    </div>
  </div>
  <div class="col-md-3">
    <h4> <a property="account" href="https://twitter.com/cboettig" onclick="recordOutboundLink(this, 'Outbound Links', 'Twitter'); return false;"><i class="icon-twitter"></i> Discussing </a></h4> 
     <div class="excerpt">
      <div class="scroll">
       <ul><li><p>RT @datacarpentry: Computational Data Science Fellow positions at UC Berkeley to work w BIDS &amp; build open source tools for data science htt…</p>
 <a href="http://twitter.com/cboettig/statuses/530443454325989377">07:35 2014/11/06</a> </li><li><p>@nickschurch yup. And several journals have been accepting Sweave for some time. Good TeX integration helps.</p>
 <a href="http://twitter.com/cboettig/statuses/530374563855859713">03:02 2014/11/06</a> </li><li><p>yay for easy, integrated submissions! @PLOS launches its Data Repository Integration Partner Program <a href="http://t.co/n844okBzwa">http://t.co/n844okBzwa</a> / ht @mfenner</p>
 <a href="http://twitter.com/cboettig/statuses/530215536299237376">04:30 2014/11/06</a> </li><li><p>Nice piece on ipython-notebooks in @nature  <a href="http://t.co/dDNOHsKv1g">http://t.co/dDNOHsKv1g</a> Pity it omits that folks have been publishing this way 4 yrs in #rstats</p>
 <a href="http://twitter.com/cboettig/statuses/530208051400159233">04:00 2014/11/06</a> </li><li><p>RT @genetics_blog: Awesome! @datacarpentry receives @MooreFound funding, @tracykteal taking the lead! Congrats! <a href="http://t.co/GLgKqrk9TF">http://t.co/GLgKqrk9TF</a></p>
 <a href="http://twitter.com/cboettig/statuses/530042455307980801">05:02 2014/11/05</a> </li></ul>
      </div>
    </div> 
  </div> 
  <div class="col-md-3">
    <h4> <a href="http://www.mendeley.com/groups/634301/theoretical-ecology/papers/" onClick="recordOutboundLink(this, 'Outbound Links', 'Mendeley'); return false;"><i class="icon-book"></i> Reading </a></h4> 
    <div class="excerpt">
      <div class="scroll">
<ul><li>The Southern Kalahari: a potential new dust source in the Southern Hemisphere?: Environmental Research Letters (2012). Volume: 7, Issue: 2. Pages: 024001. Abinash Bhattachan, Paolo D’Odorico, Matthew C Baddock, Ted M Zobeck, Gregory S Okin, Nicolas Cassar et al. <a href="http://www.mendeley.com/c/7318874474/g/634301/bhattachan-2012-the-southern-kalahari-a-potential-new-dust-source-in-the-southern-hemisphere/">11:45 2014/11/04</a></li><li>Resilience and recovery potential of duneland vegetation in the southern Kalahari: Ecosphere (2014). Volume: 5, Issue: January. Pages: 1-14. A Bhattachan, P D'Odorico, K Dintwe et al. <a href="http://www.mendeley.com/c/7318874484/g/634301/bhattachan-2014-resilience-and-recovery-potential-of-duneland-vegetation-in-the-southern-kalahari/">11:45 2014/11/04</a></li><li>Potential dust emissions from the southern Kalahari's dunelands: Journal of Geophysical Research: Earth Surface (2013). Volume: 118, Issue: 1. Pages: 307-314. Abinash Bhattachan, Paolo D'Odorico, Gregory S. Okin, Kebonyethata Dintwe et al. <a href="http://www.mendeley.com/c/7318874504/g/634301/bhattachan-2013-potential-dust-emissions-from-the-southern-kalaharis-dunelands/">11:45 2014/11/04</a></li><li>Shifting Regimes and Changing Interactions in the Lake Washington, U.S.A., Plankton Community from 1962-1994.: PloS one (2014). Volume: 9, Issue: 10. Pages: e110363. Tessa B Francis, Elizabeth M Wolkovich, Mark D Scheuerell, Stephen L Katz, Elizabeth E Holmes, Stephanie E Hampton et al. <a href="http://www.mendeley.com/c/7318874434/g/634301/francis-2014-shifting-regimes-and-changing-interactions-in-the-lake-washington-usa-plankton-community-from-1962-1994/">11:44 2014/11/04</a></li></ul>
      </div>
    </div>
  </div> 
</div>

<hr>
<div class="row postpreview">
  <div class="col-md-11 col-md-offset-1">
    <div class="row">
      <h4> <a href="http://www.carlboettiger.info/atom.xml"
              onClick="recordOutboundLink(this,
              'Outbound Links', 'RSS'); return false;"
              style="color: inherit;"
              ><i class="icon-rss" ></i> Entries</a></h4>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/11/07/dear-docker-hub-users.html">Dear DockerHub users: please configure your repository links</a></h4></header>
<p><span>(for security's sake!)</span></p>
<p style="font-style:italic"> 07 Nov 2014</p>

<article>
<div class="excerpt">
<p>The DockerHub is a great resource for discovering and distributing Dockerfiles. Many users sharing public images take advantage of the Docker Hub’s <em>Automated Build</em> configuration, which is excellent as this automatically allows the Hub to display the Dockerfile and provides some medium of security above simply downloading and running some untrusted binary black box.</p>
<p>Unfortunately, far fewer users configure <em>Repository Links</em> to trigger builds to update even when the resulting Dockerfile is unchanged. As a result, many excellent Docker containers that are not under active development have not been rebuilt in several months, meaning that they still contain widely known dangerous security flaws such as <a href="http://en.wikipedia.org/wiki/Shellshock_(software_bug)">Shellshock</a> (September 2014).</p>
<p>This problem is easily avoided by configuring the <em>Repository Links</em> setting to point to the repository being used as a base image in <code>FROM</code>. The official base images such as <code>debian</code> and <code>ubuntu</code> (e.g. the images with no additional namespace) are regularly updated to patch security vulnerabilities as soon as they are discovered, resulting in updates being made every few days on average. Setting the repository link to the <code>FROM</code> source allows your repository to be rebuilt as soon as its base image has been updated, ensuring that you inherit those updates.</p>
<p>Naturally this strategy does not help if your <code>FROM</code> image isn’t an official base image and hasn’t configured <em>Repository Links</em> (or if such a break in the chain appears anywhere along the <code>FROM</code> recursion). In such cases, having a <code>RUN apt-get update &amp;&amp; apt-get upgrade -y</code> command (or equivalent option for your distribution) might be a good idea to make sure that your image at least gets the latest updates, but you’ll still need to set up some automatic or manual <em>Build Triggers</em> to ensure this is run regularly; or better yet, just <em>avoid building on or using stale images</em>.</p>
<p>If you do have a reliable <em>Repository Links</em> chain to an official image, then <code>apt-get upgrade</code> is not necessary (and in fact is not advised in Best Practices). Instead, make sure all images in the chain call <code>apt-get update</code> in the same RUN line as <code>apt-get install -y ...</code>, which will ensure that cache is broken and the latest versions of the packages are installed. See the official <a href="https://docs.docker.com/articles/dockerfile_best-practices/">Dockerfile Best Practices</a> for more information.</p>
<hr />
<p><em>NB: I’m not a security professional; this just looks like common sense usage</em></p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/11/07/dear-docker-hub-users.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/11/03/three-interfaces-for-Docker.html">Three Interfaces For Docker</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 03 Nov 2014</p>

<article>
<div class="excerpt">
<p>Here I outline three broad, different strategies for incorporating Docker into a user’s workflow, particularly from the perspective of an instructor getting a group of students up and running in a containerized environment, but also in the context of more generic collaborations. The options require progressively more setup and result in a progressively more ‘native’ feel to running Docker. My emphasis is on running Dockerized R applications and RStudio, though much the same thing can be accomplished with iPython notebooks and many other web apps.</p>
<p>Of course the great strength of Docker is the relative ease with which one can move between these three strategies while using the identical container, maintaining a consistent computational environment in each case.</p>
<h2 id="web-hosted-docker">Web-hosted Docker</h2>
<p>In this approach, RStudio-server is deployed on a web server and accessed through the browser. The use of Docker containers makes it easier for an instructor to deploy a consistent environment quickly with the desired software pre-installed and pre-configured.</p>
<h3 id="advantages">Advantages:</h3>
<ul>
<li>A user just needs a web browser and the URL of the server.</li>
<li>No need to install any local software.</li>
<li>No need to download big files.</li>
<li>Should work with any device that supports a modern browser, including most tablets.</li>
<li>Convenient to temporarily scale computation onto a larger system.</li>
</ul>
<h3 id="disadvantages">Disadvantages:</h3>
<ul>
<li>requires a network connection (at all times)</li>
<li>requires access to a server with sufficient computational power for the task.</li>
<li>Someone has to manage user &amp; network security (as with any web server).</li>
<li>Need additional mechanisms for moving files on and off the server, such as git.</li>
<li>No native interfaces available, must manage files, edit text etc. through the RStudio IDE</li>
</ul>
<h3 id="setup">Setup:</h3>
<p>A Docker container running RStudio can be deployed with a single command, see <a href="https://github.com/rocker-org/rocker/wiki/Using-the-RStudio-image">rocker wiki instructions on RStudio</a> for details. The instructor or team-member responsible for the setup would simply need to install docker on server. If multiple students will be accessing a single RStudio-server instance, it must be configured for multiple users. Alternately multiple containers can be run on different ports of the same server. (See wiki).</p>
<p>Hint: Users can also take advantage of the new R package <a href="https://github.com/sckott/analogsea">analogsea</a> to quickly launch and manage an RStudio Server instance on the Digital Ocean cloud platform. <code>analogsea</code> can also facilitate transfers of code and other files onto and off of the server.</p>
<h2 id="self-hosted-docker">Self-hosted Docker</h2>
<p>In this approach, the user installs docker (via <code>boot2docker</code>, if necessary) on their local machine, but still interacts with the container using the same web-based interface (e.g. <code>rstudio-server</code>, <code>ipython-notebook</code>) that one would use in the cloud-hosted model.</p>
<h3 id="advantages-1">Advantages:</h3>
<ul>
<li>No need for a network connection (at least once the container image is downloaded / transfered)</li>
<li>No need to have a server available (with the associated cost and security overhead)</li>
</ul>
<h3 id="disadvantages-1">Disadvantages:</h3>
<ul>
<li>More initial setup: install <code>docker</code> locally, or install <code>boot2docker</code> for Mac/Windows users.</li>
<li>Need to use <code>git</code> or <code>docker copy</code> to move files from the container to the host or vice versa.</li>
</ul>
<p>Hint: Users might also check out the R package <a href="https://github.com/wch/harbor">harbor</a> for interacting with Docker locally from R.</p>
<h3 id="setup-1">Setup:</h3>
<p>Setup is much the same as on a remote server, though there is no need to set custom usernames or passwords since the instance will be accessible only to local users. See <a href="https://github.com/rocker-org/rocker/wiki/Using-the-RStudio-image">rocker wiki instructions on RStudio</a> for details.</p>
<h2 id="integrated-docker">Integrated Docker</h2>
<p>This approach is the same as the self-hosted approach, except that we link shared volumes with the host. At minimum this makes it easier to move files on and off the container without learning git.</p>
<p>An intriguing advantage of this approach is that it does not restrict the user to the RStudio IDE as a way of editing text, managing files and versions, etc. Most users do not rely exclusively on RStudio for these tasks, and may find that restriction limiting. The integrated approach may be more suited for experienced users who are set in their ways and do not need a pixel-identical work environment of RStudio useful for following directions in a classroom. In the integrated approach, a user can continue to rely on whatever their preferred native tools are, while ensuring that code execution occurs (invisibly) on a Dockerized container.</p>
<h3 id="advantages-2">Advantages</h3>
<ul>
<li>Can use native OS tools (text editors, file browsers, version control front ends, etc) for all interactions</li>
<li>No network required (once image is downloaded / transfered).</li>
<li>No servers required</li>
</ul>
<h3 id="disadvantages-2">Disadvantages</h3>
<ul>
<li>Additional setup beyond self-hosting: mapping shared volumes, managing user permissions.</li>
<li>Potentially less well suited for classroom use, which may benefit from everyone using the identical RStudio interface rather than a range of different text editors, etc. (Of course one can still share volumes while using RStudio as the IDE).</li>
<li>Cannot open external windows (e.g. if running R in terminal instead of RStudio, the container running R cannot open an X11 window to display plots. Instead, a user must do something like <code>ggsave()</code> after plotting interactively to view the resulting graphic in the native file browser. (This is more tedious in base graphics that need <code>dev.off()</code> etc.). Of course this is not an issue when using RStudio with linked volumes.</li>
</ul>
<h3 id="setup-2">Setup</h3>
<p>The key here is simply to link the working directory on the host to the file system on the container. That way any changes made to the host copy using the host OS tools are immediately available to the container, and vice versa. Setup requires a bit more effort on Windows at this time, though is natively supported for Mac in Docker 1.3. Some care may also be necessary not to change the permissions of the file. See details in the <a href="https://github.com/rocker-org/rocker/wiki/Shared-files-with-host-machine">rocker wiki on shared files</a></p>
<h4 id="aliases">aliases</h4>
<p>The most aggressive form of the integrated approach is to literally alias common commands like <code>R</code> or <code>rstudio</code> as the corresponding docker calls in <code>.bashrc</code>, e.g.</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">alias</span> R=<span class="st">&#39;docker run --rm -it --user docker -v $(pwd):/home/docker/`basename $PWD` -w /home/docker/`basename $PWD` rocker/hadleyverse R&#39;</span></code></pre>
<p>makes the command <code>R</code> launch an instance of the <code>rocker/hadleyverse</code> container sharing the current working directory. Clearly different containers could be substituted in place of <code>rocker/hadleyverse</code>, including custom extensions. This helps ensure that R is always run in the portable, Dockerized environment. Other than the lack of X11 display for plots, this works and feels identical to an interactive R terminal session.</p>
<h4 id="other-tweaks">Other tweaks</h4>
<p>Mac/Windows users might also want to customize <code>boot2docker</code>’s resources to make more of the host computer’s memory and processors available to Docker.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/11/03/three-interfaces-for-Docker.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/10/28/jekyll-free.html">Goodbye Jekyll?</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 28 Oct 2014</p>

<article>
<div class="excerpt">
<p>The great strength of Jekyll is in providing a really convenient HTML templating system through the <code>_layouts</code> and <code>_includes</code> directories and Liquid variables (including the auto-populated ones like <code>page.previous.url</code>).</p>
<p>For quickly deploying simple sites though, this is often unnecessary: one or two layout files will suffice, and an <code>_includes</code> directory is not so useful with only a single layout. The ease of maintenance by having a template divided into modular chunks is somewhat trumped by the greater simplicity of copying a single template or set of templates over into a new directory.</p>
<p>And deploying Jekyll could be easier, particularly with pandoc as the parser. Despite plugins that nicely let pandoc act just like the built-in parsers and a CI setup with Travis to support automated building of my site on push, setting these components up repeatedly on every new repository is a bit tedious. Occassional updates of Jekyll and related gems have also broken my build pipeline more than once, though this is less of an issue now that I’ve added bundler and a Gemfile to restrict gem versions and provide a Dockerized setup for local deploying. These things keep the overhead low for my main site, but are an overhead to replicate.</p>
<p>Meanwhile, I’ve found Pandoc’s templating system to be immensely powerful, particularly with the yaml headers now supported. To provide a lightweight way to deploy a website on a gh-pages branch of a new repository, I’ve found this system works quite well. I’ve illustrated this on my <a href="https://github.com/cboettig/tree/gh-pages">gh-pages branch of my template</a> repository. Previously, this used Jekyll with the built-in redcarpet markdown parser to deploy markdown files in a style consistent with my notebook.</p>
<p>Now, I’ve stripped this down to simply use a pandoc template, pandoc YAML, and a Makefile to accomplish much the same thing.</p>
<p>I was dissapointed to see that the <code>_output.yaml</code> used by rmarkdown for building multi-page websites did not leverage the generic <code>metadata.yaml</code> approach already built into pandoc. This prevents us specifying custom generic metadata the way one does in Jekyll with <code>_config.yaml</code>, as I describe in <a href="https://github.com/rstudio/rmarkdown/issues/297">rmarkdown#297</a> I can work around this with the Makefile by calling pandoc manually with the additional <code>metadta.yaml</code> file, as follows:</p>
<pre class="Make"><code>%.html: %.Rmd
  R --vanilla --slave -e &quot;knitr::knit(&#39;$&lt;&#39;)&quot;
  pandoc --template _layouts/default.html metadata.yaml -o $@ $(basename $&lt;).md
  rm $(basename $&lt;).md

%.html: %.md
  pandoc --template _layouts/default.html metadata.yaml -o $@ $&lt; 
</code></pre>
<p>Note the <code>Rmd</code> building is somewhat more cumbersome since we have to bypass <code>rmarkdown:render</code> for this to work.</p>
<p>I had to collapse all my <code>_includes</code> and nested <code>_layouts</code> into a single <code>layout</code>, replace the Jekyll Liquid blocks, <code>{{</code> with pandoc-template <code>$</code> ones, and write out a basic <code>metadata.yaml</code> file, and things are <a href="http://io.carlboettiger.info/template/">good to go</a>.</p>
<hr />
<p>Nonetheless, I sometimes wish I could break templates into more re-usable components; similar to the the way <code>_includes</code> provides re-usable components for the templates specified in the <code>_layouts</code> directory of a jekyll site.</p>
<p>My first thought was to simply add the re-usable elements into a metadata block itself. (This seemed particularly promising since we can already have an external metadata.yaml to provide a metadata block we can use across multiple file). However, it seems that Pandoc always escape the html contents in my yaml metadata. For instance, if I add the block:</p>
<pre><code>---
header: |
    &lt;header class=&quot;something&quot;&gt;&lt;h1&gt;$title$&lt;/h1&gt;&lt;/header&gt;
---</code></pre>
<p>and then in my template add <code>$header$</code>, I get the above block but with all the angle brackets escaped. I had thought since I have denoted this as a literal block with ‘|’ in the yaml I would get this block unaltered. How can I prevent pandoc from escaping the html? (I realize that still wouldn’t parse the <code>$title$</code> metadata, but that’s a separate issue).</p>
<p>The other approach I considered is to exploit the <code>--include-before-body</code> and <code>--include-after-body arguments</code>. While more limited since I am restricted to these two variables, this approach does allow me to specify a file with a re-usable component block and avoids the issue of HTML escaping observed above. Other than the limit of two such variables, the other limit to this approach is that metadata elements like <code>$title$</code> are processed only in templates, not in files.</p>
<p>It seems like pandoc is thus really close to being able to support templates that are made from re-usable blocks rather than completely specified from scratch, but not quite there. I realize pandoc isn’t trying to be a replacement for static website generation, but still feel that re-usable blocks would make the existing template system a bit more flexible and user-friendly.</p>
<p>Quite a few of pandoc’s current functions already approximate this behavior in a hard-wired fashion; e.g. <code>$highlight-css$</code> uses the <code>--highlight-style</code> option to select among a bunch of pre-defined highlight blocks. Thus I suspect pandoc might be easier to extend in the future if such features could just be added through an include mechanism rather than this hardwired approach.</p>
<p><em>See this as a query to <a href="https://groups.google.com/forum/#!topic/pandoc-discuss/pe63zLmNwtk">pandoc-discuss</a></em></p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/10/28/jekyll-free.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

    <div class="row">
      
        <div class="col-md-3">
          <header><h4><a href="/2014/10/21/docker-and-user-permissions-crazyness.html">Docker And User Permissions Crazyness</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 21 Oct 2014</p>

<article>
<div class="excerpt">
<p>Lots of crazyness getting to the bottom of permissions changes, as discussed in:</p>
<ul>
<li><a href="https://github.com/rocker-org/rocker/issues/50">rocker issues tracker</a></li>
<li><a href="http://stackoverflow.com/questions/26500270">Stackoverflow question</a></li>
<li><a href="https://groups.google.com/forum/#!topic/docker-user/VFdFuZ4Ze_A">Docker mailing list</a></li>
</ul>
<p>Long story short: docker cares only about UIDs, so we have to explicitly make sure these match. Some very good answers including from Docker core-team members on the discussion list. Overall approach outlined at the end of the rocker issues tracker.</p>
<p>Here’s the SO version of the question, for my reference:</p>
<hr />
<p>Consider the following trivial Dockerfile:</p>
<pre><code>FROM debian:testing
RUN  adduser --disabled-password --gecos &#39;&#39; docker
RUN  adduser --disabled-password --gecos &#39;&#39; bob </code></pre>
<p>in a working directory with nothing else. Build the docker image:</p>
<pre><code>docker build -t test .</code></pre>
<p>and then run a bash script on the container, linking the working directory into a new subdir on bob’s home directory:</p>
<pre><code>docker run --rm -it -v $(pwd):/home/bob/subdir test </code></pre>
<p>Who owns the contents of <code>subdir</code> on the container? On the container, run:</p>
<pre><code>cd /home/bob/subdir
ls -l</code></pre>
<p>ad we see:</p>
<pre><code>-rw-rw-r-- 1 docker docker 120 Oct 22 03:47 Dockerfile</code></pre>
<p>Holy smokes! <code>docker</code> owns the contents! Back on the host machine outside the container, we see that our original user still owns the <code>Dockerfile</code>. Let’s try and fix the ownership of <code>bob</code>’s home directory. On the container, run:</p>
<pre><code>chown -R bob:bob /home/bob
ls -l </code></pre>
<p>and we see:</p>
<pre><code>-rw-rw-r-- 1 bob bob 120 Oct 22 03:47 Dockerfile</code></pre>
<p>But wait! outside the container, we now run <code>ls -l</code></p>
<pre><code>-rw-rw-r-- 1 1001 1001 120 Oct 21 20:47 Dockerfile</code></pre>
<p>we no longer own our own file. Terrible news!</p>
<hr />
<p>If we had only added one user in the above example, everything would have gone more smoothly. For some reason, Docker seems to be making any home directory owned by the <em>first</em> non-root user it encounters (even if that user is declared on an earlier image). Likewise, this <em>first</em> user is the one that corresponds to the same ownership permissions as my home user.</p>
<p><strong>Question 1</strong> Is that correct? Can someone point me to documentation of this, I’m just conjecturing based on the above experiment.</p>
<p><strong>Question 2</strong>: Perhaps this is just because they both have the same numerical value on the kernel, and if I tested on a system where my home user was not id <code>1000</code> then permissions would get changed in every case?</p>
<p><strong>Question 3</strong>: The real question is, of course, ‘what do I do about this?’ If <code>bob</code> is logged in as <code>bob</code> on the given host machine, he should be able to run the container as <code>bob</code> and not have file permissions altered under his host account. As it stands, he actually needs to run the container as user <code>docker</code> to avoid having his account altered.</p>
<p>I hear you asking <em>Why do I have such a weird Dockerfile anyway?</em>. I wonder too sometimes. I am writing a container for a webapp (RStudio-server) that permits different users to log in, which simply uses the user names and credentials from the linux machine as the valid user names. This brings me the perhaps unusual motivation of wanting to create multiple users. I can get around this by creating the user only at runtime and everthing is fine. However, I use a base image that has added a single <code>docker</code> user so that it can be used interactively without running as root (as per best practice). This ruins everything since that user becomes the <em>first</em> user and ends up owning everything, so attempts to log on as other users fail (the app cannot start because it lacks write permissions). Having the startup script run <code>chown</code> first solves this issue, but at the cost of linked volumes changing permissions (obviously only a problem if we are linking volumes).</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/10/21/docker-and-user-permissions-crazyness.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/10/20/notes.html">Notes</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 20 Oct 2014</p>

<article>
<div class="excerpt">
<p>Keep thinking about this quote from Jeroen Oom’s <a href="http://arxiv.org/abs/1406.4806">recent piece on the arxiv</a>:</p>
<blockquote>
<p>The role and shape of data is the main characteristic that distinguishes scientific computing. In most general purpose programming languages, data structures are instances of classes with well-defined fields and methods. […] Strictly defined structures make it possible to write code implementing all required operations in advance without knowing the actual content of the data. <em>It also creates a clear separation between developers and users</em> [emphasis added]. Most applications do not give users direct access to raw data. Developers focus in implementing code and designing data structures, whereas users merely get to execute a limited set of operations.</p>
</blockquote>
<blockquote>
<p>This paradigm does not work for scientific computing. Developers of statistical software have relatively little control over the structure, content, and quality of the data. Data analysis starts with the user supplying a dataset, which is rarely pretty. Real world data come in all shapes and formats. They are messy, have inconsistent structures, and invisible numeric properties. Therefore statistical programming languages define data structures relatively loosely and instead implement a rich lexicon for interactively manipulating and testing the data. Unlike software operating on well-defined data structures, it is nearly impossible to write code that accounts for any scenario and will work for every possible dataset. Many functions are not applicable to every instance of a particular class, or might behave differently based on dynamic properties such as size or dimensionality. <em>For these reasons there is also less clear of a separation between developers and users in scientific computing.</em> The data analysis process involves simultaneously debugging of code and data where the user iterates back and forth between manipulating and analyzing the data. Implementations of statistical methods tend to be very flexible with many parameters and settings to specify behavior for the broad range of possible data. And still the user might have to go through many steps of cleaning and reshaping to give data the appropriate structure and properties to perform a particular analysis.</p>
</blockquote>
<p>Good inspiration for this week’s assignment:</p>
<h2 id="notes-for-swc-training-short-motivational-pitch-on-r">Notes for SWC training: short motivational pitch on R</h2>
<blockquote>
<p>What’s the difference between a novice programmer and a professional programmer?<br />The novice pauses a moment before doing something stupid.</p>
</blockquote>
<p>In this course, we’ll be learning about the R programming environment. You may already have heard of R or have used it before.</p>
<p>It’s the number one language for statistical programming. It’s used by most major companies, putting these skills in high demand.</p>
<p>Recently DICE Magazine showed that programmers with expertise in R topped the tech survey salary charts (at $115,531, above Hadoop, MapReduce, C, or Cloud, mobile or UI/UX design).</p>
<p>You may not (always) like the R programming environment. The syntax is often challenging, it can do counterintuitive things, and it’s terrible at mind reading.</p>
<p>Try not to take this out on your hardware. Hardware is expensive.</p>
<p>R’s strength lies in data.</p>
<p>No other major language has key statistical concepts like ‘missing data’ baked in at the lowest level.</p>
<p>We will not be approaching R as a series of recipes to perform predifined tasks.</p>
<p>In scientific research we can seldom predict just what our data will look like in advance or what our analysis will require. This makes it impossible to always rely on pre-made software and graphical interfaces you may be familar with, and blurs the lines between <em>users</em> <em>developers</em>. Unlike other languages such as C, Java or Python that are often used to build ‘end-user’ software in which the underlying language is completely invisible, R does not make this distnction. R gives a lto of power to the end user. And with great power comes great responsibility.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/10/20/notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/10/16/gitlab-and-other-configuration-notes.html">Gitlab And Other Configuration Notes</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 16 Oct 2014</p>

<article>
<div class="excerpt">
<p>Updating gitlab setup:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">docker</span> pull sameersbn/redis:latest
<span class="kw">docker</span> pull sameersbn/gitlab:7.3.2-1
<span class="kw">docker</span> pull sameersbn/postgresql:latest


<span class="kw">mkdir</span> -p /opt/gitlab/data
<span class="kw">mkdir</span> -p /opt/postgresql/data

<span class="kw">docker</span> run --name=postgresql -d \
  <span class="kw">-e</span> <span class="st">&#39;DB_NAME=gitlabhq_production&#39;</span> -e <span class="st">&#39;DB_USER=gitlab&#39;</span> -e <span class="st">&#39;DB_PASS=password&#39;</span> \
  <span class="kw">-v</span> /opt/postgresql/data:/var/lib/postgresql \
  <span class="kw">sameersbn</span>/postgresql:<span class="kw">latest</span>
<span class="kw">docker</span> run --name=redis -d sameersbn/redis:latest

<span class="kw">docker</span> run --name=gitlab -d \
  <span class="kw">--link</span> postgresql:postgresql \
  <span class="kw">--link</span> redis:redisio \
  <span class="kw">-p</span> 10080:80 -p 10022:22 \
  <span class="kw">-v</span> /opt/gitlab/data:/home/git/data \
    <span class="kw">sameersbn</span>/gitlab:<span class="kw">7.3.2-1</span></code></pre>
<p>More consisely, do this with <a href="http://fig.sh">fig</a></p>
<pre class="sourceCode yaml"><code class="sourceCode yaml"><span class="fu">gitlab:</span>
  <span class="fu">image:</span> sameersbn/gitlab:7.3.2-1
  <span class="fu">links:</span>
   <span class="kw">-</span> postgres
   <span class="kw">-</span> <span class="fu">redis:</span>redisio
  <span class="fu">ports:</span>
   <span class="kw">-</span> <span class="st">&quot;10080:80&quot;</span>
   <span class="kw">-</span> <span class="st">&quot;10022:22&quot;</span>
  <span class="fu">volumes:</span>
    <span class="kw">-</span> <span class="fu">/opt/gitlab/data:</span>/home/git/data
  <span class="fu">environment:</span>
    <span class="kw">-</span> SMTP_USER=USER@gmail.com
    <span class="kw">-</span> SMTP_PASS=PASSWORD

<span class="fu">postgres:</span>
  <span class="fu">image:</span> postgres:latest
  <span class="fu">volumes:</span>
    <span class="kw">-</span> <span class="fu">/opt/postgresql/data:</span>/var/lib/postgresql
  <span class="fu">environment:</span>
    <span class="kw">-</span> POSTGRESQL_USER=gitlab
    <span class="kw">-</span> POSTGRESQL_PASS=
    <span class="kw">-</span> POSTGRESQL_DB=gitlabhq_production
<span class="fu">redis:</span>
  <span class="fu">image:</span> redis:2.8.9</code></pre>
<p>Hmm… memory error using the <code>fig</code> approach; doesn’t happen when running individual containers as above…</p>
<p>Looks like we have to run the original version if we want to keep our database. But no go since sql database information is lost:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">docker</span> pull gitlab:7.2.1-1
<span class="kw">docker</span> run --name=gitlab -d \
  <span class="kw">-p</span> 10080:80 -p 10022:22 \
  <span class="kw">-v</span> /opt/gitlab/data:/home/git/data \
    <span class="kw">sameersbn</span>/gitlab:<span class="kw">7.2.1-1</span>
<span class="kw">docker</span> stop gitlab
<span class="kw">docker</span> run --rm -it \
  <span class="kw">-p</span> 20080:80 -p 20022:22 \
  <span class="kw">-v</span> /opt/gitlab/data:/home/git/data \
    <span class="kw">sameersbn</span>/gitlab:<span class="kw">7.2.1-1</span> app:rake gitlab:backup:restore
<span class="kw">docker</span> restart gitlab</code></pre>
<h2 id="drone">Drone</h2>
<p>Ah, Drone now provides their own Dockerfile, which we can grab and build for the latest Drone:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">git</span> clone https://github.com/drone/drone.git
<span class="kw">docker</span> build -t drone/drone drone</code></pre>
<p>Then we can run, linking volumes appropriately:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">docker</span> run --name drone -d -p 88:80 \
<span class="kw">-v</span> /var/run/docker.sock:/var/run/docker.sock \
<span class="kw">-t</span> \
<span class="kw">-e</span> DRONE_GITHUB_CLIENT=<span class="kw">&lt;</span>clientkey<span class="kw">&gt;</span> \
<span class="kw">-e</span> DRONE_GITHUB_SECRET=<span class="kw">&lt;</span>secretkey<span class="kw">&gt;</span> \
<span class="kw">drone/drone</span><span class="st">&quot;</span></code></pre>
<p>Note that this doesn’t work with a <code>drone.toml</code> file even when linking volumes etc., see <a href="https://github.com/drone/drone/issues/580">#580</a>.</p>
<p>Also note that this setup shares docker images with the host machine, rather than having a seperate library, which is rather good for saving space. I believe this should be trivial to back-up (just by exporting the container), but have to test that stil.</p>
<p>These rather verbose docker calls for drone and gitlab make a great use-case for fig. Unfortunately, fig seems to crash out of memory on my tiny DO droplet, but running these commands manually works like a charm.</p>
<h2 id="digitalocean">DigitalOcean</h2>
<p>Ooh: configure scripts for starting DO droplets. e.g. automate the launch of <a href="https://www.digitalocean.com/community/tutorials/how-to-use-cloud-config-for-your-initial-server-setup">a more secure configuration</a>, looks like a more formal way than my shell script. /ht <span class="citation" data-cites="hadley">@hadley</span>.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/10/16/gitlab-and-other-configuration-notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

    <div class="row">
      
        <div class="col-md-3">
          <header><h4><a href="/2014/10/14/rocker-versioning.html">Rocker Versioning</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 14 Oct 2014</p>

<article>
<div class="excerpt">
<p>Been looking into building versioned images for previous R releases using Docker, based on somewhat common requests to our recently begun <a href="http://github.com/rocker-org">rocker</a> project. Versioning is under early development and the best way to go about this is not yet clear. Getting the correct version of R installed is not always trivial but is relatively straight forward, and I outline two approaches below.</p>
<p>Getting the correct version of packages (or even merely any compatible version of the package) to install is a considerably more difficult problem, which I’ll discuss later.</p>
<p>We’re is considering two different strategies, each with strengths and weaknesses:</p>
<h2 id="compiled-builds">Compiled builds</h2>
<p>The most straight-forward recipe seems to be to adapt the <code>rocker/r-devel</code> file to compile the desired version by pulling from the appropriate tag in the R SVN repository, as suggested by <span class="citation" data-cites="eddelbuettel">@eddelbuettel</span></p>
<p>As Dirk suggested, we can build on the r-devel recipe, simply by pointing to the appropriate tag. Occasionally this needs a few extra packages added to the list. I was able to get R 2.0.0 to compile, but not R 1.0.0. More recent versions than 2.0.0 don’t seem to pose any difficulty for compiling. Nonetheless, installing additional packages is still an issue.</p>
<h2 id="binary-builds">Binary builds</h2>
<p>At different approach is to use the binary versions from old Debian images. This approach works rather well when docker images are available for earlier Debian releases (<code>oldstable</code> and <code>stable</code>, which currently go back as far as Debian <code>6.0</code> and <code>7.0</code>; while the main rocker release builds on Debian <code>testing</code> which is at <code>8.0</code>). Merely using the earlier Debian releases, we can jump back to certain versions of R:</p>
<ul>
<li>6.0 : R 2.11.1</li>
<li>7.0 : R 2.15.1</li>
</ul>
<p>The advantage of this is that binary forms of many common R packages may also be available from the same repositories.</p>
<p>Dirk <span class="citation" data-cites="eddelbuettel">@eddelbuettel</span> also suggests looking at <a href="http://snapshot.debian.org/">Debian snapshot archive</a> binaries. This allows us to install intermediate versions of R in binary form, as well as specific versions of any package for which debian binaries have been built. The brilliant bit about this is that we can add any particular snapshot time-period as a normal repository, e.g.</p>
<pre><code>deb     http://snapshot.debian.org/archive/debian/20091004T111800Z/ lenny main
deb-src http://snapshot.debian.org/archive/debian/20091004T111800Z/ lenny main
deb     http://snapshot.debian.org/archive/debian-security/20091004T121501Z/ lenny/updates main
deb-src http://snapshot.debian.org/archive/debian-security/20091004T121501Z/ lenny/updates main</code></pre>
<p>and the package manage can thus handle all the dependencies. As noted, this works only for those packages for which we have debian binaries available in the release.</p>
<p>This is limited to what we can use as a base image, particularly for old versions of R where the binaries are only available for i386 architectures (while there are some Docker images providing i386 architectures, we’ve so far used only amd64 versions). Given the rapid growth of R however, it is likely that the preponderance of use-cases will focus on relatively recent R versions.</p>
<p>Unfortunately, I haven’t gotten this working yet (See issue <a href="https://github.com/rocker-org/rocker-versioned/issues/2">#2</a>).</p>
<h2 id="installing-r-packages">Installing R packages</h2>
<p>Installing packages directly from CRAN is more dubious. We may be able to install earlier versions of particular packages from the CRAN archives using the CRAN data from <a href="https://github.com/metacran/crandb">metacran/crandb</a> as <span class="citation" data-cites="hadley">@hadley</span> recommended.</p>
<p>Hoping that we can do this more generally by building on <span class="citation" data-cites="gmbecker">@gmbecker</span> ’s work, which does just this using R versions built as Amazon EC2 AMIs. (See issue <a href="https://github.com/rocker-org/rocker-versioned/issues/1">#1</a>).</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/10/14/rocker-versioning.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/10/09/lessons-learned-in-writing-dockerfiles.html">Lessons Learned In Writing Dockerfiles</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 09 Oct 2014</p>

<article>
<div class="excerpt">
<p>Writing dockerfiles is pretty straight forward. Nevertheless, a little extra care goes a long way. Docker’s own <a href="https://docs.docker.com/articles/dockerfile_best-practices/">Best Practices</a> are a great starting point, covering everything from formatting to use of certain commands. In Rocker, We’ve tried to follow all of these suggestions and have found them very helpful. In particular:</p>
<ul>
<li><p>Minimize the number of layers, but use <code>\</code> to break commands across multiple lines,</p></li>
<li><p>Always run <code>apt-get update &amp;&amp; apt-get install -y ...</code> rather than running updates in one layer and install in a different layer,</p></li>
<li><p>Use <code>COPY</code> instead of <code>ADD</code>, <code>WORKDIR</code> instead of <code>cd</code>,</p></li>
<li><p>Create a non-root user</p></li>
</ul>
<p>This was tricky since we intend (and use) our dockerfiles as base images for other Dockerfiles. Setting the default user with <code>USER</code> would interfere with this (adding that user to sudoers, having to use <code>sudo apt-get update</code> or switch back to <code>USER root</code> and back again. Both <code>sudo</code> and switching back and forth on <code>USER</code> are discouraged in best practices)</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/10/09/lessons-learned-in-writing-dockerfiles.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/10/08/response-to-software-discovery-index-report.html">Response To Software Discovery Index Report</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 08 Oct 2014</p>

<article>
<div class="excerpt">
<p>The NIH has recently announced the <a href="http://softwarediscoveryindex.org/report">report</a> of a landmark meeting which presents a vision for a <em>Software Discovery Index</em> (SDI). The report is both timely and focused on the key issues of locating, citing, reusing software:</p>
<blockquote>
<p>Software developers face challenges disseminating their software and measuring its adoption. Software users have difficulty identifying the most appropriate software for their work. Journal publishers lack a consistent way to handle software citations or to ensure reproducibility of published findings. Funding agencies struggle to make informed funding decisions about which software projects to support, while reviewers have a hard time understanding the relevancy and effectiveness of proposed software in the context of data management plans and proposed analysis.</p>
</blockquote>
<p>To address this, they propose an Index which would do three things:</p>
<ol type="1">
<li>to assign standard and unambiguous identifiers to reference all software,</li>
<li>to track specific metadata features that describe that software, and</li>
<li>to enable robust querying of all relevant information for users.</li>
</ol>
<p>The report is both timely and focused on key issues confronting our community, including the challenges of identifying, citing, and reusing software. The appendices do an excellent job in outlining key metadata, metrics, and use cases which help frame the discussion. The proposal does well to focus on the importance of identifiers and the creation of a query-able metadata index for research software, but leaves out an essential element necessary to make this work.</p>
<p>This proposal sounds very much like the CrossRef and DataCite infrastructure already in place for academic literature and data, respectively; and indeed this is an excellent model to follow. However, a key piece of that infrastructure is missing from the present proposal – the social contract between repository or publisher and the index itself.</p>
<p>CrossRef provides unique identifiers for the academic literature (CrossRef DOIs), but it also defines specific metadata that describe that literature (as well as metrics of its use), and embed that information into a robust, query-able, machine-readable format. DataCite does the same for scientific data. These are exactly the features that the authors of the report seek to emulate.</p>
<p>Just as CrossRef itself does not host academic papers but only the metadata records, the SDI does not propose to host software itself. This introduces a substantial challenge in <em>maintaining the link</em> between the metadata and the software itself. The authors have simply proposed that the metadata include “Links to the code repository.” If CrossRef or DataCite DOIs worked in this way, we would soon loose all ability to recover many of the papers or the data itself, and we would be left with only access to the metadata record and a broken link. DOIs were created explicitly to solve this problem, not through technology, but through a <em>social contract</em>.</p>
<p>The scientific publishers who host the actual publications are responsible for ensuring that this link is always maintained when they change names, etc. Should the publisher go out of business, these links may be adjusted to point to a new home, such as <a href="http://clockss.org">CLOCKSS</a>. This guarantees that the DOI always resolves to the resource in question, regardless of where it moves. Should a publisher fail to maintain these links, CrossRef may refuse to provide the publisher any additional DOIs, cutting it off from this key index. This is the social contract. Data repositories work in exactly the same way, purchasing their DOIs from DataCite. (While financial transaction isn’t strictly necessary for the financial contract, it provides a clear business model for maintaining the key organization responsible for the index).</p>
<p>Without such a mechanism, links in the SDI would surely rot away, all the more rapidly in the fast-moving world of software. Without links to the software itself, the function of the index would be purely academic. Yet such a mechanism requires that the software repositories, not the individual software authors, would be willing to accept the same social contract, receiving (and possibly paying for) identifiers on the condition that they assume the responsibility of maintaining the links. It is unclear that the primary software repositories in use to day (Sourceforge, Github, Bitbucket, etc) would be willing to accept this.</p>
<p>Data repositories already offer many of the compelling features of this proposal. Many data repositories accept a wide array of file formats including software packages, and would provide such software with a permanent unique identifier in the form of a DataCite DOI, as well as collecting much of the essential metadata listed in report’s Appendix 1, which would then already be accessible through the DataCite API in a nice machine-readable format. This strategy finds several aspects wanting.</p>
<p>The primary barrier to using data repositories indexed by DataCite arises from the dynamic nature of software relative to data. Data repositories are designed to serve relatively static content with few versions. Software repositories, by contrast, are usually built upon explicit version control platforms such as Git or Subversion designed explicitly for handling continual changes, including branches and mergers, of software code. The report discusses the challenges of software versions as a reason for that citing a software paper as a proxy for citing software is not ideal: the citation to the paper does not convey what version was used. Rapid versioning creates other problems though, both in the number of identifiers that might be created (is each commit a new identifier?) and defining the relationship between different versions of the same software. Branches and merges exacerbate this problem. Existing approaches that provide the user a one-time way to import software from a software repository to a data repository such as those cited in the report (“One significant initiative is a collaboration between Mozilla, figshare, GitHub, and Zenodo”) do nothing to address this issues.</p>
<p>Less challenging issues involve resolving differences between DataCite metadata and the proposed metadata records for software. Most obviously, the metadata would need a way to declare the object involved software instead of data per se, which would thus allow queries to restrict results to ‘software’ objects to avoid cluttering searches. Ideally, one would also create tools that can import such metadata from the format in which it is usually already defined in software, into the desired format of the index, rather than requiring manual double-entry of this information. These are important but more straight-forward problems which the report already seeks to address.</p>
<hr />
<!-- comments
Ilya raises the question: Why not just use Github? I think it is important to note that:

a) Github isn't forever, repositories come and go all the time, or move to new links, etc

b) Re-creating and running an NIH-Github would be both expensive (Gitlab notwithstanding) and redundant -- researchers would continue to use Github etc.

c) Github provides somewhat limited query-able metadata, that doesn't capture even the minimal list of fields suggested by the report.
Leveraging existing scientific data repositories by linking them to versioned releases on software repositories addresses each of these problems.

-->


<!--
A. FRAMEWORK SUPPORTING THE SOFTWARE DISCOVERY INDEX
Unique identifiers
Connections to publishers
Use cases
Complementarity with the Data Discovery Index
B. CHALLENGES AND REMAINING QUESTIONS
Defining relevant software
Integrating with other repositories
Evaluating progress and distinguishing this from other efforts
C. IMPLEMENTATION ROADMAP
-->


 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/10/08/response-to-software-discovery-index-report.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

  </div>
</div> <!--end row -->

<div class="row socialicons">
  <div class="col-md-11 col-md-offset-1">
      <p> <a href="/archive.html"><i class="icon-calendar"></i> All entries by date</a></p> 
      <p> <a href="/categories.html"><i class="icon-list"></i> All entries by category</a> </p>
      <p> <a href="/tags.html"><i class="icon-tags"></i> All entries by tag</a> </p>
  </div> <!--end col-md-9 -->
</div> <!--end row -->




      <footer class="footer">

<!--************** FOAF information to social networks ***************************** -->
  <div class="row">
    <div class="col-md-3 col-xs-4 socialicons" style="font-size:20px" typeof="foaf:Person" about="http://www.carlboettiger.info#me">
      <p>
          <script type="text/javascript" src="/assets/js/obfuscate-email-link.js"></script> 

          <a rel="foaf:account" href="https://twitter.com/cboettig" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Twitter'); 
             return false;"><span class="showtooltip" title="follow me on twitter (reading, discussing)"><i class="fa fa-twitter"></i></span></a> 

          <a rel="foaf:account" href="https://github.com/cboettig" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Github'); 
             return false;"><span class="showtooltip" title="follow me on Github (code, research)"><i class="fa fa-github"></i></span></a>
      <!--
          <a rel="foaf:account" href="https://plus.google.com/" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'GPlus'); 
             return false;"><i class="fa fa-google-plus"></i></a>

          <a rel="foaf:account" href="http://www.mendeley.com/profiles/carl-boettiger" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Mendeley'); 
             return false;"><img src="/assets/img/icon-mendeley.png" /></a> 

           citations on google-scholar

           stackoverflow
      -->
      <a rel="foaf:weblog" type="application/atom+xml" href="/blog.xml"  
         class="showtooltip" title="RSS feeds for my blog-style entries. See the feed on my lab notebook (/atom.xml) to follow all entries instead." 
         onclick="recordOutboundLink(this, 'Outbound Links', 'RSS'); 
         return false;"><i class="fa fa-rss"></i></a>
       </p>
    </div>

    
    <!--**************** End social links **************************** -->


    <div class="col-md-4 col-md-offset-1 col-xs-4">
      <p><a onclick="recordOutboundLink(this, 'Outbound Links', 'ONS_claim'); return false;" href="http://onsclaims.wikispaces.com/"><img src="/assets/img/ons-aci2-icon.svg" alt="ONS" class="showtooltip" title="An Open Notebook Science (ONS) project claim: Entry provides all content (AC) immediately (I) or without significant delay.  See link for details"/></a></p>
    </div>


    <div class="col-md-3 col-md-offset-1 col-xs-4">
      <p>
      <a rel="license" property="http://creativecommons.org/ns#license" href="http://creativecommons.org/publicdomain/zero/1.0/" onclick="recordOutboundLink(this, 'Outbound Links', 'CC0'); return false;"><img src="/assets/img/cc-zero.svg" alt="CC0"/></a> 
      </p>
    </div>
  </div>


  
<!-- COinS metadata (for citation managers like Zotero etc), goes in body text -->
  <span
      class="Z3988" 
      title="ctx_ver=Z39.88-2004
      &amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc
      &amp;rfr_id=info%3Asid%2Focoins.info%3Agenerator
      &amp;rft.title=Lab Notebook
      &amp;rft.creator=Carl Boettiger
      &amp;rft.date=
      &amp;rft.language=EN
      &amp;rft.rights=CC0
      &amp;rft_id=http://www.carlboettiger.info/lab-notebook.html">
  </span>


</footer>




          <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->

    <!-- JQuery, used on a few pages (still?) -->
    <!-- <script type="text/javascript" src="/assets/js/jquery.js"></script> -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <!-- Equations using MathJax -->
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "all"} } });       </script>
    <!-- Twitter Bootstrap Javascript -->
    <!--  <script src="/assets/js/bootstrap.min.js"></script> -->
    <script src="//netdna.bootstrapcdn.com/bootstrap/3.1.1/js/bootstrap.min.js"></script>


    

        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-18401403-1']);
          _gaq.push(['_trackPageview']);
          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
  </script>



<script type="text/javascript">
function recordOutboundLink(link, category, action) {
  try {
    var pageTracker=_gat._getTracker("UA-18401403-1");
    pageTracker._trackEvent(category, action);
    setTimeout('document.location = "' + link.href + '"', 100)
  }catch(err){}
}
</script>




    </div>
  </body>
</html>
   
