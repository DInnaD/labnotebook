<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  <head prefix="dc: http://purl.org/dc/terms/ og: http://ogp.me/ns#"> <!-- namespaces used in metadata.html -->
  <meta http-equiv='Content-Type' content='text/html; charset=utf-8'/>
  <title>Lab Notebook</title>
  <meta name="author" content="Carl Boettiger" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <!-- HTML5 metadata -->
<meta name="keywords" content="" />
<meta name="description" content="" />
<!-- RDFa Metadata (in DublinCore) -->
<meta property="dc:title" content="Lab Notebook" />
<meta property="dc:creator" content="Carl Boettiger" />
<meta property="dc:date" content="" />
<meta property="dc:format" content="text/html" />
<meta property="dc:language" content="en" />
<meta property="dc:identifier" content="/lab-notebook.html" />
<meta property="dc:rights" content="CC0" />
<meta property="dc:source" content="Lab Notebook" />
<meta property="dc:subject" content="Ecology" /> 
<meta property="dc:type" content="website" /> 
<!-- RDFa Metadata (in OpenGraph) -->
<meta property="og:title" content="Lab Notebook" />
<meta property="og:author" content="http://www.carlboettiger.info/index.html#me" />  <!-- Should be Liquid? URI? -->
<meta property="http://ogp.me/ns/profile#first_name" content="Carl"/>
<meta property="http://ogp.me/ns/profile#last_name" content="Boettiger"/>
<meta property="http://ogp.me/ns/article#published_time" content="" />
<meta property="og:site_name" content="Lab Notebook" /> <!-- Same as dc:source? -->
<meta property="og:url" content="http://www.carlboettiger.info/lab-notebook.html" />
<meta property="og:type" content="website" /> 
<!-- Google Scholar Metadata -->
<!--
<meta name="citation_author" content="Carl Boettiger"/>
<meta name="citation_date" content=""/>
<meta name="citation_title" content="Lab Notebook"/>
<meta name="citation_journal_title" content="Lab Notebook"/>
-->
<!--NOTE: see also the COinS Metadata in span element in footer -->




  <link href="/assets/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
  <!-- Help the browser identify the RSS feed automatically -->
  <link rel="alternate" type="application/rss+xml" title="Carl Boettiger's Lab Notebook" href="/blog.xml" />
</head>


  <body prefix="dc: http://purl.org/dc/terms/ foaf: http://xmlns.com/foaf/0.1/"> 
    <!-- Navbar  ================================================== -->

<nav class="navbar navbar-default" role="navigation">
  <div class="container-fluid">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/README.html"><i class="icon-info-sign"></i></a>
    </div>

 <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">

          <li  >
          <a href="/index.html">Home</a></li>
          <li  >
          <a href="/vita.html">Vita</a></li>
          <li  >
          <a href="/research.html">Research</a></li>
          <li  >
          <a href="/teaching.html">Teaching</a></li>
          <li  >
          <a href="/community.html">Community</a></li>
          <li  class="active" >
          <a href="/lab-notebook.html">Lab Notebook</a></li>

        </ul>

      <!-- Search site using Google's index -->
        <form class="navbar-form navbar-right" role="search" method="get" action="http://google.com/search">
          <div class="form-group">
            <input type="hidden" name="q" value="site:carlboettiger.info" />
            <input type="text" class="form-control search-query" name="q" placeholder="Search"/>
          </div>
          <button class="btn btn-mini" type="submit"><i class="icon-search"></i></button> 
       </form>

    </div><!--/.nav-collapse -->
  </div> <!-- /container -->
</nav>



    <div class="container"> <!-- Responsive grid layout, doesn't jump to full-width --> 
      <header>
        <h1 class="entry-title">Lab Notebook</h1>
        <h2>(<a href="http://www.carlboettiger.info/2012/09/28/Welcome-to-my-lab-notebook.html">Introduction</a>)</h2>
      </header>

      <div class="row feed">
  <div class="col-md-3 col-md-offset-1">
    <h4>  <a property="account" href="https://github.com/cboettig" onclick="recordOutboundLink(this, 'Outbound Links', 'Github'); return false;"><i class="icon-github" alt="github"></i> Coding </a></h4> 
    <div class="excerpt">
      <div class="scroll">
        <ul><li>cboettig pushed to master at cboettig/labnotebook: <em>unpub drafts</em> <a href="https://github.com/cboettig/labnotebook/compare/75c3c06c5d...991d999bec">05:47 2014/10/28</a></li><li>cboettig pushed to master at cboettig/labnotebook: <em>notes update sha and Dockerfile</em> <a href="https://github.com/cboettig/labnotebook/compare/42495a09a9...75c3c06c5d">05:46 2014/10/28</a></li><li>cboettig commented on pull request swcarpentry/site#650: <em>Ah, that makes sense. Then https://github.com/gvwilson/subdir/blob/gh-pages/src/Makefile would probably want to add the -s flag to the pandoc comma…</em> <a href="https://github.com/swcarpentry/site/pull/650#discussion_r19488575">05:35 2014/10/28</a></li><li>cboettig forked gvwilson/subdir to cboettig/subdir: <em></em> <a href="https://github.com/cboettig/subdir">05:24 2014/10/28</a></li><li>cboettig commented on pull request swcarpentry/site#650: <em>It's not clear how this approach handles HTML templating, CSS, etc. Ideally you'd want this to be part of the Jekyll yaml header in the markdown. N…</em> <a href="https://github.com/swcarpentry/site/pull/650#discussion_r19487473">05:23 2014/10/28</a></li></ul>
      </div>
    </div>
  </div>
  <div class="col-md-3">
    <h4> <a property="account" href="https://twitter.com/cboettig" onclick="recordOutboundLink(this, 'Outbound Links', 'Twitter'); return false;"><i class="icon-twitter"></i> Discussing </a></h4> 
     <div class="excerpt">
      <div class="scroll">
       <ul><li><p>RT @arfon: Pretty sure this would work well in academia too: The living future of technical writing by @chacon - <a href="https://t.co/CSWQ2rkJER">https://t.co/CSWQ2rkJER</a></p>
 <a href="http://twitter.com/cboettig/statuses/526876582002962432">11:22 2014/10/27</a> </li><li><p>RT @ucfagls: Non-academic careers for ecologists: data science - guest post on @DynamicEcology by @DistribEcology <a href="http://t.co/vqchoOH7zi">http://t.co/vqchoOH7zi</a></p>
 <a href="http://twitter.com/cboettig/statuses/526875700406390785">11:18 2014/10/27</a> </li><li><p>@BrunaLab @carlystrasser @caseybergman @ethanwhite @ucfagls @_inundata sounds cool to me</p>
 <a href="http://twitter.com/cboettig/statuses/525711769000759296">06:13 2014/10/24</a> </li><li><p>RT @algaebarnacle: Great discussion going on at @DynamicEcology on what math ecologists should learn. See comments for a reading list! http…</p>
 <a href="http://twitter.com/cboettig/statuses/525682185978646528">04:16 2014/10/24</a> </li><li><p>RT @mwpennell: Think the rise if preprint culture is great. Just wish it was accompanied by a decline in PDF culture. I want to read your p…</p>
 <a href="http://twitter.com/cboettig/statuses/525682146095034369">04:16 2014/10/24</a> </li></ul>
      </div>
    </div> 
  </div> 
  <div class="col-md-3">
    <h4> <a href="http://www.mendeley.com/groups/634301/theoretical-ecology/papers/" onClick="recordOutboundLink(this, 'Outbound Links', 'Mendeley'); return false;"><i class="icon-book"></i> Reading </a></h4> 
    <div class="excerpt">
      <div class="scroll">
<ul><li>Collapse of an ecological network in Ancient Egypt: Pages: 1-6. Justin D Yeakel, Mathias M Pires, Lars Rudolf, Nathaniel J Dominy, Paul L Koch et al. <a href="http://www.mendeley.com/c/7145752934/g/634301/yeakel-2014-collapse-of-an-ecological-network-in-ancient-egypt/">07:35 2014/09/11</a></li><li>Regime shifts in models of dryland vegetation Regime shifts in models of dryland vegetation: Yuval R Zelnik, Shai Kinast, Hezi Yizhaq, Golan Bel, Ehud Meron, Phil Trans R Soc A et al.Published using Mendeley: The library management tool for researchers <a href="http://www.mendeley.com/c/7145752914/g/634301/zelnik-2013-regime-shifts-in-models-of-dryland-vegetation-regime-shifts-in-models-of-dryland-vegetation/">07:35 2014/09/11</a></li><li>Temporal ecology in the Anthropocene: Ecology Letters (2014). Pages: n/a-n/a. E. M. Wolkovich, B. I. Cook, K. K. McLauchlan, T. J. Davies et al. <a href="http://www.mendeley.com/c/7145752874/g/634301/wolkovich-2014-temporal-ecology-in-the-anthropocene/">07:35 2014/09/11</a></li><li>Uncertainty , learning , and the optimal management of wildlife: Environmental and Ecological Statistics (2001). Volume: 8, Issue: 3. Pages: 269-288. Byron K. Williams et al. <a href="/catalog/uncertainty-learning-optimal-management-wildlife/">08:57 2014/08/06</a></li></ul>
      </div>
    </div>
  </div> 
</div>

<hr>
<div class="row postpreview">
  <div class="col-md-11 col-md-offset-1">
    <div class="row">
      <h4> <a href="http://www.carlboettiger.info/atom.xml"
              onClick="recordOutboundLink(this,
              'Outbound Links', 'RSS'); return false;"
              style="color: inherit;"
              ><i class="icon-rss" ></i> Entries</a></h4>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/10/16/gitlab-and-other-configuration-notes.html">Gitlab And Other Configuration Notes</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 16 Oct 2014</p>

<article>
<div class="excerpt">
<p>Updating gitlab setup:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">docker</span> pull sameersbn/redis:latest
<span class="kw">docker</span> pull sameersbn/gitlab:7.3.2-1
<span class="kw">docker</span> pull sameersbn/postgresql:latest


<span class="kw">mkdir</span> -p /opt/gitlab/data
<span class="kw">mkdir</span> -p /opt/postgresql/data

<span class="kw">docker</span> run --name=postgresql -d \
  <span class="kw">-e</span> <span class="st">&#39;DB_NAME=gitlabhq_production&#39;</span> -e <span class="st">&#39;DB_USER=gitlab&#39;</span> -e <span class="st">&#39;DB_PASS=password&#39;</span> \
  <span class="kw">-v</span> /opt/postgresql/data:/var/lib/postgresql \
  <span class="kw">sameersbn</span>/postgresql:<span class="kw">latest</span>
<span class="kw">docker</span> run --name=redis -d sameersbn/redis:latest

<span class="kw">docker</span> run --name=gitlab -d \
  <span class="kw">--link</span> postgresql:postgresql \
  <span class="kw">--link</span> redis:redisio \
  <span class="kw">-p</span> 10080:80 -p 10022:22 \
  <span class="kw">-v</span> /opt/gitlab/data:/home/git/data \
    <span class="kw">sameersbn</span>/gitlab:<span class="kw">7.3.2-1</span></code></pre>
<p>More consisely, do this with <a href="http://fig.sh">fig</a></p>
<pre class="sourceCode yaml"><code class="sourceCode yaml"><span class="fu">gitlab:</span>
  <span class="fu">image:</span> sameersbn/gitlab:7.3.2-1
  <span class="fu">links:</span>
   <span class="kw">-</span> postgres
   <span class="kw">-</span> <span class="fu">redis:</span>redisio
  <span class="fu">ports:</span>
   <span class="kw">-</span> <span class="st">&quot;10080:80&quot;</span>
   <span class="kw">-</span> <span class="st">&quot;10022:22&quot;</span>
  <span class="fu">volumes:</span>
    <span class="kw">-</span> <span class="fu">/opt/gitlab/data:</span>/home/git/data
  <span class="fu">environment:</span>
    <span class="kw">-</span> SMTP_USER=USER@gmail.com
    <span class="kw">-</span> SMTP_PASS=PASSWORD

<span class="fu">postgres:</span>
  <span class="fu">image:</span> postgres:latest
  <span class="fu">volumes:</span>
    <span class="kw">-</span> <span class="fu">/opt/postgresql/data:</span>/var/lib/postgresql
  <span class="fu">environment:</span>
    <span class="kw">-</span> POSTGRESQL_USER=gitlab
    <span class="kw">-</span> POSTGRESQL_PASS=
    <span class="kw">-</span> POSTGRESQL_DB=gitlabhq_production
<span class="fu">redis:</span>
  <span class="fu">image:</span> redis:2.8.9</code></pre>
<p>Hmm… memory error using the <code>fig</code> approach; doesn’t happen when running individual containers as above…</p>
<p>Looks like we have to run the original version if we want to keep our database. But no go since sql database information is lost:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">docker</span> pull gitlab:7.2.1-1
<span class="kw">docker</span> run --name=gitlab -d \
  <span class="kw">-p</span> 10080:80 -p 10022:22 \
  <span class="kw">-v</span> /opt/gitlab/data:/home/git/data \
    <span class="kw">sameersbn</span>/gitlab:<span class="kw">7.2.1-1</span>
<span class="kw">docker</span> stop gitlab
<span class="kw">docker</span> run --rm -it \
  <span class="kw">-p</span> 20080:80 -p 20022:22 \
  <span class="kw">-v</span> /opt/gitlab/data:/home/git/data \
    <span class="kw">sameersbn</span>/gitlab:<span class="kw">7.2.1-1</span> app:rake gitlab:backup:restore
<span class="kw">docker</span> restart gitlab</code></pre>
<h2 id="drone">Drone</h2>
<p>Ah, Drone now provides their own Dockerfile, which we can grab and build for the latest Drone:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">git</span> clone https://github.com/drone/drone.git
<span class="kw">docker</span> build -t drone/drone drone</code></pre>
<p>Then we can run, linking volumes appropriately:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">docker</span> run --name drone -d -p 88:80 \
<span class="kw">-v</span> /var/run/docker.sock:/var/run/docker.sock \
<span class="kw">-t</span> \
<span class="kw">-e</span> DRONE_GITHUB_CLIENT=<span class="kw">&lt;</span>clientkey<span class="kw">&gt;</span> \
<span class="kw">-e</span> DRONE_GITHUB_SECRET=<span class="kw">&lt;</span>secretkey<span class="kw">&gt;</span> \
<span class="kw">drone/drone</span><span class="st">&quot;</span></code></pre>
<p>Note that this doesn’t work with a <code>drone.toml</code> file even when linking volumes etc., see <a href="https://github.com/drone/drone/issues/580">#580</a>.</p>
<p>Also note that this setup shares docker images with the host machine, rather than having a seperate library, which is rather good for saving space. I believe this should be trivial to back-up (just by exporting the container), but have to test that stil.</p>
<p>These rather verbose docker calls for drone and gitlab make a great use-case for fig. Unfortunately, fig seems to crash out of memory on my tiny DO droplet, but running these commands manually works like a charm.</p>
<h2 id="digitalocean">DigitalOcean</h2>
<p>Ooh: configure scripts for starting DO droplets. e.g. automate the launch of <a href="https://www.digitalocean.com/community/tutorials/how-to-use-cloud-config-for-your-initial-server-setup">a more secure configuration</a>, looks like a more formal way than my shell script. /ht <span class="citation" data-cites="hadley">@hadley</span>.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/10/16/gitlab-and-other-configuration-notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/10/14/rocker-versioning.html">Rocker Versioning</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 14 Oct 2014</p>

<article>
<div class="excerpt">
<p>Been looking into building versioned images for previous R releases using Docker, based on somewhat common requests to our recently begun <a href="http://github.com/rocker-org">rocker</a> project. Versioning is under early development and the best way to go about this is not yet clear. Getting the correct version of R installed is not always trivial but is relatively straight forward, and I outline two approaches below.</p>
<p>Getting the correct version of packages (or even merely any compatible version of the package) to install is a considerably more difficult problem, which I’ll discuss later.</p>
<p>We’re is considering two different strategies, each with strengths and weaknesses:</p>
<h2 id="compiled-builds">Compiled builds</h2>
<p>The most straight-forward recipe seems to be to adapt the <code>rocker/r-devel</code> file to compile the desired version by pulling from the appropriate tag in the R SVN repository, as suggested by <span class="citation" data-cites="eddelbuettel">@eddelbuettel</span></p>
<p>As Dirk suggested, we can build on the r-devel recipe, simply by pointing to the appropriate tag. Occasionally this needs a few extra packages added to the list. I was able to get R 2.0.0 to compile, but not R 1.0.0. More recent versions than 2.0.0 don’t seem to pose any difficulty for compiling. Nonetheless, installing additional packages is still an issue.</p>
<h2 id="binary-builds">Binary builds</h2>
<p>At different approach is to use the binary versions from old Debian images. This approach works rather well when docker images are available for earlier Debian releases (<code>oldstable</code> and <code>stable</code>, which currently go back as far as Debian <code>6.0</code> and <code>7.0</code>; while the main rocker release builds on Debian <code>testing</code> which is at <code>8.0</code>). Merely using the earlier Debian releases, we can jump back to certain versions of R:</p>
<ul>
<li>6.0 : R 2.11.1</li>
<li>7.0 : R 2.15.1</li>
</ul>
<p>The advantage of this is that binary forms of many common R packages may also be available from the same repositories.</p>
<p>Dirk <span class="citation" data-cites="eddelbuettel">@eddelbuettel</span> also suggests looking at <a href="http://snapshot.debian.org/">Debian snapshot archive</a> binaries. This allows us to install intermediate versions of R in binary form, as well as specific versions of any package for which debian binaries have been built. The brilliant bit about this is that we can add any particular snapshot time-period as a normal repository, e.g.</p>
<pre><code>deb     http://snapshot.debian.org/archive/debian/20091004T111800Z/ lenny main
deb-src http://snapshot.debian.org/archive/debian/20091004T111800Z/ lenny main
deb     http://snapshot.debian.org/archive/debian-security/20091004T121501Z/ lenny/updates main
deb-src http://snapshot.debian.org/archive/debian-security/20091004T121501Z/ lenny/updates main</code></pre>
<p>and the package manage can thus handle all the dependencies. As noted, this works only for those packages for which we have debian binaries available in the release.</p>
<p>This is limited to what we can use as a base image, particularly for old versions of R where the binaries are only available for i386 architectures (while there are some Docker images providing i386 architectures, we’ve so far used only amd64 versions). Given the rapid growth of R however, it is likely that the preponderance of use-cases will focus on relatively recent R versions.</p>
<p>Unfortunately, I haven’t gotten this working yet (See issue <a href="https://github.com/rocker-org/rocker-versioned/issues/2">#2</a>).</p>
<h2 id="installing-r-packages">Installing R packages</h2>
<p>Installing packages directly from CRAN is more dubious. We may be able to install earlier versions of particular packages from the CRAN archives using the CRAN data from <a href="https://github.com/metacran/crandb">metacran/crandb</a> as <span class="citation" data-cites="hadley">@hadley</span> recommended.</p>
<p>Hoping that we can do this more generally by building on <span class="citation" data-cites="gmbecker">@gmbecker</span> ’s work, which does just this using R versions built as Amazon EC2 AMIs. (See issue <a href="https://github.com/rocker-org/rocker-versioned/issues/1">#1</a>).</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/10/14/rocker-versioning.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/10/08/response-to-software-discovery-index-report.html">Response To Software Discovery Index Report</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 08 Oct 2014</p>

<article>
<div class="excerpt">
<p>The NIH has recently announced the <a href="http://softwarediscoveryindex.org/report">report</a> of a landmark meeting which presents a vision for a <em>Software Discovery Index</em> (SDI). The report is both timely and focused on the key issues of locating, citing, reusing software:</p>
<blockquote>
<p>Software developers face challenges disseminating their software and measuring its adoption. Software users have difficulty identifying the most appropriate software for their work. Journal publishers lack a consistent way to handle software citations or to ensure reproducibility of published findings. Funding agencies struggle to make informed funding decisions about which software projects to support, while reviewers have a hard time understanding the relevancy and effectiveness of proposed software in the context of data management plans and proposed analysis.</p>
</blockquote>
<p>To address this, they propose an Index which would do three things:</p>
<ol type="1">
<li>to assign standard and unambiguous identifiers to reference all software,</li>
<li>to track specific metadata features that describe that software, and</li>
<li>to enable robust querying of all relevant information for users.</li>
</ol>
<p>The report is both timely and focused on key issues confronting our community, including the challenges of identifying, citing, and reusing software. The appendices do an excellent job in outlining key metadata, metrics, and use cases which help frame the discussion. The proposal does well to focus on the importance of identifiers and the creation of a query-able metadata index for research software, but leaves out an essential element necessary to make this work.</p>
<p>This proposal sounds very much like the CrossRef and DataCite infrastructure already in place for academic literature and data, respectively; and indeed this is an excellent model to follow. However, a key piece of that infrastructure is missing from the present proposal – the social contract between repository or publisher and the index itself.</p>
<p>CrossRef provides unique identifiers for the academic literature (CrossRef DOIs), but it also defines specific metadata that describe that literature (as well as metrics of its use), and embed that information into a robust, query-able, machine-readable format. DataCite does the same for scientific data. These are exactly the features that the authors of the report seek to emulate.</p>
<p>Just as CrossRef itself does not host academic papers but only the metadata records, the SDI does not propose to host software itself. This introduces a substantial challenge in <em>maintaining the link</em> between the metadata and the software itself. The authors have simply proposed that the metadata include “Links to the code repository.” If CrossRef or DataCite DOIs worked in this way, we would soon loose all ability to recover many of the papers or the data itself, and we would be left with only access to the metadata record and a broken link. DOIs were created explicitly to solve this problem, not through technology, but through a <em>social contract</em>.</p>
<p>The scientific publishers who host the actual publications are responsible for ensuring that this link is always maintained when they change names, etc. Should the publisher go out of business, these links may be adjusted to point to a new home, such as <a href="http://clockss.org">CLOCKSS</a>. This guarantees that the DOI always resolves to the resource in question, regardless of where it moves. Should a publisher fail to maintain these links, CrossRef may refuse to provide the publisher any additional DOIs, cutting it off from this key index. This is the social contract. Data repositories work in exactly the same way, purchasing their DOIs from DataCite. (While financial transaction isn’t strictly necessary for the financial contract, it provides a clear business model for maintaining the key organization responsible for the index).</p>
<p>Without such a mechanism, links in the SDI would surely rot away, all the more rapidly in the fast-moving world of software. Without links to the software itself, the function of the index would be purely academic. Yet such a mechanism requires that the software repositories, not the individual software authors, would be willing to accept the same social contract, receiving (and possibly paying for) identifiers on the condition that they assume the responsibility of maintaining the links. It is unclear that the primary software repositories in use to day (Sourceforge, Github, Bitbucket, etc) would be willing to accept this.</p>
<p>Data repositories already offer many of the compelling features of this proposal. Many data repositories accept a wide array of file formats including software packages, and would provide such software with a permanent unique identifier in the form of a DataCite DOI, as well as collecting much of the essential metadata listed in report’s Appendix 1, which would then already be accessible through the DataCite API in a nice machine-readable format. This strategy finds several aspects wanting.</p>
<p>The primary barrier to using data repositories indexed by DataCite arises from the dynamic nature of software relative to data. Data repositories are designed to serve relatively static content with few versions. Software repositories, by contrast, are usually built upon explicit version control platforms such as Git or Subversion designed explicitly for handling continual changes, including branches and mergers, of software code. The report discusses the challenges of software versions as a reason for that citing a software paper as a proxy for citing software is not ideal: the citation to the paper does not convey what version was used. Rapid versioning creates other problems though, both in the number of identifiers that might be created (is each commit a new identifier?) and defining the relationship between different versions of the same software. Branches and merges exacerbate this problem. Existing approaches that provide the user a one-time way to import software from a software repository to a data repository such as those cited in the report (“One significant initiative is a collaboration between Mozilla, figshare, GitHub, and Zenodo”) do nothing to address this issues.</p>
<p>Less challenging issues involve resolving differences between DataCite metadata and the proposed metadata records for software. Most obviously, the metadata would need a way to declare the object involved software instead of data per se, which would thus allow queries to restrict results to ‘software’ objects to avoid cluttering searches. Ideally, one would also create tools that can import such metadata from the format in which it is usually already defined in software, into the desired format of the index, rather than requiring manual double-entry of this information. These are important but more straight-forward problems which the report already seeks to address.</p>
<hr />
<!-- comments
Ilya raises the question: Why not just use Github? I think it is important to note that:

a) Github isn't forever, repositories come and go all the time, or move to new links, etc

b) Re-creating and running an NIH-Github would be both expensive (Gitlab notwithstanding) and redundant -- researchers would continue to use Github etc.

c) Github provides somewhat limited query-able metadata, that doesn't capture even the minimal list of fields suggested by the report.
Leveraging existing scientific data repositories by linking them to versioned releases on software repositories addresses each of these problems.

-->


<!--
A. FRAMEWORK SUPPORTING THE SOFTWARE DISCOVERY INDEX
Unique identifiers
Connections to publishers
Use cases
Complementarity with the Data Discovery Index
B. CHALLENGES AND REMAINING QUESTIONS
Defining relevant software
Integrating with other repositories
Evaluating progress and distinguishing this from other efforts
C. IMPLEMENTATION ROADMAP
-->


 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/10/08/response-to-software-discovery-index-report.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

    <div class="row">
      
        <div class="col-md-3">
          <header><h4><a href="/2014/10/02/notes.html">Notes</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 02 Oct 2014</p>

<article>
<div class="excerpt">
<h2 id="docker">docker</h2>
<p>2014-09-29:</p>
<ul>
<li>Discussion with Dirk on repositories, library paths, versions.</li>
<li>library paths: apt-get users the <code>usr/lib</code> path, while user-run install commands (e.g. <code>install.packages</code>) uses <code>usr/local/lib/</code>, path. Dirk recommends that <code>/usr/local/lib/R/site-library</code> is configured to be user-writable for package installation, rather than installing into home.</li>
<li>building directly from CRAN</li>
<li>building dependencies: <code>apt-get build-dep</code>, needs the corresponding <code>deb-src</code> lines.</li>
<li>issues and tweaks to littler see <a href="https://github.com/eddelbuettel/littler/pull/2">PR #2</a></li>
</ul>
<p>2014-10-01:</p>
<ul>
<li>Discussion on <a href="https://github.com/ropensci/docker/issues/5">minimal images</a></li>
<li>Discussion on <a href="https://github.com/sckott/analogsea/issues/47">analogsea + docker</a></li>
<li><p>Blog <a href="http://www.magesblog.com/2014/09/running-rstudio-via-docker-in-cloud.html">coverage</a> of Dirk’s talk on our Docker work.</p></li>
<li><p><a href="https://github.com/boot2docker/boot2docker-cli">boot2docker-cli</a> includes linux flavors, so I might get a look at what the docker experience feels like for those poor souls who can only live it through full virutalization. No go on the install methods listed, but the binary seems to work. Unfortunately my laptop cannot run 64 bit virtualbox…</p></li>
</ul>
<p>2014-10-02:</p>
<ul>
<li><a href="https://docs.docker.com/articles/dockerfile_best-practices/">Official Dockerfile Best Practices</a></li>
<li>See <code>rocker</code> commit log and issues log.</li>
</ul>
<p>2014-09-29:</p>
<ul>
<li>Carsten’s suggestion re docker registeries, is this something that scientific repositories might one day support? (Excerpt from my reply post):</li>
</ul>
<blockquote>
<p>While I see your point that the Docker Hub might not be ideal for all cases, I think the most important attribute of a repository should be longevity. Certainly Docker Hub won’t be around forever, but at this stage with 60 million in it’s latest VC round it’s likely to be more long-lasting than anything that a small organization like rOpenSci would host. It would be great to see existing scientific repositories show an interest in archiving images in this way though, since organizations like DataONE and Dryad already have recognition in the scientific community and better discoverability / search / metadata features. Building of the docker registry technology would of course make a lot more sense than just archiving static binary docker images, which lack both the space saving features and the ease of download / integration that examples like the docker registry have.</p>
</blockquote>
<blockquote>
<p>I think it would be interesting to bring that discussion to some of the scientific data repositories and see what they say. Of course there’s the chicken &amp; egg problem in that most researchers have never heard of docker. Would be curious what others think of this.</p>
</blockquote>
<h2 id="reading">Reading</h2>
<ul>
<li>on <a href="http://theincidentaleconomist.com/wordpress/how-do-you-do-it-all/">productivity</a>; surprisingly resonates with me.</li>
<li>SWC discussion on teaching material in semester courses. In particular see <a href="http://www.programmingforbiologists.org">Ethan White’s course</a></li>
<li>SWC and MozillaScience mention starting a repo for <a href="https://github.com/mozillascience/codeReview">code review best practices</a></li>
<li>Katz slides: <a href="http://www.slideshare.net/danielskatz/valuing-software-and-other-research-outputs">valuing software and other research outputs</a> <!-- Query to Dan Katz --></li>
</ul>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/10/02/notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/09/24/notes.html">Notes</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 24 Sep 2014</p>

<article>
<div class="excerpt">
<h2 id="rocker-docker">rocker / docker</h2>
<ul>
<li>Talking over strategy with Dirk, see summary in <a href="https://github.com/eddelbuettel/rocker/issues/1">#1</a> and follow-up issues, <a href="https://github.com/eddelbuettel/rocker/issues/3">#3</a>, <a href="https://github.com/eddelbuettel/rocker/issues/4">#4</a>, <a href="https://github.com/eddelbuettel/rocker/issues/5">#5</a>.</li>
</ul>
<h2 id="rdataone-eml">rdataone &amp; EML</h2>
<p>Trying to fix travis issues. Much craziness.</p>
<p><code>travis.sh</code> doesn’t provide notes on setup for repos where the R package is in a subdirectory. Looks like <code>cd</code> commands are persistent though throughout a travis file. okay.</p>
<ul>
<li><p><code>dataone</code> is imported by EML but suggested by <code>dataone</code>. Since <code>install_github</code> likes to install the suggests list, this creates problems:</p></li>
<li><p><code>travis.sh install_github</code> has no way to indicate that I don’t want to install suggests list.</p></li>
<li><p><code>install_github(&quot;DataONEorg/dataone/dataone&quot;, dependencies=NA)</code> should get around this by not installing the suggested EML package when trying to install <code>dataon</code>. For reasons inexplicable to me, that doesn’t seem to work(!), at least on travis. I’ve had to remove the package from the suggests list.</p></li>
</ul>
<p>The build environment often seems a lot more fragile than the package itself. EML travis builds were rather badly broken with both <code>dataone</code> and <code>rrdf</code> disappearing from CRAN. If we were installing them from the ubuntu binaries, of course this wouldn’t be quite as common a problem. Or even better, if our build environment came as a custom docker image. Fixing this is not completely trivial: we now have to install these packages from github, which in the case of rrdf means installing the latex build environment simply to build the rrdf vignette that we don’t need.</p>
<p>While these issues can no doubt frustrate users as well, I’m not convinced that CI should really be testing build environment problems when I want it to be testing changes I’m making to my package. In the big picture, we need more stable build environments, and of course I’m asking for trouble by depending on lots of packages, particularly new, complex and otherwise fragile packages, so this testing is valuable. But on the other hand, this mostly just gets in the way. Ideally I should be able to point to a stable build environment and just ignore changes to the later packages until I want to deal with them. That’s what most users do with their own systems – not upgrading their personal libraries, distributions, etc, until they are ready to deal with anything that breaks. Being forced onto the bleeding edge all the time forces me to waste considerable time or accept a broken CI state that need not actually be broken.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/09/24/notes.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/09/22/containerizing-my-development-environment.html">Containerizing My Development Environment</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 22 Sep 2014</p>

<article>
<div class="excerpt">
<p>A key challenge for reproducible research is developing solutions that integrate easily into a researcher’s existing workflow. Having to move all of one’s development onto remote machines, into a particular piece of workflow software or IDE, or even just constrained to a window running a local virtual machine in an unfamiliar or primitive environment isn’t particularly appealing. In my experience this doesn’t reflect the workflow of even those folks already concerned about reproducibility, and is, I suspect, a major barrier in adoption of such tools.</p>
<p>One reason I find docker particularly attractive for reproducible research it the idea of containerizing my development environment into something I can transport or recreate identically anywhere, particularly on another Linux machine. This also provides a convenient backup system for my development environment, no need to remember each different program or how I installed or configured it when moving to a new machine.</p>
<h2 id="using-aliases">Using aliases</h2>
<p>For me, a convenient way to do this involves creating a simple alias for running a container. This allows me to distinguish between running any software and the container, while managing my files and data through my native operating system tools. I’ve set the following alias in my <code>bashrc</code>.</p>
<pre><code>alias c=&#39;docker run --rm -it -v $(pwd):/home/$USER/`basename $PWD` -w /home/$USER/`basename $PWD` -e HOME=$HOME -e USER=$USER --user=$USER strata&#39;</code></pre>
<p>I can then just do <code>c R</code> (think <code>c</code> for container) to get R running in a container, <code>c bash</code> to drop into a bash shell on the container, <code>c pandoc --version</code> echoes the version of pandoc available on our container (or otherwise execute the container version of pandoc), and so forth.</p>
<h3 id="explanation-a-non-root-container">explanation: a non-root container</h3>
<p>The trick here is primarily to handle permissions appropriately. Docker is run as a root user by default, which results in any files created or modified become owned by root instead of the user, which is clearly not desirable. Getting around this requires quite a bit of trickery. The break down of each of these arguments is as follows:</p>
<ul>
<li><code>--rm</code> remove this container when we quit, we don’t need to let it persist as a stopped container we could later return to.</li>
<li><code>-it</code> Interactive terminal</li>
<li><code>-v</code> binds a host volume to the container. Files on the host working directory (<code>pwd</code>) will be available on the container, and changes made on the container are immediately written to the host directory:</li>
</ul>
<pre><code>-v $(pwd):/home/$USER/`basename $PWD`</code></pre>
<p>The path after the colon specifies where this directory should live on the container: we specify in a directory that has the same name as the current working directory <code>basename $PWD</code>, located in the home directory of the user (e.g. where the user has write permissions).</p>
<ul>
<li><code>-w</code> specifies the working directory we should drop into when our session on the container starts. We set this to match the path where we have just mounted our current working directory:</li>
</ul>
<pre><code>-w /home/$USER/`basename $PWD`</code></pre>
<ul>
<li><p><code>-e HOME=$HOME</code> sets the value of the environmental variable <code>HOME</code> to whatever it is on the host machine (e.g. <code>/home/username</code>), so that when R tries to access <code>~/</code>, it gets the user’s directory and not the root directory.</p></li>
<li><p><code>-e USER=$USER</code> though this seems redundant, we set the user environmental variable by default in the cboettig/rstudio image, so this overrides that environmental variable with the current user.</p></li>
<li><p><code>--user=$USER</code> Specifies the user we log in as. This is rather important, otherwise the we find that we are the root (or whatever user has been set in the Dockerfile). That would cause any files we generate from the container to be owned by the root user, not our local user. Note that this only works if the specific user has already been created (e.g. by <code>adduser</code>) on the container, otherwise this will fail.</p></li>
<li><p><code>strata</code> the name of the container (could be <code>cboettig/ropensci</code>, but my <code>strata</code> image provides a few additional customizations, created by <a href="">it’s own Dockerfile</a>. That Dockerfile (and its FROM dependencies) specify all the software available on this container. Importantly, it also already creates my username in it’s Dockerfile. Otherwise, the argument given above should use <code>--user=rstudio</code>, since the <code>rstudio</code> user is already created by the base image <code>cboettig/rstudio</code>, and thus available in <code>cboettig/ropensci</code> and <code>strata</code>. Note that this user can be created interactively by passing the environmental variable <code>-e USER=$USER</code> when running in deamon mode, since the user is then created by the start-up script. However, when we provide a custom command (like <code>/usr/bin/R</code> in this example, the <code>CMD</code> from the Dockerfile is overriden and the user isn’t created.</p></li>
</ul>
<p>A stricter alias I considered first enforces running R as a container rather than a local operation:</p>
<pre><code>alias R=&#39;docker run --rm -it -v $(pwd):/home/$USER/`basename $PWD` -w /home/$USER/`basename $PWD` -e HOME=$HOME --user=$USER strata /usr/bin/R&#39;</code></pre>
<h2 id="why-not-separate-containers-per-application">Why not separate containers per application?</h2>
<p>A more natural / more docker-esque approach might simply be to have separate containers for each application (R, pandoc, etc). This idealism belies the fact that I already need many of these tools installed on the same container, as they regularly interact in a deep way (e.g. R packages like <code>rmarkdown</code> already depend on pandoc), so these should really be thought of as a single development environment.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/09/22/containerizing-my-development-environment.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

    <div class="row">
      
        <div class="col-md-3">
          <header><h4><a href="/2014/09/09/server-backups.html">Server Backups</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 09 Sep 2014</p>

<article>
<div class="excerpt">
<h2 id="digital-ocean-snapshots">Digital Ocean Snapshots</h2>
<p>At $0.02 per gig per month, this looks like this is the cheapest way to make complete backups.</p>
<p>The process is rather manual: we have to <code>sudo poweroff</code> the droplet and then trigger the snapshot (the container will come back online after that, though we have to restart the services / active docker containers). We also have to delete old snapshots manually. Some of this can be automated from the API. DigitalOcean uses redundant storage for these (paying $0.01/month/gigabyte to Amazon Glacier), but at the moment we can’t export these images. Snapshots are also handy to deploy to a larger (but not smaller) droplet.</p>
<h3 id="digital-ocean-backups">Digital Ocean Backups</h3>
<p>These backups are an automated, always-online alternative to snapshots but must me initialized when the droplet is created and cost more (20% of server cost).</p>
<h2 id="manually-configuring-backups">Manually configuring backups</h2>
<p>To have the flexibility to restore individual pieces, to move between machines, etc we need a different approach.</p>
<h3 id="container-backups">Container backups</h3>
<p>Docker containers, including running containers, should be effectively backed up by either of these approaches to the state we would be in after a power cycle (e.g. we may need to start stopped containers, but not rebuild them from scratch).</p>
<p>Nevertheless we may want to back up containers themselves. For many containers this is trivial (e.g. our ssh container): we can just commit the running container to an image and save that as a tar archive (or equivalently, just export the container to a tarball).</p>
<p>If the containers have a <code>VOLUME</code> command in their dockerfile or in their execution however, this is insufficient. Containers using volumes (such as <code>sameersbn/gitlab</code> and <code>mattgruter/drone</code>) need <a href="http://serverfault.com/questions/576490/docker-volume-backup-and-restore">four things</a> to be backed up:</p>
<ul>
<li>Dockerfile (or container image, from <code>save</code> or <code>commit</code>)</li>
<li>volume</li>
<li>volume path in container</li>
<li>name of the container the volume belongs to</li>
</ul>
<p>A <a href="https://github.com/discordianfish/docker-backup">utility</a> makes this easier.</p>
<h3 id="sparkleshare">Sparkleshare</h3>
<p>Sparkleshare is a git-backed dropbox alterantive. With binaries for most major platforms (Windows, Mac, Ubuntu/Linux) it’s pretty easy to set up and acts in much the same way, with automated synch and notifications. The backend just needs a server running git – Gitlab is a great way to set this up to permit relatively easy sharing / user management. (Ignore the information about setting up separately on a server, Gitlab is much easier. Also ignore advice about building from source on Ubuntu, installing the binary is far more straight forward: <code>apt-get install sparkleshare</code>. Certainly it is not as feature rich as dropbox (e.g. email links to add users, web links to share individual files), but easy sharing over the server at no extra cost. The Sparkleshare directory is also a fully functional git repo.</p>
<h3 id="encrypted-backup-of-filesystem-with-duplicity">Encrypted backup of filesystem with duplicity</h3>
<p>See <a href="https://www.digitalocean.com/community/tutorials/how-to-use-duplicity-with-gpg-to-securely-automate-backups-on-ubuntu">Duplicity setup</a></p>
<p>Good for backing up to another host for which we have ssh access, or to an Amazon S3 bucket, etc. (Unclear if this works with Glacier due to upload-only et-up).</p>
<h3 id="some-other-rates-for-data-storage">Some other rates for data storage:</h3>
<ul>
<li>Compare to S3 ($0.03 /gig/month)</li>
<li>EBS ($0.12 /gig/month) (really for computing I/O, not storage).</li>
<li>Remarkably, Google Drive and Dropbox now offer 1 TB at $10 / mo. Clearly a lot can be saved by ‘overselling’ (most users will not use their capacity) and by shared files (counting against the space for all users but requiring no more storage capacity). Nonetheless, impressive, on par with Glacier (without the bandwidth charges or delay).</li>
<li>For comparison, (non-redundant, non-enterprise, disk-based) storage is roughly $100/TB, or on order of that annual cost.</li>
</ul>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/09/09/server-backups.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/09/08/server-security-basics.html">Server Security Basics</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 08 Sep 2014</p>

<article>
<div class="excerpt">
<h2 id="security-configuration">Security configuration</h2>
<p>We set up SSH key-only login on non-standard port, with root login forbidden. We then set up <code>ufw</code> firewall, <code>fail2ban</code>, and <code>tripwire</code>.</p>
<ol type="1">
<li>Configure an <a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-ssh-keys--2">SSH key login</a>. Next, <a href="https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-12-04">Create a user, add to sudoers, and then disable root login.</a>. Edits <code>/etc/ssh/sshd_config</code>:</li>
</ol>
<ul>
<li>Disabling root logins. (We’ll need to add ourselves to sudo first: (<code>adduser</code>, edit <code>/etc/sudoers</code>)</li>
<li>Change ssh port from default to something else.</li>
<li>Whitelist user login ids</li>
</ul>
<p>Additionally, let’s be sure to disable password authentication: Add <code>PasswordAuthentication no</code> to <code>/etc/ssh/sshd_config</code>. (editing PermitRootLogin only doesn’t do this).</p>
<p>Locally add an entry in <code>~/.ssh/config</code> to alias the host and port to avoid having to remember these numbers for login. Run <code>ssh-copy-id &lt;droplet-ip&gt;</code> to enable key-based login for the user.</p>
<ol start="2" type="1">
<li><a href="https://www.digitalocean.com/community/tutorials/how-to-setup-a-firewall-with-ufw-on-an-ubuntu-and-debian-cloud-server">Install and configure</a> <code>ufw</code> firewall. As we’re not using the default <code>ssh</code> port, we need to explicitly tell <code>ufw</code> which ssh port to allow.</li>
</ol>
<pre><code>sudo ufw allow &lt;PORT&gt;/tcp</code></pre>
<p>(The <code>/tcp</code> part is optional, saying only allow <code>tcp</code> protocol over that port, not other protocols.)</p>
<p>We must also tell ufw to <a href="http://docs.docker.com/installation/ubuntulinux/#docker-and-ufw">allow Docker</a>: In <code>/etc/default/ufw</code> change <code>DEFAULT_FORWARD_POLICY</code> to ACCEPT, then:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">sudo</span> ufw reload
<span class="kw">sudo</span> ufw allow 2375/tcp</code></pre>
<p>and similarly allow any ports we export for our various services (Gitlab, Drone, etc).</p>
<ol start="3" type="1">
<li><p><a href="https://www.digitalocean.com/community/tutorials/how-to-protect-ssh-with-fail2ban-on-ubuntu-12-04">Install and configure</a> <code>fail2ban</code>. Prevents brute force password attacks. Be sure to assign the config to match chosen ssh port.</p></li>
<li><p><a href="https://www.digitalocean.com/community/tutorials/how-to-use-tripwire-to-detect-server-intrusions-on-an-ubuntu-vps">Install and configure</a> <code>tripwire</code> (intrusion detection).</p></li>
<li><p>Update software:</p></li>
</ol>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">sudo</span> apt-get -q update <span class="kw">&amp;&amp;</span> <span class="kw">sudo</span> apt-get -qy dist-upgrade</code></pre>
<p>and then also update tripwire log:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">sudo</span> tripwire --check --interactive</code></pre>
<p>Note: Clearly all these steps need to be running on the server itself, not merely in a container image deployed on server so that they are securing access to the actual host.</p>
<h2 id="additional-configuration">Additional configuration</h2>
<p>While we’re doing things, add user to the docker group for convenience: <code>sudo addgroup cboettig docker</code></p>
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-add-swap-on-ubuntu-12-04">Enable swap</a> on a small instance. Here we set up 1GB of swap (setting swap at twice the available RAM is the recommended rule-of-thumb, though makes less sense once RAM is large)</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">sudo</span> fallocate -l 1G /swapfile
<span class="kw">sudo</span> chmod 600 /swapfile
<span class="kw">sudo</span> mkswap /swapfile
<span class="kw">sudo</span> swapon /swapfile</code></pre>
<p>To make this persistant on reboot edit <code>/etc/fstab</code>:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">sudo</span> echo <span class="st">&quot;/swapfile       none    swap    sw      0       0&quot;</span> <span class="kw">&gt;&gt;</span> /etc/fstab</code></pre>
<p>For better performance, we might tweak swappiness to 10 (default is 60 out of 100, where 0 is never swap and 1 is swap frequently):</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">echo</span> 10 <span class="kw">|</span> <span class="kw">sudo</span> tee /proc/sys/vm/swappiness
<span class="kw">echo</span> vm.swappiness = 10 <span class="kw">|</span> <span class="kw">sudo</span> tee -a /etc/sysctl.conf</code></pre>
<p>Set ownership</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">sudo</span> chown root:root /swapfile
<span class="kw">sudo</span> chmod 0600 /swapfile</code></pre>
<h2 id="server-modules">Server modules</h2>
<p>Running different services as their own docker containers offers serveral advantages:</p>
<ul>
<li><p>Containers often make it easier to install and deploy existing services, since the necessary configuration is scripted in the Dockerfile and we can often find Dockerfiles already made on <a href="http://hub.docker.com">Docker Hub</a> for common services. This note illustrates several examples.</p></li>
<li><p>Containers may provide an added level of stability, since they run largely in isolation from each other.</p></li>
<li><p>Containers can be <a href="http://stackoverflow.com/questions/16084741/how-do-i-set-resources-allocated-to-a-container-using-docker">resource limited</a>, e.g.</p></li>
</ul>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">docker</span> run -it -m 100m -c 100 ubuntu /bin/bash</code></pre>
<p>would provide the container with 100 MB of RAM and 100 “shares” of CPU (acts kind of like a niceness, where the default share of a container is 1024. On multicore machines you can also pass <code>--cpuset &quot;0&quot;</code> or <code>--cpuset &quot;0,1&quot;</code> etc, which is a list of which cpus (numbered 0 to n-1, as in <code>/proc/cpuinfo</code>) the container is permitted to use.</p>
<p>As noted in the link, restricting disk space is more tricky, though might become easier down the road.</p>
<h3 id="ssh-server">ssh server:</h3>
<p>Permit users to ssh directly into a container rather than access the server itself. Despite its simplicity, I found this a bit tricky to set up correctly, particularly in managing users.</p>
<p>Here’s the basic Dockerfile for an image we’ll call <code>ssh</code>. This creates a user given by the environmental variable. A few tricks:</p>
<ul>
<li>We use <code>adduser</code> instead of <code>useradd</code> so that we get the home directory for the user created and granted the correct permissions automaticalliy. We need the <code>--gecos</code> information so that we’re not prompted to enter the user’s full name etc. We use <code>--disabled-password</code> rather than set a password here.</li>
<li>Login is still possible through ssh key (as well as through nsenter on the host machine). We go ahead and add the ssh key now, though this could be done after the container is running by using nsenter.</li>
<li>In this dockerfile, we’ve added the user to <code>sudo</code>ers group for root access on the container (installing software, etc). This won’t be active until the user has a password.</li>
</ul>
<pre><code>FROM     ubuntu:14.04
ENV USER cboettig
RUN apt-get update &amp;&amp; apt-get install -y openssh-server
RUN mkdir /var/run/sshd
RUN adduser --disabled-password --gecos &quot;&quot; $USER
RUN adduser $USER sudo
ADD authorized_keys /home/$USER/.ssh/authorized_keys
RUN chown $USER /home/$USER/.ssh/authorized_keys
EXPOSE 22
CMD    [&quot;/usr/sbin/sshd&quot;, &quot;-D&quot;]</code></pre>
<p>When building the image, note that a copy of <code>authorized_keys</code> (contains the contents of the <code>id_rda.pub</code> public key) file must be found in the same directory as the Dockerfile so that it can be added to the image.</p>
<p>Start the ssh server on port 2200:</p>
<pre><code>docker run -d -p 2200:22 --name=&quot;ssh&quot; ssh</code></pre>
<p>Add to the firewall permissions</p>
<pre><code>sudo ufw add 2200/tcp</code></pre>
<p>From here I can now ssh in from the computer housing the private key pair to the public key that is added to the image here. However, that user doesn’t have root access since we haven’t provided a password.</p>
<p>Use <code>nsenter</code> to enter the instance:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">docker</span> run -v /usr/local/bin:/target jpetazzo/nsenter
<span class="kw">nsenter</span> -m -u -n -i -p -t <span class="kw">`docker</span> inspect --format <span class="st">&#39;&#39;</span> ssh<span class="kw">`</span> /bin/bash</code></pre>
<p>Create a password for the user to enable root access:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">echo</span> <span class="st">&#39;$USER:&lt;password&gt;&#39;</span> <span class="kw">|</span> <span class="kw">chpasswd</span></code></pre>
<p>We can create other users and add them to sudoers or not as desired, e.g. add interactively using:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">useradd</span> <span class="kw">&lt;</span>username<span class="kw">&gt;</span></code></pre>
<p>users can later change their passwords once they log in.</p>
<h2 id="restoring-containers-when-restarting">Restoring containers when restarting</h2>
<p>A certain times we need to power cycle the server (e.g. after certain software updates), using the <code>sudo reboot now</code> command or the DigitalOcean console. Any running containers will be automatically stopped. Once the machine is back up and we log back in, these containers can be brought back up with <code>docker restart &lt;container_id&gt;</code> (or <code>&lt;container_name&gt;</code>), and then everything is back to normal.</p>
<p>Note that while we can stop and restart a container, it seems we cannot simply save a container (e.g. with <code>docker commit</code> or <code>docker save</code> and re-run it and expect the server functionality to be restored after the container is destroyed (e.g. by <code>docker rm -f</code>). (See previous notes 2014-09-05) for an illustration of this problem. This occurs because the container image does not include the volume where it writes its data, and that volume address is generated uniquely each time a container is run.</p>
<p>Consequently, a different (probably more traditional) approach is needed to backup the configuration of a server such as Gitlab or Drone-CI even when running in a container. Will explore this later.</p>
<p>Meanwhile, remember remove unneeded containers with</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">docker</span> rm <span class="ot">$(</span><span class="kw">docker</span> ps -a <span class="kw">|</span> <span class="kw">grep</span> Exited <span class="kw">|</span> <span class="kw">awk</span> <span class="st">&#39;{print $1}&#39;</span><span class="ot">)</span></code></pre>
<p>and not with <code>-f</code> (destroying running containers!)</p>
<h2 id="key-security">Key security</h2>
<p>We can largely avoid needing a private ssh key for the server, though may use https authentication to let us use git (rather than, say, rsync) to develop and save changes made remotely (say, through RStudio server).</p>
<h3 id="backing-up-keys">Backing up keys</h3>
<p>Probably unnecessary to have a backup of the ssh private RSA key, as we can access the DigitalOcean Server or Github through the web consoles and add a new public key and replace our private key.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/09/08/server-security-basics.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
        <div class="col-md-3">
          <header><h4><a href="/2014/09/05/drone-ci-and-docker.html">Drone Ci And Docker</a></h4></header>
<p><span></span></p>
<p style="font-style:italic"> 05 Sep 2014</p>

<article>
<div class="excerpt">
<h2 id="drone-ci-continous-integration-in-custom-docker-environments">Drone CI: Continous integration in custom docker environments</h2>
<p>Having gotten accustomed to Docker, configuring the appropriate build environment for a Continuous Integration system like Travis CI or Shippable CI starts to feel incredibly tedious and archaic (particularly if you work primarily in a language like R or haskell that usually isn’t supported out of the box).</p>
<ul>
<li>We do not have to hack together a custom image environment</li>
<li>We can build and test our environment locally instead of having to rely on trial-and-error pushes to the CI server</li>
<li>We do not have to download, compile and install the development environment each time, (which frequently takes longer than the CI checks themselves and can break)</li>
</ul>
<p>(Shippable provides a persistent environment too, by preserving the state of your ‘minion’. But unlike Shippable, I believe the Drone approach is unlikely that you can create troublesome side-effects in your environment, such as removing a necessary dependency from the <code>shippable.yml</code> and yet not catching it since the dependency is still available on the minion from before. In the Drone approach, we start on the same docker image each time, but merely avoid the few minutes it might take to download that image).</p>
<p>Unfortunately, custom images are not available on the fully hosted <a href="http://drone.io">drone.io</a> system. (Though perhaps they’d accept pull requests that would add an R environment to <a href="https://github.com/drone/images">their image library</a>). Fortunately, the Drone team kindly provides an <a href="https://github.com/drone.drone">open source version</a> of their platform that can be hosted on a self-hosted / private server (such as the new web darling DigitalOcean or Amazon’s EC2). This has other advantages as well – such as using privately hosted repositories (it also integrates with BitBucket and GitLab) or running very long tests / simulations (since we’re now paying for the server time ourselves, after all).</p>
<h2 id="the-easy-way-use-docker">The easy way: use docker</h2>
<p>We can deploy the Drone CI server somewhat more seamlessly by running it in a container itself. Rather than worry about the above configuration, we can simply launch an existing docker image for Drone, rather cleverly created by Matt Gruter:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">docker</span> run --name=<span class="st">&#39;drone&#39;</span> -d -p 8080:80 --privileged mattgruter/drone</code></pre>
<ul>
<li>Now we can follow the <a href="http://drone.readthedocs.org/en/latest/setup.html">setup instructions</a>. Be sure to use the matching case in the application name (<code>Drone</code> not <code>drone</code>) and the appropriate URLs for the authorization call back.</li>
</ul>
<p>Note that we must use a different port than 80, and that we must give this port explicitly in the Authorization callback URL: <code>http://localhost:8080/auth/login/github</code> in order to authenticate.</p>
<p>Also note that in this approach, the Drone CI’s docker image library will be separate from the docker image library. To manage or update the images available, we have to first <code>nsenter</code> into the Drone CI container.</p>
<p>This runs rather nicely on a tiny DigitalOcean droplet. Bare in mind that the tiny droplet has only 20 GB of disk space though, which can be consumed rather quickly with too many images. If many of the images use the same base templates, the total disk space required will fortunately be much lower than the sum of their virtual sizes.</p>
<h3 id="experimenting-with-saving-images">experimenting with saving images</h3>
<p>Being a docker image, we can snapshot and export it for later use, and meanwhile can even destroy our server instance.</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">docker</span> export drone <span class="kw">&gt;</span> dronedroplet.tar</code></pre>
<p>Not clear that this works. Consider saving an image instead? Save container named drone as image named drone:droplet</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">docker</span> commit drone drone:droplet
<span class="kw">docker</span> save drone:droplet <span class="kw">&gt;</span> dronedroplet.tar</code></pre>
<p>are these identical?</p>
<p>Hmm, doesn’t seem to store configuration, login is no longer valid. Starting a stopped container maintains the configuration of course, but not launching from scratch (e.g. the sqlite database is local to the container, not accessible through an externally linked volume).</p>
<p>Note that this tarball does not include the Drone CI image library itself, which is not part of the container but rather connected as a volume. This makes it quite a bit smaller, and that library can presumably be reconstructed from the docker hub.</p>
<h2 id="configuring-drone-ci-the-hard-way">Configuring Drone CI: the hard way</h2>
<ul>
<li>Install and launch drone: (see <a href="https://github.com/drone/drone">drone/README</a>)</li>
<li>Add <code>DOCKER_OPTS=&quot;-H 127.0.0.1:4243 -d&quot;</code> to <code>/etc/default/docker</code></li>
<li>Kill the docker deamon and restart docker. Or run docker with the explicit binding:</li>
</ul>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">sudo</span> docker -d -H 127.0.0.1:4243 <span class="kw">&amp;</span></code></pre>
<ul>
<li>You may need to <a href="http://docs.docker.com/installation/ubuntulinux/#docker-and-ufw">configure firewall</a>, if ufw is running.</li>
<li>References: <a href="https://github.com/drone/drone/issues/149">drone/issues/149</a>, <a href="https://github.com/drone/drone/issues/24">drone/issues/24</a></li>
<li>Now we can follow the <a href="http://drone.readthedocs.org/en/latest/setup.html">setup instructions</a>. Be sure to use the matching case in the application name (<code>Drone</code> not <code>drone</code>) and the appropriate URLs for the authorization call back.</li>
</ul>
<h2 id="configuring-an-already-running-docker-session">Configuring an already-running docker session</h2>
<p>Launch a named repository in deamon mode:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">docker</span> run -d -p 8787:8787 --name=<span class="st">&#39;drone&#39;</span> mattgruter/drone</code></pre>
<p>Use a docker-based install to add <code>nsenter</code> into your executable path:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">docker</span> run -v /usr/local/bin:/target jpetazzo/nsenter</code></pre>
<p>Run <code>nsenter</code> to log into the docker image:</p>
<pre><code>nsenter -m -u -n -i -p -t `docker inspect --format &#39;{{ .State.Pid }}&#39; drone` /bin/bash</code></pre>
<p>Now we can update or delete images with <code>docker pull</code>, <code>docker rmi</code>, etc.</p>
<p>This is useful with many containers, for instance, with our ssh container or rstudio container we may want to modify usernames and passwords, etc:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">useradd</span> -m <span class="ot">$USER</span> <span class="kw">&amp;&amp;</span> <span class="kw">echo</span> <span class="st">&quot;</span><span class="ot">$USER</span><span class="st">:</span><span class="ot">$PASSWORD</span><span class="st">&quot;</span> <span class="kw">|</span> <span class="kw">chpasswd</span></code></pre>
<h3 id="making-this-easier">Making this easier:</h3>
<p>Add to <code>.bashrc</code>:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">function</span><span class="fu"> dock</span> <span class="kw">{</span> <span class="kw">sudo</span> nsenter -m -u -n -i -p -t <span class="kw">`docker</span> inspect --format  <span class="st">&quot;</span><span class="ot">$1</span><span class="st">&quot;</span><span class="kw">`</span> /bin/bash<span class="kw">;</span> <span class="kw">}</span></code></pre>
<p>This defines the function <code>dock</code> such that <code>dock &lt;name&gt;</code> will enter a running container named <code>&lt;name&gt;</code>. Note that we have to have <code>nsenter</code> bound to the executable path as indicated above. Yay less typing.</p>
 
<!-- not that raw_content depends on custom generator, 
     see _plugins/jekyll-labnotebook-plugins/raw_content --> 
</article> 
<p> <a href="/2014/09/05/drone-ci-and-docker.html"> <em>Read more</em></a> </p>
<br />
<br />


        </div>
      
    </div>

  </div>
</div> <!--end row -->

<div class="row socialicons">
  <div class="col-md-11 col-md-offset-1">
      <p> <a href="/archive.html"><i class="icon-calendar"></i> All entries by date</a></p> 
      <p> <a href="/categories.html"><i class="icon-list"></i> All entries by category</a> </p>
      <p> <a href="/tags.html"><i class="icon-tags"></i> All entries by tag</a> </p>
  </div> <!--end col-md-9 -->
</div> <!--end row -->




      <footer class="footer">

<!--************** FOAF information to social networks ***************************** -->
  <div class="row">
    <div class="col-md-3 col-xs-4 socialicons" style="font-size:20px" typeof="foaf:Person" about="http://www.carlboettiger.info#me">
      <p>
          <script type="text/javascript" src="/assets/js/obfuscate-email-link.js"></script> 

          <a rel="foaf:account" href="https://twitter.com/cboettig" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Twitter'); 
             return false;"><span class="showtooltip" title="follow me on twitter (reading, discussing)"><i class="fa fa-twitter"></i></span></a> 

          <a rel="foaf:account" href="https://github.com/cboettig" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Github'); 
             return false;"><span class="showtooltip" title="follow me on Github (code, research)"><i class="fa fa-github"></i></span></a>
      <!--
          <a rel="foaf:account" href="https://plus.google.com/" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'GPlus'); 
             return false;"><i class="fa fa-google-plus"></i></a>

          <a rel="foaf:account" href="http://www.mendeley.com/profiles/carl-boettiger" 
             onclick="recordOutboundLink(this, 'Outbound Links', 'Mendeley'); 
             return false;"><img src="/assets/img/icon-mendeley.png" /></a> 

           citations on google-scholar

           stackoverflow
      -->
      <a rel="foaf:weblog" type="application/atom+xml" href="/blog.xml"  
         class="showtooltip" title="RSS feeds for my blog-style entries. See the feed on my lab notebook (/atom.xml) to follow all entries instead." 
         onclick="recordOutboundLink(this, 'Outbound Links', 'RSS'); 
         return false;"><i class="fa fa-rss"></i></a>
       </p>
    </div>

    
    <!--**************** End social links **************************** -->


    <div class="col-md-4 col-md-offset-1 col-xs-4">
      <p><a onclick="recordOutboundLink(this, 'Outbound Links', 'ONS_claim'); return false;" href="http://onsclaims.wikispaces.com/"><img src="/assets/img/ons-aci2-icon.svg" alt="ONS" class="showtooltip" title="An Open Notebook Science (ONS) project claim: Entry provides all content (AC) immediately (I) or without significant delay.  See link for details"/></a></p>
    </div>


    <div class="col-md-3 col-md-offset-1 col-xs-4">
      <p>
      <a rel="license" property="http://creativecommons.org/ns#license" href="http://creativecommons.org/publicdomain/zero/1.0/" onclick="recordOutboundLink(this, 'Outbound Links', 'CC0'); return false;"><img src="/assets/img/cc-zero.svg" alt="CC0"/></a> 
      </p>
    </div>
  </div>


  
<!-- COinS metadata (for citation managers like Zotero etc), goes in body text -->
  <span
      class="Z3988" 
      title="ctx_ver=Z39.88-2004
      &amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc
      &amp;rfr_id=info%3Asid%2Focoins.info%3Agenerator
      &amp;rft.title=Lab Notebook
      &amp;rft.creator=Carl Boettiger
      &amp;rft.date=
      &amp;rft.language=EN
      &amp;rft.rights=CC0
      &amp;rft_id=http://www.carlboettiger.info/lab-notebook.html">
  </span>


</footer>




          <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->

    <!-- JQuery, used on a few pages (still?) -->
    <!-- <script type="text/javascript" src="/assets/js/jquery.js"></script> -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <!-- Equations using MathJax -->
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "all"} } });       </script>
    <!-- Twitter Bootstrap Javascript -->
    <!--  <script src="/assets/js/bootstrap.min.js"></script> -->
    <script src="//netdna.bootstrapcdn.com/bootstrap/3.1.1/js/bootstrap.min.js"></script>


    

        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-18401403-1']);
          _gaq.push(['_trackPageview']);
          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
  </script>



<script type="text/javascript">
function recordOutboundLink(link, category, action) {
  try {
    var pageTracker=_gat._getTracker("UA-18401403-1");
    pageTracker._trackEvent(category, action);
    setTimeout('document.location = "' + link.href + '"', 100)
  }catch(err){}
}
</script>




    </div>
  </body>
</html>
   
